V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] Output code: 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # AOT ID: ['63_forward']
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import torch
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import random
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import os
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import tempfile
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from math import inf, nan
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from cmath import nanj
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch import device, empty_strided
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     grid,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     split_scan_grid,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     grid_combo_kernels,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     start_graph,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     end_graph,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     cooperative_reduction_grid,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] aten = torch.ops.aten
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] _quantized = torch.ops._quantized
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] async_compile = AsyncCompile()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3q/c3qs6yypbnbpqcop7l6kiryerkbhymomkvmghz574dvp226lxi3v.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [hx1], Original ATen: [aten._to_copy]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   hx1 => full_default
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 40], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused__to_copy_0 = async_compile.triton('triton_poi_fused__to_copy_0', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused__to_copy_0(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = 0.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5m/c5mmsedfqfofuqzlncvinlplaieokpymhrddn3l45rm5acwv2tr6.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_1, x_2], Original ATen: [aten.add, aten.view]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_1 => add_15
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_2 => view_4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_15 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_3, %primals_4), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %view_4 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%add_15, [-1, 20]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_view_1 = async_compile.triton('triton_poi_fused_add_view_1', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 4096}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_view_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_view_1(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 20)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j5/cj5gxm7uj7p2rcjmziqcs3tn4xx7tyiwpekvbkwox36sekcxkvfe.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.repeat, aten.clone, aten._native_batch_norm_legit_functional]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_5 => add_58, add_61, clone, mul_49, mul_55, repeat, rsqrt, sub_19, var_mean
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %repeat : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%primals_9, [%primals_1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_8, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_58 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_58,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_8, %getitem_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_19, %rsqrt), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_55 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_49, %unsqueeze), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_61 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_55, %unsqueeze_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2 = async_compile.triton('triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512, 'r0_': 32},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_3 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = (xindex % 30)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // 30
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + ((x0 % 30)), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x1 + 30*r0_3 + 600*x2), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.load(in_ptr3 + ((x0 % 30)), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.where(r0_mask & xmask, tmp4, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.where(r0_mask & xmask, tmp7, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.sum(tmp9, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.full([XBLOCK, 1], 20, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp10 / tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp4 - tmp13
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp14 * tmp14
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.where(r0_mask & xmask, tmp16, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp3 - tmp13
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = 20.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp19 / tmp21
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = 1e-05
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp22 + tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = libdevice.rsqrt(tmp24)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp20 * tmp25
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp26 * tmp0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp27 + tmp28
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (r0_3 + 20*x0), tmp3, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (r0_3 + 20*x0), tmp29, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp25, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp19, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/db/cdbnemgmjzsta6msnlztqvzj5hqetmruvqwi2o6p2vvekolavj7u.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mean]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_5 => mean_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_12, [0]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_8, %mean_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_mean_3 = async_compile.triton('triton_red_fused_mean_3', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 16},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_mean_3', 'mutated_arg_names': ['in_ptr1', 'out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_mean_3(in_ptr0, in_ptr1, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp13 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 30*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = 20.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 / tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = (((600*ks0) / (30*ks0)) / ((tl.full([], -1.00000000000000, tl.float64)) + ((600*ks0) / (30*ks0))))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = tmp3.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tmp2 * tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp6 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = tmp5 * tmp6
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp9 = 0.9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp11 = tmp7 + tmp10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp14 = _tmp13 + tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp13 = tl.where(r0_mask & xmask, tmp14, _tmp13)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.sum(_tmp13, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = ks0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tmp15.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp13 / tmp16
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp17, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nr/cnrrgupfqqgsl3srv3cwvnjusjjmgplzaphbgjbagjorggvnlxaa.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mean]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_5 => mean
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_10, [0]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_7, %mean), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_mean_4 = async_compile.triton('triton_red_fused_mean_4', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 16},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_mean_4', 'mutated_arg_names': ['in_ptr1', 'out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_mean_4(in_ptr0, in_ptr1, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp8 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 30*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 * tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = 0.9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tmp3 * tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp6 = tmp2 + tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp9 = _tmp8 + tmp7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp8 = tl.where(r0_mask & xmask, tmp9, _tmp8)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.sum(_tmp8, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = ks0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tmp10.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp8 / tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp12, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wc/cwclzirtjfxrxke5qh5l4ydcqkbupzfam2mjczn6tsgatohcsxh6.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret => mm_default_98
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_98 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_5 = async_compile.triton('triton_poi_fused_addmm_5', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_5(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5y/c5yo7rgfvniltiyfuod45omthtsqmsgwl2xqc365flfkgqz4zete.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret => add_117, add_tensor_98, add_tensor_99, tanh
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_99 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_99, %primals_14), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_98 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_98, %primals_13), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_117 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_99, %add_tensor_98), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%add_117,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_addmm_tanh_6 = async_compile.triton('triton_poi_fused_add_addmm_tanh_6', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_tanh_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_addmm_tanh_6(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 40)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 + tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp2 + tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/y3/cy36ccjcqukk4om4cfmksf2w226oopqae674uyr4ratncdxthdww.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_2 => mm_default_94
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_94 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_1, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_7 = async_compile.triton('triton_poi_fused_addmm_7', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_7(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (1 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5h/c5ha2yjullbvt2ina54twdqkpjgvltxmk27igowwu4rrfwf3ei2p.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_4 => mm_default_90
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_90 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_2, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_8 = async_compile.triton('triton_poi_fused_addmm_8', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_8(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/w3/cw3wbdsnb5ipbdcbrtqwq6pcrariessubnlf2r2ws4msgylr5e25.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_6 => mm_default_86
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_86 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_3, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_9 = async_compile.triton('triton_poi_fused_addmm_9', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_9(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (3 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ww/cwwsobqrgdygogcrcso2zsfil6i2g3wukaznclxnolok3tmna4kq.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_8 => mm_default_82
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_82 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_4, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_10 = async_compile.triton('triton_poi_fused_addmm_10', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_10(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/l4/cl4tjmchiqyv4ezjc4w6di2jb2ez4b2zzbbozpp3p6npqa3in2ki.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_10 => mm_default_78
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_78 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_5, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_11 = async_compile.triton('triton_poi_fused_addmm_11', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_11(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (5 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c2/cc2nguitv3ngubu2oojx3cdvitgqasgnpwv5rrepuvjhm43rodr3.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_12 => mm_default_74
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_74 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_6, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_12 = async_compile.triton('triton_poi_fused_addmm_12', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_12(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (6 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7x/c7xf7nq7negp4javuahijy4a4ysl7zrearvchtoof5hpz2yhmv23.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_14 => mm_default_70
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_70 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_7, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_13 = async_compile.triton('triton_poi_fused_addmm_13', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_13(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (7 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yi/cyirb3al7zdlgf4ild7mp6zi2qgmrslqorrncp3x4arrgou4i7d7.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_16 => mm_default_66
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_66 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_8, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_14 = async_compile.triton('triton_poi_fused_addmm_14', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_14(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/la/claesvzgqomzyyq7ievhd2kabkuv6idtmmgjznbjyoezueuifddd.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_18 => mm_default_62
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_62 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_9, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_15 = async_compile.triton('triton_poi_fused_addmm_15', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_15(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (9 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/n5/cn5jtushi3ubol26fwyzzrwa2xfzfkv2pklk5q2vlup22r27fnnz.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_20 => mm_default_58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_58 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_10, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_16 = async_compile.triton('triton_poi_fused_addmm_16', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_16(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (10 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/w4/cw424rovlgnx4kfo7o6zhmxkcboik7i6tnd2h26rusfhtlaybt4l.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_22 => mm_default_54
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_54 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_11, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_17 = async_compile.triton('triton_poi_fused_addmm_17', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_17(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (11 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qi/cqitpe7ovfjsxuvgzc4he3k3h4o2vdhpm2ruds2dn3yydl4au5nu.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_24 => mm_default_50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_50 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_12, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_18 = async_compile.triton('triton_poi_fused_addmm_18', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_18(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (12 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mc/cmckztpwapc6zdpl5rjnmsy7sbkjocucskycfcbjwsedizw4nmxh.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_26 => mm_default_46
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_46 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_13, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_19 = async_compile.triton('triton_poi_fused_addmm_19', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_19(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (13 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fu/cfuq34lrjry3clzddtsgjjb4cqr56ceq2r6kmxbnvkhzvhsltyps.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_28 => mm_default_42
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_42 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_14, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_20 = async_compile.triton('triton_poi_fused_addmm_20', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_20(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (14 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cg/ccgmuiopelez22sj63dsa7bbxmu7bfmqsrs4dsxnd5kvbigvb6qn.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_30 => mm_default_38
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_38 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_15, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_21 = async_compile.triton('triton_poi_fused_addmm_21', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_21(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (15 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4t/c4tumn2x6wshlb7d4jn34pheitgojcyyndm6c2upsol2vdjy2pjn.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_32 => mm_default_34
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_34 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_16, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_22 = async_compile.triton('triton_poi_fused_addmm_22', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_22(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (16 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xl/cxlz23ylxwkz7frnwgjxzvpyfq36mvo4k5ko5timxogg35bhrfzi.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_34 => mm_default_30
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_30 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_17, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_23 = async_compile.triton('triton_poi_fused_addmm_23', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_23(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (17 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g7/cg7btqk7mjg3dwoqaeggxkff4ccv42jaub6ijg2cuqwhprhg4dw4.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_36 => mm_default_26
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_26 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_18, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_24 = async_compile.triton('triton_poi_fused_addmm_24', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_24(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (18 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wf/cwfzq3vhun5ru4dr4rcbyulpei6aa2mpdgsrd26h77xhd7uvlgxt.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_38 => mm_default_22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_default_22 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_19, %permute_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_addmm_25 = async_compile.triton('triton_poi_fused_addmm_25', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_addmm_25(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (19 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jh/cjh3vrlw4r6ivczb62qehxt3qewllhexp35hkfclxsllenvei4yo.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_1, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_1 => add_139, add_tensor_96, add_tensor_97, tanh_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_7 => cat
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_97 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_97, %primals_18), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_96 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_96, %primals_17), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_139 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_97, %add_tensor_96), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh_1 : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%add_139,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%tanh_1, %tanh_3, %tanh_5, %tanh_7, %tanh_9, %tanh_11, %tanh_13, %tanh_15, %tanh_17, %tanh_19, %tanh_21, %tanh_23, %tanh_25, %tanh_27, %tanh_29, %tanh_31, %tanh_33, %tanh_35, %tanh_37, %tanh_39], 1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_addmm_stack_tanh_26 = async_compile.triton('triton_poi_fused_add_addmm_stack_tanh_26', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_stack_tanh_26', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_addmm_stack_tanh_26(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 + tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp2 + tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0 + 1000*x1), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wq/cwqshwm5h6hsykjbzyvparfsrei25q6orskvzctatnak3yhrpdho.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_3, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_3 => add_193, add_tensor_92, add_tensor_93, tanh_3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_7 => cat
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_93 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_93, %primals_18), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_92 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_92, %primals_17), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_193 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_93, %add_tensor_92), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh_3 : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%add_193,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%tanh_1, %tanh_3, %tanh_5, %tanh_7, %tanh_9, %tanh_11, %tanh_13, %tanh_15, %tanh_17, %tanh_19, %tanh_21, %tanh_23, %tanh_25, %tanh_27, %tanh_29, %tanh_31, %tanh_33, %tanh_35, %tanh_37, %tanh_39], 1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_addmm_stack_tanh_27 = async_compile.triton('triton_poi_fused_add_addmm_stack_tanh_27', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_stack_tanh_27', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_addmm_stack_tanh_27(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 + tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp2 + tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0 + 1000*x1), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xs/cxsr3hu4nwopey7qbssu35buji4uqsrnimkobrsclkv2a73f7api.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.tanh_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   ret_39 => add_1165, add_tensor_20, add_tensor_21, tanh_39
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_21 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_21, %primals_18), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_tensor_20 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_20, %primals_17), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1165 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_21, %add_tensor_20), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh_39 : [num_users=2] = call_function[target=torch.ops.aten.tanh.default](args = (%add_1165,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2381 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_39, %tanh_39), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_813 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2381), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_addmm_tanh_tanh_backward_28 = async_compile.triton('triton_poi_fused_add_addmm_tanh_tanh_backward_28', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_tanh_tanh_backward_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_addmm_tanh_tanh_backward_28(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 + tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp2 + tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp7 * tmp7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = 1.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 - tmp8
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0 + 1000*x1), tmp7, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp10, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3r/c3rl2242l33rwllsbzswb6bbfoy5jrvgk5dahnaatfp2du2v42kv.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => clone_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_82,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_29 = async_compile.triton('triton_poi_fused_clone_29', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_29', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_29(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 50*x2 + 1000*x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7e/c7em6pip52qovk2rxizvhydaxl6pn6rwv2npj25tqjgr6cjw5fzw.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => mul_862
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_862 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%permute_88, 0.5623413251903491), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_mul_30 = async_compile.triton('triton_poi_fused_mul_30', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'y': 512, 'x': 32}, tile_hint=TileHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_mul_30(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     ymask = yindex < ynumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y0 = (yindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y1 = ((yindex // 10) % 5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y2 = yindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y4 = (yindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y5 = yindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (50 + y0 + 10*y1 + 150*((((y0 + 10*y1 + 50*y2) // 50) % ks1)) + 150*ks1*((((y0 + 10*y1 + 50*y2 + 50*ks1*x3) // ks0) % 20))), xmask & ymask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (50 + y4), ymask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.5623413251903491
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3 + 20*y5), tmp4, xmask & ymask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dn/cdnxezznaruajo6kqts3waoiwkuta2ypgcblbhr5khzpyqfblgds.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %permute_282 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_25, [0, 2, 1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_transpose_31 = async_compile.triton('triton_poi_fused_transpose_31', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'y': 1024, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_transpose_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_transpose_31(in_ptr0, out_ptr0, ks0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     ymask = yindex < ynumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y0 = (yindex % 20)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y1 = yindex // 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 20*x2 + 200*y1), xmask & ymask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2 + 10*y1 + 50*ks0*y0), tmp0, xmask & ymask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ay/cay5yd37zhlcsvyfge3oylirc4rmy7ekyy3l6tqoycj632yr2cse.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => mul_855
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_855 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%view_21, 0.5623413251903491), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %permute_281 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_24, [0, 2, 1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_mul_transpose_32 = async_compile.triton('triton_poi_fused_mul_transpose_32', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_transpose_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_mul_transpose_32(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % 20)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = ((xindex // 200) % 5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // 1000
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x5 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x4 = xindex // 200
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 10*x2 + 150*((((x0 + 10*x2 + 50*x3) // 50) % ks1)) + 150*ks1*((((x0 + 10*x2 + 50*x3 + 50*ks1*x1) // ks0) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 10*x2), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.5623413251903491
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp4, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0 + 10*x4 + 50*ks1*x1), tmp4, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/le/cleqhhppkapqcyaavtcnjolfyzjzijtubkbxtpqsnld67xr2zs2c.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => clone_2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_2 : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_3,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_33 = async_compile.triton('triton_poi_fused_clone_33', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_33(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 50*x2 + 150*x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 50*x2), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/en/cenqf7t3wji3ld2j3dqhuujst4gam4g5f3z7veccaobz245d3tbt.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => bmm_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %bmm_1 : [num_users=1] = call_function[target=torch.ops.aten.bmm.default](args = (%view_27, %view_28), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_bmm_34 = async_compile.triton('triton_poi_fused_bmm_34', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bmm_34', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_bmm_34(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 10*((x1 % 5)) + 50*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5)) // 50) % ks2)) + 2000*ks2 + 50*ks2*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5) + 50*ks2*x2) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7p/c7pm6na2v5gnnoiwlugpxq2xfh6as7fnifkfwefh3nkelxifegke.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => amax, any_1, div, eq_608, exp, full_default_2, gt, inductor_lookup_seed_default, inductor_random_default_19, logical_not, logical_not_1, mul_908, mul_909, sub_405, sum_1, where
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %amax : [num_users=2] = call_function[target=torch.ops.aten.amax.default](args = (%view_26, [-1], True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_405 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_26, %amax), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %exp : [num_users=2] = call_function[target=torch.ops.aten.exp.default](args = (%sub_405,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_1 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp, [-1], True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%exp, %sum_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %eq_608 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%view_26, -inf), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %logical_not : [num_users=1] = call_function[target=torch.ops.aten.logical_not.default](args = (%eq_608,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %any_1 : [num_users=1] = call_function[target=torch.ops.aten.any.dim](args = (%logical_not, -1, True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %logical_not_1 : [num_users=2] = call_function[target=torch.ops.aten.logical_not.default](args = (%any_1,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_2 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 5, 20, 20], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%logical_not_1, %full_default_2, %div), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_19 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_1, 5, 20, 20], %inductor_lookup_seed_default, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_19, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_908 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt, %where), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_909 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_908, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused__safe_softmax_native_dropout_35 = async_compile.triton('triton_per_fused__safe_softmax_native_dropout_35', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 1024, 'r0_': 32},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*i1', 'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr3': '*i1', 'out_ptr4': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__safe_softmax_native_dropout_35', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused__safe_softmax_native_dropout_35(in_out_ptr0, in_ptr0, in_ptr1, out_ptr0, out_ptr1, out_ptr3, out_ptr4, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, float("-inf"))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = triton_helpers.max2(tmp3, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp0 - tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl_math.exp(tmp5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.where(r0_mask & xmask, tmp7, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.sum(tmp9, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = float("-inf")
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp0 == tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp12 == 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp13.to(tl.int64)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = (tmp14 != 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.where(r0_mask & xmask, tmp16, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = triton_helpers.any(tmp18, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp19 == 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.load(in_ptr1 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = r0_1 + 20*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.rand(tmp21, (tmp22).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp23 > tmp24
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp25.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp6 / tmp10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = 0.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.where(tmp20, tmp28, tmp27)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp26 * tmp29
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp30 * tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.debug_barrier()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp20, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 20*x0), tmp25, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 20*x0), tmp32, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp10, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4b/c4bgkr32izvhcznwvhvzqkzzpcjk6gawvmgb7ymeps443u6par2a.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => clone_3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_89,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_36 = async_compile.triton('triton_poi_fused_clone_36', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_36(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 10*x2 + 200*x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6k/c6kgaul5vbrk5w7nsmtpuzjdjyymqkgf5okj7fmxadbmtbiwkc2m.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_2], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => full_default_2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_2 => amax_2, any_3, div_2, eq_827, exp_2, gt_8, inductor_lookup_seed_default_8, inductor_random_default_11, logical_not_4, logical_not_5, mul_1435, mul_1436, sub_549, sum_3, where_2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_2 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 5, 20, 20], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %amax_2 : [num_users=1] = call_function[target=torch.ops.aten.amax.default](args = (%view_68, [-1], True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_549 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_68, %amax_2), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %exp_2 : [num_users=2] = call_function[target=torch.ops.aten.exp.default](args = (%sub_549,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp_2, [-1], True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%exp_2, %sum_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %eq_827 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%view_68, -inf), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %logical_not_4 : [num_users=1] = call_function[target=torch.ops.aten.logical_not.default](args = (%eq_827,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %any_3 : [num_users=1] = call_function[target=torch.ops.aten.any.dim](args = (%logical_not_4, -1, True), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %logical_not_5 : [num_users=1] = call_function[target=torch.ops.aten.logical_not.default](args = (%any_3,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where_2 : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%logical_not_5, %full_default_2, %div_2), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_8 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 8), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_11 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_1, 5, 20, 20], %inductor_lookup_seed_default_8, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_8 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_11, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1435 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_8, %where_2), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1436 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1435, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused__safe_softmax_native_dropout_37 = async_compile.triton('triton_per_fused__safe_softmax_native_dropout_37', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 1024, 'r0_': 32},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'out_ptr4': '*i1', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__safe_softmax_native_dropout_37', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused__safe_softmax_native_dropout_37(in_out_ptr0, in_ptr0, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, float("-inf"))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = triton_helpers.max2(tmp3, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp0 - tmp4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl_math.exp(tmp5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.where(r0_mask & xmask, tmp7, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.sum(tmp9, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = float("-inf")
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp0 == tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp12 == 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp13.to(tl.int64)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = (tmp14 != 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.where(r0_mask & xmask, tmp16, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = triton_helpers.any(tmp18, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = r0_1 + 20*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.rand(tmp20, (tmp21).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp22 > tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp19 == 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp6 / tmp10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = 0.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.where(tmp25, tmp27, tmp26)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp24.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp29 * tmp28
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp30 * tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 20*x0), tmp24, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 20*x0), tmp28, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 20*x0), tmp32, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tr/ctrbjgjealz26kkd7gcx7yjuswgk6aumvyerjebztpjcas32ntjm.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_9, dropout_6, add_4, x_15], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   add => add_1392
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   add_4 => add_1980
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout => gt_1, inductor_lookup_seed_default_1, inductor_random_default_18, mul_958, mul_959
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_6 => gt_9, inductor_lookup_seed_default_9, inductor_random_default_10, mul_1485, mul_1486
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_15 => add_1984, add_1985, clone_10, mul_1494, mul_1495, rsqrt_6, sub_568, var_mean_6
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_9 => add_1396, add_1397, clone_4, mul_967, mul_968, rsqrt_1, sub_424, var_mean_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_18 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 50], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_1 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_18, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_958 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_1, %view_31), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_959 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_958, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1392 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute_82, %mul_959), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_4 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_1392,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_4, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1396 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_2, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_1 : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1396,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_424 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_4, %getitem_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_967 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_424, %rsqrt_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_968 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_967, %primals_23), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1397 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_968, %primals_24), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_9 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 9), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_10 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 50], %inductor_lookup_seed_default_9, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_9 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_10, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1485 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_9, %view_73), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1486 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1485, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1980 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute_82, %mul_1486), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_10 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_1980,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_6 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_10, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1984 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_6 : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1984,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_568 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_10, %getitem_13), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1494 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_568, %rsqrt_6), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1495 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1494, %primals_49), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1985 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1495, %primals_50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_795 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1980, %getitem_13), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2310 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_795, %rsqrt_6), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_12 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_6, 50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_810 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1392, %getitem_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2367 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_810, %rsqrt_1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_17 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, 50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'out_ptr1': '*i1', 'out_ptr3': '*i1', 'out_ptr6': '*fp32', 'out_ptr9': '*fp32', 'out_ptr10': '*fp32', 'out_ptr11': '*fp32', 'out_ptr12': '*fp32', 'out_ptr13': '*fp32', 'load_seed_offset': 'i32', 'load_seed_offset1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset1': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), 'tt.equal_to': (19,)}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 9, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr1, out_ptr3, out_ptr6, out_ptr9, out_ptr10, out_ptr11, out_ptr12, out_ptr13, load_seed_offset, load_seed_offset1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = (xindex % ks2)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // ks2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (r0_1 + 50*x3 + 1000*x2), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tl.load(in_ptr4 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tl.load(in_ptr5 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp45 = tl.load(in_ptr6 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.load(in_ptr7 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp70 = tl.load(in_ptr8 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp72 = tl.load(in_ptr9 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = r0_1 + 50*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr0 + load_seed_offset1)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.rand(tmp5, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp6 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp9 * tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tmp8 + tmp15
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(r0_mask & xmask, tmp17, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.broadcast_to(tmp17, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.where(r0_mask & xmask, tmp20, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.sum(tmp22, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tl.full([XBLOCK, 1], 50, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp24.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp23 / tmp25
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp17 - tmp26
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tmp27 * tmp27
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tl.where(r0_mask & xmask, tmp29, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tl.sum(tmp31, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = tmp16 - tmp26
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = 50.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = tmp32 / tmp34
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = 1e-05
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tmp35 + tmp36
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = libdevice.rsqrt(tmp37)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tmp33 * tmp38
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = tmp39 * tmp40
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp43 = tmp41 + tmp42
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp44 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp47 = tmp45 + tmp46
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp48 = tmp44 * tmp47
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp49 = tmp48 * tmp14
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tmp8 + tmp49
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp53 = tl.where(r0_mask & xmask, tmp51, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.broadcast_to(tmp51, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp56 = tl.where(r0_mask & xmask, tmp54, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp57 = tl.sum(tmp56, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = tmp57 / tmp25
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp59 = tmp51 - tmp58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp60 = tmp59 * tmp59
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp61 = tl.broadcast_to(tmp60, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp63 = tl.where(r0_mask & xmask, tmp61, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp64 = tl.sum(tmp63, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp65 = tmp50 - tmp58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp66 = tmp64 / tmp34
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp67 = tmp66 + tmp36
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp68 = libdevice.rsqrt(tmp67)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp69 = tmp65 * tmp68
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp71 = tmp69 * tmp70
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp73 = tmp71 + tmp72
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp74 = 0.02
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp75 = tmp68 * tmp74
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp76 = tmp38 * tmp74
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 50*x0), tmp4, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 50*x0), tmp7, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 50*x0), tmp43, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr9 + (r0_1 + 50*x0), tmp73, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr10 + (r0_1 + 50*x3 + 1000*x2), tmp69, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr11 + (r0_1 + 50*x3 + 1000*x2), tmp39, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr12 + (x0), tmp75, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr13 + (x0), tmp76, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ux/cuxugcnethu6d5au6xsyojnuies2okvjfo5uwmwetmcrhzdeowad.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_3 => mul_1582
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1582 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%view_82, 0.5623413251903491), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %permute_207 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_85, [0, 2, 1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_mul_transpose_39 = async_compile.triton('triton_poi_fused_mul_transpose_39', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_transpose_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_mul_transpose_39(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % 20)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = ((xindex // 200) % 5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // 1000
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x5 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x4 = xindex // 200
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 10*x2 + 50*((((x0 + 10*x2 + 50*x3) // 50) % ks1)) + 50*ks1*((((x0 + 10*x2 + 50*x3 + 50*ks1*x1) // ks0) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 10*x2), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.5623413251903491
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp4, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0 + 10*x4 + 50*ks1*x1), tmp4, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ej/cejiv7idcc4mku2t5v3736mwigiyh4uduy4dk63mhhycpbnos47y.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   relu => relu
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_33,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %le_4 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_relu_threshold_backward_40 = async_compile.triton('triton_poi_fused_relu_threshold_backward_40', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 524288}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_threshold_backward_40', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_relu_threshold_backward_40(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 2048)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = 0.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/k6/ck6plyaszbtnbcohrajfgycsug234u3mnltvgwbdene24ajq5lkw.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_1 => gt_2, inductor_lookup_seed_default_2, inductor_random_default_17, mul_994, mul_995
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   relu => relu
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_33,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_17 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 2048], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_2 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_17, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_994 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_2, %relu), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_995 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_994, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_native_dropout_relu_41 = async_compile.triton('triton_poi_fused_native_dropout_relu_41', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 524288}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_41', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_native_dropout_relu_41(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = (xindex % 2048)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tmp5 * tmp10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gl/cglfg3z3hyjes3yznvm7crvku3tua5mmvzpj4a3kct5abuarlqug.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_2, add_1, x_11], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   add_1 => add_1454
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_2 => gt_3, inductor_lookup_seed_default_3, inductor_random_default_16, mul_1013, mul_1014
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_11 => add_1459, add_1460, mul_1023, mul_1024, rsqrt_2, sub_441, var_mean_2
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_16 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 50], %inductor_lookup_seed_default_3, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_3 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_16, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1013 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_3, %view_35), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1014 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1013, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1454 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1397, %mul_1014), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_2 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1454, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1459 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_2 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1459,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_441 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1454, %getitem_5), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1023 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_441, %rsqrt_2), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1024 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1023, %primals_29), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1460 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1024, %primals_30), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_16 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_2, 50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = r0_1 + 50*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.where(r0_mask & xmask, tmp14, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(r0_mask & xmask, tmp17, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 50, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.where(r0_mask & xmask, tmp26, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = 50.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = 1e-05
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = 0.02
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tmp35 * tmp41
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 50*x0), tmp4, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 50*x0), tmp36, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 50*x0), tmp40, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/se/csec2va4ttudeda65dxtn4237grloccpzki4xmanvxzb6vtq43xd.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_5, add_3, x_14, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   add_3 => add_1737
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_5 => gt_7, inductor_lookup_seed_default_7, inductor_random_default_12, mul_1262, mul_1263
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   output => add_1756, add_1757, mul_1281, mul_1282, rsqrt_5, sub_514, var_mean_5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_14 => add_1742, add_1743, mul_1272, mul_1273, rsqrt_4, sub_510, var_mean_4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_7 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 7), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_12 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 50], %inductor_lookup_seed_default_7, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_7 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_12, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1262 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_7, %view_56), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1263 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1262, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1737 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1680, %mul_1263), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_4 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1737, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1742 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_8, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_4 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1742,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_510 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1737, %getitem_9), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1272 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_510, %rsqrt_4), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1273 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1272, %primals_41), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1743 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1273, %primals_42), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_5 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1743, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1756 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_10, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_5 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1756,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_514 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1743, %getitem_11), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1281 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_514, %rsqrt_5), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1282 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1281, %primals_43), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1757 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1282, %primals_44), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_14 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_4, 50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp62 = tl.load(in_ptr5 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp64 = tl.load(in_ptr6 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = r0_1 + 50*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.where(r0_mask & xmask, tmp14, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(r0_mask & xmask, tmp17, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 50, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.where(r0_mask & xmask, tmp26, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = 50.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = 1e-05
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp43 = tl.where(r0_mask & xmask, tmp41, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp44 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.where(r0_mask & xmask, tmp44, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp47 = tl.sum(tmp46, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp48 = tmp47 / tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp49 = tmp41 - tmp48
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tmp49 * tmp49
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp53 = tl.where(r0_mask & xmask, tmp51, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp55 = tmp54 / tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp56 = tmp55 + tmp33
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp57 = libdevice.rsqrt(tmp56)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = 0.02
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp59 = tmp35 * tmp58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp60 = tmp40 - tmp48
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp61 = tmp60 * tmp57
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp63 = tmp61 * tmp62
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp65 = tmp63 + tmp64
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 50*x0), tmp4, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 50*x0), tmp36, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.debug_barrier()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp57, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp59, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 50*x0), tmp65, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gv/cgvbg2ae5k4577ywmqtyebyr3osbjhm5jywc6olcvwxqa6nzyusg.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_3 => mul_1589
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1589 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%permute_117, 0.5623413251903491), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_mul_44 = async_compile.triton('triton_poi_fused_mul_44', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'y': 512, 'x': 32}, tile_hint=TileHint.DEFAULT,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_44', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_mul_44(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 20
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     ymask = yindex < ynumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y0 = (yindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y1 = ((yindex // 10) % 5)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y2 = yindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y4 = (yindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y5 = yindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 10*y1 + 100*((((y0 + 10*y1 + 50*y2) // 50) % ks1)) + 100*ks1*((((y0 + 10*y1 + 50*y2 + 50*ks1*x3) // ks0) % 20))), xmask & ymask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (50 + y4), ymask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.5623413251903491
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3 + 20*y5), tmp4, xmask & ymask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jd/cjdps2jtb4beq3fhizuivw2pfbhsg32oe3hmplwxi6qbxxxwbkji.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_3 => clone_11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_11 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_6,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_45 = async_compile.triton('triton_poi_fused_clone_45', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_45', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_45(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 50*x2 + 100*x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (50 + x0 + 50*x2), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2i/c2iz7tthnaefonews7dkj57xlr5bhb37b3bonrmsdnjstz2bgpto.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_3 => bmm_7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %bmm_7 : [num_users=1] = call_function[target=torch.ops.aten.bmm.default](args = (%view_88, %view_89), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_bmm_46 = async_compile.triton('triton_poi_fused_bmm_46', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bmm_46', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_bmm_46(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 10*((x1 % 5)) + 50*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5)) // 50) % ks3)) + 50*ks3*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5) + 50*ks3*x2) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nl/cnlrlt5klviijnndmt6qydc6o3u5g4jgppykbzu4raor346xca7t.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.bmm, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_5 => bmm_11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %bmm_11 : [num_users=1] = call_function[target=torch.ops.aten.bmm.default](args = (%view_128, %view_129), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %permute_158 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_129, [0, 2, 1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_bmm_transpose_47 = async_compile.triton('triton_poi_fused_bmm_transpose_47', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bmm_transpose_47', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_bmm_transpose_47(in_ptr0, out_ptr0, out_ptr1, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 10*((x1 % 5)) + 50*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5)) // 50) % ks3)) + 50*ks3*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5) + 50*ks3*x2) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2a/c2adxgfvce35vcw6tvfjxppn4xzvkjabd6jgtie5jozbt5bi2nfz.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.bmm, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward_4 => bmm_9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %bmm_9 : [num_users=1] = call_function[target=torch.ops.aten.bmm.default](args = (%view_109, %view_110), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %permute_180 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_110, [0, 2, 1]), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_bmm_transpose_48 = async_compile.triton('triton_poi_fused_bmm_transpose_48', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bmm_transpose_48', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_bmm_transpose_48(in_ptr0, out_ptr0, out_ptr1, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 10)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 10) % ks0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 10*((x1 % 5)) + 50*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5)) // 50) % ks2)) + 2000*ks2 + 50*ks2*((((x0 + 10*((x1 % 5)) + 50*(x1 // 5) + 50*ks2*x2) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp0, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g7/cg7c52mqtgxqiusr22ia7ntpm2dk2gmqdaou6d2bsi2kgkaz6jrj.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [relu_3, dropout_12], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_12 => gt_18, inductor_lookup_seed_default_18, inductor_random_default_1, mul_2168, mul_2169
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   relu_3 => relu_3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_134,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_18 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 18), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 2048], %inductor_lookup_seed_default_18, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_18 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_1, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2168 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_18, %relu_3), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2169 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2168, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %le_1 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_3, 0), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_49 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_49', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 524288}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_49', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_49(in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = (xindex % 2048)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tmp5 * tmp10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = 0.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp10 <= tmp14
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp15, None)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rj/crjqkmyowhxz3mlt2ajgwb4rrltb6aw3zms6eja4k3jdmocfer3e.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_13, add_9, x_22, output_1], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   add_9 => add_2777
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   dropout_13 => gt_19, inductor_lookup_seed_default_19, inductor_random_default, mul_2187, mul_2188
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   output_1 => add_2796, rsqrt_12, var_mean_12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_22 => add_2782, add_2783, mul_2197, mul_2198, rsqrt_11, sub_762, var_mean_11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_lookup_seed_default_19 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 19), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %inductor_random_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 50], %inductor_lookup_seed_default_19, rand), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_19 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default, 0.1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2187 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_19, %view_136), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2188 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2187, 1.1111111111111112), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2777 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2720, %mul_2188), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_11 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_2777, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2782 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_30, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_11 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_2782,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_762 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_2777, %getitem_31), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2197 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_762, %rsqrt_11), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2198 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2197, %primals_79), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2783 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2198, %primals_80), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %var_mean_12 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_2783, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2796 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_32, 1e-05), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %rsqrt_12 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_2796,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_7 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_11, 50), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = r0_1 + 50*x0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 0.1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.where(r0_mask & xmask, tmp14, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(r0_mask & xmask, tmp17, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 50, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.where(r0_mask & xmask, tmp26, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = 50.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = 1e-05
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp43 = tl.where(r0_mask & xmask, tmp41, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp44 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.where(r0_mask & xmask, tmp44, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp47 = tl.sum(tmp46, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp48 = tmp47 / tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp49 = tmp41 - tmp48
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tmp49 * tmp49
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp53 = tl.where(r0_mask & xmask, tmp51, 0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp55 = tmp54 / tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp56 = tmp55 + tmp33
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp57 = libdevice.rsqrt(tmp56)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = 0.02
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp59 = tmp35 * tmp58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 50*x0), tmp4, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 50*x0), tmp36, r0_mask & xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.debug_barrier()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp57, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp59, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yc/cyczk6tbiz645sngfgn4xybpmb5gw2f47jgqteiu5dkzp3er3ipb.py
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_24, x_25, x_26], Original ATen: [aten.glu, aten.relu, aten.mish]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_24 => glu
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_25 => relu_4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_26 => exp_6, gt_20, log1p, mul_2227, tanh_40, where_6
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %glu : [num_users=2] = call_function[target=torch.ops.aten.glu.default](args = (%permute_141, 1), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %relu_4 : [num_users=4] = call_function[target=torch.ops.aten.relu.default](args = (%glu,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %exp_6 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%relu_4,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %log1p : [num_users=1] = call_function[target=torch.ops.aten.log1p.default](args = (%exp_6,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_20 : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%relu_4, 20), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where_6 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%gt_20, %relu_4, %log1p), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh_40 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%where_6,), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2227 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%relu_4, %tanh_40), kwargs = {})
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_glu_mish_relu_51 = async_compile.triton('triton_poi_fused_glu_mish_relu_51', '''
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 8192}, 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_glu_mish_relu_51', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 10, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_glu_mish_relu_51(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.load(in_ptr6 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.load(in_ptr0 + (x2 + 500*ks0), xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.load(in_ptr3 + (x1 + 10*ks0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.load(in_ptr4 + (x1 + 10*ks0), xmask, eviction_policy='evict_last')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp8 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp13 * tmp1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp14 + tmp3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp15 - tmp16
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tmp17 * tmp18
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp19 * tmp9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tmp20 + tmp11
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.sigmoid(tmp21)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp12 * tmp22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tl.full([1], 0, tl.int32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = triton_helpers.maximum(tmp24, tmp23)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = 20.0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp25 > tmp26
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl_math.exp(tmp25)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = libdevice.log1p(tmp28)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tl.where(tmp27, tmp25, tmp29)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = libdevice.tanh(tmp30)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp25 * tmp31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp23, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp32, xmask)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] async_compile.wait(globals())
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] del async_compile
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def call(args):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82 = args
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     args.clear()
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     s0 = primals_1
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_2, (s0, 20, 10), (200, 10, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_3, (20, 10, 10), (100, 10, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_4, (20, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_5, (30, 20, 20), (400, 20, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_6, (30, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_7, (30, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_8, (30, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_9, (30, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_10, (30, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_11, (40, 30), (30, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_12, (40, 40), (40, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_13, (40, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_14, (40, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_15, (50, 40), (40, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_16, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_17, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_18, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_19, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_20, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_21, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_22, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_23, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_24, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_25, (2048, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_26, (2048, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_27, (50, 2048), (2048, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_28, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_29, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_30, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_31, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_32, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_33, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_34, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_35, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_36, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_37, (2048, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_38, (2048, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_39, (50, 2048), (2048, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_40, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_41, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_42, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_43, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_44, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_45, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_46, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_47, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_48, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_49, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_50, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_51, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_52, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_53, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_54, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_55, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_56, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_57, (2048, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_58, (2048, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_59, (50, 2048), (2048, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_60, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_61, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_62, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_63, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_64, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_65, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_66, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_67, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_68, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_69, (150, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_70, (150, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_71, (50, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_72, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_73, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_74, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_75, (2048, 50), (50, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_76, (2048, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_77, (50, 2048), (2048, 1))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_78, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_79, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_80, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_81, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_82, (50, ), (1, ))
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         torch.cuda.set_device(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf185 = empty_strided_cuda((20, ), (1, ), torch.int64)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [20], out=buf185)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf14 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [hx1], Original ATen: [aten._to_copy]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused__to_copy_0_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused__to_copy_0.run(buf14, triton_poi_fused__to_copy_0_xnumel, grid=grid(triton_poi_fused__to_copy_0_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf16 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf14, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf16)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf15 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [hx2], Original ATen: [aten._to_copy]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused__to_copy_0_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused__to_copy_0.run(buf15, triton_poi_fused__to_copy_0_xnumel, grid=grid(triton_poi_fused__to_copy_0_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf20 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf15, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf20)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten._trilinear]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf0 = torch.ops.aten._trilinear.default(reinterpret_tensor(primals_2, (20*s0, 10), (10, 1), 0), primals_3, reinterpret_tensor(primals_2, (20*s0, 10), (10, 1), 0), [1, 3], [0], [1, 2], [2, 3])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf1 = buf0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf2 = buf1; del buf1  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_1, x_2], Original ATen: [aten.add, aten.view]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_view_1_xnumel = 400*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_view_1.run(buf2, primals_4, triton_poi_fused_add_view_1_xnumel, grid=grid(triton_poi_fused_add_view_1_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten._trilinear]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf3 = torch.ops.aten._trilinear.default(buf2, primals_5, buf2, [1, 3], [0], [1, 2], [2, 3])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf4 = buf3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf3
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf5 = empty_strided_cuda((30*s0, ), (1, ), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf6 = empty_strided_cuda((s0, 30, 20), (600, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf7 = empty_strided_cuda((1, 30*s0, 1), (30*s0, 1, 30*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf8 = empty_strided_cuda((1, 30*s0, 1), (30*s0, 1, 30*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf13 = empty_strided_cuda((1, 30*s0, 20), (600*s0, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf10 = empty_strided_cuda((1, 30*s0, 1), (30*s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.repeat, aten.clone, aten._native_batch_norm_legit_functional]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2.run(primals_9, buf4, primals_6, primals_10, buf5, buf6, buf7, buf8, buf13, buf10, triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2_xnumel, 20, grid=grid(triton_per_fused__native_batch_norm_legit_functional_clone_repeat_2_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf4
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_6
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_9
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mean]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_mean_3.run(buf8, primals_8, primals_8, s0, 30, s0, grid=grid(30), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_8
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mean]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_mean_4.run(buf7, primals_7, primals_7, s0, 30, s0, grid=grid(30), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_7
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf17 = reinterpret_tensor(buf8, (s0, 30), (30, 1), 0); del buf8  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_5_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_5.run(buf13, buf17, triton_poi_fused_addmm_5_xnumel, grid=grid(triton_poi_fused_addmm_5_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf18 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf17, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf18)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf19 = buf16; del buf16  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf19, primals_14, buf18, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf24 = buf17; del buf17  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_7_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_7.run(buf13, buf24, triton_poi_fused_addmm_7_xnumel, grid=grid(triton_poi_fused_addmm_7_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf25 = buf18; del buf18  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf24, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf25)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf31 = buf24; del buf24  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_8_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_8.run(buf13, buf31, triton_poi_fused_addmm_8_xnumel, grid=grid(triton_poi_fused_addmm_8_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf32 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf31, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf38 = buf31; del buf31  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_9_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_9.run(buf13, buf38, triton_poi_fused_addmm_9_xnumel, grid=grid(triton_poi_fused_addmm_9_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf39 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf38, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf39)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf45 = buf38; del buf38  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_10_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_10.run(buf13, buf45, triton_poi_fused_addmm_10_xnumel, grid=grid(triton_poi_fused_addmm_10_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf46 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf45, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf46)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf52 = buf45; del buf45  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_11_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_11.run(buf13, buf52, triton_poi_fused_addmm_11_xnumel, grid=grid(triton_poi_fused_addmm_11_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf53 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf52, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf53)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf59 = buf52; del buf52  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_12_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_12.run(buf13, buf59, triton_poi_fused_addmm_12_xnumel, grid=grid(triton_poi_fused_addmm_12_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf60 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf59, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf60)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf66 = buf59; del buf59  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_13_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_13.run(buf13, buf66, triton_poi_fused_addmm_13_xnumel, grid=grid(triton_poi_fused_addmm_13_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf67 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf66, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf67)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf73 = buf66; del buf66  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_14_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_14.run(buf13, buf73, triton_poi_fused_addmm_14_xnumel, grid=grid(triton_poi_fused_addmm_14_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf74 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf73, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf74)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf80 = buf73; del buf73  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_15_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_15.run(buf13, buf80, triton_poi_fused_addmm_15_xnumel, grid=grid(triton_poi_fused_addmm_15_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf81 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf80, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf81)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf87 = buf80; del buf80  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_16_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_16.run(buf13, buf87, triton_poi_fused_addmm_16_xnumel, grid=grid(triton_poi_fused_addmm_16_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf88 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf87, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf88)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf94 = buf87; del buf87  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_17_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_17.run(buf13, buf94, triton_poi_fused_addmm_17_xnumel, grid=grid(triton_poi_fused_addmm_17_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf95 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf94, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf95)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf101 = buf94; del buf94  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_18_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_18.run(buf13, buf101, triton_poi_fused_addmm_18_xnumel, grid=grid(triton_poi_fused_addmm_18_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf102 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf101, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf102)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf108 = buf101; del buf101  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_19_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_19.run(buf13, buf108, triton_poi_fused_addmm_19_xnumel, grid=grid(triton_poi_fused_addmm_19_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf109 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf108, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf109)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf115 = buf108; del buf108  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_20_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_20.run(buf13, buf115, triton_poi_fused_addmm_20_xnumel, grid=grid(triton_poi_fused_addmm_20_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf116 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf115, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf116)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf122 = buf115; del buf115  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_21_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_21.run(buf13, buf122, triton_poi_fused_addmm_21_xnumel, grid=grid(triton_poi_fused_addmm_21_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf123 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf122, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf123)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf129 = buf122; del buf122  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_22_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_22.run(buf13, buf129, triton_poi_fused_addmm_22_xnumel, grid=grid(triton_poi_fused_addmm_22_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf130 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf129, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf130)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf136 = buf129; del buf129  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_23_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_23.run(buf13, buf136, triton_poi_fused_addmm_23_xnumel, grid=grid(triton_poi_fused_addmm_23_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf137 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf136, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf137)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf143 = buf136; del buf136  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_24_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_24.run(buf13, buf143, triton_poi_fused_addmm_24_xnumel, grid=grid(triton_poi_fused_addmm_24_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf144 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf143, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf144)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf150 = buf143; del buf143  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_25_xnumel = 30*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_addmm_25.run(buf13, buf150, triton_poi_fused_addmm_25_xnumel, grid=grid(triton_poi_fused_addmm_25_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf151 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf150, reinterpret_tensor(primals_11, (30, 40), (1, 30), 0), out=buf151)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf150
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf23 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf19, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf23)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf26 = buf23; del buf23  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf26, primals_14, buf25, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf30 = buf25; del buf25  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf26, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf30)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf33 = buf30; del buf30  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf33, primals_14, buf32, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf37 = buf32; del buf32  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf33, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf37)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf40 = buf37; del buf37  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf40, primals_14, buf39, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf44 = buf39; del buf39  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf40, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf44)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf47 = buf44; del buf44  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf47, primals_14, buf46, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf51 = buf46; del buf46  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf47, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf51)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf54 = buf51; del buf51  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf54, primals_14, buf53, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf58 = buf53; del buf53  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf54, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf58)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf61 = buf58; del buf58  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf61, primals_14, buf60, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf65 = buf60; del buf60  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf61, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf65)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf68 = buf65; del buf65  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf68, primals_14, buf67, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf72 = buf67; del buf67  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf68, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf72)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf75 = buf72; del buf72  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf75, primals_14, buf74, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf79 = buf74; del buf74  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf75, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf79)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf82 = buf79; del buf79  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf82, primals_14, buf81, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf86 = buf81; del buf81  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf82, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf86)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf89 = buf86; del buf86  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf89, primals_14, buf88, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf93 = buf88; del buf88  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf89, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf93)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf96 = buf93; del buf93  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf96, primals_14, buf95, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf100 = buf95; del buf95  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf96, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf100)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf103 = buf100; del buf100  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf103, primals_14, buf102, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf107 = buf102; del buf102  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf103, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf107)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf110 = buf107; del buf107  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf110, primals_14, buf109, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf114 = buf109; del buf109  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf110, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf114)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf117 = buf114; del buf114  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf117, primals_14, buf116, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf121 = buf116; del buf116  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf117, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf121)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf124 = buf121; del buf121  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf124, primals_14, buf123, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf128 = buf123; del buf123  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf124, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf128)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf131 = buf128; del buf128  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf131, primals_14, buf130, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf135 = buf130; del buf130  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf131, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf135)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf138 = buf135; del buf135  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf138, primals_14, buf137, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf142 = buf137; del buf137  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf138, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf142)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf145 = buf142; del buf142  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf145, primals_14, buf144, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf149 = buf144; del buf144  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf145, reinterpret_tensor(primals_12, (40, 40), (1, 40), 0), out=buf149)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf152 = buf149; del buf149  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6_xnumel = 40*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_6.run(buf152, primals_14, buf151, primals_13, triton_poi_fused_add_addmm_tanh_6_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_6_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf151
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_13
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_14
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf21 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf19, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf21)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf22 = buf20; del buf20  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf175 = empty_strided_cuda((s0, 1000), (1000, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf155 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 0)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26.run(buf22, primals_18, buf21, primals_17, buf155, triton_poi_fused_add_addmm_stack_tanh_26_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_26_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf27 = buf21; del buf21  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf22, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf27)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf28 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf26, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf28)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf29 = buf27; del buf27  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf156 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 50)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf29, primals_18, buf28, primals_17, buf156, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf34 = buf28; del buf28  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf29, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf34)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf35 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf33, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf35)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf36 = buf34; del buf34  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf157 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 100)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf36, primals_18, buf35, primals_17, buf157, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf41 = buf35; del buf35  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf36, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf41)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf42 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf40, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf42)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf43 = buf41; del buf41  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf158 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 150)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf43, primals_18, buf42, primals_17, buf158, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf48 = buf42; del buf42  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf43, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf48)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf49 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf47, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf49)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf50 = buf48; del buf48  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf159 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 200)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf50, primals_18, buf49, primals_17, buf159, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf55 = buf49; del buf49  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf50, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf55)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf56 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf54, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf56)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf57 = buf55; del buf55  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf160 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 250)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf57, primals_18, buf56, primals_17, buf160, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf62 = buf56; del buf56  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf57, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf62)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf63 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf61, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf63)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf64 = buf62; del buf62  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf161 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 300)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf64, primals_18, buf63, primals_17, buf161, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf69 = buf63; del buf63  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf64, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf69)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf70 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf68, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf70)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf71 = buf69; del buf69  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf162 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 350)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf71, primals_18, buf70, primals_17, buf162, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf76 = buf70; del buf70  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf71, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf76)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf77 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf75, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf77)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf78 = buf76; del buf76  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf163 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 400)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26.run(buf78, primals_18, buf77, primals_17, buf163, triton_poi_fused_add_addmm_stack_tanh_26_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_26_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf83 = buf77; del buf77  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf78, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf83)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf84 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf82, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf84)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf85 = buf83; del buf83  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf164 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 450)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf85, primals_18, buf84, primals_17, buf164, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf90 = buf84; del buf84  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf85, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf90)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf91 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf89, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf91)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf92 = buf90; del buf90  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf165 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 500)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf92, primals_18, buf91, primals_17, buf165, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf97 = buf91; del buf91  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf92, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf97)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf98 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf96, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf98)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf99 = buf97; del buf97  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf166 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 550)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf99, primals_18, buf98, primals_17, buf166, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf104 = buf98; del buf98  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf99, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf104)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf105 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf103, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf105)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf106 = buf104; del buf104  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf167 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 600)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf106, primals_18, buf105, primals_17, buf167, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf111 = buf105; del buf105  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf106, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf111)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf112 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf110, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf112)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf113 = buf111; del buf111  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf168 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 650)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf113, primals_18, buf112, primals_17, buf168, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf118 = buf112; del buf112  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf113, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf118)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf119 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf117, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf119)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf120 = buf118; del buf118  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf169 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 700)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf120, primals_18, buf119, primals_17, buf169, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf125 = buf119; del buf119  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf120, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf125)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf126 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf124, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf126)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf127 = buf125; del buf125  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf170 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 750)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf127, primals_18, buf126, primals_17, buf170, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf132 = buf126; del buf126  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf127, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf132)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf133 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf131, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf133)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf134 = buf132; del buf132  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf171 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 800)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_26.run(buf134, primals_18, buf133, primals_17, buf171, triton_poi_fused_add_addmm_stack_tanh_26_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_26_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf139 = buf133; del buf133  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf134, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf139)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf140 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf138, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf140)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf141 = buf139; del buf139  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf172 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 850)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf141, primals_18, buf140, primals_17, buf172, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf146 = buf140; del buf140  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf141, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf146)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf147 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf145, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf147)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf148 = buf146; del buf146  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf173 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 900)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_27.run(buf148, primals_18, buf147, primals_17, buf173, triton_poi_fused_add_addmm_stack_tanh_27_xnumel, grid=grid(triton_poi_fused_add_addmm_stack_tanh_27_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf153 = buf147; del buf147  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf148, reinterpret_tensor(primals_16, (50, 50), (1, 50), 0), out=buf153)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf154 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf152, reinterpret_tensor(primals_15, (40, 50), (1, 40), 0), out=buf154)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf174 = reinterpret_tensor(buf175, (s0, 50), (1000, 1), 950)  # alias
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf407 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.tanh_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_tanh_backward_28_xnumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_addmm_tanh_tanh_backward_28.run(buf153, primals_18, buf154, primals_17, buf174, buf407, triton_poi_fused_add_addmm_tanh_tanh_backward_28_xnumel, grid=grid(triton_poi_fused_add_addmm_tanh_tanh_backward_28_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf153
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf154
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_17
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_18
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         ps0 = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf176 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_29_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_29.run(buf175, buf176, s0, ps0, triton_poi_fused_clone_29_xnumel, grid=grid(triton_poi_fused_clone_29_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf155
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf156
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf157
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf158
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf159
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf160
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf161
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf162
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf163
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf164
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf165
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf166
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf167
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf168
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf169
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf170
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf171
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf172
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf173
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf174
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf177 = empty_strided_cuda((20*s0, 150), (150, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf176, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_20, (50, 150), (1, 50), 0), out=buf177)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf179 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30.run(buf177, primals_19, buf179, ps0, s0, triton_poi_fused_mul_30_ynumel, 20, grid=grid(triton_poi_fused_mul_30_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf406 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf179, buf406, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf178 = empty_strided_cuda((s0, 5, 20, 10), (1000, 200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf405 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32.run(buf177, primals_19, buf178, buf405, ps0, s0, triton_poi_fused_mul_transpose_32_xnumel, grid=grid(triton_poi_fused_mul_transpose_32_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf180 = empty_strided_cuda((5*s0, 20, 20), (400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf178, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf179, (5*s0, 10, 20), (200, 20, 1), 0), out=buf180)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         ps1 = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         ps2 = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf189 = empty_strided_cuda((3, 20, s0, 50), (1000*s0, 50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33_xnumel = 3000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33.run(buf177, primals_19, buf189, ps1, ps2, triton_poi_fused_clone_33_xnumel, grid=grid(triton_poi_fused_clone_33_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_19
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         ps3 = 5*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf190 = reinterpret_tensor(buf179, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf179  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf189, buf190, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf404 = reinterpret_tensor(buf178, (5*s0, 10, 20), (10, 1, 50*s0), 0); del buf178  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf189, buf404, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf181 = empty_strided_cuda((s0, 5, 20, 1), (100, 20, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf182 = empty_strided_cuda((s0, 5, 20, 1), (100, 20, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf183 = empty_strided_cuda((s0, 5, 20, 1), (100, 20, 1, 100*s0), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf184 = reinterpret_tensor(buf183, (s0, 5, 20, 1), (100, 20, 1, 1), 0); del buf183  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf187 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf188 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_35_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_35.run(buf184, buf180, buf185, buf181, buf182, buf187, buf188, 0, triton_per_fused__safe_softmax_native_dropout_35_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_35_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf191 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf188, (5*s0, 20, 20), (400, 20, 1), 0), buf190, out=buf191)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf192 = reinterpret_tensor(buf190, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf190  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf191, buf192, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf193 = reinterpret_tensor(buf191, (20*s0, 50), (50, 1), 0); del buf191  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf192, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_21, (50, 50), (1, 50), 0), out=buf193)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf250 = reinterpret_tensor(buf189, (20*s0, 150), (150, 1), 0); del buf189  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.mm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf176, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_46, (50, 150), (1, 50), 0), out=buf250)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf252 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30.run(buf250, primals_45, buf252, ps0, s0, triton_poi_fused_mul_30_ynumel, 20, grid=grid(triton_poi_fused_mul_30_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf393 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf252, buf393, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf251 = empty_strided_cuda((s0, 5, 20, 10), (1000, 200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf392 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32.run(buf250, primals_45, buf251, buf392, ps0, s0, triton_poi_fused_mul_transpose_32_xnumel, grid=grid(triton_poi_fused_mul_transpose_32_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf253 = empty_strided_cuda((5*s0, 20, 20), (400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf251, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf252, (5*s0, 10, 20), (200, 20, 1), 0), out=buf253)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf261 = reinterpret_tensor(buf177, (3, 20, s0, 50), (1000*s0, 50*s0, 50, 1), 0); del buf177  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33_xnumel = 3000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33.run(buf250, primals_45, buf261, ps1, ps2, triton_poi_fused_clone_33_xnumel, grid=grid(triton_poi_fused_clone_33_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_45
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf262 = reinterpret_tensor(buf252, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf252  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf261, buf262, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf391 = reinterpret_tensor(buf251, (5*s0, 10, 20), (10, 1, 50*s0), 0); del buf251  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf261, buf391, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf259 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf257 = reinterpret_tensor(buf253, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf253  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf260 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_2], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37.run(buf257, buf185, buf259, buf260, 8, triton_per_fused__safe_softmax_native_dropout_37_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_37_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf263 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf260, (5*s0, 20, 20), (400, 20, 1), 0), buf262, out=buf263)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf264 = reinterpret_tensor(buf262, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf262  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf263, buf264, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf265 = reinterpret_tensor(buf263, (20*s0, 50), (50, 1), 0); del buf263  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf264, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_47, (50, 50), (1, 50), 0), out=buf265)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf267 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf195 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf199 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf271 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf389 = empty_strided_cuda((20, s0, 50), (50, 1000, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf402 = empty_strided_cuda((20, s0, 50), (50, 1000, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf390 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf403 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_9, dropout_6, add_4, x_15], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38.run(buf185, buf175, buf193, primals_22, primals_23, primals_24, buf265, primals_48, primals_49, primals_50, buf267, buf195, buf199, buf271, buf389, buf402, buf390, buf403, 9, 1, s0, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_38_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_22
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_24
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_48
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_50
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf272 = buf265; del buf265  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf271, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_51, (50, 50), (1, 50), 0), out=buf272)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf275 = reinterpret_tensor(buf193, (s0, 5, 20, 10), (1000, 200, 10, 1), 0); del buf193  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf387 = reinterpret_tensor(buf175, (5*s0, 10, 20), (10, 1, 50*s0), 0); del buf175  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_39_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_39.run(buf272, primals_52, buf275, buf387, ps0, s0, triton_poi_fused_mul_transpose_39_xnumel, grid=grid(triton_poi_fused_mul_transpose_39_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf200 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf199, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_25, (50, 2048), (1, 50), 0), out=buf200)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf401 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40.run(buf200, primals_26, buf401, triton_poi_fused_relu_threshold_backward_40_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_40_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf202 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf203 = reinterpret_tensor(buf200, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf200  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41.run(buf203, buf185, primals_26, buf202, 2, triton_poi_fused_native_dropout_relu_41_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_41_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_26
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf204 = buf272; del buf272  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf203, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_27, (2048, 50), (1, 2048), 0), out=buf204)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf206 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf210 = reinterpret_tensor(buf204, (20, s0, 50), (50*s0, 50, 1), 0); del buf204  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf211 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf400 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_2, add_1, x_11], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf210, buf185, buf199, primals_28, primals_29, primals_30, buf206, buf211, buf400, 3, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_28
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_30
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf212 = reinterpret_tensor(buf261, (20*s0, 150), (150, 1), 0); del buf261  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf211, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_32, (50, 150), (1, 50), 0), out=buf212)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf214 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30.run(buf212, primals_31, buf214, ps0, s0, triton_poi_fused_mul_30_ynumel, 20, grid=grid(triton_poi_fused_mul_30_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf399 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf214, buf399, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf213 = empty_strided_cuda((s0, 5, 20, 10), (1000, 200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf398 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32.run(buf212, primals_31, buf213, buf398, ps0, s0, triton_poi_fused_mul_transpose_32_xnumel, grid=grid(triton_poi_fused_mul_transpose_32_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf215 = empty_strided_cuda((5*s0, 20, 20), (400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf213, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf214, (5*s0, 10, 20), (200, 20, 1), 0), out=buf215)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf223 = reinterpret_tensor(buf250, (3, 20, s0, 50), (1000*s0, 50*s0, 50, 1), 0); del buf250  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33_xnumel = 3000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33.run(buf212, primals_31, buf223, ps1, ps2, triton_poi_fused_clone_33_xnumel, grid=grid(triton_poi_fused_clone_33_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_31
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf224 = reinterpret_tensor(buf214, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf214  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf223, buf224, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf397 = reinterpret_tensor(buf213, (5*s0, 10, 20), (10, 1, 50*s0), 0); del buf213  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_34.run(buf223, buf397, ps3, ps0, s0, triton_poi_fused_bmm_34_xnumel, grid=grid(triton_poi_fused_bmm_34_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf221 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf219 = reinterpret_tensor(buf215, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf215  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf222 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_1], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37.run(buf219, buf185, buf221, buf222, 4, triton_per_fused__safe_softmax_native_dropout_37_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_37_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf225 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf222, (5*s0, 20, 20), (400, 20, 1), 0), buf224, out=buf225)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf226 = reinterpret_tensor(buf224, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf224  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf225, buf226, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf227 = reinterpret_tensor(buf225, (20*s0, 50), (50, 1), 0); del buf225  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf226, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_33, (50, 50), (1, 50), 0), out=buf227)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf229 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf233 = reinterpret_tensor(buf227, (20, s0, 50), (50*s0, 50, 1), 0); del buf227  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf234 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf396 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_12], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf233, buf185, buf211, primals_34, primals_35, primals_36, buf229, buf234, buf396, 5, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_34
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_36
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf235 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf234, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_37, (50, 2048), (1, 50), 0), out=buf235)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf395 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40.run(buf235, primals_38, buf395, triton_poi_fused_relu_threshold_backward_40_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_40_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf237 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf238 = reinterpret_tensor(buf235, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf235  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1, dropout_4], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41.run(buf238, buf185, primals_38, buf237, 6, triton_poi_fused_native_dropout_relu_41_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_41_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_38
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf239 = empty_strided_cuda((20*s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_13], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf238, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_39, (2048, 50), (1, 2048), 0), out=buf239)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf241 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf245 = reinterpret_tensor(buf239, (20, s0, 50), (50*s0, 50, 1), 0); del buf239  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf246 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf247 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf249 = reinterpret_tensor(buf247, (20, s0, 1), (s0, 1, 1), 0); del buf247  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf394 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf273 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_5, add_3, x_14, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43.run(buf245, buf249, buf185, buf234, primals_40, primals_41, primals_42, primals_43, primals_44, buf241, buf246, buf394, buf273, 7, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_43_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_40
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_44
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf274 = empty_strided_cuda((20*s0, 100), (100, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_51, (50, 100), (1, 50), 2500), out=buf274)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf276 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_44_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_44.run(buf274, primals_52, buf276, ps0, s0, triton_poi_fused_mul_44_ynumel, 20, grid=grid(triton_poi_fused_mul_44_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf285 = empty_strided_cuda((2, 20, s0, 50), (1000*s0, 50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_45_xnumel = 2000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_45.run(buf274, primals_52, buf285, ps1, ps2, triton_poi_fused_clone_45_xnumel, grid=grid(triton_poi_fused_clone_45_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_52
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf277 = reinterpret_tensor(buf274, (5*s0, 20, 20), (400, 20, 1), 0); del buf274  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf275, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf276, (5*s0, 10, 20), (200, 20, 1), 0), out=buf277)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf388 = reinterpret_tensor(buf275, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf275  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf276, buf388, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf286 = reinterpret_tensor(buf276, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf276  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_46_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_46.run(buf285, buf286, ps3, ps0, ps2, s0, triton_poi_fused_bmm_46_xnumel, grid=grid(triton_poi_fused_bmm_46_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf386 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_46_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_46.run(buf285, buf386, ps3, ps0, ps2, s0, triton_poi_fused_bmm_46_xnumel, grid=grid(triton_poi_fused_bmm_46_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf333 = reinterpret_tensor(buf285, (20*s0, 100), (100, 1), 0); del buf285  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_69, (50, 100), (1, 50), 2500), out=buf333)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf335 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_44_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_44.run(buf333, primals_70, buf335, ps0, s0, triton_poi_fused_mul_44_ynumel, 20, grid=grid(triton_poi_fused_mul_44_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf344 = empty_strided_cuda((2, 20, s0, 50), (1000*s0, 50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_45_xnumel = 2000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_45.run(buf333, primals_70, buf344, ps1, ps2, triton_poi_fused_clone_45_xnumel, grid=grid(triton_poi_fused_clone_45_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf345 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf376 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.bmm, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_transpose_47_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_transpose_47.run(buf344, buf345, buf376, ps3, ps0, ps2, s0, triton_poi_fused_bmm_transpose_47_xnumel, grid=grid(triton_poi_fused_bmm_transpose_47_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf378 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf335, buf378, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf283 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf281 = reinterpret_tensor(buf277, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf277  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf284 = reinterpret_tensor(buf344, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf344  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_3], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37.run(buf281, buf185, buf283, buf284, 10, triton_per_fused__safe_softmax_native_dropout_37_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_37_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf287 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf284, (5*s0, 20, 20), (400, 20, 1), 0), buf286, out=buf287)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf288 = reinterpret_tensor(buf286, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf286  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf287, buf288, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf289 = reinterpret_tensor(buf287, (20*s0, 50), (50, 1), 0); del buf287  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf288, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_53, (50, 50), (1, 50), 0), out=buf289)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf291 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf295 = reinterpret_tensor(buf289, (20, s0, 50), (50*s0, 50, 1), 0); del buf289  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf296 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf385 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_7, add_5, x_16], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf295, buf185, buf271, primals_54, primals_55, primals_56, buf291, buf296, buf385, 11, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_54
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_56
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf297 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf296, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_57, (50, 2048), (1, 50), 0), out=buf297)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf384 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_relu_threshold_backward_40.run(buf297, primals_58, buf384, triton_poi_fused_relu_threshold_backward_40_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_40_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf299 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf300 = reinterpret_tensor(buf297, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf297  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2, dropout_8], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_41.run(buf300, buf185, primals_58, buf299, 12, triton_poi_fused_native_dropout_relu_41_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_41_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_58
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf301 = empty_strided_cuda((20*s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_17], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf300, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_59, (2048, 50), (1, 2048), 0), out=buf301)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf303 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf307 = reinterpret_tensor(buf301, (20, s0, 50), (50*s0, 50, 1), 0); del buf301  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf308 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf383 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_9, add_6, x_18], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf307, buf185, buf296, primals_60, primals_61, primals_62, buf303, buf308, buf383, 13, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_60
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_62
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf309 = reinterpret_tensor(buf223, (20*s0, 150), (150, 1), 0); del buf223  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf308, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_64, (50, 150), (1, 50), 0), out=buf309)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf311 = empty_strided_cuda((s0, 5, 10, 20), (1000, 200, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.mul]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30_ynumel = 50*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_30.run(buf309, primals_63, buf311, ps0, s0, triton_poi_fused_mul_30_ynumel, 20, grid=grid(triton_poi_fused_mul_30_ynumel, 20), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf382 = empty_strided_cuda((5*s0, 20, 10), (10, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31_ynumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_transpose_31.run(buf311, buf382, s0, triton_poi_fused_transpose_31_ynumel, 10, grid=grid(triton_poi_fused_transpose_31_ynumel, 10), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf310 = empty_strided_cuda((s0, 5, 20, 10), (1000, 200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf381 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_32.run(buf309, primals_63, buf310, buf381, ps0, s0, triton_poi_fused_mul_transpose_32_xnumel, grid=grid(triton_poi_fused_mul_transpose_32_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf312 = reinterpret_tensor(buf333, (5*s0, 20, 20), (400, 20, 1), 0); del buf333  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf310, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf311, (5*s0, 10, 20), (200, 20, 1), 0), out=buf312)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf320 = reinterpret_tensor(buf212, (3, 20, s0, 50), (1000*s0, 50*s0, 50, 1), 0); del buf212  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33_xnumel = 3000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_33.run(buf309, primals_63, buf320, ps1, ps2, triton_poi_fused_clone_33_xnumel, grid=grid(triton_poi_fused_clone_33_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf309
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_63
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf321 = reinterpret_tensor(buf311, (5*s0, 20, 10), (10, 50*s0, 1), 0); del buf311  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf380 = reinterpret_tensor(buf310, (5*s0, 10, 20), (10, 1, 50*s0), 0); del buf310  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.bmm, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_transpose_48_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_bmm_transpose_48.run(buf320, buf321, buf380, ps3, ps0, s0, triton_poi_fused_bmm_transpose_48_xnumel, grid=grid(triton_poi_fused_bmm_transpose_48_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf320
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf318 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf316 = reinterpret_tensor(buf312, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf312  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf319 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_4], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37.run(buf316, buf185, buf318, buf319, 14, triton_per_fused__safe_softmax_native_dropout_37_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_37_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf322 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf319, (5*s0, 20, 20), (400, 20, 1), 0), buf321, out=buf322)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf323 = reinterpret_tensor(buf321, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf321  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf322, buf323, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf324 = reinterpret_tensor(buf322, (20*s0, 50), (50, 1), 0); del buf322  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_65, (50, 50), (1, 50), 0), out=buf324)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf326 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf330 = reinterpret_tensor(buf324, (20, s0, 50), (50*s0, 50, 1), 0); del buf324  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf331 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf379 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_10, add_7, x_19], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf330, buf185, buf308, primals_66, primals_67, primals_68, buf326, buf331, buf379, 15, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_66
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_68
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf332 = empty_strided_cuda((20*s0, 50), (50, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf331, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_69, (50, 50), (1, 50), 0), out=buf332)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf334 = empty_strided_cuda((s0, 5, 20, 10), (1000, 200, 10, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf377 = empty_strided_cuda((5*s0, 10, 20), (10, 1, 50*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.mul, aten.transpose]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_39_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mul_transpose_39.run(buf332, primals_70, buf334, buf377, ps0, s0, triton_poi_fused_mul_transpose_39_xnumel, grid=grid(triton_poi_fused_mul_transpose_39_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_70
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf336 = empty_strided_cuda((5*s0, 20, 20), (400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf334, (5*s0, 20, 10), (200, 10, 1), 0), reinterpret_tensor(buf335, (5*s0, 10, 20), (200, 20, 1), 0), out=buf336)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf342 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf340 = reinterpret_tensor(buf336, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf336  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf343 = empty_strided_cuda((s0, 5, 20, 20), (2000, 400, 20, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward, multi_head_attention_forward_5], Original ATen: [aten._safe_softmax, aten.native_dropout]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37_xnumel = 100*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax_native_dropout_37.run(buf340, buf185, buf342, buf343, 16, triton_per_fused__safe_softmax_native_dropout_37_xnumel, 20, grid=grid(triton_per_fused__safe_softmax_native_dropout_37_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf346 = reinterpret_tensor(buf335, (5*s0, 20, 10), (200, 10, 1), 0); del buf335  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.bmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf343, (5*s0, 20, 20), (400, 20, 1), 0), buf345, out=buf346)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf347 = reinterpret_tensor(buf345, (20, s0, 5, 10), (50*s0, 50, 10, 1), 0); del buf345  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36_xnumel = 1000*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_36.run(buf346, buf347, ps3, ps0, triton_poi_fused_clone_36_xnumel, grid=grid(triton_poi_fused_clone_36_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf348 = reinterpret_tensor(buf346, (20*s0, 50), (50, 1), 0); del buf346  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf347, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_71, (50, 50), (1, 50), 0), out=buf348)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf350 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf354 = reinterpret_tensor(buf348, (20, s0, 50), (50*s0, 50, 1), 0); del buf348  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf355 = reinterpret_tensor(buf334, (20, s0, 50), (50*s0, 50, 1), 0); del buf334  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf375 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_11, add_8, x_20], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42.run(buf354, buf185, buf331, primals_72, primals_73, primals_74, buf350, buf355, buf375, 17, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_42_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_72
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_74
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf356 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf355, (20*s0, 50), (50, 1), 0), reinterpret_tensor(primals_75, (50, 2048), (1, 50), 0), out=buf356)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf358 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf359 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf374 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_3, dropout_12], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_49_xnumel = 40960*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_49.run(buf185, buf356, primals_76, buf358, buf359, buf374, 18, triton_poi_fused_native_dropout_relu_threshold_backward_49_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_49_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf356
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_76
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf360 = buf332; del buf332  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21], Original ATen: [aten.addmm]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf359, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_77, (2048, 50), (1, 2048), 0), out=buf360)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf362 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.bool)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf366 = reinterpret_tensor(buf360, (20, s0, 50), (50*s0, 50, 1), 0); del buf360  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf367 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf368 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf370 = reinterpret_tensor(buf368, (20, s0, 1), (s0, 1, 1), 0); del buf368  # reuse
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf373 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_13, add_9, x_22, output_1], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50_xnumel = 20*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50.run(buf366, buf370, buf185, buf355, primals_78, primals_79, primals_80, buf362, buf367, buf373, 19, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_50_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf185
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_78
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf371 = empty_strided_cuda((s0, 10, 50), (50, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf372 = empty_strided_cuda((s0, 10, 50), (50, 50*s0, 1), torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_24, x_25, x_26], Original ATen: [aten.glu, aten.relu, aten.mish]
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_glu_mish_relu_51_xnumel = 500*s0
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_glu_mish_relu_51.run(buf366, primals_79, primals_80, buf367, buf370, primals_81, primals_82, buf371, buf372, s0, triton_poi_fused_glu_mish_relu_51_xnumel, grid=grid(triton_poi_fused_glu_mish_relu_51_xnumel), stream=stream0)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     return (buf372, primals_5, primals_23, primals_29, primals_35, primals_41, primals_42, primals_43, primals_49, primals_55, primals_61, primals_67, primals_73, primals_79, primals_80, primals_81, primals_82, reinterpret_tensor(primals_2, (20*s0, 10), (10, 1), 0), buf2, buf5, reinterpret_tensor(buf6, (1, 30*s0, 20), (600*s0, 20, 1), 0), reinterpret_tensor(buf10, (30*s0, ), (1, ), 0), buf14, buf15, reinterpret_tensor(buf13, (s0, 30), (600, 20), 0), buf19, buf22, reinterpret_tensor(buf13, (s0, 30), (600, 20), 1), buf26, buf29, reinterpret_tensor(buf13, (s0, 30), (600, 20), 2), buf33, buf36, reinterpret_tensor(buf13, (s0, 30), (600, 20), 3), buf40, buf43, reinterpret_tensor(buf13, (s0, 30), (600, 20), 4), buf47, buf50, reinterpret_tensor(buf13, (s0, 30), (600, 20), 5), buf54, buf57, reinterpret_tensor(buf13, (s0, 30), (600, 20), 6), buf61, buf64, reinterpret_tensor(buf13, (s0, 30), (600, 20), 7), buf68, buf71, reinterpret_tensor(buf13, (s0, 30), (600, 20), 8), buf75, buf78, reinterpret_tensor(buf13, (s0, 30), (600, 20), 9), buf82, buf85, reinterpret_tensor(buf13, (s0, 30), (600, 20), 10), buf89, buf92, reinterpret_tensor(buf13, (s0, 30), (600, 20), 11), buf96, buf99, reinterpret_tensor(buf13, (s0, 30), (600, 20), 12), buf103, buf106, reinterpret_tensor(buf13, (s0, 30), (600, 20), 13), buf110, buf113, reinterpret_tensor(buf13, (s0, 30), (600, 20), 14), buf117, buf120, reinterpret_tensor(buf13, (s0, 30), (600, 20), 15), buf124, buf127, reinterpret_tensor(buf13, (s0, 30), (600, 20), 16), buf131, buf134, reinterpret_tensor(buf13, (s0, 30), (600, 20), 17), buf138, buf141, reinterpret_tensor(buf13, (s0, 30), (600, 20), 18), buf145, buf148, reinterpret_tensor(buf13, (s0, 30), (600, 20), 19), buf152, reinterpret_tensor(buf176, (20*s0, 50), (50, 1), 0), buf180, buf181, buf182, buf184, buf187, reinterpret_tensor(buf192, (20*s0, 50), (50, 1), 0), buf195, reinterpret_tensor(buf199, (20*s0, 50), (50, 1), 0), buf202, reinterpret_tensor(buf203, (20*s0, 2048), (2048, 1), 0), buf206, buf210, reinterpret_tensor(buf211, (20*s0, 50), (50, 1), 0), buf219, buf221, reinterpret_tensor(buf226, (20*s0, 50), (50, 1), 0), buf229, buf233, reinterpret_tensor(buf234, (20*s0, 50), (50, 1), 0), buf237, reinterpret_tensor(buf238, (20*s0, 2048), (2048, 1), 0), buf241, buf245, buf246, buf249, buf257, buf259, reinterpret_tensor(buf264, (20*s0, 50), (50, 1), 0), buf267, reinterpret_tensor(buf271, (20*s0, 50), (50, 1), 0), reinterpret_tensor(buf273, (20*s0, 50), (50, 1), 0), buf281, buf283, reinterpret_tensor(buf288, (20*s0, 50), (50, 1), 0), buf291, buf295, reinterpret_tensor(buf296, (20*s0, 50), (50, 1), 0), buf299, reinterpret_tensor(buf300, (20*s0, 2048), (2048, 1), 0), buf303, buf307, reinterpret_tensor(buf308, (20*s0, 50), (50, 1), 0), buf316, buf318, reinterpret_tensor(buf323, (20*s0, 50), (50, 1), 0), buf326, buf330, reinterpret_tensor(buf331, (20*s0, 50), (50, 1), 0), buf340, buf342, reinterpret_tensor(buf347, (20*s0, 50), (50, 1), 0), buf350, buf354, reinterpret_tensor(buf355, (20*s0, 50), (50, 1), 0), buf358, reinterpret_tensor(buf359, (20*s0, 2048), (2048, 1), 0), buf362, buf366, buf367, buf370, buf371, buf373, primals_77, buf374, primals_75, buf375, primals_71, reinterpret_tensor(buf343, (5*s0, 20, 20), (400, 1, 20), 0), buf376, buf377, buf378, reinterpret_tensor(primals_69, (100, 50), (50, 1), 2500), reinterpret_tensor(primals_69, (50, 50), (50, 1), 0), buf379, primals_65, reinterpret_tensor(buf319, (5*s0, 20, 20), (400, 1, 20), 0), buf380, buf381, buf382, primals_64, buf383, primals_59, buf384, primals_57, buf385, primals_53, reinterpret_tensor(buf284, (5*s0, 20, 20), (400, 1, 20), 0), buf386, buf387, buf388, reinterpret_tensor(primals_51, (100, 50), (50, 1), 2500), reinterpret_tensor(primals_51, (50, 50), (50, 1), 0), buf389, buf390, primals_47, reinterpret_tensor(buf260, (5*s0, 20, 20), (400, 1, 20), 0), buf391, buf392, buf393, primals_46, buf394, primals_39, buf395, primals_37, buf396, primals_33, reinterpret_tensor(buf222, (5*s0, 20, 20), (400, 1, 20), 0), buf397, buf398, buf399, primals_32, buf400, primals_27, buf401, primals_25, buf402, buf403, primals_21, reinterpret_tensor(buf188, (5*s0, 20, 20), (400, 1, 20), 0), buf404, buf405, buf406, primals_20, buf407, primals_15, primals_16, primals_11, primals_12, reinterpret_tensor(buf7, (1, 30*s0, 1), (30*s0, 1, 1), 0), s0, 20*s0, 5*s0, )
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_1 = 10
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_2 = rand_strided((10, 20, 10), (200, 10, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_3 = rand_strided((20, 10, 10), (100, 10, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_4 = rand_strided((20, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_5 = rand_strided((30, 20, 20), (400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_6 = rand_strided((30, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_7 = rand_strided((30, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_8 = rand_strided((30, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_9 = rand_strided((30, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_10 = rand_strided((30, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_11 = rand_strided((40, 30), (30, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_12 = rand_strided((40, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_13 = rand_strided((40, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_14 = rand_strided((40, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_15 = rand_strided((50, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_16 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_17 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_18 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_19 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_20 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_21 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_22 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_23 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_24 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_25 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_26 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_27 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_28 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_29 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_30 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_31 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_32 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_33 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_34 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_35 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_36 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_37 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_38 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_39 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_40 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_41 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_42 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_43 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_44 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_45 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_46 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_47 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_48 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_49 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_50 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_51 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_52 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_53 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_54 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_55 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_56 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_57 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_58 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_59 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_60 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_61 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_62 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_63 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_64 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_65 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_66 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_67 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_68 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_69 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_70 = rand_strided((150, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_71 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_72 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_73 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_74 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_75 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_76 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_77 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_78 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_79 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_80 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_81 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_82 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82])
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] if __name__ == "__main__":
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:55:39.852000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:39.939000 2742634 site-packages/torch/_inductor/graph.py:2022] [275/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/iu/ciuz4lxyke5zovmodylj37ntu52m2mmh2ivxelfq5t6jdcrd2lg7.py
I0204 20:55:41.172000 2742634 site-packages/torch/_inductor/graph.py:2056] [275/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/iu/ciuz4lxyke5zovmodylj37ntu52m2mmh2ivxelfq5t6jdcrd2lg7.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] Output code: 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # AOT ID: ['63_backward']
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import torch
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import random
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import os
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import tempfile
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from math import inf, nan
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from cmath import nanj
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch import device, empty_strided
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     grid,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     split_scan_grid,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     grid_combo_kernels,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     start_graph,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     end_graph,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     cooperative_reduction_grid,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] aten = torch.ops.aten
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] _quantized = torch.ops._quantized
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] async_compile = AsyncCompile()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qv/cqv3k3esxolkpwvgb4t3quqleoelgf5w2bhd3ks7tq7mcirhx4ub.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mm_51 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%permute_302, %select_19), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_mm_0 = async_compile.triton('triton_poi_fused_mm_0', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (1,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mm_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_mm_0(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ge/cget3xsagdzonlfxqtsrxnx6dlqrtm2ccsf34gf7a4dm4gg5kgft.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %addmm_default_65 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%addmm_default_69, %permute_350, %select_16), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_poi_fused_1', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_1(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3r/c3ruvb2yckkd7dhahpiy7u6msynje5m3sar2bqcyvoucvss3s2jc.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_22, output_1], Original ATen: [aten.native_layer_norm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   output_1 => mul_2206, sub_766
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_22 => add_2783, mul_2198
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2198 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2197, %primals_79), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2783 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2198, %primals_80), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_766 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_2783, %getitem_33), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2206 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_766, %rsqrt_12), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_native_layer_norm_2 = async_compile.triton('triton_poi_fused_native_layer_norm_2', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_native_layer_norm_2(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp8, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pk/cpkjysqctlexsjbrukfeezdspvijquc7ettovcw723m3bjn7a4ma.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_25, x_26], Original ATen: [aten.relu, aten.mish, aten.sigmoid, aten.mul, aten.fill, aten.sub, aten.add, aten.threshold_backward, aten.glu_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_25 => relu_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_26 => exp_6, gt_20, log1p, tanh_40, where_6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %relu_4 : [num_users=6] = call_function[target=torch.ops.aten.relu.default](args = (%glu,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %exp_6 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%relu_4,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %log1p : [num_users=1] = call_function[target=torch.ops.aten.log1p.default](args = (%exp_6,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %gt_20 : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%relu_4, 20), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where_6 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%gt_20, %relu_4, %log1p), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %tanh_40 : [num_users=2] = call_function[target=torch.ops.aten.tanh.default](args = (%where_6,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%relu_4,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2231 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_40, %tanh_40), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_8 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 10, 50], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_775 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%full_default_8, %mul_2231), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2232 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%relu_4, %sigmoid), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2233 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2232, %sub_775), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2830 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%tanh_40, %mul_2233), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2234 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, %add_2830), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_4, 0), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_9 : [num_users=5] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where_8 : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default_9, %mul_2234), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sigmoid_1 : [num_users=3] = call_function[target=torch.ops.aten.sigmoid.default](args = (%slice_42,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_776 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1.0, %sigmoid_1), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2235 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_776, %sigmoid_1), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2236 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2235, %slice_41), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2237 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2236, %where_8), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2238 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_1, %where_8), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3 = async_compile.triton('triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 8192}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % ks0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // ks1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3 + 500*ks0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.load(in_ptr3 + (x3), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.load(in_ptr4 + (x0 + 50*x2 + 500*x1), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.sigmoid(tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp6 - tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp7 * tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tmp10 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp8 * tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.full([1], 0, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = triton_helpers.maximum(tmp14, tmp13)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp15 <= tmp16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = 20.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp15 > tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl_math.exp(tmp15)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = libdevice.log1p(tmp21)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.where(tmp20, tmp15, tmp22)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = libdevice.tanh(tmp23)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tl.sigmoid(tmp15)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp15 * tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp24 * tmp24
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tmp6 - tmp27
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp26 * tmp28
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp24 + tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tmp18 * tmp30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tl.where(tmp17, tmp16, tmp31)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = tmp12 * tmp32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp5 * tmp32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0 + 50*x2 + 1000*x1), tmp33, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0 + 50*x2 + 1000*x1), tmp34, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/25/c25m7fqk5tbm6lu7zqk4vzir3qfzqdnr4lugva7gltmg45i3ip6v.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2245 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_143, %mul_2206), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2245, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%permute_143, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_native_layer_norm_backward_4 = async_compile.triton('triton_red_fused_native_layer_norm_backward_4', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_native_layer_norm_backward_4(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp7 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + 1000*((r0_2 % ks0))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp6 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = _tmp7 + tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp7 = tl.where(r0_mask & xmask, tmp8, _tmp7)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.sum(_tmp7, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mq/cmqoyevwnnteiyha5aypqkxeukm7xoyl7wu3ghdz5yk6gbir42kj.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2245 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_143, %mul_2206), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2245, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_native_layer_norm_backward_5 = async_compile.triton('triton_per_fused_native_layer_norm_backward_5', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 64, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_native_layer_norm_backward_5(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 50*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tz/ctzzz4r5xookwxvfwna7bwejvp2lkdpmedk2tlwvnrhmofsghskt.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2240 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_143, %primals_81), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2240, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2242 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2240, %mul_2206), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2242, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_native_layer_norm_backward_6 = async_compile.triton('triton_per_fused_native_layer_norm_backward_6', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_native_layer_norm_backward_6(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = (xindex % ks0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // ks0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (r0_1 + 50*x3 + 1000*x2), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.where(r0_mask & xmask, tmp3, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.sum(tmp5, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp7 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp8 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.where(r0_mask & xmask, tmp11, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp14, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ap/caphou7f2ercgxrsaqc7nk4xzl6qdr7mjcjolppvsaerh4bbu3li.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2240 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_143, %primals_81), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2241 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2240, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2243 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2206, %sum_8), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_778 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2241, %sum_7), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_779 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_778, %mul_2243), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_6 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_12, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2244 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_6, %sub_779), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2247 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2244, %primals_79), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2248 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2247, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2247, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2249 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2247, %mul_2197), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2249, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2250 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2197, %sum_12), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_781 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2248, %sum_11), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_782 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_781, %mul_2250), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2251 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_7, %sub_782), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_19, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2253 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2254 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2251, %mul_2253), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_native_dropout_backward_native_layer_norm_backward_7 = async_compile.triton('triton_per_fused_native_dropout_backward_native_layer_norm_backward_7', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_dropout_backward_native_layer_norm_backward_7', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 10, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_native_dropout_backward_native_layer_norm_backward_7(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr2, out_ptr3, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % ks0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // ks0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_2 + 50*x1 + 1000*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (r0_2), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr3 + (x1 + 20*x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.load(in_out_ptr0 + (r0_2 + 50*x3), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x3), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tl.load(in_ptr5 + (r0_2), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.load(in_ptr6 + (r0_2 + 50*x3), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tl.load(in_ptr7 + (x3), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = tl.load(in_ptr8 + (r0_2 + 50*x3), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = 0.02
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = 50.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp5 * tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7 - tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp9 - tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp2 * tmp13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(r0_mask & xmask, tmp17, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp16 * tmp21
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.broadcast_to(tmp22, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tl.where(r0_mask & xmask, tmp23, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.sum(tmp25, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tmp16 * tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp28 - tmp20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp21 * tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tmp29 - tmp30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp27 * tmp31
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp33.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tmp32 * tmp36
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_2 + 50*x3), tmp14, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr2 + (r0_2 + 50*x3), tmp32, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (r0_2 + 50*x3), tmp37, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s3/cs3sx5hdzfhwi46dzxlxr2kmtslsxmbkugzcgkrckbmsd4fz66wn.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2252 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2244, %mul_2197), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2252, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2244, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_native_layer_norm_backward_8 = async_compile.triton('triton_red_fused_native_layer_norm_backward_8', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_native_layer_norm_backward_8(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp7 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp6 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = _tmp7 + tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp7 = tl.where(r0_mask & xmask, tmp8, _tmp7)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.sum(_tmp7, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/p6/cp6732y6je2jr57r5pb7l2joz6laidd64r2sbib7qqbipky47nx2.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_15 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_137, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_9 = async_compile.triton('triton_red_fused_sum_9', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_9', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_9(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*r0_2 + 500*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ri/cric2nxl6rmghgcxzinbkgxr5q5pmoft6yjr4s6taskzu32hlpze.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_9 : [num_users=5] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_18, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2255 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2256 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_139, %mul_2255), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where_9 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_1, %full_default_9, %mul_2256), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_native_dropout_backward_threshold_backward_10 = async_compile.triton('triton_poi_fused_native_dropout_backward_threshold_backward_10', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 524288}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_threshold_backward_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_native_dropout_backward_threshold_backward_10(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), None).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), None)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), None).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp1 * tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, None)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ow/cowmpbewtmutw6auaew5ev5svn5bsct5o2g6wwj6lm5udvm5zexo.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2831 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2251, %view_142), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2263 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2831, %mul_2141), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_19 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2263, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_20 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_2831, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_11 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_11', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_11(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp9, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ws/cws43agfndaqaubsko26u2lcacuy5k6nxsajds7lfezvrkytxhqn.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2831 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2251, %view_142), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2258 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2831, %primals_73), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2259 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2258, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2258, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2260 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2258, %mul_2141), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_18 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2260, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2261 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2141, %sum_18), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_784 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2259, %sum_17), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_785 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_784, %mul_2261), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2262 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_8, %sub_785), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_4 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_17, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2264 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_4, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2265 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2262, %mul_2264), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.where(r0_mask & xmask, tmp5, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp4 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.where(r0_mask & xmask, tmp11, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = 50.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp4 * tmp16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tmp17 - tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tmp9 * tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp18 - tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tmp15 * tmp20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp23 * tmp24
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp21 * tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 50*x0), tmp21, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 50*x0), tmp26, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uy/cuyxwvg2qalfc35slywruypjbnre3medigzyt4xc6wyg3yj5mr57.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_5 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_16, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2266 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_5, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2267 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_148, %mul_2266), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2268 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2267, %where_5), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_22 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2268, [-1], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %neg : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%where_5,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %fma : [num_users=1] = call_function[target=torch.ops.prims.fma.default](args = (%neg, %sum_22, %mul_2268), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused__softmax_backward_data_native_dropout_backward_13 = async_compile.triton('triton_per_fused__softmax_backward_data_native_dropout_backward_13', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 1024, 'r0_': 32},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*i1', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__softmax_backward_data_native_dropout_backward_13', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused__softmax_backward_data_native_dropout_backward_13(in_out_ptr0, in_ptr0, in_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp0 * tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp5 * tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.broadcast_to(tmp7, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.where(r0_mask & xmask, tmp8, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.sum(tmp10, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = -tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = libdevice.fma(tmp12, tmp11, tmp7)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 20*x0), tmp13, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oj/coji63qi6dq3scggn7xvd7zzn3yikcpptfqpkzsw2xz7syh7zhtt.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_9,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_14 = async_compile.triton('triton_poi_fused_clone_14', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_14(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % 2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = ((xindex // 100) % 20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // 2000
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x4 = (xindex % 100)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (10*((((x0 + 50*x3 + 50*ks1*x2) // ks0) % 20)) + 200*((((x0 + 50*x3) // 10) % (5*ks1))) + ((x0 % 10))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (20*((x0 % 10)) + 200*((((((x0 + 50*x3) // 10) % (5*ks1))) % (5*ks1))) + ((((x0 + 50*x3 + 50*ks1*x2) // ks0) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = x1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 == tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp0 == tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = 0.5623413251903491
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp8 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.where(tmp7, tmp10, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp5 + tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x4 + 100*x3 + 100*ks1*x2), tmp12, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xp/cxpci4uk4u7bxddwvuh4opxjct2msnhxqhzk7l73jpynzl25hll5.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %view_162 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view_157, [%mul, 50]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_view_15 = async_compile.triton('triton_poi_fused_view_15', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 16384}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_view_15(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (10*((((x0 + 50*((x1 % ks1)) + 50*ks1*(x1 // ks1)) // ks0) % 20)) + 200*((((((x0 + 50*((x1 % ks1))) // 10) % (5*ks1))) % (5*ks1))) + ((x0 % 10))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = 0.5623413251903491
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fz/cfzdx45i4e7qs6nqejvgizl6fh6ufbxdyeruowlkrmo2me6523dg.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_24 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_162, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_163, %view_160],), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_cat_sum_16 = async_compile.triton('triton_per_fused_cat_sum_16', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 64, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_cat_sum_16(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 50*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pl/cplorp7zyq4whq2ye5otd3dui4jil45qhzcukpeumjghjub6sih6.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_159, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_17 = async_compile.triton('triton_red_fused_sum_17', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_17(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 200
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 100)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 100*r0_2 + 1000*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rm/crm7jrgsbbcrodofalrpvmk7jmcxedqt2peyp2imsqsyyj2c6pjs.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_159, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_163, %view_160],), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_cat_sum_18 = async_compile.triton('triton_per_fused_cat_sum_18', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_cat_sum_18(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 100*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ha/chakpne6s5kdkcimiisxswps7542jfsuzisu7hke4fgt6gmotsxk.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_28 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_10,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_19 = async_compile.triton('triton_poi_fused_clone_19', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_19(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 50) % 3)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = ((xindex // 150) % 20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // 3000
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x4 = (xindex % 150)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (10*((((x0 + 50*x3 + 50*ks1*x2) // ks0) % 20)) + 200*((((x0 + 50*x3) // 10) % (5*ks1))) + ((x0 % 10))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (20*((x0 % 10)) + 200*((((((x0 + 50*x3) // 10) % (5*ks1))) % (5*ks1))) + ((((x0 + 50*x3 + 50*ks1*x2) // ks0) % 20))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tl.load(in_ptr2 + (10*((((x0 + 50*x3 + 50*ks1*x2) // ks0) % 20)) + 200*((((((x0 + 50*x3) // 10) % (5*ks1))) % (5*ks1))) + ((x0 % 10))), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = x1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 == tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp0 == tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = 0.5623413251903491
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp8 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.where(tmp7, tmp10, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp5 + tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.full([1], 0, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tmp0 == tmp13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tmp15 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.where(tmp14, tmp16, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tmp12 + tmp17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x4 + 150*x3 + 150*ks1*x2), tmp18, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tl/ctlyachupcjyjo4seapp3yxmoczkmfvhynyqwegx7raju2uqmdiw.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_31 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_181, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_20 = async_compile.triton('triton_red_fused_sum_20', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_20', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_20(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 300
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 150)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 150
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 150*r0_2 + 1500*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mp/cmpckdr3oqpuzzi2osov2wbzwnxupwomyajj2thizrlft4qn5cn7.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_31 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_181, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_sum_21 = async_compile.triton('triton_per_fused_sum_21', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_sum_21(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 150
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 150*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rb/crb7hc5llczjlry3nopexbm2tjyfmspwwclrv3gutlv42bcw4gda.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_140, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_22 = async_compile.triton('triton_red_fused_sum_22', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 4096, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_22', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_22(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 4096
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 2048)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 2048
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_2 + 20480*ks0*x1), r0_mask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, None)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u7/cu7bxcmbs4msq2sutsqbtmlju2xsouiafauqed75s3refz4c4mfo.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_140, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_sum_23 = async_compile.triton('triton_per_fused_sum_23', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 2048, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_sum_23(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 2048
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pd/cpd47o3hbnzvo2jxxx2ksfb4s6nxgmtood3wobwxnrmabds7fjbp.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2840 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2301, %view_211), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2316 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2840, %mul_2310), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_48 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2316, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_49 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_2840, [0, 1]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_24 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_24', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_24', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_24(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 100
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 50*((r0_2 % ks0)) + 50*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 50*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + 1000*((r0_2 % ks0))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp9, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ow/cowzeu7nbni63zp7ve2altvpfvsskbryasckyl3jkkrsr2cxoaoy.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2840 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2301, %view_211), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2311 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2840, %primals_49), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2312 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2311, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_46 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2311, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2313 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2311, %mul_2310), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_47 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2313, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2314 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2310, %sum_47), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_796 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2312, %sum_46), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_797 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_796, %mul_2314), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2315 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_12, %sub_797), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_12 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_9, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2317 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_12, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2318 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2315, %mul_2317), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr2': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr2, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = (xindex % ks0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex // ks0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 50*x3 + 1000*x2), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.where(r0_mask & xmask, tmp5, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp4 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.where(r0_mask & xmask, tmp11, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = 50.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp4 * tmp16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tmp17 - tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tmp9 * tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp18 - tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tmp15 * tmp20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp23 * tmp24
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp21 * tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 50*x0), tmp21, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 50*x0), tmp26, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ig/cig5dl7xw3x2phc6dadg6q2qp6qp54xieshu6d72cyyv5rhcelr4.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_52 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_227, [0, 1], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_26 = async_compile.triton('triton_red_fused_sum_26', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_26', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_26(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 300
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 150)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 150
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp20 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (10*((((50*((r0_2 % ks1)) + 50*ks1*((((r0_2 + 10*ks1*x1) // ks1) % 20)) + ((x0 % 50))) // ks0) % 20)) + 200*((((50*((r0_2 % ks1)) + ((x0 % 50))) // 10) % (5*ks1))) + ((((x0 % 50)) % 10))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = tl.load(in_ptr1 + (20*((((x0 % 50)) % 10)) + 200*((((((50*((r0_2 % ks1)) + ((x0 % 50))) // 10) % (5*ks1))) % (5*ks1))) + ((((50*((r0_2 % ks1)) + 50*ks1*((((r0_2 + 10*ks1*x1) // ks1) % 20)) + ((x0 % 50))) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp15 = tl.load(in_ptr2 + (10*((((50*((r0_2 % ks1)) + 50*ks1*((((r0_2 + 10*ks1*x1) // ks1) % 20)) + ((x0 % 50))) // ks0) % 20)) + 200*((((((50*((r0_2 % ks1)) + ((x0 % 50))) // 10) % (5*ks1))) % (5*ks1))) + ((((x0 % 50)) % 10))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = x0 // 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.full([1, 1], 2, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 == tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp6 = tl.full([1, 1], 1, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = tmp0 == tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp9 = 0.5623413251903491
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp11 = tl.where(tmp7, tmp10, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp12 = tmp5 + tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp13 = tl.full([1, 1], 0, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp14 = tmp0 == tmp13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp16 = tmp15 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp17 = tl.where(tmp14, tmp16, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp18 = tmp12 + tmp17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp19 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp21 = _tmp20 + tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp20 = tl.where(r0_mask & xmask, tmp21, _tmp20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tl.sum(_tmp20, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp20, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xw/cxwzuwykfmnfjcl7u5f5n3mrz6i62dx2xlky2h72oqgs4vmvqfgl.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [x_14, output], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   output => mul_1281, sub_514
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   x_14 => add_1743, mul_1273
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2839 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_161, %view_208), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2325 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2839, %primals_43), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2326 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2325, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_53 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2325, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1273 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1272, %primals_41), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_1743 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1273, %primals_42), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_514 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1743, %getitem_11), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_1281 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_514, %rsqrt_5), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2327 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2325, %mul_1281), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_54 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2327, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2328 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1281, %sum_54), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_799 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2326, %sum_53), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_800 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_799, %mul_2328), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div_13 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_5, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2329 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_13, %sub_800), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2332 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2329, %primals_41), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2333 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2332, 50), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_57 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2332, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2334 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2332, %mul_1272), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_58 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2334, [2], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2335 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1272, %sum_58), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_802 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2333, %sum_57), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_803 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_802, %mul_2335), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2336 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_14, %sub_803), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_14 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_7, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2338 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_14, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2339 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2336, %mul_2338), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*i1', 'out_ptr0': '*fp32', 'out_ptr3': '*fp32', 'out_ptr6': '*fp32', 'out_ptr7': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 10, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr0, out_ptr3, out_ptr6, out_ptr7, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tl.load(in_ptr7 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = tl.load(in_ptr8 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp47 = tl.load(in_ptr9 + (r0_1 + 50*x0), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.where(r0_mask & xmask, tmp14, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.sum(tmp16, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tmp13 * tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.where(r0_mask & xmask, tmp19, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.sum(tmp21, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = 0.02
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tmp7 * tmp23
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = 50.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp13 * tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp26 - tmp17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tmp8 * tmp22
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp27 - tmp28
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp24 * tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tmp30 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tl.broadcast_to(tmp31, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tl.where(r0_mask & xmask, tmp32, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = tl.sum(tmp34, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp31 * tmp0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tl.broadcast_to(tmp36, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tl.where(r0_mask & xmask, tmp37, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tl.sum(tmp39, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tmp31 * tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp43 = tmp42 - tmp35
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp44 = tmp0 * tmp40
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp45 = tmp43 - tmp44
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tmp41 * tmp45
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp48 = tmp47.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp49 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tmp48 * tmp49
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp51 = tmp46 * tmp50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 50*x0), tmp8, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 50*x0), tmp30, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 50*x0), tmp46, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr7 + (r0_1 + 50*x0), tmp51, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6a/c6aj53bzk7y7ra2nnnvwoqueow3opxhd3n7ed3htywmrcvpndjce.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.native_dropout_backward, aten._safe_softmax, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   multi_head_attention_forward => div, exp, full_default_2, sub_405, where
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %convert_element_type_21 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt, torch.float32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2376 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_21, 1.1111111111111112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2377 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_267, %mul_2376), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_405 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_26, %amax), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%sub_405,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%exp, %sum_1), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_2 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 5, 20, 20], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %where : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%logical_not_1, %full_default_2, %div), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2378 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2377, %where), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_81 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2378, [-1], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %neg_5 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%where,), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %fma_5 : [num_users=1] = call_function[target=torch.ops.prims.fma.default](args = (%neg_5, %sum_81, %mul_2378), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28 = async_compile.triton('triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 1024, 'r0_': 32},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0).to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last').to(tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr1 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 1.1111111111111112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp0 * tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp7 - tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl_math.exp(tmp9)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp10 / tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.where(tmp6, tmp13, tmp12)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp5 * tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.where(r0_mask & xmask, tmp16, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = -tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = libdevice.fma(tmp20, tmp19, tmp15)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr1 + (r0_1 + 20*x0), tmp21, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j4/cj4yh64w4akgjcmwhrxzc4dkfgfeeuab5dalse3fxx5qchlmcy7h.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2382 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%select_55, %sub_813), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_tanh_backward_29 = async_compile.triton('triton_poi_fused_tanh_backward_29', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_tanh_backward_29', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_tanh_backward_29(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 950*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 950*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 950*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 950*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rz/crz2dsxgcavkzfx5egpcaqpf7jmlq7yqt44rioi5pf4erqvqkvdl.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2383 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_38, %tanh_38), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_814 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2383), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2384 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mm_46, %sub_814), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_tanh_backward_30 = async_compile.triton('triton_poi_fused_tanh_backward_30', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_tanh_backward_30', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_tanh_backward_30(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp1 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp3 - tmp2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tmp0 * tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp5, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tz/ctzecivw5ckywwlmc5on7xsvijev23tlgsuxhy5r5uyv5hduf423.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2853 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_54, %mm_48), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2385 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_37, %tanh_37), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_815 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2385), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2386 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2853, %sub_815), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_31 = async_compile.triton('triton_poi_fused_add_tanh_backward_31', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_31', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_31(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 900*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 900*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 900*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 900*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7m/c7mtxppxul4imzmkcufwa2tznczpq7uxjq5l2otonbrg5bl6eff7.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2855 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_52, %mm_54), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2387 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_36, %tanh_36), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_816 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2387), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2388 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2855, %sub_816), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_32 = async_compile.triton('triton_poi_fused_add_tanh_backward_32', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_32', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_32(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp3 * tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp5 - tmp4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp2 * tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp7, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nb/cnbnkhcqjjztctc46hvcwpenrd7q43kd2iigoqgbveljrlf7r4nl.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2858 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_53, %mm_56), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2389 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_35, %tanh_35), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_817 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2389), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2390 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2858, %sub_817), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_33 = async_compile.triton('triton_poi_fused_add_tanh_backward_33', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_33', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_33(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 850*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 850*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 850*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 850*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/if/cifrpndt6q755vhuy23jxfzopsxvnc7tswxs5dn42q3rfo5x7oyg.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2869 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_52, %mm_64), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2393 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_33, %tanh_33), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_819 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2393), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2394 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2869, %sub_819), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_34 = async_compile.triton('triton_poi_fused_add_tanh_backward_34', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_34', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_34(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 800*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 800*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 800*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 800*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b4/cb4pfz776ngefq2shqr2gvxgh5kgc6eotgm6bq5y6flc32dup2q6.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2880 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_51, %mm_72), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2397 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_31, %tanh_31), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_821 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2397), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2398 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2880, %sub_821), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_35 = async_compile.triton('triton_poi_fused_add_tanh_backward_35', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_35', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_35(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 750*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 750*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 750*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 750*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qe/cqeqmtidhxcr764epbzwxrrw4q6qejco2nx2mwjro2qwaommvh3d.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2891 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_50, %mm_80), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2401 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_29, %tanh_29), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_823 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2401), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2402 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2891, %sub_823), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_36 = async_compile.triton('triton_poi_fused_add_tanh_backward_36', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_36', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_36(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 700*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 700*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 700*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 700*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ya/cyar5g7z4pqv6gpt66agbzi337zhc6xb5qrqfohck3qdtttgaygb.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2902 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_49, %mm_88), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2405 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_27, %tanh_27), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_825 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2405), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2406 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2902, %sub_825), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_37 = async_compile.triton('triton_poi_fused_add_tanh_backward_37', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_37', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_37(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 650*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 650*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 650*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 650*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uh/cuhezck4ayspyhbz6ydrj3poxc35x7s7mvyregrb5ioocvd6rttf.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2913 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_48, %mm_96), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2409 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_25, %tanh_25), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_827 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2409), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2410 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2913, %sub_827), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_38 = async_compile.triton('triton_poi_fused_add_tanh_backward_38', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_38', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_38(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 600*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 600*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 600*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 600*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c6/cc6mdt4zuhehsuzjsxbmtxhevs5264fvatng6gvd4u7kjadxtve5.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2924 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_47, %mm_104), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2413 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_23, %tanh_23), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_829 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2413), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2414 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2924, %sub_829), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_39 = async_compile.triton('triton_poi_fused_add_tanh_backward_39', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_39', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_39(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 550*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 550*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 550*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 550*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/o4/co4skjucpqodvnpa32abg62w3jroa5wysyskhg4ovocvsrn74ofp.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2935 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_46, %mm_112), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2417 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_21, %tanh_21), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_831 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2417), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2418 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2935, %sub_831), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_40 = async_compile.triton('triton_poi_fused_add_tanh_backward_40', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_40', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_40(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 500*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 500*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 500*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 500*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rm/crmj4ufcyscxulmnmlab3gnvmojinn4lu6mtdzzb47vexchtgxwc.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2946 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_45, %mm_120), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2421 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_19, %tanh_19), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_833 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2421), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2422 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2946, %sub_833), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_41 = async_compile.triton('triton_poi_fused_add_tanh_backward_41', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_41', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_41(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 450*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 450*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 450*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 450*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j6/cj6fnvjw2eqav4ztovo442v5jhwhv4r7kjg3jqvvmswudzjb6dly.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2957 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_44, %mm_128), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2425 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_17, %tanh_17), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_835 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2425), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2426 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2957, %sub_835), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_42 = async_compile.triton('triton_poi_fused_add_tanh_backward_42', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_42', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_42(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 400*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 400*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 400*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 400*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ds/cds46l5ihi7d2juqzwkfp6h4kaev2zmbs7cz27cxqssfrtihdb3b.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2968 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_43, %mm_136), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2429 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_15, %tanh_15), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_837 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2429), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2430 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2968, %sub_837), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_43 = async_compile.triton('triton_poi_fused_add_tanh_backward_43', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_43', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_43(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 350*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 350*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 350*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 350*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yt/cytu2ux54rgh6vemc5niofphelvql3blbmcd7gu5mhjrna4w4yuq.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2979 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_42, %mm_144), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2433 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_13, %tanh_13), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_839 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2433), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2434 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2979, %sub_839), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_44 = async_compile.triton('triton_poi_fused_add_tanh_backward_44', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_44', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_44(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 300*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 300*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 300*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 300*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g2/cg266mtgaaxplknkhx4nf5pu3ctaqqwodtvewve575ul3fhosilj.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2990 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_41, %mm_152), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2437 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_11, %tanh_11), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_841 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2437), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2438 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2990, %sub_841), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_45 = async_compile.triton('triton_poi_fused_add_tanh_backward_45', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_45', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_45(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 250*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 250*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 250*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 250*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4i/c4iy6sdhkpydbxdsrvm7m6tlq2z4lwk4jqpxk4yvyinj56isa65q.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3001 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_40, %mm_160), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2441 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_9, %tanh_9), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_843 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2441), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2442 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3001, %sub_843), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_46 = async_compile.triton('triton_poi_fused_add_tanh_backward_46', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_46', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_46(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 200*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 200*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 200*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 200*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5y/c5yfa5zme4ao43h4dwreimfzizqghyzmrkqhwdohkem7ytjwf2mi.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3012 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_39, %mm_168), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2445 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_7, %tanh_7), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_845 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2445), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2446 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3012, %sub_845), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_47 = async_compile.triton('triton_poi_fused_add_tanh_backward_47', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_47', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_47(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 150*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 150*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 150*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 150*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/il/cilb2i66e2brnzonriheeptm6j4bjt2s75lptg7lr66spfeqswsu.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3023 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_38, %mm_176), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2449 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_5, %tanh_5), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_847 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2449), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2450 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3023, %sub_847), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_48 = async_compile.triton('triton_poi_fused_add_tanh_backward_48', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_48', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_48(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 100*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 100*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0 + 100*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0 + 100*ks0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/id/cidmqtj43rcp6sr2fxnngv5ogkibkkzeenqyo7buz5lkknt37bl6.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3034 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_37, %mm_184), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_3, %tanh_3), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_849 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2453), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2454 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3034, %sub_849), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_49 = async_compile.triton('triton_poi_fused_add_tanh_backward_49', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_49', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_49(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks0 + x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (ks0 + x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (ks0 + x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (ks0 + x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yl/cyli5j5sa53wmnm4txqnlvgnjxi36eknjrj5volvjtb5yxpbiusj.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3045 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_36, %mm_192), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2457 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_1, %tanh_1), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_851 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_2457), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2458 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3045, %sub_851), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_tanh_backward_50 = async_compile.triton('triton_poi_fused_add_tanh_backward_50', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_tanh_backward_50', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_tanh_backward_50(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp9 * tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = 1.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tmp8 * tmp12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7d/c7d3uobhhm2ro7unl4h7flg74kylkr7ho76oyeisetuyyz3ew7i3.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_83 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2382, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_87 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2386, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2854 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_281, %view_285), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_91 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2390, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2865 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2854, %view_289), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_95 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2394, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2876 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2865, %view_293), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_99 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2398, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2887 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2876, %view_297), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_103 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2402, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2898 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2887, %view_301), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_107 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2406, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2909 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2898, %view_305), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_111 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2410, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2920 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2909, %view_309), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_115 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2414, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2931 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2920, %view_313), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_119 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2418, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2942 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2931, %view_317), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_123 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2422, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2953 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2942, %view_321), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_127 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2426, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2964 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2953, %view_325), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_131 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2430, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2975 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2964, %view_329), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_135 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2434, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2986 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2975, %view_333), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_139 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2438, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2997 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2986, %view_337), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_143 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2442, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3008 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2997, %view_341), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_147 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2446, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3019 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3008, %view_345), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_151 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2450, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3030 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3019, %view_349), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_155 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2454, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3041 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3030, %view_353), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_159 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2458, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3052 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3041, %view_357), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3055 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3041, %view_357), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_add_sum_51 = async_compile.triton('triton_red_fused_add_sum_51', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 64, 'r0_': 16},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*fp32', 'in_ptr11': '*fp32', 'in_ptr12': '*fp32', 'in_ptr13': '*fp32', 'in_ptr14': '*fp32', 'in_ptr15': '*fp32', 'in_ptr16': '*fp32', 'in_ptr17': '*fp32', 'in_ptr18': '*fp32', 'in_ptr19': '*fp32', 'out_ptr19': '*fp32', 'out_ptr20': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_sum_51', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 20, 'num_reduction': 20, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_add_sum_51(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, out_ptr19, out_ptr20, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp10 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp14 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp18 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp26 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp30 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp34 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp38 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp42 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp46 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp50 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp54 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp58 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp62 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp66 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp70 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp74 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp78 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp12 = tl.load(in_ptr3 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp16 = tl.load(in_ptr4 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp20 = tl.load(in_ptr5 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp24 = tl.load(in_ptr6 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp28 = tl.load(in_ptr7 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp32 = tl.load(in_ptr8 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp36 = tl.load(in_ptr9 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp40 = tl.load(in_ptr10 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp44 = tl.load(in_ptr11 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp48 = tl.load(in_ptr12 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp52 = tl.load(in_ptr13 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp56 = tl.load(in_ptr14 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp60 = tl.load(in_ptr15 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp64 = tl.load(in_ptr16 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp68 = tl.load(in_ptr17 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp72 = tl.load(in_ptr18 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp76 = tl.load(in_ptr19 + (x0 + 50*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp9 = tl.broadcast_to(tmp8, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp11 = _tmp10 + tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp10 = tl.where(r0_mask & xmask, tmp11, _tmp10)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp13 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp15 = _tmp14 + tmp13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp14 = tl.where(r0_mask & xmask, tmp15, _tmp14)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp19 = _tmp18 + tmp17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp18 = tl.where(r0_mask & xmask, tmp19, _tmp18)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp25 = tl.broadcast_to(tmp24, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp27 = _tmp26 + tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp26 = tl.where(r0_mask & xmask, tmp27, _tmp26)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp31 = _tmp30 + tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp30 = tl.where(r0_mask & xmask, tmp31, _tmp30)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp33 = tl.broadcast_to(tmp32, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp35 = _tmp34 + tmp33
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp34 = tl.where(r0_mask & xmask, tmp35, _tmp34)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp37 = tl.broadcast_to(tmp36, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp39 = _tmp38 + tmp37
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp38 = tl.where(r0_mask & xmask, tmp39, _tmp38)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp43 = _tmp42 + tmp41
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp42 = tl.where(r0_mask & xmask, tmp43, _tmp42)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp45 = tl.broadcast_to(tmp44, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp47 = _tmp46 + tmp45
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp46 = tl.where(r0_mask & xmask, tmp47, _tmp46)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp49 = tl.broadcast_to(tmp48, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp51 = _tmp50 + tmp49
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp50 = tl.where(r0_mask & xmask, tmp51, _tmp50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp53 = tl.broadcast_to(tmp52, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp55 = _tmp54 + tmp53
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp54 = tl.where(r0_mask & xmask, tmp55, _tmp54)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp57 = tl.broadcast_to(tmp56, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp59 = _tmp58 + tmp57
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp58 = tl.where(r0_mask & xmask, tmp59, _tmp58)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp61 = tl.broadcast_to(tmp60, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp63 = _tmp62 + tmp61
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp62 = tl.where(r0_mask & xmask, tmp63, _tmp62)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp65 = tl.broadcast_to(tmp64, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp67 = _tmp66 + tmp65
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp66 = tl.where(r0_mask & xmask, tmp67, _tmp66)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp69 = tl.broadcast_to(tmp68, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp71 = _tmp70 + tmp69
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp70 = tl.where(r0_mask & xmask, tmp71, _tmp70)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp73 = tl.broadcast_to(tmp72, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp75 = _tmp74 + tmp73
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp74 = tl.where(r0_mask & xmask, tmp75, _tmp74)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp77 = tl.broadcast_to(tmp76, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp79 = _tmp78 + tmp77
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp78 = tl.where(r0_mask & xmask, tmp79, _tmp78)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.sum(_tmp10, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.sum(_tmp14, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.sum(_tmp18, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.sum(_tmp26, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tl.sum(_tmp30, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tl.sum(_tmp34, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tl.sum(_tmp38, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tl.sum(_tmp42, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.sum(_tmp46, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tl.sum(_tmp50, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.sum(_tmp54, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = tl.sum(_tmp58, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp62 = tl.sum(_tmp62, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp66 = tl.sum(_tmp66, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp70 = tl.sum(_tmp70, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp74 = tl.sum(_tmp74, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp78 = tl.sum(_tmp78, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp80 = tmp2 + tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp81 = tmp80 + tmp18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp82 = tmp81 + tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp83 = tmp82 + tmp30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp84 = tmp83 + tmp38
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp85 = tmp84 + tmp54
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp86 = tmp85 + tmp66
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp87 = tmp86 + tmp78
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp88 = tmp87 + tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp89 = tmp88 + tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp90 = tmp89 + tmp22
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp91 = tmp90 + tmp34
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp92 = tmp91 + tmp42
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp93 = tmp92 + tmp50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp94 = tmp93 + tmp62
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp95 = tmp94 + tmp74
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp96 = tmp95 + tmp46
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp97 = tmp96 + tmp58
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp98 = tmp97 + tmp70
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr19 + (x0), tmp98, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr20 + (x0), tmp98, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nx/cnxadkepk3pmfeqcefzlzzv5w5lcj7q37b2eab763kocemtfot45.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_85 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2384, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_89 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2388, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2860 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_283, %view_287), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_93 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2392, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2871 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2860, %view_291), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_97 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2396, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2882 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2871, %view_295), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_101 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2400, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2893 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2882, %view_299), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_105 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2404, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2904 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2893, %view_303), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_109 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2408, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2915 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2904, %view_307), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_113 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2412, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2926 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2915, %view_311), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_117 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2416, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2937 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2926, %view_315), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_121 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2420, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2948 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2937, %view_319), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_125 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2424, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2959 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2948, %view_323), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_129 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2428, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2970 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2959, %view_327), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_133 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2432, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2981 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2970, %view_331), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_137 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2436, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2992 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2981, %view_335), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_141 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2440, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3003 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2992, %view_339), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_145 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2444, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3014 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3003, %view_343), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_149 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2448, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3025 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3014, %view_347), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_153 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2452, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3036 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3025, %view_351), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_157 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2456, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3047 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3036, %view_355), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_161 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2460, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3057 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3047, %view_359), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3059 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3047, %view_359), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_add_sum_52 = async_compile.triton('triton_red_fused_add_sum_52', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 64, 'r0_': 16},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*fp32', 'in_ptr11': '*fp32', 'in_ptr12': '*fp32', 'in_ptr13': '*fp32', 'in_ptr14': '*fp32', 'in_ptr15': '*fp32', 'in_ptr16': '*fp32', 'in_ptr17': '*fp32', 'in_ptr18': '*fp32', 'in_ptr19': '*fp32', 'out_ptr19': '*fp32', 'out_ptr20': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_sum_52', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 20, 'num_reduction': 20, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_add_sum_52(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, out_ptr19, out_ptr20, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 40
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp10 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp14 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp18 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp26 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp30 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp34 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp38 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp42 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp46 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp50 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp54 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp58 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp62 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp66 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp70 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp74 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp78 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp12 = tl.load(in_ptr3 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp16 = tl.load(in_ptr4 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp20 = tl.load(in_ptr5 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp24 = tl.load(in_ptr6 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp28 = tl.load(in_ptr7 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp32 = tl.load(in_ptr8 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp36 = tl.load(in_ptr9 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp40 = tl.load(in_ptr10 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp44 = tl.load(in_ptr11 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp48 = tl.load(in_ptr12 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp52 = tl.load(in_ptr13 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp56 = tl.load(in_ptr14 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp60 = tl.load(in_ptr15 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp64 = tl.load(in_ptr16 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp68 = tl.load(in_ptr17 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp72 = tl.load(in_ptr18 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp76 = tl.load(in_ptr19 + (x0 + 40*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp9 = tl.broadcast_to(tmp8, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp11 = _tmp10 + tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp10 = tl.where(r0_mask & xmask, tmp11, _tmp10)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp13 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp15 = _tmp14 + tmp13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp14 = tl.where(r0_mask & xmask, tmp15, _tmp14)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp19 = _tmp18 + tmp17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp18 = tl.where(r0_mask & xmask, tmp19, _tmp18)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp25 = tl.broadcast_to(tmp24, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp27 = _tmp26 + tmp25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp26 = tl.where(r0_mask & xmask, tmp27, _tmp26)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp31 = _tmp30 + tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp30 = tl.where(r0_mask & xmask, tmp31, _tmp30)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp33 = tl.broadcast_to(tmp32, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp35 = _tmp34 + tmp33
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp34 = tl.where(r0_mask & xmask, tmp35, _tmp34)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp37 = tl.broadcast_to(tmp36, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp39 = _tmp38 + tmp37
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp38 = tl.where(r0_mask & xmask, tmp39, _tmp38)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp43 = _tmp42 + tmp41
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp42 = tl.where(r0_mask & xmask, tmp43, _tmp42)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp45 = tl.broadcast_to(tmp44, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp47 = _tmp46 + tmp45
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp46 = tl.where(r0_mask & xmask, tmp47, _tmp46)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp49 = tl.broadcast_to(tmp48, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp51 = _tmp50 + tmp49
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp50 = tl.where(r0_mask & xmask, tmp51, _tmp50)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp53 = tl.broadcast_to(tmp52, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp55 = _tmp54 + tmp53
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp54 = tl.where(r0_mask & xmask, tmp55, _tmp54)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp57 = tl.broadcast_to(tmp56, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp59 = _tmp58 + tmp57
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp58 = tl.where(r0_mask & xmask, tmp59, _tmp58)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp61 = tl.broadcast_to(tmp60, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp63 = _tmp62 + tmp61
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp62 = tl.where(r0_mask & xmask, tmp63, _tmp62)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp65 = tl.broadcast_to(tmp64, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp67 = _tmp66 + tmp65
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp66 = tl.where(r0_mask & xmask, tmp67, _tmp66)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp69 = tl.broadcast_to(tmp68, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp71 = _tmp70 + tmp69
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp70 = tl.where(r0_mask & xmask, tmp71, _tmp70)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp73 = tl.broadcast_to(tmp72, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp75 = _tmp74 + tmp73
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp74 = tl.where(r0_mask & xmask, tmp75, _tmp74)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp77 = tl.broadcast_to(tmp76, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp79 = _tmp78 + tmp77
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp78 = tl.where(r0_mask & xmask, tmp79, _tmp78)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.sum(_tmp10, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.sum(_tmp14, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.sum(_tmp18, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.sum(_tmp26, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tl.sum(_tmp30, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tl.sum(_tmp34, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tl.sum(_tmp38, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tl.sum(_tmp42, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.sum(_tmp46, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tl.sum(_tmp50, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.sum(_tmp54, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = tl.sum(_tmp58, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp62 = tl.sum(_tmp62, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp66 = tl.sum(_tmp66, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp70 = tl.sum(_tmp70, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp74 = tl.sum(_tmp74, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp78 = tl.sum(_tmp78, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp80 = tmp2 + tmp10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp81 = tmp80 + tmp18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp82 = tmp81 + tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp83 = tmp82 + tmp30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp84 = tmp83 + tmp38
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp85 = tmp84 + tmp54
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp86 = tmp85 + tmp66
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp87 = tmp86 + tmp78
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp88 = tmp87 + tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp89 = tmp88 + tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp90 = tmp89 + tmp22
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp91 = tmp90 + tmp34
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp92 = tmp91 + tmp42
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp93 = tmp92 + tmp50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp94 = tmp93 + tmp62
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp95 = tmp94 + tmp74
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp96 = tmp95 + tmp46
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp97 = tmp96 + tmp58
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp98 = tmp97 + tmp70
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr19 + (x0), tmp98, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr20 + (x0), tmp98, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qz/cqz4bjzmvnk4xu7e5iht2jvqc7i37m23zy5pw2apd5jjzoum2dkz.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.select_backward, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %full_default_31 : [num_users=20] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 20, 30], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_16 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_50, 1, 19), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_17 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_58, 1, 18), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2864 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_scatter_default_16, %select_scatter_default_17), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_18 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_66, 1, 17), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2875 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2864, %select_scatter_default_18), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_19 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_74, 1, 16), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2886 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2875, %select_scatter_default_19), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_20 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_82, 1, 15), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2897 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2886, %select_scatter_default_20), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_21 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_90, 1, 14), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2908 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2897, %select_scatter_default_21), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_22 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_98, 1, 13), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2919 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2908, %select_scatter_default_22), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_23 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_106, 1, 12), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2930 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2919, %select_scatter_default_23), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_24 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_114, 1, 11), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2941 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2930, %select_scatter_default_24), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_25 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_122, 1, 10), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2952 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2941, %select_scatter_default_25), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_26 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_130, 1, 9), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2963 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2952, %select_scatter_default_26), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_27 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_138, 1, 8), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2974 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2963, %select_scatter_default_27), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_28 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_146, 1, 7), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2985 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2974, %select_scatter_default_28), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_29 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_154, 1, 6), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_2996 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2985, %select_scatter_default_29), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_30 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_162, 1, 5), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3007 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2996, %select_scatter_default_30), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_31 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_170, 1, 4), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3018 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3007, %select_scatter_default_31), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_32 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_178, 1, 3), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3029 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3018, %select_scatter_default_32), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %select_scatter_default_33 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_default_31, %mm_186, 1, 2), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3040 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3029, %select_scatter_default_33), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_select_backward_53 = async_compile.triton('triton_poi_fused_add_select_backward_53', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 8192}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*fp32', 'in_ptr11': '*fp32', 'in_ptr12': '*fp32', 'in_ptr13': '*fp32', 'in_ptr14': '*fp32', 'in_ptr15': '*fp32', 'in_ptr16': '*fp32', 'in_ptr17': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_select_backward_53', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 18, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_select_backward_53(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = ((xindex // 30) % 20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 30)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex // 600
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.load(in_ptr3 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.load(in_ptr4 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = tl.load(in_ptr6 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp38 = tl.load(in_ptr7 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp43 = tl.load(in_ptr8 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp48 = tl.load(in_ptr9 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp53 = tl.load(in_ptr10 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp58 = tl.load(in_ptr11 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp63 = tl.load(in_ptr12 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp68 = tl.load(in_ptr13 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp73 = tl.load(in_ptr14 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp78 = tl.load(in_ptr15 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp83 = tl.load(in_ptr16 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp88 = tl.load(in_ptr17 + (x0 + 30*x2), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = x1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.full([1], 19, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 == tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.full([1], 18, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp0 == tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tmp5 + tmp9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.full([1], 17, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp0 == tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tmp10 + tmp14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.full([1], 16, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tmp0 == tmp16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tl.where(tmp17, tmp18, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp15 + tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.full([1], 15, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp22 = tmp0 == tmp21
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tl.where(tmp22, tmp23, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = tmp20 + tmp24
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tl.full([1], 14, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp0 == tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tl.where(tmp27, tmp28, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp25 + tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tl.full([1], 13, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp0 == tmp31
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tl.where(tmp32, tmp33, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = tmp30 + tmp34
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tl.full([1], 12, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tmp0 == tmp36
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp39 = tl.where(tmp37, tmp38, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp40 = tmp35 + tmp39
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp41 = tl.full([1], 11, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp42 = tmp0 == tmp41
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp44 = tl.where(tmp42, tmp43, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp45 = tmp40 + tmp44
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp46 = tl.full([1], 10, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp47 = tmp0 == tmp46
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp49 = tl.where(tmp47, tmp48, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp50 = tmp45 + tmp49
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp51 = tl.full([1], 9, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp52 = tmp0 == tmp51
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp54 = tl.where(tmp52, tmp53, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp55 = tmp50 + tmp54
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp56 = tl.full([1], 8, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp57 = tmp0 == tmp56
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp59 = tl.where(tmp57, tmp58, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp60 = tmp55 + tmp59
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp61 = tl.full([1], 7, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp62 = tmp0 == tmp61
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp64 = tl.where(tmp62, tmp63, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp65 = tmp60 + tmp64
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp66 = tl.full([1], 6, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp67 = tmp0 == tmp66
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp69 = tl.where(tmp67, tmp68, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp70 = tmp65 + tmp69
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp71 = tl.full([1], 5, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp72 = tmp0 == tmp71
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp74 = tl.where(tmp72, tmp73, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp75 = tmp70 + tmp74
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp76 = tl.full([1], 4, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp77 = tmp0 == tmp76
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp79 = tl.where(tmp77, tmp78, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp80 = tmp75 + tmp79
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp81 = tl.full([1], 3, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp82 = tmp0 == tmp81
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp84 = tl.where(tmp82, tmp83, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp85 = tmp80 + tmp84
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp86 = tl.full([1], 2, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp87 = tmp0 == tmp86
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp89 = tl.where(tmp87, tmp88, tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp90 = tmp85 + tmp89
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp90, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e5/ce5fi6ozstv324e25vzzecuynrcuwgpeku4vjjwvrao32qyso2zm.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_163 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_361, [0, 2]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_853 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_8, %unsqueeze_15), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2461 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_361, %sub_853), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_164 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2461, [0, 2]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2468 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_853, %unsqueeze_19), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_855 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_361, %mul_2468), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sub_856 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_855, %unsqueeze_17), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %mul_2469 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_856, %unsqueeze_21), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_native_batch_norm_backward_54 = async_compile.triton('triton_per_fused_native_batch_norm_backward_54', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 512, 'r0_': 32},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_54', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_native_batch_norm_backward_54(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (30*r0_1 + 600*(x0 // 30) + ((x0 % 30))), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp17 = tl.load(in_out_ptr0 + (r0_1 + 20*x0), r0_mask & xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp18 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp28 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp35 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = r0_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.full([1, 1], 1, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tmp1 == tmp2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp5 = 0.0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp7 = tmp0 + tmp6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp8 = tl.full([1, 1], 0, tl.int32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp9 = tmp1 == tmp8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp11 = tl.where(tmp9, tmp10, tmp5)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp12 = tmp7 + tmp11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp15 = tl.where(r0_mask & xmask, tmp13, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp16 = tl.sum(tmp15, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp19 = tmp17 - tmp18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp20 = tmp12 * tmp19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp23 = tl.where(r0_mask & xmask, tmp21, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp24 = tl.sum(tmp23, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp25 = (tl.full([], 1.00000000000000, tl.float64) / ((600*ks0) / (30*ks0)))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp26 = tmp25.to(tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp27 = tmp24 * tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp29 = tmp28 * tmp28
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp30 = tmp27 * tmp29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp31 = tmp19 * tmp30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp32 = tmp12 - tmp31
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp33 = tmp16 * tmp26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp34 = tmp32 - tmp33
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp36 = tmp28 * tmp35
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp37 = tmp34 * tmp36
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 20*x0), tmp37, r0_mask & xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp16, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp24, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e4/ce4wdghl3xg5xo4bimlkh2azgbo7dr6g4bjlsvshi22q7rezf3vb.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_166 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_364, [0]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_55 = async_compile.triton('triton_red_fused_sum_55', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 16},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_55', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_55(in_ptr0, in_ptr1, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 30*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 30*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 * tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/p4/cp4b5dy2xt3fc7mul7ow2rjdfgbyoqg3hwn4snjbsarggnugxhrp.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_165 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_363, [0]), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_56 = async_compile.triton('triton_red_fused_sum_56', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 16},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_56', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_56(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 30*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sz/cszbl6omhxmsl6khpwjnmtn4pejp5k5nvtbpuxewtge3bql7ft4u.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_167 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_365, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_sum_57 = async_compile.triton('triton_red_fused_sum_57', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 256},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_57', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_sum_57(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (20*x0 + 600*(r0_1 // 20) + ((r0_1 % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ty/cty6oyjxprvwhv36ckmotxtoywmo2og63d367wdhwljkrftmy5dw.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %clone_56 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_612,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_clone_58 = async_compile.triton('triton_poi_fused_clone_58', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'y': 256, 'x': 32}, tile_hint=TileHint.SQUARE,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_58', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_clone_58(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     ymask = yindex < ynumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x2 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y0 = (yindex % 20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y1 = yindex // 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     y3 = yindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 20*x2 + 600*y1), xmask & ymask, eviction_policy='evict_last')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x2 + 30*y3), tmp0, xmask & ymask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/34/c34z6kgsnmt3uyspjntaxn5p3t6ml2wyqksemcw6qjdkacak265o.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3062 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_368, %view_369), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_168 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3062, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_red_fused_add_sum_59 = async_compile.triton('triton_red_fused_add_sum_59', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 64, 'r0_': 128},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_sum_59', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_red_fused_add_sum_59(in_ptr0, in_ptr1, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 40
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rbase = r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = (xindex % 20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x1 = xindex // 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x3 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         r0_2 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 20*r0_2 + 200*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 20*r0_2 + 200*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yr/cyr23vmiaerezozn4em2tafns6no26zrqb6tdlfweb2subqi3v3j.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3062 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_368, %view_369), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_poi_fused_add_60 = async_compile.triton('triton_poi_fused_add_60', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 4096}, 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_60', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     min_elem_per_thread=0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_poi_fused_add_60(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp2, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sq/csqnokywdekhkjwggkswawyyoj4udd4hgu6gbjvp7btqsb7u4e36.py
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Source node to ATen node mapping:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] # Graph fragment:
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %add_3062 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_368, %view_369), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] #   %sum_168 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3062, [0], True), kwargs = {})
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_per_fused_add_sum_61 = async_compile.triton('triton_per_fused_add_sum_61', '''
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] import triton.language as tl
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     size_hints={'x': 32, 'r0_': 2},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     filename=__file__,
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_sum_61', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] @triton.jit
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def triton_per_fused_add_sum_61(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xnumel = 20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_numel = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rnumel = r0_numel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     xmask = xindex < xnumel
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_offset = 0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     roffset = r0_offset
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rindex = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     r0_1 = r0_index
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     x0 = xindex
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 20*r0_1), xmask, other=0.0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] ''', device_str='cuda')
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] async_compile.wait(globals())
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] del async_compile
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def call(args):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_1, mul, mul_825, primals_5, primals_23, primals_29, primals_35, primals_41, primals_42, primals_43, primals_49, primals_55, primals_61, primals_67, primals_73, primals_79, primals_80, primals_81, primals_82, view_1, view_4, repeat, view_8, squeeze_1, full_default, full_default_1, select, tanh, tanh_1, select_1, tanh_2, tanh_3, select_2, tanh_4, tanh_5, select_3, tanh_6, tanh_7, select_4, tanh_8, tanh_9, select_5, tanh_10, tanh_11, select_6, tanh_12, tanh_13, select_7, tanh_14, tanh_15, select_8, tanh_16, tanh_17, select_9, tanh_18, tanh_19, select_10, tanh_20, tanh_21, select_11, tanh_22, tanh_23, select_12, tanh_24, tanh_25, select_13, tanh_26, tanh_27, select_14, tanh_28, tanh_29, select_15, tanh_30, tanh_31, select_16, tanh_32, tanh_33, select_17, tanh_34, tanh_35, select_18, tanh_36, tanh_37, select_19, tanh_38, view_15, bmm, amax, sum_1, logical_not_1, gt, view_30, gt_1, view_32, gt_2, view_34, gt_3, mul_1023, view_36, where_1, gt_4, view_51, gt_5, mul_1216, view_53, gt_6, view_55, gt_7, mul_1272, getitem_11, rsqrt_5, where_2, gt_8, view_72, gt_9, view_74, view_76, where_3, gt_10, view_91, gt_11, mul_1695, view_93, gt_12, view_95, gt_13, mul_1751, view_97, where_4, gt_14, view_112, gt_15, mul_1944, view_114, where_5, gt_16, view_131, gt_17, mul_2141, view_133, gt_18, view_135, gt_19, mul_2197, getitem_33, rsqrt_12, glu, div_7, permute_144, le_1, permute_148, div_8, permute_152, permute_157, permute_158, permute_159, permute_160, permute_166, permute_170, div_9, permute_174, permute_179, permute_180, permute_181, permute_182, permute_188, div_10, permute_192, le_2, permute_196, div_11, permute_200, permute_205, permute_206, permute_207, permute_208, permute_214, permute_218, mul_2310, div_12, permute_222, permute_227, permute_228, permute_229, permute_230, permute_238, div_14, permute_240, le_3, permute_244, div_15, permute_248, permute_253, permute_254, permute_255, permute_256, permute_262, div_16, permute_266, le_4, permute_270, mul_2367, div_17, permute_274, permute_279, permute_280, permute_281, permute_282, permute_290, sub_813, permute_293, permute_297, permute_301, permute_305, unsqueeze_15, tangents_1 = args
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     args.clear()
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     s0 = primals_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_5, (30, 20, 20), (400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_23, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_29, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_35, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_41, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_42, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_43, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_49, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_55, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_61, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_67, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_73, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_79, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_80, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_81, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(primals_82, (50, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_1, (20*s0, 10), (10, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_4, (20*s0, 20), (20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(repeat, (30*s0, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_8, (1, 30*s0, 20), (600*s0, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(squeeze_1, (30*s0, ), (1, ))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(full_default, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(full_default_1, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_1, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_1, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_2, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_3, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_2, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_4, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_5, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_3, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_6, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_7, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_4, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_8, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_9, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_5, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_10, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_11, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_6, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_12, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_13, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_7, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_14, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_15, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_8, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_16, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_17, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_9, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_18, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_19, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_10, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_20, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_21, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_11, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_22, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_23, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_12, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_24, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_25, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_13, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_26, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_27, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_14, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_28, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_29, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_15, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_30, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_31, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_16, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_32, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_33, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_17, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_34, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_35, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_18, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_36, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_37, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(select_19, (s0, 30), (600, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tanh_38, (s0, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_15, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(bmm, (5*s0, 20, 20), (400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(amax, (s0, 5, 20, 1), (100, 20, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(sum_1, (s0, 5, 20, 1), (100, 20, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(logical_not_1, (s0, 5, 20, 1), (100, 20, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_30, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_1, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_32, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_2, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_34, (20*s0, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_3, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1023, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_36, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(where_1, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_4, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_51, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_5, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1216, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_53, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_6, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_55, (20*s0, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_7, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1272, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(getitem_11, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(rsqrt_5, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(where_2, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_8, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_72, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_9, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_74, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_76, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(where_3, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_10, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_91, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_11, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1695, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_93, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_12, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_95, (20*s0, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_13, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1751, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_97, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(where_4, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_14, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_112, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_15, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_1944, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_114, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(where_5, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_16, (s0, 5, 20, 20), (2000, 400, 20, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_131, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_17, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_2141, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_133, (20*s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_18, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(view_135, (20*s0, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(gt_19, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_2197, (20, s0, 50), (50*s0, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(getitem_33, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(rsqrt_12, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(glu, (s0, 10, 50), (50, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_7, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_144, (50, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(le_1, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_148, (2048, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_8, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_152, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_157, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_158, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_159, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_160, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_166, (100, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_170, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_9, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_174, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_179, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_180, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_181, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_182, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_188, (150, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_10, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_192, (50, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(le_2, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_196, (2048, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_11, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_200, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_205, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_206, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_207, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_208, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_214, (100, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_218, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_2310, (20, s0, 50), (50, 1000, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_12, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_222, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_227, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_228, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_229, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_230, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_238, (150, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_14, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_240, (50, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(le_3, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_244, (2048, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_15, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_248, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_253, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_254, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_255, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_256, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_262, (150, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_16, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_266, (50, 2048), (2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(le_4, (20, s0, 2048), (2048*s0, 2048, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_270, (2048, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(mul_2367, (20, s0, 50), (50, 1000, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(div_17, (20, s0, 1), (s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_274, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_279, (5*s0, 20, 20), (400, 1, 20))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_280, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_281, (5*s0, 10, 20), (10, 1, 50*s0))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_282, (5*s0, 20, 10), (10, 50*s0, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_290, (150, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(sub_813, (s0, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_293, (50, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_297, (50, 50), (50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_301, (40, 30), (30, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(permute_305, (40, 40), (40, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(unsqueeze_15, (1, 30*s0, 1), (30*s0, 1, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     assert_size_stride(tangents_1, (s0, 10, 50), (500, 50, 1))
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         torch.cuda.set_device(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf252 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_19, buf252, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf266 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_18, buf266, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf279 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_17, buf279, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf292 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1.run(select_16, buf292, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf305 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_15, buf305, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf318 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_14, buf318, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf332 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_13, buf332, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf345 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1.run(select_12, buf345, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf360 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_11, buf360, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf373 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_10, buf373, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf386 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_9, buf386, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf399 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1.run(select_8, buf399, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf413 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_7, buf413, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf426 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_6, buf426, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf439 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_5, buf439, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf452 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1.run(select_4, buf452, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf467 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_3, buf467, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf480 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_2, buf480, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf494 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_mm_0.run(select_1, buf494, triton_poi_fused_mm_0_xnumel, grid=grid(triton_poi_fused_mm_0_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf509 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_1.run(select, buf509, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del select
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf0 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_22, output_1], Original ATen: [aten.native_layer_norm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_layer_norm_2_xnumel = 1000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_layer_norm_2.run(mul_2197, primals_79, primals_80, getitem_33, rsqrt_12, buf0, triton_poi_fused_native_layer_norm_2_xnumel, grid=grid(triton_poi_fused_native_layer_norm_2_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del getitem_33
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_80
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         ps0 = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf3 = empty_strided_cuda((s0, 20, 50), (1000, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf1 = reinterpret_tensor(buf3, (s0, 10, 50), (1000, 50, 1), 500)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf2 = reinterpret_tensor(buf3, (s0, 10, 50), (1000, 50, 1), 0)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_25, x_26], Original ATen: [aten.relu, aten.mish, aten.sigmoid, aten.mul, aten.fill, aten.sub, aten.add, aten.threshold_backward, aten.glu_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3_xnumel = 500*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3.run(buf0, primals_81, primals_82, glu, tangents_1, buf1, buf2, s0, ps0, triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3_xnumel, grid=grid(triton_poi_fused_add_fill_glu_backward_mish_mul_relu_sigmoid_sub_threshold_backward_3_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del glu
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_82
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tangents_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf7 = empty_strided_cuda((50, 2), (1, 50), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf9 = empty_strided_cuda((50, 2), (1, 50), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_4_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_4.run(buf3, buf0, buf7, buf9, s0, 100, triton_red_fused_native_layer_norm_backward_4_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf8 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf7, buf8, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf10 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf9, buf10, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf4 = empty_strided_cuda((20, s0, 1), (1, 20, 20*s0), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf5 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_6_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_6.run(buf3, primals_81, buf0, buf4, buf5, s0, triton_per_fused_native_layer_norm_backward_6_xnumel, 50, grid=grid(triton_per_fused_native_layer_norm_backward_6_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf6 = buf0; del buf0  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf13 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf18 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_7_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_7.run(buf6, rsqrt_12, buf3, primals_81, buf4, buf5, primals_79, mul_2197, div_7, gt_19, buf13, buf18, s0, triton_per_fused_native_dropout_backward_native_layer_norm_backward_7_xnumel, 50, grid=grid(triton_per_fused_native_dropout_backward_native_layer_norm_backward_7_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_79
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_81
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del rsqrt_12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf14 = buf9; del buf9  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf16 = buf7; del buf7  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8.run(buf6, mul_2197, buf14, buf16, s0, 100, triton_red_fused_native_layer_norm_backward_8_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_2197
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf15 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf14, buf15, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf17 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf16, buf17, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf21 = reinterpret_tensor(buf16, (1, 50, 2), (100, 1, 50), 0); del buf16  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf18, buf21, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf22 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf21, buf22, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf20 = empty_strided_cuda((50, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (50, 20*s0), (1, 50), 0), view_135, out=buf20)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_135
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf19 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (20*s0, 50), (50, 1), 0), permute_144, out=buf19)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_144
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf23 = reinterpret_tensor(buf19, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf19  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel = 40960*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10.run(buf23, le_1, gt_18, triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del le_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf24 = reinterpret_tensor(buf18, (20*s0, 50), (50, 1), 0); del buf18  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0), permute_148, out=buf24)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_148
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf31 = reinterpret_tensor(buf21, (50, 2), (1, 50), 0); del buf21  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf33 = buf14; del buf14  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf13, buf24, mul_2141, buf31, buf33, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf30 = buf13; del buf13  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf35 = buf6; del buf6  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf30, buf24, primals_73, mul_2141, div_8, gt_17, buf35, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_2141
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_73
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf37 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (50, 20*s0), (1, 50), 0), view_131, out=buf37)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_131
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf32 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf31, buf32, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf34 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf33, buf34, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf38 = reinterpret_tensor(buf33, (1, 50, 2), (100, 1, 50), 0); del buf33  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf35, buf38, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf36 = buf24; del buf24  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (20*s0, 50), (50, 1), 0), permute_152, out=buf36)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_152
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf40 = reinterpret_tensor(buf35, (5*s0, 20, 10), (200, 10, 1), 0); del buf35  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_157, reinterpret_tensor(buf36, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf40)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_157
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf39 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf38, buf39, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf41 = empty_strided_cuda((5*s0, 20, 20), (400, 20, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf36, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_158, out=buf41)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_158
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf43 = where_5; del where_5  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13.run(buf43, buf41, gt_16, triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel, 20, grid=grid(triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf44 = reinterpret_tensor(buf36, (5*s0, 10, 20), (200, 20, 1), 0); del buf36  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_159, reinterpret_tensor(buf43, (5*s0, 20, 20), (400, 20, 1), 0), out=buf44)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_159
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf45 = reinterpret_tensor(buf3, (5*s0, 20, 10), (200, 10, 1), 0); del buf3  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf43, (5*s0, 20, 20), (400, 20, 1), 0), permute_160, out=buf45)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_160
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf46 = reinterpret_tensor(buf43, (20, s0, 2, 50), (100*s0, 100, 50, 1), 0); del buf43  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_14.run(buf40, buf44, buf46, ps0, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf51 = reinterpret_tensor(buf44, (20*s0, 50), (50, 1), 0); del buf44  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_view_15.run(buf45, buf51, ps0, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf59 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf53 = reinterpret_tensor(buf59, (50, 50), (50, 1), 0)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf51, (50, 20*s0), (1, 50), 0), view_114, out=buf53)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_114
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf54 = buf38; del buf38  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf51, buf54, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf52 = reinterpret_tensor(buf45, (20*s0, 50), (50, 1), 0); del buf45  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf51, permute_170, out=buf52)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_170
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf58 = empty_strided_cuda((150, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf56 = reinterpret_tensor(buf58, (50, ), (1, ), 0)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf54, buf56, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf49 = empty_strided_cuda((1, 100, 2), (200, 1, 100), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_17.run(buf46, buf49, s0, 200, triton_red_fused_sum_17_r0_numel, grid=grid(200), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf57 = reinterpret_tensor(buf58, (100, ), (1, ), 50)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf49, buf57, 100, 2, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf63 = reinterpret_tensor(buf54, (50, 2), (1, 50), 0); del buf54  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf65 = buf31; del buf31  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf30, buf52, mul_1944, buf63, buf65, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf62 = buf30; del buf30  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf67 = reinterpret_tensor(buf51, (20, s0, 50), (50*s0, 50, 1), 0); del buf51  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf62, buf52, primals_67, mul_1944, div_9, gt_15, buf67, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1944
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_67
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf69 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf67, (50, 20*s0), (1, 50), 0), view_112, out=buf69)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_112
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf64 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf63, buf64, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf66 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf65, buf66, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf70 = reinterpret_tensor(buf65, (1, 50, 2), (100, 1, 50), 0); del buf65  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf67, buf70, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf68 = buf52; del buf52  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf67, (20*s0, 50), (50, 1), 0), permute_174, out=buf68)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_174
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf72 = reinterpret_tensor(buf67, (5*s0, 20, 10), (200, 10, 1), 0); del buf67  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_179, reinterpret_tensor(buf68, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf72)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_179
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf71 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf70, buf71, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf73 = buf41; del buf41  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf68, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_180, out=buf73)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_180
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf75 = where_4; del where_4  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13.run(buf75, buf73, gt_14, triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel, 20, grid=grid(triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf73
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf76 = reinterpret_tensor(buf68, (5*s0, 10, 20), (200, 20, 1), 0); del buf68  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_181, reinterpret_tensor(buf75, (5*s0, 20, 20), (400, 20, 1), 0), out=buf76)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_181
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf77 = buf40; del buf40  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf75, (5*s0, 20, 20), (400, 20, 1), 0), permute_182, out=buf77)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf75
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_182
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf78 = empty_strided_cuda((20, s0, 3, 50), (150*s0, 150, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19.run(buf72, buf76, buf77, buf78, ps0, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf80 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf78, (150, 20*s0), (1, 150), 0), view_97, out=buf80)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_97
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf81 = empty_strided_cuda((1, 150, 2), (300, 1, 150), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_20.run(buf78, buf81, s0, 300, triton_red_fused_sum_20_r0_numel, grid=grid(300), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf79 = reinterpret_tensor(buf77, (20*s0, 50), (50, 1), 0); del buf77  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf78, (20*s0, 150), (150, 1), 0), permute_188, out=buf79)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_188
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf82 = empty_strided_cuda((1, 150), (150, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_21.run(buf81, buf82, 150, 2, grid=grid(150), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf86 = reinterpret_tensor(buf70, (50, 2), (1, 50), 0); del buf70  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf88 = buf63; del buf63  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf62, buf79, mul_1751, buf86, buf88, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf85 = buf62; del buf62  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf90 = reinterpret_tensor(buf76, (20, s0, 50), (50*s0, 50, 1), 0); del buf76  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf85, buf79, primals_61, mul_1751, div_10, gt_13, buf90, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1751
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_61
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf92 = empty_strided_cuda((50, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf90, (50, 20*s0), (1, 50), 0), view_95, out=buf92)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_95
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf87 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf86, buf87, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf89 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf88, buf89, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf93 = reinterpret_tensor(buf88, (1, 50, 2), (100, 1, 50), 0); del buf88  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf90, buf93, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf94 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf93, buf94, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf26 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22.run(buf23, buf26, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf25 = empty_strided_cuda((2048, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (2048, 20*s0), (1, 2048), 0), view_133, out=buf25)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_133
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf27 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_23.run(buf26, buf27, 2048, 2, grid=grid(2048), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf47 = buf79; del buf79  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf46, (20*s0, 100), (100, 1), 0), permute_166, out=buf47)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_166
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf48 = reinterpret_tensor(buf59, (100, 50), (50, 1), 2500)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf46, (100, 20*s0), (1, 100), 0), view_76, out=buf48)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf91 = reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0); del buf23  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf90, (20*s0, 50), (50, 1), 0), permute_192, out=buf91)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_192
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf95 = reinterpret_tensor(buf91, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf91  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel = 40960*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10.run(buf95, le_2, gt_12, triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del le_2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf96 = reinterpret_tensor(buf90, (20*s0, 50), (50, 1), 0); del buf90  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf95, (20*s0, 2048), (2048, 1), 0), permute_196, out=buf96)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_196
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf103 = reinterpret_tensor(buf93, (50, 2), (1, 50), 0); del buf93  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf105 = buf86; del buf86  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf85, buf96, mul_1695, buf103, buf105, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf102 = buf85; del buf85  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf107 = reinterpret_tensor(buf72, (20, s0, 50), (50*s0, 50, 1), 0); del buf72  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf102, buf96, primals_55, mul_1695, div_11, gt_11, buf107, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1695
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_55
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf109 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (50, 20*s0), (1, 50), 0), view_91, out=buf109)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_91
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf104 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf103, buf104, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf106 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf105, buf106, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf110 = reinterpret_tensor(buf105, (1, 50, 2), (100, 1, 50), 0); del buf105  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf107, buf110, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf108 = buf96; del buf96  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (20*s0, 50), (50, 1), 0), permute_200, out=buf108)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_200
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf112 = reinterpret_tensor(buf107, (5*s0, 20, 10), (200, 10, 1), 0); del buf107  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_205, reinterpret_tensor(buf108, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf112)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_205
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf111 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf110, buf111, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf113 = reinterpret_tensor(buf46, (5*s0, 20, 20), (400, 20, 1), 0); del buf46  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf108, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_206, out=buf113)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_206
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf115 = where_3; del where_3  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13.run(buf115, buf113, gt_10, triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel, 20, grid=grid(triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf113
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf116 = reinterpret_tensor(buf108, (5*s0, 10, 20), (200, 20, 1), 0); del buf108  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_207, reinterpret_tensor(buf115, (5*s0, 20, 20), (400, 20, 1), 0), out=buf116)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_207
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf117 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf115, (5*s0, 20, 20), (400, 20, 1), 0), permute_208, out=buf117)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_208
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf118 = reinterpret_tensor(buf115, (20, s0, 2, 50), (100*s0, 100, 50, 1), 0); del buf115  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_14.run(buf112, buf116, buf118, ps0, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf131 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf120 = reinterpret_tensor(buf131, (100, 50), (50, 1), 2500)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf118, (100, 20*s0), (1, 100), 0), view_76, out=buf120)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_76
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf123 = reinterpret_tensor(buf116, (20*s0, 50), (50, 1), 0); del buf116  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_view_15.run(buf117, buf123, ps0, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf125 = reinterpret_tensor(buf131, (50, 50), (50, 1), 0)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf123, (50, 20*s0), (1, 50), 0), view_74, out=buf125)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_74
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf126 = buf110; del buf110  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf123, buf126, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf124 = reinterpret_tensor(buf117, (20*s0, 50), (50, 1), 0); del buf117  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf123, permute_218, out=buf124)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_218
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf130 = empty_strided_cuda((150, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf128 = reinterpret_tensor(buf130, (50, ), (1, ), 0)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf126, buf128, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf121 = buf49; del buf49  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_17.run(buf118, buf121, s0, 200, triton_red_fused_sum_17_r0_numel, grid=grid(200), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf119 = buf123; del buf123  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf118, (20*s0, 100), (100, 1), 0), permute_214, out=buf119)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_214
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf129 = reinterpret_tensor(buf130, (100, ), (1, ), 50)  # alias
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf121, buf129, 100, 2, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf121
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf135 = reinterpret_tensor(buf126, (50, 2), (1, 50), 0); del buf126  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf137 = buf103; del buf103  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_24_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_24.run(buf102, buf124, mul_2310, buf135, buf137, s0, 100, triton_red_fused_add_native_layer_norm_backward_24_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf134 = buf102; del buf102  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf139 = reinterpret_tensor(buf112, (20, s0, 50), (50*s0, 50, 1), 0); del buf112  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25.run(buf134, buf124, primals_49, mul_2310, div_12, gt_9, buf139, s0, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_2310
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_49
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf141 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf139, (50, 20*s0), (1, 50), 0), view_72, out=buf141)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_72
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf136 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf135, buf136, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf138 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf137, buf138, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf142 = reinterpret_tensor(buf137, (1, 50, 2), (100, 1, 50), 0); del buf137  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf139, buf142, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf140 = buf124; del buf124  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf139, (20*s0, 50), (50, 1), 0), permute_222, out=buf140)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_222
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf144 = reinterpret_tensor(buf139, (5*s0, 20, 10), (200, 10, 1), 0); del buf139  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_227, reinterpret_tensor(buf140, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf144)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_227
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf143 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf142, buf143, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf145 = reinterpret_tensor(buf118, (5*s0, 20, 20), (400, 20, 1), 0); del buf118  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf140, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_228, out=buf145)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_228
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf147 = where_2; del where_2  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13.run(buf147, buf145, gt_8, triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel, 20, grid=grid(triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf145
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf148 = reinterpret_tensor(buf140, (5*s0, 10, 20), (200, 20, 1), 0); del buf140  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_229, reinterpret_tensor(buf147, (5*s0, 20, 20), (400, 20, 1), 0), out=buf148)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_229
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf149 = empty_strided_cuda((5*s0, 20, 10), (200, 10, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf147, (5*s0, 20, 20), (400, 20, 1), 0), permute_230, out=buf149)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_230
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf150 = reinterpret_tensor(buf81, (1, 1, 150, 2), (300, 300, 1, 150), 0); del buf81  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_26_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_26.run(buf144, buf148, buf149, buf150, ps0, s0, 300, triton_red_fused_sum_26_r0_numel, grid=grid(300), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf151 = empty_strided_cuda((1, 1, 150), (150, 150, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_21.run(buf150, buf151, 150, 2, grid=grid(150), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf152 = buf78; del buf78  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19.run(buf144, buf148, buf149, buf152, ps0, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf154 = reinterpret_tensor(buf149, (20*s0, 50), (50, 1), 0); del buf149  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf152, (20*s0, 150), (150, 1), 0), permute_238, out=buf154)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_238
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf153 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf152, (150, 20*s0), (1, 150), 0), view_15, out=buf153)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf98 = buf26; del buf26  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22.run(buf95, buf98, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf97 = empty_strided_cuda((2048, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf95, (2048, 20*s0), (1, 2048), 0), view_93, out=buf97)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_93
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf99 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_23.run(buf98, buf99, 2048, 2, grid=grid(2048), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf156 = reinterpret_tensor(buf148, (20, s0, 50), (50*s0, 50, 1), 0); del buf148  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf158 = reinterpret_tensor(buf144, (20, s0, 50), (50*s0, 50, 1), 0); del buf144  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf165 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf170 = empty_strided_cuda((20, s0, 50), (50*s0, 50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14, output], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27.run(mul_1272, primals_41, primals_42, getitem_11, rsqrt_5, buf47, buf119, primals_43, div_14, gt_7, buf156, buf158, buf165, buf170, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_27_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del getitem_11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_41
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_42
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_43
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del rsqrt_5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf172 = empty_strided_cuda((50, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf170, (50, 20*s0), (1, 50), 0), view_55, out=buf172)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_55
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf159 = reinterpret_tensor(buf142, (50, 2), (1, 50), 0); del buf142  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf161 = buf135; del buf135  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf47, buf119, buf156, buf159, buf161, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf119
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf156
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf166 = empty_strided_cuda((50, 2), (1, 50), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf168 = empty_strided_cuda((50, 2), (1, 50), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8.run(buf158, mul_1272, buf166, buf168, s0, 100, triton_red_fused_native_layer_norm_backward_8_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1272
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf160 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf159, buf160, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf159
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf162 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf161, buf162, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf161
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf167 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf166, buf167, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf169 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf168, buf169, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf173 = reinterpret_tensor(buf168, (1, 50, 2), (100, 1, 50), 0); del buf168  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf170, buf173, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf174 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf173, buf174, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf171 = reinterpret_tensor(buf95, (20*s0, 2048), (2048, 1), 0); del buf95  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf170, (20*s0, 50), (50, 1), 0), permute_240, out=buf171)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_240
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf175 = reinterpret_tensor(buf171, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf171  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel = 40960*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10.run(buf175, le_3, gt_6, triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del le_3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf176 = reinterpret_tensor(buf170, (20*s0, 50), (50, 1), 0); del buf170  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf175, (20*s0, 2048), (2048, 1), 0), permute_244, out=buf176)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_244
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf183 = reinterpret_tensor(buf173, (50, 2), (1, 50), 0); del buf173  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf185 = buf166; del buf166  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf165, buf176, mul_1216, buf183, buf185, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf182 = buf165; del buf165  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf187 = buf158; del buf158  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf182, buf176, primals_35, mul_1216, div_15, gt_5, buf187, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1216
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_35
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf189 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf187, (50, 20*s0), (1, 50), 0), view_51, out=buf189)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_51
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf184 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf183, buf184, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf186 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf185, buf186, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf190 = reinterpret_tensor(buf185, (1, 50, 2), (100, 1, 50), 0); del buf185  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf187, buf190, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf188 = buf176; del buf176  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf187, (20*s0, 50), (50, 1), 0), permute_248, out=buf188)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_248
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf192 = reinterpret_tensor(buf187, (5*s0, 20, 10), (200, 10, 1), 0); del buf187  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_253, reinterpret_tensor(buf188, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf192)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_253
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf191 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf190, buf191, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf193 = reinterpret_tensor(buf147, (5*s0, 20, 20), (400, 20, 1), 0); del buf147  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf188, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_254, out=buf193)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_254
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf195 = where_1; del where_1  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__softmax_backward_data_native_dropout_backward_13.run(buf195, buf193, gt_4, triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel, 20, grid=grid(triton_per_fused__softmax_backward_data_native_dropout_backward_13_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf193
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf196 = reinterpret_tensor(buf188, (5*s0, 10, 20), (200, 20, 1), 0); del buf188  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_255, reinterpret_tensor(buf195, (5*s0, 20, 20), (400, 20, 1), 0), out=buf196)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_255
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf197 = reinterpret_tensor(buf47, (5*s0, 20, 10), (200, 10, 1), 0); del buf47  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf195, (5*s0, 20, 20), (400, 20, 1), 0), permute_256, out=buf197)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_256
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf198 = buf152; del buf152  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19.run(buf192, buf196, buf197, buf198, ps0, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf200 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf198, (150, 20*s0), (1, 150), 0), view_36, out=buf200)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_36
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf201 = reinterpret_tensor(buf150, (1, 150, 2), (300, 1, 150), 0); del buf150  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_20.run(buf198, buf201, s0, 300, triton_red_fused_sum_20_r0_numel, grid=grid(300), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf199 = reinterpret_tensor(buf197, (20*s0, 50), (50, 1), 0); del buf197  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf198, (20*s0, 150), (150, 1), 0), permute_262, out=buf199)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_262
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf202 = empty_strided_cuda((1, 150), (150, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_21.run(buf201, buf202, 150, 2, grid=grid(150), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf206 = reinterpret_tensor(buf190, (50, 2), (1, 50), 0); del buf190  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf208 = buf183; del buf183  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_11.run(buf182, buf199, mul_1023, buf206, buf208, s0, 100, triton_red_fused_add_native_layer_norm_backward_11_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf205 = buf182; del buf182  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf210 = reinterpret_tensor(buf196, (20, s0, 50), (50*s0, 50, 1), 0); del buf196  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12.run(buf205, buf199, primals_29, mul_1023, div_16, gt_3, buf210, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_1023
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf212 = empty_strided_cuda((50, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (50, 20*s0), (1, 50), 0), view_34, out=buf212)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_34
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf207 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf206, buf207, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf209 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf208, buf209, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf213 = reinterpret_tensor(buf208, (1, 50, 2), (100, 1, 50), 0); del buf208  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf210, buf213, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf214 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf213, buf214, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf178 = buf98; del buf98  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22.run(buf175, buf178, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf177 = empty_strided_cuda((2048, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf175, (2048, 20*s0), (1, 2048), 0), view_53, out=buf177)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_53
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf179 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_23.run(buf178, buf179, 2048, 2, grid=grid(2048), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf211 = reinterpret_tensor(buf175, (20*s0, 2048), (2048, 1), 0); del buf175  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (20*s0, 50), (50, 1), 0), permute_266, out=buf211)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_266
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf215 = reinterpret_tensor(buf211, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf211  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel = 40960*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_10.run(buf215, le_4, gt_2, triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_10_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del le_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf216 = reinterpret_tensor(buf210, (20*s0, 50), (50, 1), 0); del buf210  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf215, (20*s0, 2048), (2048, 1), 0), permute_270, out=buf216)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_270
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf223 = reinterpret_tensor(buf213, (50, 2), (1, 50), 0); del buf213  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf225 = buf206; del buf206  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_24_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_24.run(buf205, buf216, mul_2367, buf223, buf225, s0, 100, triton_red_fused_add_native_layer_norm_backward_24_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf222 = buf205; del buf205  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf227 = reinterpret_tensor(buf199, (20, s0, 50), (50*s0, 50, 1), 0); del buf199  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25.run(buf222, buf216, primals_23, mul_2367, div_17, gt_1, buf227, s0, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel, 50, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_25_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del div_17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del mul_2367
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_23
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf229 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf227, (50, 20*s0), (1, 50), 0), view_30, out=buf229)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf224 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf223, buf224, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf223
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf226 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf225, buf226, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf230 = reinterpret_tensor(buf225, (1, 50, 2), (100, 1, 50), 0); del buf225  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_9.run(buf227, buf230, s0, 100, triton_red_fused_sum_9_r0_numel, grid=grid(100), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf228 = buf216; del buf216  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf227, (20*s0, 50), (50, 1), 0), permute_274, out=buf228)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_274
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf232 = reinterpret_tensor(buf227, (5*s0, 20, 10), (200, 10, 1), 0); del buf227  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_279, reinterpret_tensor(buf228, (5*s0, 20, 10), (10, 50*s0, 1), 0), out=buf232)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_279
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf231 = empty_strided_cuda((1, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf230, buf231, 50, 2, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf230
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf233 = reinterpret_tensor(buf195, (5*s0, 20, 20), (400, 20, 1), 0); del buf195  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf228, (5*s0, 20, 10), (10, 50*s0, 1), 0), permute_280, out=buf233)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_280
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf234 = reinterpret_tensor(buf233, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del buf233  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf236 = reinterpret_tensor(bmm, (s0, 5, 20, 20), (2000, 400, 20, 1), 0); del bmm  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.native_dropout_backward, aten._safe_softmax, aten._softmax_backward_data]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28_xnumel = 100*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28.run(buf234, buf236, gt, logical_not_1, amax, sum_1, triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28_xnumel, 20, grid=grid(triton_per_fused__safe_softmax__softmax_backward_data_native_dropout_backward_28_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del amax
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf234
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del gt
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del logical_not_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del sum_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf237 = reinterpret_tensor(buf228, (5*s0, 10, 20), (200, 20, 1), 0); del buf228  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(permute_281, reinterpret_tensor(buf236, (5*s0, 20, 20), (400, 20, 1), 0), out=buf237)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_281
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf238 = buf192; del buf192  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.bmm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf236, (5*s0, 20, 20), (400, 20, 1), 0), permute_282, out=buf238)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf236
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_282
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf239 = reinterpret_tensor(buf201, (1, 1, 150, 2), (300, 300, 1, 150), 0); del buf201  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_26_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_26.run(buf232, buf237, buf238, buf239, ps0, s0, 300, triton_red_fused_sum_26_r0_numel, grid=grid(300), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf240 = empty_strided_cuda((1, 1, 150), (150, 150, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_21.run(buf239, buf240, 150, 2, grid=grid(150), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf239
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf241 = buf198; del buf198  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3000*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_19.run(buf232, buf237, buf238, buf241, ps0, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf232
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf237
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf242 = empty_strided_cuda((150, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf241, (150, 20*s0), (1, 150), 0), view_15, out=buf242)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf243 = reinterpret_tensor(buf238, (20*s0, 50), (50, 1), 0); del buf238  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf241, (20*s0, 150), (150, 1), 0), permute_290, out=buf243)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf241
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_290
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf244 = sub_813; del sub_813  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_tanh_backward_29_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_tanh_backward_29.run(buf244, buf134, buf154, buf222, buf243, s0, triton_poi_fused_tanh_backward_29_xnumel, grid=grid(triton_poi_fused_tanh_backward_29_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf245 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf244, permute_293, out=buf245)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf250 = buf245; del buf245  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_tanh_backward_30_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_tanh_backward_30.run(buf250, tanh_38, triton_poi_fused_tanh_backward_30_xnumel, grid=grid(triton_poi_fused_tanh_backward_30_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf251 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf250, permute_301, out=buf251)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf255 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf250, permute_305, out=buf255)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf248 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf244, permute_297, out=buf248)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf257 = buf248; del buf248  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_31_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_31.run(buf257, buf134, buf154, buf222, buf243, tanh_37, s0, triton_poi_fused_add_tanh_backward_31_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_31_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf258 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf257, permute_293, out=buf258)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf263 = buf255; del buf255  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf263, buf258, tanh_36, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf264 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf263, permute_301, out=buf264)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf268 = buf258; del buf258  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf263, permute_305, out=buf268)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf261 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf257, permute_297, out=buf261)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf270 = buf261; del buf261  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_33_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_33.run(buf270, buf134, buf154, buf222, buf243, tanh_35, s0, triton_poi_fused_add_tanh_backward_33_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_33_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf271 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf270, permute_293, out=buf271)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf276 = buf268; del buf268  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf276, buf271, tanh_34, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf277 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf276, permute_301, out=buf277)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf281 = buf271; del buf271  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf276, permute_305, out=buf281)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf274 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf270, permute_297, out=buf274)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf283 = buf274; del buf274  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_34_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_34.run(buf283, buf134, buf154, buf222, buf243, tanh_33, s0, triton_poi_fused_add_tanh_backward_34_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_34_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf284 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf283, permute_293, out=buf284)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf289 = buf281; del buf281  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf289, buf284, tanh_32, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf290 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf289, permute_301, out=buf290)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf294 = buf284; del buf284  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf289, permute_305, out=buf294)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf287 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf283, permute_297, out=buf287)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf296 = buf287; del buf287  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_35_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_35.run(buf296, buf134, buf154, buf222, buf243, tanh_31, s0, triton_poi_fused_add_tanh_backward_35_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_35_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf297 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf296, permute_293, out=buf297)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf302 = buf294; del buf294  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf302, buf297, tanh_30, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf303 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf302, permute_301, out=buf303)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf307 = buf297; del buf297  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf302, permute_305, out=buf307)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf300 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf296, permute_297, out=buf300)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf309 = buf300; del buf300  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_36_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_36.run(buf309, buf134, buf154, buf222, buf243, tanh_29, s0, triton_poi_fused_add_tanh_backward_36_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_36_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf310 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf309, permute_293, out=buf310)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf315 = buf307; del buf307  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf315, buf310, tanh_28, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf316 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf315, permute_301, out=buf316)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf320 = buf310; del buf310  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf315, permute_305, out=buf320)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf313 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf309, permute_297, out=buf313)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf323 = buf313; del buf313  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_37_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_37.run(buf323, buf134, buf154, buf222, buf243, tanh_27, s0, triton_poi_fused_add_tanh_backward_37_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_37_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf324 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf323, permute_293, out=buf324)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf329 = buf320; del buf320  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf329, buf324, tanh_26, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf330 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf329, permute_301, out=buf330)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf334 = buf324; del buf324  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf329, permute_305, out=buf334)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf327 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf323, permute_297, out=buf327)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf336 = buf327; del buf327  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_38_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_38.run(buf336, buf134, buf154, buf222, buf243, tanh_25, s0, triton_poi_fused_add_tanh_backward_38_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_38_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf337 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf336, permute_293, out=buf337)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf342 = buf334; del buf334  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf342, buf337, tanh_24, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf343 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf342, permute_301, out=buf343)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf347 = buf337; del buf337  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf342, permute_305, out=buf347)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf340 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf336, permute_297, out=buf340)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf349 = buf340; del buf340  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_39_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_39.run(buf349, buf134, buf154, buf222, buf243, tanh_23, s0, triton_poi_fused_add_tanh_backward_39_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_39_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf350 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf349, permute_293, out=buf350)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf356 = buf347; del buf347  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf356, buf350, tanh_22, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf357 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf356, permute_301, out=buf357)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf362 = buf350; del buf350  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf356, permute_305, out=buf362)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf354 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf349, permute_297, out=buf354)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf364 = buf354; del buf354  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_40_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_40.run(buf364, buf134, buf154, buf222, buf243, tanh_21, s0, triton_poi_fused_add_tanh_backward_40_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_40_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf365 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf364, permute_293, out=buf365)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf370 = buf362; del buf362  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf370, buf365, tanh_20, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf371 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf370, permute_301, out=buf371)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf375 = buf365; del buf365  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf370, permute_305, out=buf375)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf368 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf364, permute_297, out=buf368)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf377 = buf368; del buf368  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_41_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_41.run(buf377, buf134, buf154, buf222, buf243, tanh_19, s0, triton_poi_fused_add_tanh_backward_41_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_41_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf378 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf377, permute_293, out=buf378)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf383 = buf375; del buf375  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf383, buf378, tanh_18, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf384 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf383, permute_301, out=buf384)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf388 = buf378; del buf378  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf383, permute_305, out=buf388)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf381 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf377, permute_297, out=buf381)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf390 = buf381; del buf381  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_42_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_42.run(buf390, buf134, buf154, buf222, buf243, tanh_17, s0, triton_poi_fused_add_tanh_backward_42_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_42_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf391 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf390, permute_293, out=buf391)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf396 = buf388; del buf388  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf396, buf391, tanh_16, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf397 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf396, permute_301, out=buf397)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf401 = buf391; del buf391  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf396, permute_305, out=buf401)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf394 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf390, permute_297, out=buf394)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf404 = buf394; del buf394  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_43_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_43.run(buf404, buf134, buf154, buf222, buf243, tanh_15, s0, triton_poi_fused_add_tanh_backward_43_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_43_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf405 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf404, permute_293, out=buf405)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf410 = buf401; del buf401  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf410, buf405, tanh_14, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf411 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf410, permute_301, out=buf411)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf415 = buf405; del buf405  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf410, permute_305, out=buf415)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf408 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf404, permute_297, out=buf408)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf417 = buf408; del buf408  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_44_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_44.run(buf417, buf134, buf154, buf222, buf243, tanh_13, s0, triton_poi_fused_add_tanh_backward_44_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_44_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf418 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf417, permute_293, out=buf418)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf423 = buf415; del buf415  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf423, buf418, tanh_12, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf424 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf423, permute_301, out=buf424)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf428 = buf418; del buf418  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf423, permute_305, out=buf428)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf421 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf417, permute_297, out=buf421)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf430 = buf421; del buf421  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_45_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_45.run(buf430, buf134, buf154, buf222, buf243, tanh_11, s0, triton_poi_fused_add_tanh_backward_45_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_45_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf431 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf430, permute_293, out=buf431)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf436 = buf428; del buf428  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf436, buf431, tanh_10, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf437 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf436, permute_301, out=buf437)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf441 = buf431; del buf431  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf436, permute_305, out=buf441)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf434 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf430, permute_297, out=buf434)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf443 = buf434; del buf434  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_46_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_46.run(buf443, buf134, buf154, buf222, buf243, tanh_9, s0, triton_poi_fused_add_tanh_backward_46_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_46_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf444 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf443, permute_293, out=buf444)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf449 = buf441; del buf441  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf449, buf444, tanh_8, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf450 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf449, permute_301, out=buf450)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf454 = buf444; del buf444  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf449, permute_305, out=buf454)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf447 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf443, permute_297, out=buf447)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf456 = buf447; del buf447  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_47_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_47.run(buf456, buf134, buf154, buf222, buf243, tanh_7, s0, triton_poi_fused_add_tanh_backward_47_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_47_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf457 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf456, permute_293, out=buf457)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf463 = buf454; del buf454  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf463, buf457, tanh_6, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf464 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf463, permute_301, out=buf464)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf469 = buf457; del buf457  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf463, permute_305, out=buf469)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf461 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf456, permute_297, out=buf461)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf471 = buf461; del buf461  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_48_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_48.run(buf471, buf134, buf154, buf222, buf243, tanh_5, s0, triton_poi_fused_add_tanh_backward_48_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_48_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf472 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf471, permute_293, out=buf472)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf477 = buf469; del buf469  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf477, buf472, tanh_4, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf478 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf477, permute_301, out=buf478)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf482 = buf472; del buf472  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf477, permute_305, out=buf482)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf475 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf471, permute_297, out=buf475)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf485 = buf475; del buf475  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_49_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_49.run(buf485, buf134, buf154, buf222, buf243, tanh_3, ps0, triton_poi_fused_add_tanh_backward_49_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_49_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf489 = empty_strided_cuda((s0, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf485, permute_297, out=buf489)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_297
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf498 = buf489; del buf489  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_50_xnumel = 50*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_50.run(buf498, buf134, buf154, buf222, buf243, tanh_1, triton_poi_fused_add_tanh_backward_50_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_50_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf134
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf154
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf222
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf243
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf501 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf503 = empty_strided_cuda((50, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_sum_51.run(buf244, buf364, buf257, buf377, buf270, buf390, buf283, buf296, buf404, buf309, buf417, buf471, buf430, buf323, buf485, buf443, buf336, buf498, buf456, buf349, buf501, buf503, 50, s0, grid=grid(50), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf486 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf485, permute_293, out=buf486)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf499 = empty_strided_cuda((s0, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf498, permute_293, out=buf499)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_293
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf491 = buf482; del buf482  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf491, buf486, tanh_2, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf496 = buf486; del buf486  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf491, permute_305, out=buf496)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_305
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf505 = buf496; del buf496  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.tanh_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32_xnumel = 40*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_tanh_backward_32.run(buf505, buf499, tanh, triton_poi_fused_add_tanh_backward_32_xnumel, grid=grid(triton_poi_fused_add_tanh_backward_32_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf499
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf508 = empty_strided_cuda((40, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf511 = empty_strided_cuda((40, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_sum_52.run(buf250, buf370, buf263, buf383, buf276, buf396, buf289, buf302, buf410, buf315, buf423, buf477, buf436, buf329, buf491, buf449, buf342, buf505, buf463, buf356, buf508, buf511, 40, s0, grid=grid(40), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf492 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf491, permute_301, out=buf492)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf506 = empty_strided_cuda((s0, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(buf505, permute_301, out=buf506)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del permute_301
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf322 = empty_strided_cuda((s0, 20, 30), (600, 30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf403 = buf322; del buf322  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf484 = buf403; del buf403  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.select_backward, aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_select_backward_53_xnumel = 600*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_select_backward_53.run(buf484, buf251, buf264, buf277, buf290, buf303, buf316, buf330, buf343, buf357, buf371, buf384, buf397, buf411, buf424, buf437, buf450, buf464, buf478, triton_poi_fused_add_select_backward_53_xnumel, grid=grid(triton_poi_fused_add_select_backward_53_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf251
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf264
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf277
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf290
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf303
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf316
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf330
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf343
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf357
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf371
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf384
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf397
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf411
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf424
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf437
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf450
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf513 = reinterpret_tensor(buf478, (30*s0, ), (1, ), 0); del buf478  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf514 = reinterpret_tensor(buf464, (30*s0, ), (1, ), 0); del buf464  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf515 = view_8; del view_8  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_batch_norm_backward_54_xnumel = 30*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_native_batch_norm_backward_54.run(buf515, buf484, buf492, buf506, unsqueeze_15, squeeze_1, repeat, buf513, buf514, s0, triton_per_fused_native_batch_norm_backward_54_xnumel, 20, grid=grid(triton_per_fused_native_batch_norm_backward_54_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf492
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf506
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del repeat
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del unsqueeze_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf517 = empty_strided_cuda((30, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_55.run(buf514, squeeze_1, buf517, 30, s0, grid=grid(30), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf514
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del squeeze_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf516 = empty_strided_cuda((30, ), (1, ), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_56.run(buf513, buf516, 30, s0, grid=grid(30), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf513
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf518 = empty_strided_cuda((1, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_57_r0_numel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_57.run(buf515, buf518, 30, triton_red_fused_sum_57_r0_numel, grid=grid(30), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf519 = buf484; del buf484  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_58_ynumel = 20*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_clone_58.run(buf515, buf519, triton_poi_fused_clone_58_ynumel, 30, grid=grid(triton_poi_fused_clone_58_ynumel, 30), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf515
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf253 = empty_strided_cuda((40, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf250, (40, s0), (1, 40), 0), buf252, out=buf253)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf252
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf267 = empty_strided_cuda((40, 30), (30, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf253, reinterpret_tensor(buf263, (40, s0), (1, 40), 0), buf266, alpha=1, beta=1, out=buf267)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf266
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf280 = buf253; del buf253  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf267, reinterpret_tensor(buf276, (40, s0), (1, 40), 0), buf279, alpha=1, beta=1, out=buf280)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf279
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf293 = buf267; del buf267  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf280, reinterpret_tensor(buf289, (40, s0), (1, 40), 0), buf292, alpha=1, beta=1, out=buf293)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf292
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf306 = buf280; del buf280  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf293, reinterpret_tensor(buf302, (40, s0), (1, 40), 0), buf305, alpha=1, beta=1, out=buf306)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf305
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf319 = buf293; del buf293  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf306, reinterpret_tensor(buf315, (40, s0), (1, 40), 0), buf318, alpha=1, beta=1, out=buf319)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf318
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf333 = buf306; del buf306  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf319, reinterpret_tensor(buf329, (40, s0), (1, 40), 0), buf332, alpha=1, beta=1, out=buf333)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf332
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf346 = buf319; del buf319  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf333, reinterpret_tensor(buf342, (40, s0), (1, 40), 0), buf345, alpha=1, beta=1, out=buf346)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf345
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf361 = buf333; del buf333  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf346, reinterpret_tensor(buf356, (40, s0), (1, 40), 0), buf360, alpha=1, beta=1, out=buf361)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf360
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf374 = buf346; del buf346  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf361, reinterpret_tensor(buf370, (40, s0), (1, 40), 0), buf373, alpha=1, beta=1, out=buf374)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf373
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf387 = buf361; del buf361  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf374, reinterpret_tensor(buf383, (40, s0), (1, 40), 0), buf386, alpha=1, beta=1, out=buf387)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf386
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf400 = buf374; del buf374  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf387, reinterpret_tensor(buf396, (40, s0), (1, 40), 0), buf399, alpha=1, beta=1, out=buf400)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf399
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf414 = buf387; del buf387  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf400, reinterpret_tensor(buf410, (40, s0), (1, 40), 0), buf413, alpha=1, beta=1, out=buf414)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf413
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf427 = buf400; del buf400  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf414, reinterpret_tensor(buf423, (40, s0), (1, 40), 0), buf426, alpha=1, beta=1, out=buf427)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf426
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf440 = buf414; del buf414  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf427, reinterpret_tensor(buf436, (40, s0), (1, 40), 0), buf439, alpha=1, beta=1, out=buf440)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf439
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf453 = buf427; del buf427  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf440, reinterpret_tensor(buf449, (40, s0), (1, 40), 0), buf452, alpha=1, beta=1, out=buf453)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf452
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf468 = buf440; del buf440  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf453, reinterpret_tensor(buf463, (40, s0), (1, 40), 0), buf467, alpha=1, beta=1, out=buf468)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf467
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf481 = buf453; del buf453  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf468, reinterpret_tensor(buf477, (40, s0), (1, 40), 0), buf480, alpha=1, beta=1, out=buf481)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf480
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf495 = buf468; del buf468  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf481, reinterpret_tensor(buf491, (40, s0), (1, 40), 0), buf494, alpha=1, beta=1, out=buf495)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf494
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf510 = buf481; del buf481  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf495, reinterpret_tensor(buf505, (40, s0), (1, 40), 0), buf509, alpha=1, beta=1, out=buf510)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf495
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf509
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf256 = empty_strided_cuda((40, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf250, (40, s0), (1, 40), 0), tanh_36, out=buf256)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf250
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf269 = empty_strided_cuda((40, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf256, reinterpret_tensor(buf263, (40, s0), (1, 40), 0), tanh_34, alpha=1, beta=1, out=buf269)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf263
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf282 = buf256; del buf256  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf269, reinterpret_tensor(buf276, (40, s0), (1, 40), 0), tanh_32, alpha=1, beta=1, out=buf282)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf276
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf295 = buf269; del buf269  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf282, reinterpret_tensor(buf289, (40, s0), (1, 40), 0), tanh_30, alpha=1, beta=1, out=buf295)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf289
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf308 = buf282; del buf282  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf295, reinterpret_tensor(buf302, (40, s0), (1, 40), 0), tanh_28, alpha=1, beta=1, out=buf308)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf302
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf321 = buf295; del buf295  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf308, reinterpret_tensor(buf315, (40, s0), (1, 40), 0), tanh_26, alpha=1, beta=1, out=buf321)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf315
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf335 = buf308; del buf308  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf321, reinterpret_tensor(buf329, (40, s0), (1, 40), 0), tanh_24, alpha=1, beta=1, out=buf335)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf329
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf348 = buf321; del buf321  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf335, reinterpret_tensor(buf342, (40, s0), (1, 40), 0), tanh_22, alpha=1, beta=1, out=buf348)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf342
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf363 = buf335; del buf335  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf348, reinterpret_tensor(buf356, (40, s0), (1, 40), 0), tanh_20, alpha=1, beta=1, out=buf363)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf356
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf376 = buf348; del buf348  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf363, reinterpret_tensor(buf370, (40, s0), (1, 40), 0), tanh_18, alpha=1, beta=1, out=buf376)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf370
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf389 = buf363; del buf363  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf376, reinterpret_tensor(buf383, (40, s0), (1, 40), 0), tanh_16, alpha=1, beta=1, out=buf389)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf383
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf402 = buf376; del buf376  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf389, reinterpret_tensor(buf396, (40, s0), (1, 40), 0), tanh_14, alpha=1, beta=1, out=buf402)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf396
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf416 = buf389; del buf389  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf402, reinterpret_tensor(buf410, (40, s0), (1, 40), 0), tanh_12, alpha=1, beta=1, out=buf416)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf410
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf429 = buf402; del buf402  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf416, reinterpret_tensor(buf423, (40, s0), (1, 40), 0), tanh_10, alpha=1, beta=1, out=buf429)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf423
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf442 = buf416; del buf416  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf429, reinterpret_tensor(buf436, (40, s0), (1, 40), 0), tanh_8, alpha=1, beta=1, out=buf442)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf436
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf455 = buf429; del buf429  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf442, reinterpret_tensor(buf449, (40, s0), (1, 40), 0), tanh_6, alpha=1, beta=1, out=buf455)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf449
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf470 = buf442; del buf442  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf455, reinterpret_tensor(buf463, (40, s0), (1, 40), 0), tanh_4, alpha=1, beta=1, out=buf470)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf463
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf483 = buf455; del buf455  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf470, reinterpret_tensor(buf477, (40, s0), (1, 40), 0), tanh_2, alpha=1, beta=1, out=buf483)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf477
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf497 = buf470; del buf470  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf483, reinterpret_tensor(buf491, (40, s0), (1, 40), 0), tanh, alpha=1, beta=1, out=buf497)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf491
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf512 = buf483; del buf483  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf497, reinterpret_tensor(buf505, (40, s0), (1, 40), 0), full_default, alpha=1, beta=1, out=buf512)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf497
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf505
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del full_default
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf246 = empty_strided_cuda((50, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf244, (50, s0), (1, 50), 0), tanh_38, out=buf246)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_38
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf260 = empty_strided_cuda((50, 40), (40, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf246, reinterpret_tensor(buf257, (50, s0), (1, 50), 0), tanh_36, alpha=1, beta=1, out=buf260)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_36
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf273 = buf246; del buf246  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf260, reinterpret_tensor(buf270, (50, s0), (1, 50), 0), tanh_34, alpha=1, beta=1, out=buf273)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_34
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf286 = buf260; del buf260  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf273, reinterpret_tensor(buf283, (50, s0), (1, 50), 0), tanh_32, alpha=1, beta=1, out=buf286)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf299 = buf273; del buf273  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf286, reinterpret_tensor(buf296, (50, s0), (1, 50), 0), tanh_30, alpha=1, beta=1, out=buf299)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_30
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf312 = buf286; del buf286  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf299, reinterpret_tensor(buf309, (50, s0), (1, 50), 0), tanh_28, alpha=1, beta=1, out=buf312)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_28
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf326 = buf299; del buf299  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf312, reinterpret_tensor(buf323, (50, s0), (1, 50), 0), tanh_26, alpha=1, beta=1, out=buf326)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_26
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf339 = buf312; del buf312  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf326, reinterpret_tensor(buf336, (50, s0), (1, 50), 0), tanh_24, alpha=1, beta=1, out=buf339)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_24
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf353 = buf326; del buf326  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf339, reinterpret_tensor(buf349, (50, s0), (1, 50), 0), tanh_22, alpha=1, beta=1, out=buf353)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_22
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf367 = buf339; del buf339  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf353, reinterpret_tensor(buf364, (50, s0), (1, 50), 0), tanh_20, alpha=1, beta=1, out=buf367)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_20
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf380 = buf353; del buf353  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf367, reinterpret_tensor(buf377, (50, s0), (1, 50), 0), tanh_18, alpha=1, beta=1, out=buf380)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_18
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf393 = buf367; del buf367  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf380, reinterpret_tensor(buf390, (50, s0), (1, 50), 0), tanh_16, alpha=1, beta=1, out=buf393)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_16
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf407 = buf380; del buf380  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf393, reinterpret_tensor(buf404, (50, s0), (1, 50), 0), tanh_14, alpha=1, beta=1, out=buf407)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_14
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf420 = buf393; del buf393  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf407, reinterpret_tensor(buf417, (50, s0), (1, 50), 0), tanh_12, alpha=1, beta=1, out=buf420)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_12
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf433 = buf407; del buf407  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf420, reinterpret_tensor(buf430, (50, s0), (1, 50), 0), tanh_10, alpha=1, beta=1, out=buf433)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf446 = buf420; del buf420  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf433, reinterpret_tensor(buf443, (50, s0), (1, 50), 0), tanh_8, alpha=1, beta=1, out=buf446)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_8
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf460 = buf433; del buf433  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf446, reinterpret_tensor(buf456, (50, s0), (1, 50), 0), tanh_6, alpha=1, beta=1, out=buf460)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_6
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf474 = buf446; del buf446  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf460, reinterpret_tensor(buf471, (50, s0), (1, 50), 0), tanh_4, alpha=1, beta=1, out=buf474)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf488 = buf460; del buf460  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf474, reinterpret_tensor(buf485, (50, s0), (1, 50), 0), tanh_2, alpha=1, beta=1, out=buf488)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_2
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf502 = buf474; del buf474  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf488, reinterpret_tensor(buf498, (50, s0), (1, 50), 0), tanh, alpha=1, beta=1, out=buf502)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf488
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf249 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf244, (50, s0), (1, 50), 0), tanh_37, out=buf249)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf244
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_37
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf262 = empty_strided_cuda((50, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf249, reinterpret_tensor(buf257, (50, s0), (1, 50), 0), tanh_35, alpha=1, beta=1, out=buf262)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf257
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_35
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf275 = buf249; del buf249  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf262, reinterpret_tensor(buf270, (50, s0), (1, 50), 0), tanh_33, alpha=1, beta=1, out=buf275)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf270
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_33
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf288 = buf262; del buf262  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf275, reinterpret_tensor(buf283, (50, s0), (1, 50), 0), tanh_31, alpha=1, beta=1, out=buf288)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf283
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_31
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf301 = buf275; del buf275  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf288, reinterpret_tensor(buf296, (50, s0), (1, 50), 0), tanh_29, alpha=1, beta=1, out=buf301)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf296
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_29
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf314 = buf288; del buf288  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf301, reinterpret_tensor(buf309, (50, s0), (1, 50), 0), tanh_27, alpha=1, beta=1, out=buf314)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf309
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_27
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf328 = buf301; del buf301  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf314, reinterpret_tensor(buf323, (50, s0), (1, 50), 0), tanh_25, alpha=1, beta=1, out=buf328)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf323
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_25
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf341 = buf314; del buf314  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf328, reinterpret_tensor(buf336, (50, s0), (1, 50), 0), tanh_23, alpha=1, beta=1, out=buf341)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf336
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_23
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf355 = buf328; del buf328  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf341, reinterpret_tensor(buf349, (50, s0), (1, 50), 0), tanh_21, alpha=1, beta=1, out=buf355)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf349
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_21
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf369 = buf341; del buf341  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf355, reinterpret_tensor(buf364, (50, s0), (1, 50), 0), tanh_19, alpha=1, beta=1, out=buf369)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf364
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_19
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf382 = buf355; del buf355  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf369, reinterpret_tensor(buf377, (50, s0), (1, 50), 0), tanh_17, alpha=1, beta=1, out=buf382)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf377
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_17
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf395 = buf369; del buf369  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf382, reinterpret_tensor(buf390, (50, s0), (1, 50), 0), tanh_15, alpha=1, beta=1, out=buf395)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf390
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_15
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf409 = buf382; del buf382  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf395, reinterpret_tensor(buf404, (50, s0), (1, 50), 0), tanh_13, alpha=1, beta=1, out=buf409)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf404
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_13
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf422 = buf395; del buf395  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf409, reinterpret_tensor(buf417, (50, s0), (1, 50), 0), tanh_11, alpha=1, beta=1, out=buf422)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf417
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_11
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf435 = buf409; del buf409  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf422, reinterpret_tensor(buf430, (50, s0), (1, 50), 0), tanh_9, alpha=1, beta=1, out=buf435)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf430
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_9
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf448 = buf422; del buf422  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf435, reinterpret_tensor(buf443, (50, s0), (1, 50), 0), tanh_7, alpha=1, beta=1, out=buf448)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf443
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_7
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf462 = buf435; del buf435  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf448, reinterpret_tensor(buf456, (50, s0), (1, 50), 0), tanh_5, alpha=1, beta=1, out=buf462)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf456
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf476 = buf448; del buf448  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf462, reinterpret_tensor(buf471, (50, s0), (1, 50), 0), tanh_3, alpha=1, beta=1, out=buf476)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf471
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_3
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf490 = buf462; del buf462  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf476, reinterpret_tensor(buf485, (50, s0), (1, 50), 0), tanh_1, alpha=1, beta=1, out=buf490)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf485
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del tanh_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf504 = buf476; del buf476  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.addmm(buf490, reinterpret_tensor(buf498, (50, s0), (1, 50), 0), full_default_1, alpha=1, beta=1, out=buf504)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf490
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf498
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del full_default_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._trilinear]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf520 = torch.ops.aten._trilinear.default(reinterpret_tensor(buf519, (20*s0, 30), (30, 1), 0), primals_5, view_4, [2, 3], [0], [1, 2], [1, 3])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf521 = buf520
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf520
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._trilinear]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf524 = torch.ops.aten._trilinear.default(view_4, primals_5, reinterpret_tensor(buf519, (20*s0, 30), (30, 1), 0), [1, 3], [0], [2, 3], [1, 2])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del primals_5
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf525 = buf524
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf524
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf526 = empty_strided_cuda((1, 20, 2), (40, 1, 20), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_sum_59_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_add_sum_59.run(buf525, buf521, buf526, s0, 40, triton_red_fused_add_sum_59_r0_numel, grid=grid(40), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf528 = buf525; del buf525  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_60_xnumel = 400*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_poi_fused_add_60.run(buf528, buf521, triton_poi_fused_add_60_xnumel, grid=grid(triton_poi_fused_add_60_xnumel), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf521
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.view, aten._trilinear]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf529 = torch.ops.aten._trilinear.default(view_1, buf528, view_1, [1, 3], [2, 3], [1, 2], [0])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf528
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_1
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf527 = empty_strided_cuda((1, 20), (20, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_add_sum_61.run(buf526, buf527, 20, 2, grid=grid(20), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf526
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf530 = buf529
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf529
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._trilinear]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf522 = torch.ops.aten._trilinear.default(view_4, reinterpret_tensor(buf519, (20*s0, 30), (30, 1), 0), view_4, [1, 3], [2, 3], [1, 2], [0])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf519
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_4
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf523 = buf522
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf522
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf218 = buf178; del buf178  # reuse
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_red_fused_sum_22.run(buf215, buf218, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf217 = empty_strided_cuda((2048, 50), (50, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf215, (2048, 20*s0), (1, 2048), 0), view_32, out=buf217)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf215
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del view_32
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         buf219 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         triton_per_fused_sum_23.run(buf218, buf219, 2048, 2, grid=grid(2048), stream=stream0)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]         del buf218
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     return (None, None, buf530, reinterpret_tensor(buf527, (20, ), (1, ), 0), buf523, reinterpret_tensor(buf518, (30, ), (1, ), 0), None, None, buf517, buf516, buf510, buf512, buf508, buf511, buf502, buf504, buf501, buf503, reinterpret_tensor(buf240, (150, ), (1, ), 0), buf242, buf229, reinterpret_tensor(buf231, (50, ), (1, ), 0), buf224, buf226, buf217, reinterpret_tensor(buf219, (2048, ), (1, ), 0), buf212, reinterpret_tensor(buf214, (50, ), (1, ), 0), buf207, buf209, reinterpret_tensor(buf202, (150, ), (1, ), 0), buf200, buf189, reinterpret_tensor(buf191, (50, ), (1, ), 0), buf184, buf186, buf177, reinterpret_tensor(buf179, (2048, ), (1, ), 0), buf172, reinterpret_tensor(buf174, (50, ), (1, ), 0), buf167, buf169, buf160, buf162, reinterpret_tensor(buf151, (150, ), (1, ), 0), buf153, buf141, reinterpret_tensor(buf143, (50, ), (1, ), 0), buf136, buf138, buf131, buf130, buf109, reinterpret_tensor(buf111, (50, ), (1, ), 0), buf104, buf106, buf97, reinterpret_tensor(buf99, (2048, ), (1, ), 0), buf92, reinterpret_tensor(buf94, (50, ), (1, ), 0), buf87, buf89, reinterpret_tensor(buf82, (150, ), (1, ), 0), buf80, buf69, reinterpret_tensor(buf71, (50, ), (1, ), 0), buf64, buf66, buf59, buf58, buf37, reinterpret_tensor(buf39, (50, ), (1, ), 0), buf32, buf34, buf25, reinterpret_tensor(buf27, (2048, ), (1, ), 0), buf20, reinterpret_tensor(buf22, (50, ), (1, ), 0), buf15, buf17, buf8, buf10, )
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_1 = 10
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul = 200
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_825 = 50
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_5 = rand_strided((30, 20, 20), (400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_23 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_29 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_35 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_41 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_42 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_43 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_49 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_55 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_61 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_67 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_73 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_79 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_80 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_81 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     primals_82 = rand_strided((50, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_1 = rand_strided((200, 10), (10, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_4 = rand_strided((200, 20), (20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     repeat = rand_strided((300, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_8 = rand_strided((1, 300, 20), (6000, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     squeeze_1 = rand_strided((300, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     full_default = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     full_default_1 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_1 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_1 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_2 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_3 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_2 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_4 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_5 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_3 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_6 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_7 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_4 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_8 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_9 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_5 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_10 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_11 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_6 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_12 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_13 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_7 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_14 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_15 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_8 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_16 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_17 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_9 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_18 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_19 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_10 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_20 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_21 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_11 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_22 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_23 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_12 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_24 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_25 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_13 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_26 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_27 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_14 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_28 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_29 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_15 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_30 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_31 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_16 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_32 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_33 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_17 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_34 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_35 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_18 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_36 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_37 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     select_19 = rand_strided((10, 30), (600, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tanh_38 = rand_strided((10, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_15 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     bmm = rand_strided((50, 20, 20), (400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     amax = rand_strided((10, 5, 20, 1), (100, 20, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     sum_1 = rand_strided((10, 5, 20, 1), (100, 20, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     logical_not_1 = rand_strided((10, 5, 20, 1), (100, 20, 1, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_30 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_1 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_32 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_2 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_34 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_3 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1023 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_36 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     where_1 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_4 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_51 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_5 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1216 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_53 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_6 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_55 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_7 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1272 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     getitem_11 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rsqrt_5 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     where_2 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_8 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_72 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_9 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_74 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_76 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     where_3 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_10 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_91 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_11 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1695 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_93 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_12 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_95 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_13 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1751 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_97 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     where_4 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_14 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_112 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_15 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_1944 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_114 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     where_5 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_16 = rand_strided((10, 5, 20, 20), (2000, 400, 20, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_131 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_17 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_2141 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_133 = rand_strided((200, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_18 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     view_135 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     gt_19 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_2197 = rand_strided((20, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     getitem_33 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     rsqrt_12 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     glu = rand_strided((10, 10, 50), (50, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_7 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_144 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     le_1 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_148 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_8 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_152 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_157 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_158 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_159 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_160 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_166 = rand_strided((100, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_170 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_9 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_174 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_179 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_180 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_181 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_182 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_188 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_10 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_192 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     le_2 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_196 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_11 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_200 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_205 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_206 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_207 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_208 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_214 = rand_strided((100, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_218 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_2310 = rand_strided((20, 10, 50), (50, 1000, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_12 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_222 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_227 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_228 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_229 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_230 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_238 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_14 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_240 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     le_3 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_244 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_15 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_248 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_253 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_254 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_255 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_256 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_262 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_16 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_266 = rand_strided((50, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     le_4 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_270 = rand_strided((2048, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     mul_2367 = rand_strided((20, 10, 50), (50, 1000, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     div_17 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_274 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_279 = rand_strided((50, 20, 20), (400, 1, 20), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_280 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_281 = rand_strided((50, 10, 20), (10, 1, 500), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_282 = rand_strided((50, 20, 10), (10, 500, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_290 = rand_strided((150, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     sub_813 = rand_strided((10, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_293 = rand_strided((50, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_297 = rand_strided((50, 50), (50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_301 = rand_strided((40, 30), (30, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     permute_305 = rand_strided((40, 40), (40, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     unsqueeze_15 = rand_strided((1, 300, 1), (300, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     tangents_1 = rand_strided((10, 10, 50), (500, 50, 1), device='cuda:0', dtype=torch.float32)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     fn = lambda: call([primals_1, mul, mul_825, primals_5, primals_23, primals_29, primals_35, primals_41, primals_42, primals_43, primals_49, primals_55, primals_61, primals_67, primals_73, primals_79, primals_80, primals_81, primals_82, view_1, view_4, repeat, view_8, squeeze_1, full_default, full_default_1, select, tanh, tanh_1, select_1, tanh_2, tanh_3, select_2, tanh_4, tanh_5, select_3, tanh_6, tanh_7, select_4, tanh_8, tanh_9, select_5, tanh_10, tanh_11, select_6, tanh_12, tanh_13, select_7, tanh_14, tanh_15, select_8, tanh_16, tanh_17, select_9, tanh_18, tanh_19, select_10, tanh_20, tanh_21, select_11, tanh_22, tanh_23, select_12, tanh_24, tanh_25, select_13, tanh_26, tanh_27, select_14, tanh_28, tanh_29, select_15, tanh_30, tanh_31, select_16, tanh_32, tanh_33, select_17, tanh_34, tanh_35, select_18, tanh_36, tanh_37, select_19, tanh_38, view_15, bmm, amax, sum_1, logical_not_1, gt, view_30, gt_1, view_32, gt_2, view_34, gt_3, mul_1023, view_36, where_1, gt_4, view_51, gt_5, mul_1216, view_53, gt_6, view_55, gt_7, mul_1272, getitem_11, rsqrt_5, where_2, gt_8, view_72, gt_9, view_74, view_76, where_3, gt_10, view_91, gt_11, mul_1695, view_93, gt_12, view_95, gt_13, mul_1751, view_97, where_4, gt_14, view_112, gt_15, mul_1944, view_114, where_5, gt_16, view_131, gt_17, mul_2141, view_133, gt_18, view_135, gt_19, mul_2197, getitem_33, rsqrt_12, glu, div_7, permute_144, le_1, permute_148, div_8, permute_152, permute_157, permute_158, permute_159, permute_160, permute_166, permute_170, div_9, permute_174, permute_179, permute_180, permute_181, permute_182, permute_188, div_10, permute_192, le_2, permute_196, div_11, permute_200, permute_205, permute_206, permute_207, permute_208, permute_214, permute_218, mul_2310, div_12, permute_222, permute_227, permute_228, permute_229, permute_230, permute_238, div_14, permute_240, le_3, permute_244, div_15, permute_248, permute_253, permute_254, permute_255, permute_256, permute_262, div_16, permute_266, le_4, permute_270, mul_2367, div_17, permute_274, permute_279, permute_280, permute_281, permute_282, permute_290, sub_813, permute_293, permute_297, permute_301, permute_305, unsqueeze_15, tangents_1])
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] if __name__ == "__main__":
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:55:49.523000 2742634 site-packages/torch/_inductor/graph.py:2014] [275/0] [__output_code] 
V0204 20:55:49.647000 2742634 site-packages/torch/_inductor/graph.py:2022] [275/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/jq/cjqdh742u2gj2nkz4yv5ltewrczh2xixry36uabfefxrf4cknaem.py
I0204 20:55:52.110000 2742634 site-packages/torch/_inductor/graph.py:2056] [275/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/jq/cjqdh742u2gj2nkz4yv5ltewrczh2xixry36uabfefxrf4cknaem.py
