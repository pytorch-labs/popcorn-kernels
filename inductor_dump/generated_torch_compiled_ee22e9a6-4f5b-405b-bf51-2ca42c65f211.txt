W0205 14:28:26.729000 1612526 site-packages/torch/_inductor/utils.py:1611] [89/0] DeviceCopy in input program
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] Output code: 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # AOT ID: ['18_forward']
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import torch
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import random
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import os
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import tempfile
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from math import inf, nan
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from cmath import nanj
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch import device, empty_strided
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     grid,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     split_scan_grid,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     grid_combo_kernels,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     start_graph,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     end_graph,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     cooperative_reduction_grid,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] aten = torch.ops.aten
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] _quantized = torch.ops._quantized
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] async_compile = AsyncCompile()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] cpp_fused__to_copy_randint_0 = async_compile.cpp_pybinding(['const int64_t*', 'float*', 'const int64_t'], '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #include "/tmp/torchinductor_sahanp/3b/c3bi5gk6mslf6u4iaqafhxm64z6u65e3eain4xlary5blqnvv6xx.h"
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] extern "C"  void kernel(const int64_t* in_ptr0,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                        float* out_ptr0,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                        const int64_t ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] {
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     {
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         #pragma GCC ivdep
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(64L*ks0); x0+=static_cast<int64_t>(1L))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         {
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]             {
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                 {
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp1 = x0;
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp2 = c10::convert<int32_t>(tmp1);
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp3 = static_cast<int64_t>(0);
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp4 = static_cast<int64_t>(2);
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp5 = randint64_cpu(tmp0, tmp2, tmp3, tmp4);
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     auto tmp6 = c10::convert<float>(tmp5);
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                     out_ptr0[static_cast<int64_t>(x0)] = tmp6;
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]                 }
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]             }
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         }
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     }
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] }
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6t/c6twlv6pnvtmrwiw5vsoiqbh62euchtn5myo34l6srsj24pjiryk.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward => clone
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_clone_1 = async_compile.triton('triton_poi_fused_clone_1', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 16384}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_clone_1(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 1280*x1), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/td/ctd2gnzmh3zs5mksljqc4p2mgy36wmmlckqzhfihy3etnxwdfarl.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward => clone_1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_1 : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_clone_2 = async_compile.triton('triton_poi_fused_clone_2', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 65536}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_clone_2(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 192*x1), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fx/cfxfat5uo4nb656ixkhahqbo7l7z5nxjxexgqci5dbqupty57et4.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward => view_6
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %view_6 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_3, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_view_3 = async_compile.triton('triton_poi_fused_view_3', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 16384}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_view_3(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kz/ckzy2o5plarotu6lyerogj55r73wvwiihailtc5bti23dwbpqxny.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward => view_7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %view_7 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_4, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_view_4 = async_compile.triton('triton_poi_fused_view_4', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 16384}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_view_4(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kp/ckp6ojcovk7th32ojuvvo4vinfpnlhu57ilzsusc4zxdykfde3vg.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward => view_8
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %view_8 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_5, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_view_5 = async_compile.triton('triton_poi_fused_view_5', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 16384}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_view_5(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 2560*ks0 + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % 20))), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ls/clsm3vujl7o23urjd43mkbutvek2ky4urmkikgsxfxnlqz34vdd2.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_1, dropout_9, add_6, x_10], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   add => add_140
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   add_6 => add_790
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout => gt, inductor_lookup_seed_default, inductor_random_default_41, mul_124, mul_125
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_9 => gt_9, inductor_lookup_seed_default_9, inductor_random_default_32, mul_673, mul_674
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_1 => add_145, add_146, clone_3, mul_134, mul_135, rsqrt, sub_64, var_mean
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_10 => add_795, add_796, clone_11, mul_683, mul_684, rsqrt_7, sub_357, var_mean_7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_41 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 64], %inductor_lookup_seed_default, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_41, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_124 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt, %view_10), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_125 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_124, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_140 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute, %mul_125), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_3 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_140,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_3, [2]), kwargs = {correction: 0, keepdim: True})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_145 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %rsqrt : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_145,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_64 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_3, %getitem_5), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_64, %rsqrt), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_135 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_134, %primals_8), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_146 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_135, %primals_9), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_9 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 9), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_32 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 64], %inductor_lookup_seed_default_9, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_9 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_32, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_673 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_9, %view_55), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_674 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_673, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_790 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute, %mul_674), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_11 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_790,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %var_mean_7 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_11, [2]), kwargs = {correction: 0, keepdim: True})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_795 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_30, 1e-05), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %rsqrt_7 : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_795,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_357 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_11, %getitem_31), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_683 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_357, %rsqrt_7), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_684 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_683, %primals_46), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_796 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_684, %primals_47), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1664 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_790, %getitem_31), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3166 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1664, %rsqrt_7), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_27 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_7, 64), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1685 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_140, %getitem_5), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3233 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1685, %rsqrt), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_34 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt, 64), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'out_ptr1': '*i1', 'out_ptr3': '*i1', 'out_ptr6': '*fp32', 'out_ptr9': '*fp32', 'out_ptr10': '*fp32', 'out_ptr11': '*fp32', 'out_ptr12': '*fp32', 'out_ptr13': '*fp32', 'load_seed_offset': 'i32', 'load_seed_offset1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 9, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr1, out_ptr3, out_ptr6, out_ptr9, out_ptr10, out_ptr11, out_ptr12, out_ptr13, load_seed_offset, load_seed_offset1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = (xindex % ks2)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // ks2
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (r0_1 + 64*x3 + 1280*x2), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp40 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp42 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp45 = tl.load(in_ptr6 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp46 = tl.load(in_ptr7 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp70 = tl.load(in_ptr8 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp72 = tl.load(in_ptr9 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr0 + load_seed_offset1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.rand(tmp5, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tmp6 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tmp7.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tmp10 + tmp11
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp9 * tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tmp8 + tmp15
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tl.broadcast_to(tmp17, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tl.where(xmask, tmp20, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tl.sum(tmp22, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = tl.full([XBLOCK, 1], 64, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tmp24.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tmp23 / tmp25
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp27 = tmp17 - tmp26
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp28 = tmp27 * tmp27
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp31 = tl.where(xmask, tmp29, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp32 = tl.sum(tmp31, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp33 = tmp16 - tmp26
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp34 = 64.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp35 = tmp32 / tmp34
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp36 = 1e-05
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp37 = tmp35 + tmp36
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp38 = libdevice.rsqrt(tmp37)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp39 = tmp33 * tmp38
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp41 = tmp39 * tmp40
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp43 = tmp41 + tmp42
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp44 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp47 = tmp45 + tmp46
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp48 = tmp44 * tmp47
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp49 = tmp48 * tmp14
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp50 = tmp8 + tmp49
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp54 = tl.broadcast_to(tmp51, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp56 = tl.where(xmask, tmp54, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp57 = tl.sum(tmp56, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp58 = tmp57 / tmp25
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp59 = tmp51 - tmp58
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp60 = tmp59 * tmp59
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp61 = tl.broadcast_to(tmp60, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp63 = tl.where(xmask, tmp61, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp64 = tl.sum(tmp63, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp65 = tmp50 - tmp58
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp66 = tmp64 / tmp34
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp67 = tmp66 + tmp36
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp68 = libdevice.rsqrt(tmp67)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp69 = tmp65 * tmp68
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp71 = tmp69 * tmp70
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp73 = tmp71 + tmp72
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp74 = 0.015625
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp75 = tmp68 * tmp74
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp76 = tmp38 * tmp74
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 64*x0), tmp7, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp43, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr9 + (r0_1 + 64*x0), tmp73, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr10 + (r0_1 + 64*x3 + 1280*x2), tmp69, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr11 + (r0_1 + 64*x3 + 1280*x2), tmp39, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr12 + (x0), tmp75, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr13 + (x0), tmp76, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jj/cjjkii5gvr4ngdlyyohz4mqy5dwxufjoxg3ge7bo5a7rjiqbub7m.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   relu => relu
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_12,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %le_11 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_relu_threshold_backward_7 = async_compile.triton('triton_poi_fused_relu_threshold_backward_7', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 524288}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_threshold_backward_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_relu_threshold_backward_7(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 2048)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = 0.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lq/clqmftf7jvx5bexpuawvhrvzjfz2vm5ddvjciyv5qscs7ejyfccx.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_1 => gt_1, inductor_lookup_seed_default_1, inductor_random_default_40, mul_161, mul_162
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   relu => relu
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_12,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_40 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 2048], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_1 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_40, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_161 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_1, %relu), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_162 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_161, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_native_dropout_relu_8 = async_compile.triton('triton_poi_fused_native_dropout_relu_8', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 524288}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': (4,)}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_native_dropout_relu_8(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = (xindex % 2048)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp5 * tmp10
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp11 * tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xr/cxrpnt3thyiq3sw3relafntepqkx3spvewhrztgtgincjoas4nqg.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_2, add_1, x_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   add_1 => add_203
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_2 => gt_2, inductor_lookup_seed_default_2, inductor_random_default_39, mul_180, mul_181
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_3 => add_208, add_209, mul_190, mul_191, rsqrt_1, sub_93, var_mean_1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_39 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 64], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_2 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_39, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_180 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_2, %view_14), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_181 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_180, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_203 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_146, %mul_181), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_203, [2]), kwargs = {correction: 0, keepdim: True})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_208 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 1e-05), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %rsqrt_1 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_208,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_93 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_203, %getitem_7), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_190 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_93, %rsqrt_1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_191 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_190, %primals_14), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_209 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_191, %primals_15), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_33 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, 64), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tmp7 + tmp8
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp6 * tmp9
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp5 + tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tmp20 / tmp22
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = tmp14 - tmp23
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tmp24 * tmp24
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp30 = tmp13 - tmp23
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp31 = 64.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp32 = tmp29 / tmp31
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp33 = 1e-05
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp34 = tmp32 + tmp33
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp36 = tmp30 * tmp35
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp38 = tmp36 * tmp37
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp40 = tmp38 + tmp39
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp41 = 0.015625
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp42 = tmp35 * tmp41
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 64*x0), tmp40, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/o4/co4gfmlut7xygfqqmgwpgipfvrmluobo6z6jeifecf7fzwmvvpgv.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [relu_1, dropout_4], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_4 => gt_4, inductor_lookup_seed_default_4, inductor_random_default_37, mul_334, mul_335
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   relu_1 => relu_1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_27,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 4), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_37 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 2048], %inductor_lookup_seed_default_4, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_4 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_37, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_334 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_4, %relu_1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_335 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_334, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_native_dropout_relu_10 = async_compile.triton('triton_poi_fused_native_dropout_relu_10', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 524288}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_native_dropout_relu_10(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = (xindex % 2048)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp5 * tmp10
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp11 * tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ki/ckiy6g76d5wtwwmv26sqcljk6ufrsdq5xj44dju7m243uf22uqp5.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_8, add_5, x_9, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   add_5 => add_621
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_8 => gt_8, inductor_lookup_seed_default_8, inductor_random_default_33, mul_526, mul_527
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   output => add_640, add_641, mul_545, mul_546, rsqrt_6, sub_288, var_mean_6
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_9 => add_626, add_627, mul_536, mul_537, rsqrt_5, sub_281, var_mean_5
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_8 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 8), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_33 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 64], %inductor_lookup_seed_default_8, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_8 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_33, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_526 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_8, %view_44), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_527 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_526, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_621 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_564, %mul_527), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %var_mean_5 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_621, [2]), kwargs = {correction: 0, keepdim: True})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_626 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_22, 1e-05), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %rsqrt_5 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_626,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_281 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_621, %getitem_23), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_536 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_281, %rsqrt_5), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_537 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_536, %primals_38), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_627 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_537, %primals_39), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %var_mean_6 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_627, [2]), kwargs = {correction: 0, keepdim: True})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_640 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_24, 1e-05), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %rsqrt_6 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_640,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_288 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_627, %getitem_25), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_545 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_288, %rsqrt_6), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_546 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_545, %primals_40), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_641 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_546, %primals_41), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_29 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_5, 64), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp62 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp64 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tmp7 + tmp8
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp6 * tmp9
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp5 + tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tmp20 / tmp22
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = tmp14 - tmp23
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tmp24 * tmp24
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp30 = tmp13 - tmp23
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp31 = 64.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp32 = tmp29 / tmp31
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp33 = 1e-05
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp34 = tmp32 + tmp33
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp36 = tmp30 * tmp35
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp38 = tmp36 * tmp37
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp40 = tmp38 + tmp39
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp43 = tl.where(xmask, tmp41, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp44 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp46 = tl.where(xmask, tmp44, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp47 = tl.sum(tmp46, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp48 = tmp47 / tmp22
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp49 = tmp41 - tmp48
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp50 = tmp49 * tmp49
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp55 = tmp54 / tmp31
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp56 = tmp55 + tmp33
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp57 = libdevice.rsqrt(tmp56)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp58 = 0.015625
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp59 = tmp35 * tmp58
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp60 = tmp40 - tmp48
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp61 = tmp60 * tmp57
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp63 = tmp61 * tmp62
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp65 = tmp63 + tmp64
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.debug_barrier()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp57, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp59, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp65, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pp/cppp5erxe3l2lhngnlsl2x4v4abfrvxnaxvjzdkjvgr3nwsj5cqu.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   multi_head_attention_forward_4 => clone_12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_12 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_4,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_clone_12 = async_compile.triton('triton_poi_fused_clone_12', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 32768}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_clone_12(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex // ks1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 128*x1), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (64 + x0 + 64*x2), xmask, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3p/c3p4d5yu4wjjttoa3nsco65tjvmm7gxt77ph5keamslvhcurevta.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [relu_11, dropout_40], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   dropout_40 => gt_40, inductor_lookup_seed_default_40, inductor_random_default_1, mul_2842, mul_2843
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   relu_11 => relu_11
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %relu_11 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_255,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_lookup_seed_default_40 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 40), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %inductor_random_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([20, %primals_1, 2048], %inductor_lookup_seed_default_40, rand), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %gt_40 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_1, 0.1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2842 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_40, %relu_11), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2843 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2842, 1.1111111111111112), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_11, 0), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_13 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_13', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 524288}, 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_13(in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = (xindex % 2048)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = x0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = 0.1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 > tmp3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp5 * tmp10
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = 1.1111111111111112
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp11 * tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = 0.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp10 <= tmp14
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp15, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ys/cysb5bilfah2rwh3xrj77alfp5bakgmdv4je4h32udq3iem7is4f.py
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [x_45, loss], Original ATen: [aten.adaptive_max_pool2d, aten.binary_cross_entropy_with_logits, aten.sigmoid, aten.sub]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   loss => abs_1, exp, full_default, log1p, mean, minimum, mul_2917, neg, sub_1582, sub_1583, sub_1584
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_45 => _low_memory_max_pool2d_with_offsets, getitem_165
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=2] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%unsqueeze_18, [1, 20], [1, 20], [0, 0], [1, 1], False), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %getitem_165 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 1), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1582 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %device_put), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2917 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1582, %squeeze_20), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %full_default : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %minimum : [num_users=1] = call_function[target=torch.ops.aten.minimum.default](args = (%full_default, %squeeze_20), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%squeeze_20,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %neg : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%abs_1,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%neg,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %log1p : [num_users=1] = call_function[target=torch.ops.aten.log1p.default](args = (%exp,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1583 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%minimum, %log1p), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1584 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2917, %sub_1583), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%sub_1584,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%squeeze_20,), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1585 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sigmoid, %device_put), kwargs = {})
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14 = async_compile.triton('triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14', '''
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 1, 'r0_': 1024},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr1': '*i8', 'out_ptr2': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': (7,)}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 21, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, out_ptr2, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp112 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_0 = r0_index
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_0), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr0 + (ks0 + r0_0), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (r0_0 + 128*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.load(in_ptr0 + (r0_0 + 192*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = tl.load(in_ptr0 + (r0_0 + 256*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp9 = tl.load(in_ptr0 + (r0_0 + 320*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp11 = tl.load(in_ptr0 + (r0_0 + 384*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp13 = tl.load(in_ptr0 + (r0_0 + 448*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp15 = tl.load(in_ptr0 + (r0_0 + 512*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp17 = tl.load(in_ptr0 + (r0_0 + 576*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp19 = tl.load(in_ptr0 + (r0_0 + 640*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp21 = tl.load(in_ptr0 + (r0_0 + 704*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp23 = tl.load(in_ptr0 + (r0_0 + 768*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp25 = tl.load(in_ptr0 + (r0_0 + 832*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp27 = tl.load(in_ptr0 + (r0_0 + 896*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp29 = tl.load(in_ptr0 + (r0_0 + 960*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp31 = tl.load(in_ptr0 + (r0_0 + 1024*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp33 = tl.load(in_ptr0 + (r0_0 + 1088*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp35 = tl.load(in_ptr0 + (r0_0 + 1152*ks1), r0_mask, eviction_policy='evict_last', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp37 = tl.load(in_ptr0 + (r0_0 + 1216*ks1), r0_mask, eviction_policy='evict_first', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp98 = tl.load(in_ptr1 + (r0_0), r0_mask, eviction_policy='evict_first', other=0.0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = triton_helpers.maximum(tmp7, tmp6)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp12 = triton_helpers.maximum(tmp11, tmp10)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp14 = triton_helpers.maximum(tmp13, tmp12)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp16 = triton_helpers.maximum(tmp15, tmp14)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp18 = triton_helpers.maximum(tmp17, tmp16)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp20 = triton_helpers.maximum(tmp19, tmp18)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp24 = triton_helpers.maximum(tmp23, tmp22)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp26 = triton_helpers.maximum(tmp25, tmp24)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp28 = triton_helpers.maximum(tmp27, tmp26)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp30 = triton_helpers.maximum(tmp29, tmp28)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp32 = triton_helpers.maximum(tmp31, tmp30)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp34 = triton_helpers.maximum(tmp33, tmp32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp36 = triton_helpers.maximum(tmp35, tmp34)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp38 = triton_helpers.maximum(tmp37, tmp36)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp39 = tmp1 > tmp0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp40 = tl.full([1, 1], 1, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp41 = tl.full([1, 1], 0, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp42 = tl.where(tmp39, tmp40, tmp41)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp43 = tmp3 > tmp2
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp44 = tl.full([1, 1], 2, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp45 = tl.where(tmp43, tmp44, tmp42)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp46 = tmp5 > tmp4
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp47 = tl.full([1, 1], 3, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp48 = tl.where(tmp46, tmp47, tmp45)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp49 = tmp7 > tmp6
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp50 = tl.full([1, 1], 4, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp51 = tl.where(tmp49, tmp50, tmp48)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp52 = tmp9 > tmp8
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp53 = tl.full([1, 1], 5, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp54 = tl.where(tmp52, tmp53, tmp51)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp55 = tmp11 > tmp10
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp56 = tl.full([1, 1], 6, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp57 = tl.where(tmp55, tmp56, tmp54)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp58 = tmp13 > tmp12
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp59 = tl.full([1, 1], 7, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp60 = tl.where(tmp58, tmp59, tmp57)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp61 = tmp15 > tmp14
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp62 = tl.full([1, 1], 8, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp63 = tl.where(tmp61, tmp62, tmp60)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp64 = tmp17 > tmp16
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp65 = tl.full([1, 1], 9, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp66 = tl.where(tmp64, tmp65, tmp63)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp67 = tmp19 > tmp18
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp68 = tl.full([1, 1], 10, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp69 = tl.where(tmp67, tmp68, tmp66)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp70 = tmp21 > tmp20
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp71 = tl.full([1, 1], 11, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp72 = tl.where(tmp70, tmp71, tmp69)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp73 = tmp23 > tmp22
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp74 = tl.full([1, 1], 12, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp75 = tl.where(tmp73, tmp74, tmp72)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp76 = tmp25 > tmp24
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp77 = tl.full([1, 1], 13, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp78 = tl.where(tmp76, tmp77, tmp75)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp79 = tmp27 > tmp26
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp80 = tl.full([1, 1], 14, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp81 = tl.where(tmp79, tmp80, tmp78)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp82 = tmp29 > tmp28
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp83 = tl.full([1, 1], 15, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp84 = tl.where(tmp82, tmp83, tmp81)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp85 = tmp31 > tmp30
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp86 = tl.full([1, 1], 16, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp87 = tl.where(tmp85, tmp86, tmp84)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp88 = tmp33 > tmp32
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp89 = tl.full([1, 1], 17, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp90 = tl.where(tmp88, tmp89, tmp87)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp91 = tmp35 > tmp34
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp92 = tl.full([1, 1], 18, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp93 = tl.where(tmp91, tmp92, tmp90)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp94 = tmp37 > tmp36
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp95 = tl.full([1, 1], 19, tl.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp96 = tl.where(tmp94, tmp95, tmp93)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp97 = tl.sigmoid(tmp38)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp99 = tmp97 - tmp98
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp100 = 1.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp101 = tmp100 - tmp98
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp102 = tmp101 * tmp38
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp103 = 0.0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp104 = triton_helpers.minimum(tmp103, tmp38)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp105 = tl_math.abs(tmp38)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp106 = -tmp105
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp107 = tl_math.exp(tmp106)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp108 = libdevice.log1p(tmp107)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp109 = tmp104 - tmp108
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp110 = tmp102 - tmp109
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp111 = tl.broadcast_to(tmp110, [XBLOCK, R0_BLOCK])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp113 = _tmp112 + tmp111
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp112 = tl.where(r0_mask, tmp113, _tmp112)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tl.store(out_ptr1 + (tl.broadcast_to(r0_0, [XBLOCK, R0_BLOCK])), tmp96, r0_mask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tl.store(out_ptr2 + (tl.broadcast_to(r0_0, [XBLOCK, R0_BLOCK])), tmp99, r0_mask)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp112 = tl.sum(_tmp112, 1)[:, None]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp114 = ks0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp115 = tmp114.to(tl.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp116 = tmp112 / tmp115
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.debug_barrier()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp116, None)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] async_compile.wait(globals())
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] del async_compile
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def call(args):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191 = args
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     args.clear()
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     s0 = primals_1
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_3, (s0, 20, 64), (1280, 64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_4, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_5, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_6, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_7, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_10, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_11, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_12, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_13, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_16, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_17, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_18, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_19, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_21, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_22, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_23, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_24, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_25, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_26, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_27, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_28, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_29, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_30, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_31, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_32, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_33, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_34, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_35, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_36, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_37, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_38, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_39, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_40, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_41, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_42, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_43, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_44, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_45, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_46, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_47, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_48, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_49, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_50, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_51, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_52, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_53, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_54, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_55, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_56, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_57, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_58, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_59, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_60, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_61, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_62, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_63, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_64, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_65, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_66, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_67, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_68, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_69, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_70, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_71, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_72, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_73, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_74, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_75, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_76, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_77, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_78, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_79, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_80, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_81, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_82, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_83, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_84, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_85, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_86, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_87, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_88, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_89, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_90, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_91, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_92, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_93, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_94, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_95, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_96, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_97, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_98, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_99, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_100, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_101, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_102, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_103, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_104, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_105, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_106, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_107, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_108, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_109, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_110, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_111, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_112, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_113, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_114, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_115, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_116, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_117, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_118, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_119, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_120, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_121, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_122, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_123, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_124, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_125, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_126, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_127, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_128, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_129, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_130, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_131, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_132, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_133, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_134, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_135, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_136, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_137, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_138, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_139, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_140, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_141, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_142, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_143, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_144, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_145, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_146, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_147, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_148, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_149, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_150, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_151, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_152, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_153, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_154, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_155, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_156, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_157, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_158, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_159, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_160, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_161, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_162, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_163, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_164, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_165, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_166, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_167, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_168, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_169, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_171, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_172, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_173, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_174, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_175, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_177, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_178, (192, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_179, (192, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_180, (64, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_181, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_183, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_184, (2048, 64), (64, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_185, (2048, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_186, (64, 2048), (2048, 1))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_187, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_190, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_191, (64, ), (1, ))
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     buf504 = empty_strided_cpu((1, ), (1, ), torch.int64)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     # Topologically Sorted Source Nodes: [], Original ATen: []
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     aten.randint.low_out(-9223372036854775808, 9223372036854775807, [1], out=buf504)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         torch.cuda.set_device(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf13 = empty_strided_cuda((42, ), (1, ), torch.int64)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [42], out=buf13)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     buf505 = empty_strided_cpu((s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     cpp_fused__to_copy_randint_0(buf504, buf505, s0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     del buf504
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         torch.cuda.set_device(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf506 = empty_strided_cuda((s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf506.copy_(buf505, False)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf505
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         ps0 = 64*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf0 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(primals_3, buf0, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf1 = empty_strided_cuda((20*s0, 192), (192, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf0, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_5, (64, 192), (1, 64), 0), out=buf1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_5
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         ps1 = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         ps2 = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf2 = empty_strided_cuda((3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf1, primals_4, buf2, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_4
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf3 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf2, buf3, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf4 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf2, buf4, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf5 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf2, buf5, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf6 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf3, buf4, buf5, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf7 = buf6[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf8 = buf6[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf9 = buf6[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf10 = buf6[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf6
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf11 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf7, buf11, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf12 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf11, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_6, (64, 64), (1, 64), 0), out=buf12)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf97 = reinterpret_tensor(buf2, (20*s0, 192), (192, 1), 0); del buf2  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf0, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_43, (64, 192), (1, 64), 0), out=buf97)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_43
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf98 = reinterpret_tensor(buf1, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf1  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf97, primals_42, buf98, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_42
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf100 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf98, buf100, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf101 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf98, buf101, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf99 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf98, buf99, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf102 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf99, buf100, buf101, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf103 = buf102[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf104 = buf102[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf105 = buf102[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf106 = buf102[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf102
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf107 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf103, buf107, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf108 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_44, (64, 64), (1, 64), 0), out=buf108)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf110 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf15 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf19 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf114 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf541 = empty_strided_cuda((20, s0, 64), (64, 1280, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf551 = empty_strided_cuda((20, s0, 64), (64, 1280, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf542 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf552 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_1, dropout_9, add_6, x_10], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6.run(buf13, primals_3, buf12, primals_7, primals_8, primals_9, buf108, primals_45, primals_46, primals_47, buf110, buf15, buf19, buf114, buf541, buf551, buf542, buf552, 9, 0, s0, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_6_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_3
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_45
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_47
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_7
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_9
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf115 = buf12; del buf12  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_49, (64, ), (1, ), 0), reinterpret_tensor(buf114, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_48, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf115)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf20 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf19, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_10, (64, 2048), (1, 64), 0), out=buf20)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf550 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf20, primals_11, buf550, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf22 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf23 = reinterpret_tensor(buf20, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf20  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_8_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_8.run(buf23, buf13, primals_11, buf22, 1, triton_poi_fused_native_dropout_relu_8_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_8_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_11
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf24 = buf108; del buf108  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_12, (2048, 64), (1, 2048), 0), out=buf24)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf26 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf30 = reinterpret_tensor(buf24, (20, s0, 64), (64*s0, 64, 1), 0); del buf24  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf31 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf549 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_2, add_1, x_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf30, buf13, buf19, primals_13, primals_14, primals_15, buf26, buf31, buf549, 2, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_13
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_15
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf32 = reinterpret_tensor(buf98, (20*s0, 192), (192, 1), 0); del buf98  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf31, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_17, (64, 192), (1, 64), 0), out=buf32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf33 = reinterpret_tensor(buf97, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf97  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf32, primals_16, buf33, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_16
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf34 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf33, buf34, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf35 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf33, buf35, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf36 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf33, buf36, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf37 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf34, buf35, buf36, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf38 = buf37[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf39 = buf37[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf40 = buf37[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf41 = buf37[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf37
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf42 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf38, buf42, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf43 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf42, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_18, (64, 64), (1, 64), 0), out=buf43)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf45 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf49 = reinterpret_tensor(buf43, (20, s0, 64), (64*s0, 64, 1), 0); del buf43  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf50 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf548 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_4], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf49, buf13, buf31, primals_19, primals_20, primals_21, buf45, buf50, buf548, 3, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_19
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_21
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf51 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf50, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_22, (64, 2048), (1, 64), 0), out=buf51)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf547 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf51, primals_23, buf547, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf53 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf54 = reinterpret_tensor(buf51, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf51  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1, dropout_4], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf54, buf13, primals_23, buf53, 4, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_23
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf55 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf54, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_24, (2048, 64), (1, 2048), 0), out=buf55)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf57 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf61 = reinterpret_tensor(buf55, (20, s0, 64), (64*s0, 64, 1), 0); del buf55  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf62 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf546 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_5, add_3, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf61, buf13, buf50, primals_25, primals_26, primals_27, buf57, buf62, buf546, 5, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_25
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_27
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf63 = reinterpret_tensor(buf33, (20*s0, 192), (192, 1), 0); del buf33  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf62, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_29, (64, 192), (1, 64), 0), out=buf63)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf64 = reinterpret_tensor(buf32, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf32  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf63, primals_28, buf64, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_28
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf65 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf64, buf65, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf66 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf64, buf66, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf67 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf64, buf67, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf68 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf65, buf66, buf67, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf69 = buf68[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf70 = buf68[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf71 = buf68[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf72 = buf68[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf68
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf73 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf69, buf73, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf74 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf73, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_30, (64, 64), (1, 64), 0), out=buf74)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf76 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf80 = reinterpret_tensor(buf74, (20, s0, 64), (64*s0, 64, 1), 0); del buf74  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf81 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf545 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_6, add_4, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf80, buf13, buf62, primals_31, primals_32, primals_33, buf76, buf81, buf545, 6, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_31
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_33
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf82 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_4], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf81, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_34, (64, 2048), (1, 64), 0), out=buf82)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf544 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf82, primals_35, buf544, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf84 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf85 = reinterpret_tensor(buf82, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf82  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2, dropout_7], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf85, buf13, primals_35, buf84, 7, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_35
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf86 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf85, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_36, (2048, 64), (1, 2048), 0), out=buf86)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf88 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf92 = reinterpret_tensor(buf86, (20, s0, 64), (64*s0, 64, 1), 0); del buf86  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf93 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf94 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf96 = reinterpret_tensor(buf94, (20, s0, 1), (s0, 1, 1), 0); del buf94  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf543 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf116 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_8, add_5, x_9, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11.run(buf92, buf96, buf13, buf81, primals_37, primals_38, primals_39, primals_40, primals_41, buf88, buf93, buf543, buf116, 8, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_37
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_41
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf117 = empty_strided_cuda((20*s0, 128), (128, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_48, (64, 128), (1, 64), 4096), out=buf117)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf118 = empty_strided_cuda((2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf117, primals_49, buf118, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_49
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf119 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf118, buf119, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf120 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf118, buf120, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf121 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf115, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf119, buf120, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf122 = buf121[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf123 = buf121[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf124 = buf121[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf125 = buf121[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf121
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf126 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf122, buf126, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf127 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf126, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_50, (64, 64), (1, 64), 0), out=buf127)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf129 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf133 = reinterpret_tensor(buf127, (20, s0, 64), (64*s0, 64, 1), 0); del buf127  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf134 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf540 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_10, add_7, x_11], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf133, buf13, buf114, primals_51, primals_52, primals_53, buf129, buf134, buf540, 10, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_51
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_53
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf167 = reinterpret_tensor(buf118, (20*s0, 128), (128, 1), 0); del buf118  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_66, (64, 128), (1, 64), 4096), out=buf167)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf168 = reinterpret_tensor(buf117, (2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf117  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf167, primals_67, buf168, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf169 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf168, buf169, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf170 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf168, buf170, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf217 = reinterpret_tensor(buf168, (20*s0, 128), (128, 1), 0); del buf168  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_84, (64, 128), (1, 64), 4096), out=buf217)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf218 = reinterpret_tensor(buf167, (2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf167  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf217, primals_85, buf218, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf219 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf218, buf219, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf220 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf218, buf220, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf135 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf134, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_54, (64, 2048), (1, 64), 0), out=buf135)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf539 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_3], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf135, primals_55, buf539, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf137 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf138 = reinterpret_tensor(buf135, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf135  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_3, dropout_11], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf138, buf13, primals_55, buf137, 11, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_55
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf139 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf138, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_56, (2048, 64), (1, 2048), 0), out=buf139)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf141 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf145 = reinterpret_tensor(buf139, (20, s0, 64), (64*s0, 64, 1), 0); del buf139  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf146 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf538 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_12, add_8, x_13], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf145, buf13, buf134, primals_57, primals_58, primals_59, buf141, buf146, buf538, 12, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_57
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_59
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf147 = reinterpret_tensor(buf64, (20*s0, 192), (192, 1), 0); del buf64  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf146, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_61, (64, 192), (1, 64), 0), out=buf147)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf148 = reinterpret_tensor(buf63, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf63  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf147, primals_60, buf148, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_60
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf149 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf148, buf149, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf150 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf148, buf150, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf151 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf148, buf151, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf152 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf149, buf150, buf151, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf153 = buf152[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf154 = buf152[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf155 = buf152[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf156 = buf152[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf152
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf157 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf153, buf157, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf158 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf157, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_62, (64, 64), (1, 64), 0), out=buf158)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf160 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf164 = reinterpret_tensor(buf158, (20, s0, 64), (64*s0, 64, 1), 0); del buf158  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf165 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf537 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_13, add_9, x_14], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf164, buf13, buf146, primals_63, primals_64, primals_65, buf160, buf165, buf537, 13, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_63
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_65
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf166 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_67, (64, ), (1, ), 0), reinterpret_tensor(buf165, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_66, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf166)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_67
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf171 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf166, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf169, buf170, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf172 = buf171[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf173 = buf171[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf174 = buf171[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf175 = buf171[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf171
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf176 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf172, buf176, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf177 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf176, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_68, (64, 64), (1, 64), 0), out=buf177)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf179 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf183 = reinterpret_tensor(buf177, (20, s0, 64), (64*s0, 64, 1), 0); del buf177  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf184 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf536 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_14, add_10, x_15], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf183, buf13, buf165, primals_69, primals_70, primals_71, buf179, buf184, buf536, 14, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_69
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_71
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf185 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf184, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_72, (64, 2048), (1, 64), 0), out=buf185)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf535 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_4], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf185, primals_73, buf535, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf187 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf188 = reinterpret_tensor(buf185, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf185  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_4, dropout_15], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf188, buf13, primals_73, buf187, 15, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_73
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf189 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_16], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf188, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_74, (2048, 64), (1, 2048), 0), out=buf189)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf191 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf195 = reinterpret_tensor(buf189, (20, s0, 64), (64*s0, 64, 1), 0); del buf189  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf196 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf534 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_16, add_11, x_17], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf195, buf13, buf184, primals_75, primals_76, primals_77, buf191, buf196, buf534, 16, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_75
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_77
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf197 = reinterpret_tensor(buf148, (20*s0, 192), (192, 1), 0); del buf148  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf196, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_79, (64, 192), (1, 64), 0), out=buf197)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf198 = reinterpret_tensor(buf147, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf147  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf197, primals_78, buf198, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_78
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf199 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf198, buf199, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf200 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf198, buf200, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf201 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf198, buf201, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf202 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf199, buf200, buf201, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf203 = buf202[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf204 = buf202[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf205 = buf202[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf206 = buf202[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf202
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf207 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf203, buf207, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf208 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf207, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_80, (64, 64), (1, 64), 0), out=buf208)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf210 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf214 = reinterpret_tensor(buf208, (20, s0, 64), (64*s0, 64, 1), 0); del buf208  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf215 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf533 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_17, add_12, x_18], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf214, buf13, buf196, primals_81, primals_82, primals_83, buf210, buf215, buf533, 17, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_81
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_83
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf216 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_85, (64, ), (1, ), 0), reinterpret_tensor(buf215, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_84, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf216)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_85
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf221 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf216, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf219, buf220, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf222 = buf221[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf223 = buf221[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf224 = buf221[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf225 = buf221[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf221
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf226 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf222, buf226, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf227 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf226, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_86, (64, 64), (1, 64), 0), out=buf227)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf229 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf233 = reinterpret_tensor(buf227, (20, s0, 64), (64*s0, 64, 1), 0); del buf227  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf234 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf532 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_18, add_13, x_19], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf233, buf13, buf215, primals_87, primals_88, primals_89, buf229, buf234, buf532, 18, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_87
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_89
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf235 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_10], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf234, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_90, (64, 2048), (1, 64), 0), out=buf235)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf531 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_5], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf235, primals_91, buf531, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf237 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf238 = reinterpret_tensor(buf235, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf235  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_5, dropout_19], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf238, buf13, primals_91, buf237, 19, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_91
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf239 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_20], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf238, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_92, (2048, 64), (1, 2048), 0), out=buf239)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf241 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf245 = reinterpret_tensor(buf239, (20, s0, 64), (64*s0, 64, 1), 0); del buf239  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf246 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf247 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf249 = reinterpret_tensor(buf247, (20, s0, 1), (s0, 1, 1), 0); del buf247  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf530 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf250 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_20, add_14, x_21, output_1], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11.run(buf245, buf249, buf13, buf234, primals_93, primals_94, primals_95, primals_96, primals_97, buf241, buf246, buf530, buf250, 20, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_93
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_97
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf251 = reinterpret_tensor(buf198, (20*s0, 192), (192, 1), 0); del buf198  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf250, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_99, (64, 192), (1, 64), 0), out=buf251)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf252 = reinterpret_tensor(buf197, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf197  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf251, primals_98, buf252, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_98
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf253 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf252, buf253, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf254 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf252, buf254, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf255 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf252, buf255, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf256 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf253, buf254, buf255, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf257 = buf256[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf258 = buf256[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf259 = buf256[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf260 = buf256[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf256
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf261 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf257, buf261, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf262 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf261, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_100, (64, 64), (1, 64), 0), out=buf262)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf264 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf268 = reinterpret_tensor(buf262, (20, s0, 64), (64*s0, 64, 1), 0); del buf262  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf269 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf529 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_21, add_15, x_22], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf268, buf13, buf250, primals_101, primals_102, primals_103, buf264, buf269, buf529, 21, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_101
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_103
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf347 = reinterpret_tensor(buf252, (20*s0, 192), (192, 1), 0); del buf252  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf250, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_137, (64, 192), (1, 64), 0), out=buf347)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf348 = reinterpret_tensor(buf251, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf251  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf347, primals_136, buf348, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_136
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf349 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf348, buf349, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf350 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf348, buf350, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf351 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf348, buf351, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf352 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf349, buf350, buf351, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf353 = buf352[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf354 = buf352[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf355 = buf352[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf356 = buf352[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf352
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf357 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf353, buf357, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf358 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf357, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_138, (64, 64), (1, 64), 0), out=buf358)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf360 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf364 = reinterpret_tensor(buf358, (20, s0, 64), (64*s0, 64, 1), 0); del buf358  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf365 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf520 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_30, add_21, x_31], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf364, buf13, buf250, primals_139, primals_140, primals_141, buf360, buf365, buf520, 30, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_139
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_141
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf366 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_143, (64, ), (1, ), 0), reinterpret_tensor(buf365, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_142, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf366)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf270 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_12], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf269, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_104, (64, 2048), (1, 64), 0), out=buf270)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf528 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_6], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf270, primals_105, buf528, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf272 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf273 = reinterpret_tensor(buf270, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf270  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_6, dropout_22], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf273, buf13, primals_105, buf272, 22, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_105
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf274 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_23], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_106, (2048, 64), (1, 2048), 0), out=buf274)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf276 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf280 = reinterpret_tensor(buf274, (20, s0, 64), (64*s0, 64, 1), 0); del buf274  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf281 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf527 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_23, add_16, x_24], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf280, buf13, buf269, primals_107, primals_108, primals_109, buf276, buf281, buf527, 23, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_107
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_109
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf282 = reinterpret_tensor(buf348, (20*s0, 192), (192, 1), 0); del buf348  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf281, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_111, (64, 192), (1, 64), 0), out=buf282)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf283 = reinterpret_tensor(buf347, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf347  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf282, primals_110, buf283, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_110
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf284 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf283, buf284, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf285 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf283, buf285, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf286 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf283, buf286, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf287 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf284, buf285, buf286, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf288 = buf287[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf289 = buf287[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf290 = buf287[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf291 = buf287[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf287
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf292 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf288, buf292, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf293 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf292, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_112, (64, 64), (1, 64), 0), out=buf293)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf295 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf299 = reinterpret_tensor(buf293, (20, s0, 64), (64*s0, 64, 1), 0); del buf293  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf300 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf526 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_24, add_17, x_25], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf299, buf13, buf281, primals_113, primals_114, primals_115, buf295, buf300, buf526, 24, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_113
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_115
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf301 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_14], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf300, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_116, (64, 2048), (1, 64), 0), out=buf301)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf525 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_7], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf301, primals_117, buf525, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf303 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf304 = reinterpret_tensor(buf301, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf301  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_7, dropout_25], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf304, buf13, primals_117, buf303, 25, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_117
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf305 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_26], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf304, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_118, (2048, 64), (1, 2048), 0), out=buf305)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf307 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf311 = reinterpret_tensor(buf305, (20, s0, 64), (64*s0, 64, 1), 0); del buf305  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf312 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf524 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_26, add_18, x_27], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf311, buf13, buf300, primals_119, primals_120, primals_121, buf307, buf312, buf524, 26, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_119
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_121
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf313 = reinterpret_tensor(buf283, (20*s0, 192), (192, 1), 0); del buf283  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf312, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_123, (64, 192), (1, 64), 0), out=buf313)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf314 = reinterpret_tensor(buf282, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf282  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf313, primals_122, buf314, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_122
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf315 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf314, buf315, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf316 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf314, buf316, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf317 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf314, buf317, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf318 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf315, buf316, buf317, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf319 = buf318[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf320 = buf318[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf321 = buf318[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf322 = buf318[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf318
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf323 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf319, buf323, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf324 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_124, (64, 64), (1, 64), 0), out=buf324)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf326 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf330 = reinterpret_tensor(buf324, (20, s0, 64), (64*s0, 64, 1), 0); del buf324  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf331 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf523 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_27, add_19, x_28], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf330, buf13, buf312, primals_125, primals_126, primals_127, buf326, buf331, buf523, 27, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_125
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_127
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf332 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_16], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf331, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_128, (64, 2048), (1, 64), 0), out=buf332)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf522 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_8], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf332, primals_129, buf522, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf334 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf335 = reinterpret_tensor(buf332, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf332  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_8, dropout_28], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf335, buf13, primals_129, buf334, 28, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_129
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf336 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf335, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_130, (2048, 64), (1, 2048), 0), out=buf336)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf338 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf342 = reinterpret_tensor(buf336, (20, s0, 64), (64*s0, 64, 1), 0); del buf336  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf343 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf344 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf346 = reinterpret_tensor(buf344, (20, s0, 1), (s0, 1, 1), 0); del buf344  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf521 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf367 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_29, add_20, x_30, output_2], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11.run(buf342, buf346, buf13, buf331, primals_131, primals_132, primals_133, primals_134, primals_135, buf338, buf343, buf521, buf367, 29, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_131
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_135
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf368 = reinterpret_tensor(buf218, (20*s0, 128), (128, 1), 0); del buf218  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf367, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_142, (64, 128), (1, 64), 4096), out=buf368)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf369 = reinterpret_tensor(buf217, (2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf217  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf368, primals_143, buf369, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_143
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf370 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf369, buf370, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf371 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf369, buf371, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf372 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf366, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf370, buf371, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf373 = buf372[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf374 = buf372[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf375 = buf372[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf376 = buf372[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf372
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf377 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf373, buf377, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf378 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf377, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_144, (64, 64), (1, 64), 0), out=buf378)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf380 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf384 = reinterpret_tensor(buf378, (20, s0, 64), (64*s0, 64, 1), 0); del buf378  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf385 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf519 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_31, add_22, x_32], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf384, buf13, buf365, primals_145, primals_146, primals_147, buf380, buf385, buf519, 31, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_145
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_147
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf418 = reinterpret_tensor(buf369, (20*s0, 128), (128, 1), 0); del buf369  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf367, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_160, (64, 128), (1, 64), 4096), out=buf418)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf419 = reinterpret_tensor(buf368, (2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf368  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf418, primals_161, buf419, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf420 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf419, buf420, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf421 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf419, buf421, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf468 = reinterpret_tensor(buf419, (20*s0, 128), (128, 1), 0); del buf419  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf367, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_178, (64, 128), (1, 64), 4096), out=buf468)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf469 = reinterpret_tensor(buf418, (2, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf418  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12_xnumel = 2560*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_12.run(buf468, primals_179, buf469, ps1, ps2, triton_poi_fused_clone_12_xnumel, grid=grid(triton_poi_fused_clone_12_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf468
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf470 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf469, buf470, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf471 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf469, buf471, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf469
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf386 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_18], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf385, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_148, (64, 2048), (1, 64), 0), out=buf386)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf518 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_9], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf386, primals_149, buf518, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf388 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf389 = reinterpret_tensor(buf386, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf386  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_9, dropout_32], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf389, buf13, primals_149, buf388, 32, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_149
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf390 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_33], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf389, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_150, (2048, 64), (1, 2048), 0), out=buf390)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf392 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf396 = reinterpret_tensor(buf390, (20, s0, 64), (64*s0, 64, 1), 0); del buf390  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf397 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf517 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_33, add_23, x_34], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf396, buf13, buf385, primals_151, primals_152, primals_153, buf392, buf397, buf517, 33, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_151
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_153
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf398 = reinterpret_tensor(buf314, (20*s0, 192), (192, 1), 0); del buf314  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf397, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_155, (64, 192), (1, 64), 0), out=buf398)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf399 = reinterpret_tensor(buf313, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf313  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf398, primals_154, buf399, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_154
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf400 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf399, buf400, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf401 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf399, buf401, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf402 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf399, buf402, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf403 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf400, buf401, buf402, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf404 = buf403[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf405 = buf403[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf406 = buf403[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf407 = buf403[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf403
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf408 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf404, buf408, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf409 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf408, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_156, (64, 64), (1, 64), 0), out=buf409)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf411 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf415 = reinterpret_tensor(buf409, (20, s0, 64), (64*s0, 64, 1), 0); del buf409  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf416 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf516 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_34, add_24, x_35], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf415, buf13, buf397, primals_157, primals_158, primals_159, buf411, buf416, buf516, 34, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_157
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_159
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf417 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_161, (64, ), (1, ), 0), reinterpret_tensor(buf416, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_160, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf417)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_161
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf422 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf417, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf420, buf421, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf423 = buf422[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf424 = buf422[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf425 = buf422[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf426 = buf422[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf422
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf427 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf423, buf427, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf428 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf427, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_162, (64, 64), (1, 64), 0), out=buf428)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf430 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf434 = reinterpret_tensor(buf428, (20, s0, 64), (64*s0, 64, 1), 0); del buf428  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf435 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf515 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_35, add_25, x_36], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf434, buf13, buf416, primals_163, primals_164, primals_165, buf430, buf435, buf515, 35, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_163
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_165
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf436 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_20], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf435, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_166, (64, 2048), (1, 64), 0), out=buf436)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf514 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_10], Original ATen: [aten.relu, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_relu_threshold_backward_7.run(buf436, primals_167, buf514, triton_poi_fused_relu_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_7_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf438 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf439 = reinterpret_tensor(buf436, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf436  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_10, dropout_36], Original ATen: [aten.relu, aten.native_dropout]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_10.run(buf439, buf13, primals_167, buf438, 36, triton_poi_fused_native_dropout_relu_10_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_10_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_167
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf440 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_37], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf439, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_168, (2048, 64), (1, 2048), 0), out=buf440)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf442 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf446 = reinterpret_tensor(buf440, (20, s0, 64), (64*s0, 64, 1), 0); del buf440  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf447 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf513 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_37, add_26, x_38], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf446, buf13, buf435, primals_169, primals_170, primals_171, buf442, buf447, buf513, 37, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_169
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_171
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf448 = reinterpret_tensor(buf399, (20*s0, 192), (192, 1), 0); del buf399  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf447, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_173, (64, 192), (1, 64), 0), out=buf448)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf449 = reinterpret_tensor(buf398, (3, 20, s0, 64), (1280*s0, 64*s0, 64, 1), 0); del buf398  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 3840*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_2.run(buf448, primals_172, buf449, ps1, ps2, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf448
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_172
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf450 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_3.run(buf449, buf450, s0, ps0, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf451 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_4.run(buf449, buf451, s0, ps0, ps2, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf452 = empty_strided_cuda((s0, 8, 20, 8), (64, 8, 64*s0, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_5.run(buf449, buf452, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf449
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf453 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf450, buf451, buf452, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf454 = buf453[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf455 = buf453[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf456 = buf453[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf457 = buf453[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf453
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf458 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf454, buf458, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf459 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf458, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_174, (64, 64), (1, 64), 0), out=buf459)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf461 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf465 = reinterpret_tensor(buf459, (20, s0, 64), (64*s0, 64, 1), 0); del buf459  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf466 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf512 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_38, add_27, x_39], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf465, buf13, buf447, primals_175, primals_176, primals_177, buf461, buf466, buf512, 38, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_175
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_177
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf467 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_179, (64, ), (1, ), 0), reinterpret_tensor(buf466, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_178, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf467)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_179
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf472 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf467, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf470, buf471, None, True, 0.1)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf473 = buf472[0]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf474 = buf472[1]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf475 = buf472[2]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf476 = buf472[3]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf472
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf477 = empty_strided_cuda((20, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.clone]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 1280*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_1.run(buf473, buf477, s0, ps0, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf478 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf477, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_180, (64, 64), (1, 64), 0), out=buf478)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf480 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf484 = reinterpret_tensor(buf478, (20, s0, 64), (64*s0, 64, 1), 0); del buf478  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf485 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf511 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_39, add_28, x_40], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9.run(buf484, buf13, buf466, primals_181, primals_182, primals_183, buf480, buf485, buf511, 39, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_181
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_183
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf486 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_22], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf485, (20*s0, 64), (64, 1), 0), reinterpret_tensor(primals_184, (64, 2048), (1, 64), 0), out=buf486)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf488 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf489 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf510 = empty_strided_cuda((20, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_11, dropout_40], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel = 40960*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13.run(buf13, buf486, primals_185, buf488, buf489, buf510, 40, triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf486
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_185
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf490 = empty_strided_cuda((20*s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_41], Original ATen: [aten.addmm]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf489, (20*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_186, (2048, 64), (1, 2048), 0), out=buf490)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf492 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.bool)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf496 = reinterpret_tensor(buf490, (20, s0, 64), (64*s0, 64, 1), 0); del buf490  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf497 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf498 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf500 = reinterpret_tensor(buf498, (20, s0, 1), (s0, 1, 1), 0); del buf498  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf509 = empty_strided_cuda((20, s0, 1), (s0, 1, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf501 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_41, add_29, x_42, output_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel = 20*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11.run(buf496, buf500, buf13, buf485, primals_187, primals_188, primals_189, primals_190, primals_191, buf492, buf497, buf509, buf501, 41, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_11_xnumel), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf13
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_187
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_191
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf503 = empty_strided_cuda((s0, 64, 1, 1), (64, 1, 1, 1), torch.int8)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf508 = empty_strided_cuda((s0, 64), (64, 1), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf507 = empty_strided_cuda((), (), torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf553 = buf507; del buf507  # reuse
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_45, loss], Original ATen: [aten.adaptive_max_pool2d, aten.binary_cross_entropy_with_logits, aten.sigmoid, aten.sub]
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14_r0_numel = 64*s0
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14.run(buf553, buf501, buf506, buf503, buf508, ps0, s0, 1, triton_red_fused_adaptive_max_pool2d_binary_cross_entropy_with_logits_sigmoid_sub_14_r0_numel, grid=grid(1), stream=stream0)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf506
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     return (buf553, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, reinterpret_tensor(buf0, (20*s0, 64), (64, 1), 0), buf3, buf4, buf5, buf7, buf8, buf9, buf10, reinterpret_tensor(buf11, (20*s0, 64), (64, 1), 0), buf15, reinterpret_tensor(buf19, (20*s0, 64), (64, 1), 0), buf22, reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0), buf26, buf30, reinterpret_tensor(buf31, (20*s0, 64), (64, 1), 0), buf34, buf35, buf36, buf38, buf39, buf40, buf41, reinterpret_tensor(buf42, (20*s0, 64), (64, 1), 0), buf45, buf49, reinterpret_tensor(buf50, (20*s0, 64), (64, 1), 0), buf53, reinterpret_tensor(buf54, (20*s0, 2048), (2048, 1), 0), buf57, buf61, reinterpret_tensor(buf62, (20*s0, 64), (64, 1), 0), buf65, buf66, buf67, buf69, buf70, buf71, buf72, reinterpret_tensor(buf73, (20*s0, 64), (64, 1), 0), buf76, buf80, reinterpret_tensor(buf81, (20*s0, 64), (64, 1), 0), buf84, reinterpret_tensor(buf85, (20*s0, 2048), (2048, 1), 0), buf88, buf92, buf93, buf96, buf99, buf100, buf101, buf103, buf104, buf105, buf106, reinterpret_tensor(buf107, (20*s0, 64), (64, 1), 0), buf110, reinterpret_tensor(buf114, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf116, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf115, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf119, buf120, buf122, buf123, buf124, buf125, reinterpret_tensor(buf126, (20*s0, 64), (64, 1), 0), buf129, buf133, reinterpret_tensor(buf134, (20*s0, 64), (64, 1), 0), buf137, reinterpret_tensor(buf138, (20*s0, 2048), (2048, 1), 0), buf141, buf145, reinterpret_tensor(buf146, (20*s0, 64), (64, 1), 0), buf149, buf150, buf151, buf153, buf154, buf155, buf156, reinterpret_tensor(buf157, (20*s0, 64), (64, 1), 0), buf160, buf164, reinterpret_tensor(buf165, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf166, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf169, buf170, buf172, buf173, buf174, buf175, reinterpret_tensor(buf176, (20*s0, 64), (64, 1), 0), buf179, buf183, reinterpret_tensor(buf184, (20*s0, 64), (64, 1), 0), buf187, reinterpret_tensor(buf188, (20*s0, 2048), (2048, 1), 0), buf191, buf195, reinterpret_tensor(buf196, (20*s0, 64), (64, 1), 0), buf199, buf200, buf201, buf203, buf204, buf205, buf206, reinterpret_tensor(buf207, (20*s0, 64), (64, 1), 0), buf210, buf214, reinterpret_tensor(buf215, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf216, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf219, buf220, buf222, buf223, buf224, buf225, reinterpret_tensor(buf226, (20*s0, 64), (64, 1), 0), buf229, buf233, reinterpret_tensor(buf234, (20*s0, 64), (64, 1), 0), buf237, reinterpret_tensor(buf238, (20*s0, 2048), (2048, 1), 0), buf241, buf245, buf246, buf249, reinterpret_tensor(buf250, (20*s0, 64), (64, 1), 0), buf253, buf254, buf255, buf257, buf258, buf259, buf260, reinterpret_tensor(buf261, (20*s0, 64), (64, 1), 0), buf264, buf268, reinterpret_tensor(buf269, (20*s0, 64), (64, 1), 0), buf272, reinterpret_tensor(buf273, (20*s0, 2048), (2048, 1), 0), buf276, buf280, reinterpret_tensor(buf281, (20*s0, 64), (64, 1), 0), buf284, buf285, buf286, buf288, buf289, buf290, buf291, reinterpret_tensor(buf292, (20*s0, 64), (64, 1), 0), buf295, buf299, reinterpret_tensor(buf300, (20*s0, 64), (64, 1), 0), buf303, reinterpret_tensor(buf304, (20*s0, 2048), (2048, 1), 0), buf307, buf311, reinterpret_tensor(buf312, (20*s0, 64), (64, 1), 0), buf315, buf316, buf317, buf319, buf320, buf321, buf322, reinterpret_tensor(buf323, (20*s0, 64), (64, 1), 0), buf326, buf330, reinterpret_tensor(buf331, (20*s0, 64), (64, 1), 0), buf334, reinterpret_tensor(buf335, (20*s0, 2048), (2048, 1), 0), buf338, buf342, buf343, buf346, buf349, buf350, buf351, buf353, buf354, buf355, buf356, reinterpret_tensor(buf357, (20*s0, 64), (64, 1), 0), buf360, buf364, reinterpret_tensor(buf365, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf367, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf366, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf370, buf371, buf373, buf374, buf375, buf376, reinterpret_tensor(buf377, (20*s0, 64), (64, 1), 0), buf380, buf384, reinterpret_tensor(buf385, (20*s0, 64), (64, 1), 0), buf388, reinterpret_tensor(buf389, (20*s0, 2048), (2048, 1), 0), buf392, buf396, reinterpret_tensor(buf397, (20*s0, 64), (64, 1), 0), buf400, buf401, buf402, buf404, buf405, buf406, buf407, reinterpret_tensor(buf408, (20*s0, 64), (64, 1), 0), buf411, buf415, reinterpret_tensor(buf416, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf417, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf420, buf421, buf423, buf424, buf425, buf426, reinterpret_tensor(buf427, (20*s0, 64), (64, 1), 0), buf430, buf434, reinterpret_tensor(buf435, (20*s0, 64), (64, 1), 0), buf438, reinterpret_tensor(buf439, (20*s0, 2048), (2048, 1), 0), buf442, buf446, reinterpret_tensor(buf447, (20*s0, 64), (64, 1), 0), buf450, buf451, buf452, buf454, buf455, buf456, buf457, reinterpret_tensor(buf458, (20*s0, 64), (64, 1), 0), buf461, buf465, reinterpret_tensor(buf466, (20*s0, 64), (64, 1), 0), reinterpret_tensor(buf467, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), buf470, buf471, buf473, buf474, buf475, buf476, reinterpret_tensor(buf477, (20*s0, 64), (64, 1), 0), buf480, buf484, reinterpret_tensor(buf485, (20*s0, 64), (64, 1), 0), buf488, reinterpret_tensor(buf489, (20*s0, 2048), (2048, 1), 0), buf492, buf496, buf497, buf500, reinterpret_tensor(buf501, (s0, 64, 1, 20), (64, 1, 1280*s0, 64*s0), 0), buf503, buf508, buf509, primals_186, buf510, primals_184, buf511, primals_180, reinterpret_tensor(primals_178, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_178, (64, 64), (64, 1), 0), buf512, primals_174, primals_173, buf513, primals_168, buf514, primals_166, buf515, primals_162, reinterpret_tensor(primals_160, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_160, (64, 64), (64, 1), 0), buf516, primals_156, primals_155, buf517, primals_150, buf518, primals_148, buf519, primals_144, reinterpret_tensor(primals_142, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_142, (64, 64), (64, 1), 0), buf520, primals_138, primals_137, buf521, primals_130, buf522, primals_128, buf523, primals_124, primals_123, buf524, primals_118, buf525, primals_116, buf526, primals_112, primals_111, buf527, primals_106, buf528, primals_104, buf529, primals_100, primals_99, buf530, primals_92, buf531, primals_90, buf532, primals_86, reinterpret_tensor(primals_84, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_84, (64, 64), (64, 1), 0), buf533, primals_80, primals_79, buf534, primals_74, buf535, primals_72, buf536, primals_68, reinterpret_tensor(primals_66, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_66, (64, 64), (64, 1), 0), buf537, primals_62, primals_61, buf538, primals_56, buf539, primals_54, buf540, primals_50, reinterpret_tensor(primals_48, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_48, (64, 64), (64, 1), 0), buf541, buf542, primals_44, buf543, primals_36, buf544, primals_34, buf545, primals_30, primals_29, buf546, primals_24, buf547, primals_22, buf548, primals_18, primals_17, buf549, primals_12, buf550, primals_10, buf551, buf552, primals_6, s0, 20*s0, 8*s0, )
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_1 = 10
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_2 = 20
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_3 = rand_strided((10, 20, 64), (1280, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_4 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_5 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_6 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_10 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_11 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_12 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_13 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_16 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_17 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_18 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_19 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_22 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_23 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_24 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_25 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_26 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_27 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_28 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_29 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_30 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_31 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_33 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_34 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_35 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_36 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_37 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_39 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_40 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_41 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_42 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_43 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_44 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_45 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_46 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_47 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_48 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_49 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_50 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_51 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_52 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_53 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_54 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_55 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_56 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_57 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_58 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_59 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_60 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_61 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_62 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_63 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_64 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_65 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_66 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_67 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_68 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_69 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_70 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_71 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_72 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_73 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_74 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_75 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_76 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_77 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_78 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_79 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_80 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_81 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_82 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_83 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_84 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_85 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_86 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_87 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_88 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_89 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_90 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_91 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_92 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_93 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_94 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_95 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_96 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_97 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_98 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_99 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_100 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_101 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_102 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_103 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_104 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_105 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_106 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_107 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_108 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_109 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_110 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_111 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_112 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_113 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_114 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_115 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_116 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_117 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_118 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_119 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_120 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_121 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_122 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_123 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_124 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_125 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_126 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_127 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_128 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_129 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_130 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_131 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_132 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_133 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_134 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_135 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_136 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_137 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_138 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_139 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_140 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_141 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_142 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_143 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_144 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_145 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_146 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_147 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_148 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_149 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_150 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_151 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_152 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_153 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_154 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_155 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_156 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_157 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_158 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_159 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_160 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_161 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_162 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_163 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_164 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_165 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_166 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_167 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_168 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_169 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_171 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_172 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_173 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_174 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_175 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_177 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_178 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_179 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_180 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_181 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_183 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_184 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_185 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_186 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_187 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_190 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_191 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191])
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] if __name__ == "__main__":
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 14:28:30.830000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:30.898000 1612526 site-packages/torch/_inductor/graph.py:2022] [89/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/32/c32b4wrfmbpu5wx4f7uxflvsw5de6gn5chchlu3mf3r7dyp6qs6n.py
I0205 14:28:32.317000 1612526 site-packages/torch/_inductor/graph.py:2056] [89/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/32/c32b4wrfmbpu5wx4f7uxflvsw5de6gn5chchlu3mf3r7dyp6qs6n.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] Output code: 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # AOT ID: ['18_backward']
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import torch
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import random
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import os
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import tempfile
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from math import inf, nan
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from cmath import nanj
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch import device, empty_strided
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     grid,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     split_scan_grid,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     grid_combo_kernels,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     start_graph,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     end_graph,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     cooperative_reduction_grid,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] aten = torch.ops.aten
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] _quantized = torch.ops._quantized
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] async_compile = AsyncCompile()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ha/cha2jgqqfqgl7gxs7w6qfqtext7k5u7wo6idzv5rbav66yzlx7kl.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.div]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2918 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1585, %tangents_1), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Scalar](args = (%mul_2918, %mul_2919), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_div_mul_0 = async_compile.triton('triton_poi_fused_div_mul_0', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 1024}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_mul_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_div_mul_0(in_out_ptr0, in_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (0))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.broadcast_to(tmp1, [XBLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tmp0 * tmp2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = 64*ks0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp3 / tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp6, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/m5/cm5y5mgmjf3ecggcpwsoftjqag5kw2apkuiksipc5s56ziabsrmz.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [x_45], Original ATen: [aten.adaptive_max_pool2d]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_45 => _low_memory_max_pool2d_offsets_to_indices
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %_low_memory_max_pool2d_offsets_to_indices : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_offsets_to_indices.default](args = (%getitem_165, 20, 20, [1, 20], [0, 0]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_adaptive_max_pool2d_1 = async_compile.triton('triton_poi_fused_adaptive_max_pool2d_1', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 1024}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i8', 'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_adaptive_max_pool2d_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_adaptive_max_pool2d_1(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.full([1], 20, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.where((tmp0 < 0) != (tmp1 < 0), tl.where(tmp0 % tmp1 != 0, tmp0 // tmp1 - 1, tmp0 // tmp1), tmp0 // tmp1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tmp2 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp0 - tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.full([1], 0, tl.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp5 + tmp2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tmp5 + tmp4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.full([1], 20, tl.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tmp6 * tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp9 + tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp10, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g5/cg54vobmuktra3so4puemveeow2upfpxjrsvwmoe66rzeioj6uyp.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%permute_160, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_native_layer_norm_backward_2 = async_compile.triton('triton_red_fused_native_layer_norm_backward_2', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 64, 'r0_': 256},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_native_layer_norm_backward_2(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_1 = (r0_index % 20)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index // 20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + 20*x0 + 1280*r0_2), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2a/c2ajqlamdfx3abj5hlxefhy4gzdn2yw5mq2akbc67ydv7bxyejv2.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [x_42, output_3], Original ATen: [aten.native_layer_norm_backward, aten.native_layer_norm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   output_3 => mul_2880, sub_1561
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_42 => add_3471, mul_2872
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2921 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_160, %primals_190), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2921, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2872 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2871, %primals_188), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3471 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2872, %primals_189), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1561 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_3471, %getitem_163), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2880 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1561, %rsqrt_33), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2923 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2921, %mul_2880), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2923, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_native_layer_norm_native_layer_norm_backward_3 = async_compile.triton('triton_per_fused_native_layer_norm_native_layer_norm_backward_3', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_native_layer_norm_backward_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_native_layer_norm_native_layer_norm_backward_3(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = (xindex % 20)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // 20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = (xindex % ks0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x5 = xindex // ks0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (x2 + 20*r0_1 + 1280*x3), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tl.load(in_ptr5 + (x5 + 20*r0_1 + 1280*x4), xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4 - tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 * tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp9 * tmp10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.where(xmask, tmp12, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tl.sum(tmp14, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tmp16 * tmp10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tmp17 * tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tl.where(xmask, tmp19, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tl.sum(tmp21, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp15, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp22, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e7/ce76zxtnj32gwmya6ddcph5rkswskx3qzxpj7nuzetfqwhjosref.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2926 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_160, %mul_2880), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2926, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_native_layer_norm_backward_4 = async_compile.triton('triton_red_fused_native_layer_norm_backward_4', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_native_layer_norm_backward_4(in_ptr0, in_ptr1, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (20*x1 + 1280*((r0_2 % ks0)) + ((((r0_2 + 10*ks0*x0) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x1 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x0) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2c/c2cjpcva5yk6orrljwbhzfwhbv6wouskofzhlju6ob6pjdfofuj6.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2926 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_160, %mul_2880), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2926, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_native_layer_norm_backward_5 = async_compile.triton('triton_per_fused_native_layer_norm_backward_5', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 64, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_native_layer_norm_backward_5(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 2*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kd/ckdojo6qjsgkpslu73cboqmf55pgyzzbyd4ztgb2opdckocboeni.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2921 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_160, %primals_190), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2922 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2921, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2924 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2880, %sum_2), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1587 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2922, %sum_1), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1588 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1587, %mul_2924), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_33, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2925 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %sub_1588), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_native_layer_norm_backward_6 = async_compile.triton('triton_poi_fused_native_layer_norm_backward_6', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'y': 32, 'x': 1024}, tile_hint=TileHint.DEFAULT,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_backward_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_native_layer_norm_backward_6(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     ynumel = 20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     ymask = yindex < ynumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     y0 = yindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (y0 + 20*x3), xmask & ymask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr3 + (y0 + 20*x2), xmask & ymask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.load(in_out_ptr0 + (x3 + 64*ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = 0.015625
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tmp5 * tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tmp7 - tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp9 - tmp12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tmp2 * tmp13
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.debug_barrier()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (x3 + 64*ks0*y0), tmp14, xmask & ymask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lw/clwi272xmv433qzcn4lptlyx7zut5cwyllpbozcytpym7o3cy27e.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2933 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2925, %mul_2871), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2933, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2925, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_native_layer_norm_backward_7 = async_compile.triton('triton_red_fused_native_layer_norm_backward_7', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_native_layer_norm_backward_7(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp7 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp6 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = _tmp7 + tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp7 = tl.where(r0_mask & xmask, tmp8, _tmp7)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.sum(_tmp7, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/o4/co4jnse2cspyeqytxkrjn2k6n62bhqdy3yza5kl7orm3rsrhltbx.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2933 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2925, %mul_2871), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2933, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_native_layer_norm_backward_8 = async_compile.triton('triton_per_fused_native_layer_norm_backward_8', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 64, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_native_layer_norm_backward_8(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g4/cg4rad6nbdkzx4ts42hxgwktxxfqo7eyozchx6dkxouhentiqzmb.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2928 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2925, %primals_188), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2929 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2928, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2928, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2930 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2928, %mul_2871), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2930, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2931 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2871, %sum_6), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1590 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2929, %sum_5), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1591 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1590, %mul_2931), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2932 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_2, %sub_1591), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_41, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2934 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2935 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2932, %mul_2934), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_native_dropout_backward_native_layer_norm_backward_9 = async_compile.triton('triton_per_fused_native_dropout_backward_native_layer_norm_backward_9', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*i1', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_dropout_backward_native_layer_norm_backward_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_native_dropout_backward_native_layer_norm_backward_9(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.where(xmask, tmp3, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.sum(tmp5, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp2 * tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.broadcast_to(tmp8, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.where(xmask, tmp9, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tl.sum(tmp11, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp2 * tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tmp15 - tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tmp7 * tmp12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tmp16 - tmp17
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tmp13 * tmp18
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tmp20.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = tmp19 * tmp23
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp19, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 64*x0), tmp24, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ll/cll3zwdf2x7jr5deafp3kp5sfr7ycmyflfnolhr7k63f2ljbof6k.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_258, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_sum_10 = async_compile.triton('triton_red_fused_sum_10', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_sum_10(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_2 + 640*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ft/cft6an5vdgletgrtlrga2b7abkrrkc2p4o5fvwkb5tuf5n6j45e5.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten.threshold_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_40, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2936 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2937 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_260, %mul_2936), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %full_default_1 : [num_users=12] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default_1, %mul_2937), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_native_dropout_backward_threshold_backward_11 = async_compile.triton('triton_poi_fused_native_dropout_backward_threshold_backward_11', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 524288}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_threshold_backward_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_native_dropout_backward_threshold_backward_11(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), None).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), None)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), None).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp1 * tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = 0.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, None)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/km/ckmo6piciiz3y6adl7e4xuaqfawx77g3djmmzybewbq65xgjwjnw.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3541 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2932, %view_263), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2944 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3541, %mul_2815), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2944, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3541, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_12 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_12', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_12', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_12(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = tmp2 * tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp9, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/to/cto4nlrosi4kgaawemw2ijzkjzrn4rpdtfc42qi4idzpbrzrcu6u.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3541 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2932, %view_263), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2939 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3541, %primals_182), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2940 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2939, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2939, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2941 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2939, %mul_2815), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2941, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2942 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2815, %sum_12), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1593 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2940, %sum_11), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1594 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1593, %mul_2942), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2943 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_3, %sub_1594), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_4 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_39, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2945 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_4, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_2946 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2943, %mul_2945), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 * tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp4 * tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tmp4 * tmp16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tmp17 - tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tmp9 * tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tmp18 - tmp19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tmp15 * tmp20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tmp23 * tmp24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tmp21 * tmp25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp21, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 64*x0), tmp26, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/op/copqhapyq34qb7x76tqlwdoyqsydbxfelwmkobmk66w4ed2d3pgj.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_49 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_22,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_clone_14 = async_compile.triton('triton_poi_fused_clone_14', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 32768}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_clone_14(in_ptr0, in_ptr1, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 64) % 2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = ((xindex // 128) % 20)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // 2560
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = (xindex % 128)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*x3 + 64*ks0*x2) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*x3) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*x3 + 64*ks0*x2) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*x3) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = x1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 == tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = 0.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tmp0 == tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp5 + tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x4 + 128*x3 + 128*ks0*x2), tmp10, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tc/ctc3q4l2sugouyf6esoktgegzgb4yejpgcvhkizqfkuqm6aazevt.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %view_277 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view_272, [%mul_5, 64]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_view_15 = async_compile.triton('triton_poi_fused_view_15', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 16384}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_view_15(in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*((x1 % ks0)) + 64*ks0*(x1 // ks0)) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jb/cjbgw6h3wtuzsbyt6mzzdwwli7nv5a3yzoe46qgbkjty6jpwtw46.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_277, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_278, %view_275],), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_cat_sum_16 = async_compile.triton('triton_per_fused_cat_sum_16', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 64, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_cat_sum_16(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3o/c3o2eaz34nso5dgu3jwabw72k7cpopmzzxlmncpnvdmsreomhvkd.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_274, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_sum_17 = async_compile.triton('triton_red_fused_sum_17', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_sum_17(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 256
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 128)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_2 + 1280*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rw/crwzw3w2yozfrgmddwqfr5bsqcqb2fl4lelozv5w4zwkri5ucj26.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_274, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_278, %view_275],), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_cat_sum_18 = async_compile.triton('triton_per_fused_cat_sum_18', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_cat_sum_18(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3c/c3cwie6w7mwto3n7zdclhn33c5nvdgqmq7sywaknpcgqhv5mybez.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %clone_57 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_23,), kwargs = {memory_format: torch.contiguous_format})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_poi_fused_clone_19 = async_compile.triton('triton_poi_fused_clone_19', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.pointwise(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 65536}, 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     min_elem_per_thread=0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_poi_fused_clone_19(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = ((xindex // 64) % 3)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = ((xindex // 192) % 20)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // 3840
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x4 = (xindex % 192)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*x3 + 64*ks0*x2) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*x3) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*x3 + 64*ks0*x2) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*x3) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (8*((((((x0 + 64*x3) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*x3 + 64*ks0*x2) // (64*ks0)) % 20)) + 1280*(((((((x0 + 64*x3) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = x1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 == tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = 0.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tmp0 == tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp5 + tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tmp0 == tmp11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp10 + tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x4 + 192*x3 + 192*ks0*x2), tmp15, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j6/cj6t2niys5p3wymi7maeiyc2g7qjeu2dagz3v365klbtnnongfx2.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_290, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_sum_20 = async_compile.triton('triton_red_fused_sum_20', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_20', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_sum_20(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 384
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 192)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 192
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 192*r0_2 + 1920*ks0*x1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kj/ckjkbzfjemilksskwdxbuf6ugphy3ddkfxptaxd3ro7apwq3yhoq.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_290, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_sum_21 = async_compile.triton('triton_per_fused_sum_21', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_sum_21(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 192
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 192*r0_1), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rb/crb7hc5llczjlry3nopexbm2tjyfmspwwclrv3gutlv42bcw4gda.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_261, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_sum_22 = async_compile.triton('triton_red_fused_sum_22', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 4096, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_22', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_sum_22(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 4096
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 2048)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 2048
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_2 + 20480*ks0*x1), r0_mask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp2 = tl.where(r0_mask, tmp3, _tmp2)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, None)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u7/cu7bxcmbs4msq2sutsqbtmlju2xsouiafauqed75s3refz4c4mfo.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_261, [0], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_sum_23 = async_compile.triton('triton_per_fused_sum_23', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 2048, 'r0_': 2},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_sum_23(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 2048
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ib/cibep34a6mtwo274qopmbcnc2qchnn7tgcn3mo6ocewhjotsugzf.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [x_30, output_2], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   output_2 => mul_1989, sub_1071
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_30 => add_2374, mul_1981
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3549 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_276, %view_311), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3556 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3549, %view_346), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3015 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3556, %primals_134), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3016 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3015, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_62 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3015, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_1981 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1980, %primals_132), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_2374 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1981, %primals_133), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1071 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_2374, %getitem_107), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_1989 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1071, %rsqrt_23), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3017 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3015, %mul_1989), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_63 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3017, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3018 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1989, %sum_63), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1617 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3016, %sum_62), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1618 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1617, %mul_3018), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_11 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_23, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3019 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_11, %sub_1618), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3022 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3019, %primals_132), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3023 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3022, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_66 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3022, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3024 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3022, %mul_1980), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_67 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3024, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3025 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1980, %sum_67), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1620 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3023, %sum_66), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1621 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1620, %mul_3025), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3026 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_12, %sub_1621), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_14 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_29, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3028 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_14, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3029 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3026, %mul_3028), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*i1', 'out_ptr0': '*fp32', 'out_ptr3': '*fp32', 'out_ptr6': '*fp32', 'out_ptr7': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 11, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr3, out_ptr6, out_ptr7, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tl.load(in_ptr7 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.load(in_ptr8 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp43 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp49 = tl.load(in_ptr10 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4 - tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 * tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp11 + tmp12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tl.where(xmask, tmp16, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tmp15 * tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tl.where(xmask, tmp21, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = tl.sum(tmp23, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = 0.015625
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tmp7 * tmp25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp27 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp28 = tmp15 * tmp27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp29 = tmp28 - tmp19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp30 = tmp8 * tmp24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp31 = tmp29 - tmp30
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp32 = tmp26 * tmp31
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp33 = tmp32 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp34 = tl.broadcast_to(tmp33, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp36 = tl.where(xmask, tmp34, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp37 = tl.sum(tmp36, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp38 = tmp33 * tmp0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp39 = tl.broadcast_to(tmp38, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp41 = tl.where(xmask, tmp39, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp42 = tl.sum(tmp41, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp44 = tmp33 * tmp27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp45 = tmp44 - tmp37
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp46 = tmp0 * tmp42
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp47 = tmp45 - tmp46
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp48 = tmp43 * tmp47
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp50 = tmp49.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp51 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp52 = tmp50 * tmp51
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp53 = tmp48 * tmp52
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 64*x0), tmp32, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp48, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr7 + (r0_1 + 64*x0), tmp53, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gn/cgnfl5wgqj7i7lowhjycyvtl2iftny3h72i2fmhxg3kw672pqpo2.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3549 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_276, %view_311), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3556 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3549, %view_346), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3020 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3556, %mul_1989), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_64 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3020, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_65 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3556, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_25 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_25', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_25', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_25(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp8 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.load(in_ptr3 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = tmp2 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp6 = tmp4 * tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp9 = _tmp8 + tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp8 = tl.where(r0_mask & xmask, tmp9, _tmp8)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp10 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.sum(_tmp8, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp8, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp11, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/m5/cm5csyraeosg6hyy6nsbc3g3w2nvgnfznhlx65njgti6pagjbf5c.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, output_1], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   output_1 => mul_1461, sub_782
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   x_21 => add_1733, mul_1453
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3560 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3010, %view_362), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3570 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3560, %mul_3077), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3573 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3570, %view_419), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3082 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3573, %primals_96), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3083 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3082, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_102 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3082, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_1453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1452, %primals_94), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_1733 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1453, %primals_95), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_782 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1733, %getitem_81), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_1461 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_782, %rsqrt_16), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3084 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3082, %mul_1461), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_103 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3084, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3085 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1461, %sum_103), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1638 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3083, %sum_102), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1639 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1638, %mul_3085), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %div_18 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_16, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3086 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_18, %sub_1639), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3089 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3086, %primals_94), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3090 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3089, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_106 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3089, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3091 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3089, %mul_1452), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_107 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3091, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3092 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1452, %sum_107), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1641 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3090, %sum_106), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1642 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1641, %mul_3092), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3093 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_19, %sub_1642), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_23 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_20, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3095 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_23, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3096 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3093, %mul_3095), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*fp32', 'in_ptr11': '*i1', 'out_ptr0': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 12, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr5, out_ptr6, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp12 = tl.load(in_ptr7 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.load(in_ptr8 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = tl.load(in_ptr9 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp45 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp51 = tl.load(in_ptr11 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tmp4 - tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tmp6 * tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tmp11 + tmp12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tmp13 + tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tl.broadcast_to(tmp17, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tl.where(xmask, tmp18, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tl.sum(tmp20, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tmp17 * tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tl.broadcast_to(tmp22, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tl.where(xmask, tmp23, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tl.sum(tmp25, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp27 = 0.015625
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp28 = tmp7 * tmp27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp29 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp30 = tmp17 * tmp29
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp31 = tmp30 - tmp21
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp32 = tmp8 * tmp26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp33 = tmp31 - tmp32
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp34 = tmp28 * tmp33
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp35 = tmp34 * tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp36 = tl.broadcast_to(tmp35, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp38 = tl.where(xmask, tmp36, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp39 = tl.sum(tmp38, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp40 = tmp35 * tmp0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp43 = tl.where(xmask, tmp41, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp44 = tl.sum(tmp43, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp46 = tmp35 * tmp29
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp47 = tmp46 - tmp39
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp48 = tmp0 * tmp44
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp49 = tmp47 - tmp48
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp50 = tmp45 * tmp49
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp52 = tmp51.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp53 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp54 = tmp52 * tmp53
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp55 = tmp50 * tmp54
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp34, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 64*x0), tmp50, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp55, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/my/cmyucdixsxbgyb2t5f3eram3rytga2yqvf6t2mqvavkyqriswxpb.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3560 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3010, %view_362), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3570 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3560, %mul_3077), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3573 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3570, %view_419), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3087 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3573, %mul_1461), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_104 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3087, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_105 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3573, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_27 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_27', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_27', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_27(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp10 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp13 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.load(in_ptr3 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = tl.load(in_ptr4 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = tmp2 + tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp6 = tmp4 + tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = tmp6 * tmp7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp9 = tl.broadcast_to(tmp8, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp11 = _tmp10 + tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp10 = tl.where(r0_mask & xmask, tmp11, _tmp10)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp12 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp14 = _tmp13 + tmp12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp13 = tl.where(r0_mask & xmask, tmp14, _tmp13)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tl.sum(_tmp10, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tl.sum(_tmp13, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp10, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp13, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/35/c35meyxmhxqlhhpbomt4qi4inp63yjdnwgehrwz2cciqmc226cfp.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3590 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3162, %view_511), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3172 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3590, %mul_3166), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_159 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3172, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_160 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3590, [0, 1]), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_28 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_28', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 128, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_28', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_28(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 64*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + 1280*((r0_2 % ks0))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = tmp2 * tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp9, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gw/cgwb2ksgi6tntm2e447yqalocrp2biyloxaw5glux3ydchrcdjdz.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %add_3590 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3162, %view_511), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3167 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3590, %primals_46), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3168 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3167, 64), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_157 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3167, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3169 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3167, %mul_3166), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_158 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3169, [2], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3170 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3166, %sum_158), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1665 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3168, %sum_157), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sub_1666 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1665, %mul_3170), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3171 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_27, %sub_1666), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %convert_element_type_34 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_9, torch.float32), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3173 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_34, 1.1111111111111112), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %mul_3174 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3171, %mul_3173), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 256, 'r0_': 64},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_numel = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_offset = 0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_1 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x2 = (xindex % ks0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex // ks0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x3 + 1280*x2), xmask, other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp4 = tmp2 * tmp3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp10 = tmp4 * tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp16 = 64.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tmp4 * tmp16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp18 = tmp17 - tmp8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp19 = tmp9 * tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp20 = tmp18 - tmp19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp21 = tmp15 * tmp20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp24 = 1.1111111111111112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp25 = tmp23 * tmp24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp26 = tmp21 * tmp25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp26, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wx/cwxc7auw7ott6nqas3ftxrk4l5k56sj3dl74nfxzqmuakyo3qs6e.py
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Source node to ATen node mapping:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] # Graph fragment:
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] #   %sum_162 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_521, [0, 1], True), kwargs = {})
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_red_fused_sum_30 = async_compile.triton('triton_red_fused_sum_30', '''
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] import triton.language as tl
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton_heuristics.reduction(
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     filename=__file__,
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_30', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] @triton.jit
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def triton_red_fused_sum_30(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xnumel = 384
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rnumel = r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     xmask = xindex < xnumel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rbase = r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x0 = (xindex % 192)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x1 = xindex // 192
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     _tmp17 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     x3 = xindex
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_index = r0_offset + r0_base
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_mask = r0_index < r0_numel
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         roffset = r0_offset
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         rindex = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         r0_2 = r0_index
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (8*((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + ((x0 % 64))) // (64*ks0)) % 20)) + 1280*(((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp8 = tl.load(in_ptr1 + (8*((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + ((x0 % 64))) // (64*ks0)) % 20)) + 1280*(((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp13 = tl.load(in_ptr2 + (8*((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*((r0_2 % ks0)) + 64*ks0*((((r0_2 + 10*ks0*x1) // ks0) % 20)) + ((x0 % 64))) // (64*ks0)) % 20)) + 1280*(((((((64*((r0_2 % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp0 = x0 // 64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp1 = tl.full([1, 1], 2, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp2 = tmp0 == tmp1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp4 = 0.0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp5 = tl.where(tmp2, tmp3, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp6 = tl.full([1, 1], 1, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp7 = tmp0 == tmp6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp9 = tl.where(tmp7, tmp8, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp10 = tmp5 + tmp9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp11 = tl.full([1, 1], 0, tl.int32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp12 = tmp0 == tmp11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp14 = tl.where(tmp12, tmp13, tmp4)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp15 = tmp10 + tmp14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         tmp18 = _tmp17 + tmp16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         _tmp17 = tl.where(r0_mask & xmask, tmp18, _tmp17)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tmp17 = tl.sum(_tmp17, 1)[:, None]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] ''', device_str='cuda')
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] async_compile.wait(globals())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] del async_compile
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def call(args):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_1, mul_5, mul_68, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, gt_1, view_13, gt_2, mul_190, view_15, view_21, view_22, view_23, getitem_8, getitem_9, getitem_10, getitem_11, view_24, gt_3, mul_307, view_26, gt_4, view_28, gt_5, mul_363, view_30, view_36, view_37, view_38, getitem_16, getitem_17, getitem_18, getitem_19, view_39, gt_6, mul_480, view_41, gt_7, view_43, gt_8, mul_536, getitem_25, rsqrt_6, view_51, view_52, view_53, getitem_26, getitem_27, getitem_28, getitem_29, view_54, gt_9, view_56, view_58, view_64, view_65, view_66, getitem_36, getitem_37, getitem_38, getitem_39, view_67, gt_10, mul_808, view_69, gt_11, view_71, gt_12, mul_864, view_73, view_79, view_80, view_81, getitem_44, getitem_45, getitem_46, getitem_47, view_82, gt_13, mul_981, view_84, view_92, view_93, view_94, getitem_54, getitem_55, getitem_56, getitem_57, view_95, gt_14, mul_1102, view_97, gt_15, view_99, gt_16, mul_1158, view_101, view_107, view_108, view_109, getitem_62, getitem_63, getitem_64, getitem_65, view_110, gt_17, mul_1275, view_112, view_120, view_121, view_122, getitem_72, getitem_73, getitem_74, getitem_75, view_123, gt_18, mul_1396, view_125, gt_19, view_127, gt_20, mul_1452, getitem_81, rsqrt_16, view_129, view_135, view_136, view_137, getitem_82, getitem_83, getitem_84, getitem_85, view_138, gt_21, mul_1578, view_140, gt_22, view_142, gt_23, mul_1634, view_144, view_150, view_151, view_152, getitem_90, getitem_91, getitem_92, getitem_93, view_153, gt_24, mul_1751, view_155, gt_25, view_157, gt_26, mul_1807, view_159, view_165, view_166, view_167, getitem_98, getitem_99, getitem_100, getitem_101, view_168, gt_27, mul_1924, view_170, gt_28, view_172, gt_29, mul_1980, getitem_107, rsqrt_23, view_180, view_181, view_182, getitem_108, getitem_109, getitem_110, getitem_111, view_183, gt_30, mul_2102, view_185, view_187, view_193, view_194, view_195, getitem_118, getitem_119, getitem_120, getitem_121, view_196, gt_31, mul_2227, view_198, gt_32, view_200, gt_33, mul_2283, view_202, view_208, view_209, view_210, getitem_126, getitem_127, getitem_128, getitem_129, view_211, gt_34, mul_2400, view_213, view_221, view_222, view_223, getitem_136, getitem_137, getitem_138, getitem_139, view_224, gt_35, mul_2521, view_226, gt_36, view_228, gt_37, mul_2577, view_230, view_236, view_237, view_238, getitem_144, getitem_145, getitem_146, getitem_147, view_239, gt_38, mul_2694, view_241, view_249, view_250, view_251, getitem_154, getitem_155, getitem_156, getitem_157, view_252, gt_39, mul_2815, view_254, gt_40, view_256, gt_41, mul_2871, getitem_163, rsqrt_33, unsqueeze_18, getitem_165, sub_1585, div_2, permute_161, le, permute_165, div_3, permute_169, permute_178, permute_182, div_4, permute_186, permute_195, div_5, permute_199, le_1, permute_203, div_6, permute_207, permute_216, permute_220, div_7, permute_224, permute_233, div_8, permute_237, le_2, permute_241, div_9, permute_245, permute_254, permute_258, div_10, permute_262, permute_271, div_12, permute_275, le_3, permute_279, div_13, permute_283, permute_292, div_14, permute_296, le_4, permute_300, div_15, permute_304, permute_313, div_16, permute_317, le_5, permute_321, div_17, permute_325, permute_334, div_19, permute_338, le_6, permute_342, div_20, permute_346, permute_355, permute_359, div_21, permute_363, permute_372, div_22, permute_376, le_7, permute_380, div_23, permute_384, permute_393, permute_397, div_24, permute_401, permute_410, div_25, permute_414, le_8, permute_418, div_26, permute_422, permute_431, permute_435, mul_3166, div_27, permute_439, div_29, permute_451, le_9, permute_455, div_30, permute_459, permute_468, div_31, permute_472, le_10, permute_476, div_32, permute_480, permute_489, div_33, permute_493, le_11, permute_497, mul_3233, div_34, permute_501, tangents_1 = args
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     args.clear()
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     s0 = primals_1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_26, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_32, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_38, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_39, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_40, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_46, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_52, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_58, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_64, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_70, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_76, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_82, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_88, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_94, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_95, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_96, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_102, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_108, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_114, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_120, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_126, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_132, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_133, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_134, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_140, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_146, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_152, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_158, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_164, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(primals_190, (64, ), (1, ))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_6, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_7, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_8, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_1, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_2, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_3, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_9, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_11, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_1, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_13, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_2, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_190, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_15, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_21, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_22, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_23, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_8, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_9, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_10, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_11, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_24, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_3, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_307, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_26, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_4, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_28, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_5, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_363, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_30, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_36, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_37, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_38, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_16, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_17, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_18, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_19, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_39, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_6, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_480, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_41, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_7, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_43, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_8, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_536, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_25, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(rsqrt_6, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_51, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_52, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_53, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_26, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_27, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_28, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_29, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_54, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_9, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_56, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_58, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_64, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_65, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_66, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_36, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_37, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_38, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_39, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_67, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_10, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_808, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_69, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_11, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_71, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_12, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_864, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_73, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_79, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_80, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_81, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_44, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_45, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_46, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_47, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_82, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_13, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_981, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_84, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_92, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_93, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_94, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_54, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_55, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_56, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_57, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_95, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_14, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1102, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_97, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_15, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_99, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_16, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1158, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_101, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_107, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_108, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_109, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_62, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_63, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_64, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_65, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_110, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_17, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1275, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_112, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_120, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_121, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_122, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_72, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_73, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_74, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_75, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_123, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_18, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1396, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_125, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_19, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_127, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_20, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1452, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_81, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(rsqrt_16, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_129, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_135, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_136, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_137, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_82, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_83, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_84, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_85, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_138, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_21, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1578, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_140, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_22, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_142, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_23, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1634, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_144, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_150, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_151, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_152, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_90, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_91, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_92, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_93, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_153, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_24, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1751, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_155, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_25, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_157, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_26, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1807, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_159, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_165, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_166, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_167, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_98, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_99, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_100, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_101, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_168, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_27, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1924, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_170, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_28, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_172, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_29, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_1980, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_107, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(rsqrt_23, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_180, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_181, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_182, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_108, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_109, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_110, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_111, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_183, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_30, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2102, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_185, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_187, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_193, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_194, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_195, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_118, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_119, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_120, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_121, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_196, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_31, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2227, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_198, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_32, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_200, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_33, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2283, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_202, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_208, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_209, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_210, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_126, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_127, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_128, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_129, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_211, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_34, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2400, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_213, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_221, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_222, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_223, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_136, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_137, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_138, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_139, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_224, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_35, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2521, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_226, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_36, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_228, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_37, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2577, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_230, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_236, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_237, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_238, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_144, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_145, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_146, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_147, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_239, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_38, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2694, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_241, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_249, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_250, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_251, (s0, 8, 20, 8), (64, 8, 64*s0, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_154, (s0, 8, 20, 8), (1280, 8, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_155, (s0, 8, 32), (256, 32, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_156, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_157, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_252, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_39, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2815, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_254, (20*s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_40, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(view_256, (20*s0, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(gt_41, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_2871, (20, s0, 64), (64*s0, 64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_163, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(rsqrt_33, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(unsqueeze_18, (s0, 64, 1, 20), (64, 1, 1280*s0, 64*s0))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(getitem_165, (s0, 64, 1, 1), (64, 1, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(sub_1585, (s0, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_2, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_161, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_165, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_3, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_169, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_178, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_182, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_4, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_186, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_195, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_5, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_199, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_1, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_203, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_6, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_207, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_216, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_220, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_7, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_224, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_233, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_8, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_237, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_2, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_241, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_9, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_245, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_254, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_258, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_10, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_262, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_271, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_12, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_275, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_3, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_279, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_13, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_283, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_292, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_14, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_296, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_4, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_300, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_15, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_304, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_313, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_16, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_317, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_5, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_321, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_17, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_325, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_334, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_19, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_338, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_6, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_342, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_20, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_346, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_355, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_359, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_21, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_363, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_372, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_22, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_376, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_7, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_380, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_23, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_384, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_393, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_397, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_24, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_401, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_410, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_25, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_414, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_8, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_418, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_26, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_422, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_431, (128, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_435, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_3166, (20, s0, 64), (64, 1280, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_27, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_439, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_29, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_451, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_9, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_455, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_30, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_459, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_468, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_31, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_472, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_10, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_476, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_32, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_480, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_489, (192, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_33, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_493, (64, 2048), (2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(le_11, (20, s0, 2048), (2048*s0, 2048, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_497, (2048, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(mul_3233, (20, s0, 64), (64, 1280, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(div_34, (20, s0, 1), (s0, 1, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(permute_501, (64, 64), (64, 1))
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     assert_size_stride(tangents_1, (), ())
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         torch.cuda.set_device(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf0 = sub_1585; del sub_1585  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.div]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_div_mul_0_xnumel = 64*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_div_mul_0.run(buf0, tangents_1, s0, triton_poi_fused_div_mul_0_xnumel, grid=grid(triton_poi_fused_div_mul_0_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del tangents_1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf1 = empty_strided_cuda((s0, 64, 1, 1), (64, 1, 64*s0, 64*s0), torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_45], Original ATen: [aten.adaptive_max_pool2d]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_adaptive_max_pool2d_1_xnumel = 64*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_adaptive_max_pool2d_1.run(getitem_165, buf1, triton_poi_fused_adaptive_max_pool2d_1_xnumel, grid=grid(triton_poi_fused_adaptive_max_pool2d_1_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_165
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_45], Original ATen: [aten.adaptive_max_pool2d, aten.adaptive_max_pool2d_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf2 = torch.ops.aten.adaptive_max_pool2d_backward.default(reinterpret_tensor(buf0, (s0, 64, 1, 1), (64, 1, 0, 0), 0), unsqueeze_18, buf1)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del unsqueeze_18
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf3 = buf2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf10 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_2_r0_numel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_2.run(buf3, buf10, 64, triton_red_fused_native_layer_norm_backward_2_r0_numel, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf5 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf4 = empty_strided_cuda((20, s0, 1), (1, 20, 20*s0), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf6 = empty_strided_cuda((20, s0, 1), (s0, 1, 20*s0), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_42, output_3], Original ATen: [aten.native_layer_norm_backward, aten.native_layer_norm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_native_layer_norm_backward_3_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_native_layer_norm_backward_3.run(mul_2871, primals_188, primals_189, getitem_163, rsqrt_33, buf3, primals_190, buf5, buf4, buf6, s0, triton_per_fused_native_layer_norm_native_layer_norm_backward_3_xnumel, 64, grid=grid(triton_per_fused_native_layer_norm_native_layer_norm_backward_3_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_163
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_189
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf8 = empty_strided_cuda((64, 2), (2, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_4_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_4.run(buf3, buf5, buf8, s0, 128, triton_red_fused_native_layer_norm_backward_4_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf9 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_5.run(buf8, buf9, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf7 = buf5; del buf5  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_6_xnumel = 64*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_6.run(buf7, rsqrt_33, buf3, primals_190, buf4, buf6, s0, 20, triton_poi_fused_native_layer_norm_backward_6_xnumel, grid=grid(20, triton_poi_fused_native_layer_norm_backward_6_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_190
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del rsqrt_33
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf14 = reinterpret_tensor(buf8, (64, 2), (1, 64), 0); del buf8  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf16 = empty_strided_cuda((64, 2), (1, 64), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7.run(buf7, mul_2871, buf14, buf16, s0, 128, triton_red_fused_native_layer_norm_backward_7_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf15 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf14, buf15, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf13 = buf7; del buf7  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf18 = reinterpret_tensor(buf3, (20, s0, 64), (64*s0, 64, 1), 0); del buf3  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_9_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_9.run(buf13, primals_188, mul_2871, div_2, gt_41, buf18, triton_per_fused_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_41
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2871
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_188
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf17 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf16, buf17, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf21 = reinterpret_tensor(buf16, (1, 64, 2), (128, 1, 64), 0); del buf16  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf18, buf21, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf22 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf21, buf22, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf20 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (64, 20*s0), (1, 64), 0), view_256, out=buf20)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_256
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf19 = empty_strided_cuda((20*s0, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (20*s0, 64), (64, 1), 0), permute_161, out=buf19)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_161
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf23 = reinterpret_tensor(buf19, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf19  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten.threshold_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf23, le, gt_40, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_40
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf24 = reinterpret_tensor(buf18, (20*s0, 64), (64, 1), 0); del buf18  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0), permute_165, out=buf24)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_165
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf31 = reinterpret_tensor(buf21, (64, 2), (1, 64), 0); del buf21  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf33 = buf14; del buf14  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf13, buf24, mul_2815, buf31, buf33, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf30 = buf13; del buf13  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf35 = empty_strided_cuda((20, s0, 64), (64*s0, 64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf30, buf24, primals_182, mul_2815, div_3, gt_39, buf35, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_39
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2815
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_182
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf37 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (64, 20*s0), (1, 64), 0), view_252, out=buf37)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_252
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf32 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf31, buf32, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf34 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf33, buf34, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf38 = reinterpret_tensor(buf33, (1, 64, 2), (128, 1, 64), 0); del buf33  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf35, buf38, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf36 = buf24; del buf24  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (20*s0, 64), (64, 1), 0), permute_169, out=buf36)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf35
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_169
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf40 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf36, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_249, view_250, view_251, None, getitem_154, getitem_155, getitem_156, getitem_157, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf36
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_154
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_155
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_156
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_157
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_249
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_250
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_251
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf39 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf38, buf39, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf41 = buf40[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf42 = buf40[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf43 = buf40[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf40
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf44 = empty_strided_cuda((20, s0, 2, 64), (128*s0, 128, 64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf43, buf42, buf44, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf42
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf49 = reinterpret_tensor(buf43, (20*s0, 64), (64, 1), 0); del buf43  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf41, buf49, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf57 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf51 = reinterpret_tensor(buf57, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf49, (64, 20*s0), (1, 64), 0), view_241, out=buf51)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_241
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf52 = buf38; del buf38  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf49, buf52, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf50 = reinterpret_tensor(buf41, (20*s0, 64), (64, 1), 0); del buf41  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf49, permute_182, out=buf50)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_182
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf56 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf54 = reinterpret_tensor(buf56, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf52, buf54, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf47 = empty_strided_cuda((1, 128, 2), (256, 1, 128), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf44, buf47, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf55 = reinterpret_tensor(buf56, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf47, buf55, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf61 = reinterpret_tensor(buf52, (64, 2), (1, 64), 0); del buf52  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf63 = buf31; del buf31  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf30, buf50, mul_2694, buf61, buf63, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf60 = buf30; del buf30  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf65 = reinterpret_tensor(buf49, (20, s0, 64), (64*s0, 64, 1), 0); del buf49  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf60, buf50, primals_176, mul_2694, div_4, gt_38, buf65, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_38
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2694
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_176
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf67 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf65, (64, 20*s0), (1, 64), 0), view_239, out=buf67)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_239
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf62 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf61, buf62, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf64 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf63, buf64, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf68 = reinterpret_tensor(buf63, (1, 64, 2), (128, 1, 64), 0); del buf63  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf65, buf68, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf66 = buf50; del buf50  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf65, (20*s0, 64), (64, 1), 0), permute_186, out=buf66)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf65
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_186
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf70 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf66, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_236, view_237, view_238, None, getitem_144, getitem_145, getitem_146, getitem_147, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf66
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_144
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_145
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_146
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_147
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_236
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_237
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_238
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf69 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf68, buf69, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf71 = buf70[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf72 = buf70[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf73 = buf70[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf70
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf74 = empty_strided_cuda((20, s0, 3, 64), (192*s0, 192, 64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf73, buf72, buf71, buf74, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf76 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf74, (192, 20*s0), (1, 192), 0), view_230, out=buf76)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_230
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf77 = empty_strided_cuda((1, 192, 2), (384, 1, 192), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf74, buf77, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf75 = reinterpret_tensor(buf73, (20*s0, 64), (64, 1), 0); del buf73  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf74, (20*s0, 192), (192, 1), 0), permute_195, out=buf75)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_195
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf78 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf77, buf78, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf82 = reinterpret_tensor(buf68, (64, 2), (1, 64), 0); del buf68  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf84 = buf61; del buf61  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf60, buf75, mul_2577, buf82, buf84, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf81 = buf60; del buf60  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf86 = reinterpret_tensor(buf72, (20, s0, 64), (64*s0, 64, 1), 0); del buf72  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf81, buf75, primals_170, mul_2577, div_5, gt_37, buf86, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_37
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2577
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_170
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf88 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf86, (64, 20*s0), (1, 64), 0), view_228, out=buf88)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_228
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf83 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf82, buf83, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf85 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf84, buf85, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf89 = reinterpret_tensor(buf84, (1, 64, 2), (128, 1, 64), 0); del buf84  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf86, buf89, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf90 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf89, buf90, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf26 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf23, buf26, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf25 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (2048, 20*s0), (1, 2048), 0), view_254, out=buf25)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_254
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf27 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf26, buf27, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf45 = buf75; del buf75  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (20*s0, 128), (128, 1), 0), permute_178, out=buf45)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_178
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf46 = reinterpret_tensor(buf57, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (128, 20*s0), (1, 128), 0), view_187, out=buf46)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf87 = reinterpret_tensor(buf23, (20*s0, 2048), (2048, 1), 0); del buf23  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf86, (20*s0, 64), (64, 1), 0), permute_199, out=buf87)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_199
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf91 = reinterpret_tensor(buf87, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf87  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf91, le_1, gt_36, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_36
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf92 = reinterpret_tensor(buf86, (20*s0, 64), (64, 1), 0); del buf86  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf91, (20*s0, 2048), (2048, 1), 0), permute_203, out=buf92)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_203
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf99 = reinterpret_tensor(buf89, (64, 2), (1, 64), 0); del buf89  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf101 = buf82; del buf82  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf81, buf92, mul_2521, buf99, buf101, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf98 = buf81; del buf81  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf103 = reinterpret_tensor(buf71, (20, s0, 64), (64*s0, 64, 1), 0); del buf71  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf98, buf92, primals_164, mul_2521, div_6, gt_35, buf103, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_35
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2521
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_164
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf105 = reinterpret_tensor(buf26, (64, 64), (64, 1), 0); del buf26  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf103, (64, 20*s0), (1, 64), 0), view_224, out=buf105)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_224
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf100 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf99, buf100, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf102 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf101, buf102, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf106 = reinterpret_tensor(buf101, (1, 64, 2), (128, 1, 64), 0); del buf101  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf103, buf106, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf104 = buf92; del buf92  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf103, (20*s0, 64), (64, 1), 0), permute_207, out=buf104)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf103
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_207
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf108 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf104, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_221, view_222, view_223, None, getitem_136, getitem_137, getitem_138, getitem_139, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf104
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_136
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_137
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_138
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_139
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_221
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_222
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_223
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf107 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf106, buf107, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf109 = buf108[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf110 = buf108[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf111 = buf108[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf108
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf112 = buf44; del buf44  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf111, buf110, buf112, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf110
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf117 = reinterpret_tensor(buf111, (20*s0, 64), (64, 1), 0); del buf111  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf109, buf117, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf125 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf119 = reinterpret_tensor(buf125, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf117, (64, 20*s0), (1, 64), 0), view_213, out=buf119)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_213
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf120 = buf106; del buf106  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf117, buf120, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf118 = reinterpret_tensor(buf109, (20*s0, 64), (64, 1), 0); del buf109  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf117, permute_220, out=buf118)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_220
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf124 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf122 = reinterpret_tensor(buf124, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf120, buf122, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf115 = buf47; del buf47  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf112, buf115, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf123 = reinterpret_tensor(buf124, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf115, buf123, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf129 = reinterpret_tensor(buf120, (64, 2), (1, 64), 0); del buf120  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf131 = buf99; del buf99  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf98, buf118, mul_2400, buf129, buf131, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf128 = buf98; del buf98  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf133 = reinterpret_tensor(buf117, (20, s0, 64), (64*s0, 64, 1), 0); del buf117  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf128, buf118, primals_158, mul_2400, div_7, gt_34, buf133, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_34
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2400
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_158
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf135 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf133, (64, 20*s0), (1, 64), 0), view_211, out=buf135)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_211
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf130 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf129, buf130, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf132 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf131, buf132, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf136 = reinterpret_tensor(buf131, (1, 64, 2), (128, 1, 64), 0); del buf131  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf133, buf136, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf134 = buf118; del buf118  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf133, (20*s0, 64), (64, 1), 0), permute_224, out=buf134)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf133
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_224
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf138 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf134, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_208, view_209, view_210, None, getitem_126, getitem_127, getitem_128, getitem_129, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf134
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_126
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_127
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_128
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_129
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_208
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_209
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_210
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf137 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf136, buf137, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf139 = buf138[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf140 = buf138[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf141 = buf138[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf138
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf142 = buf74; del buf74  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf141, buf140, buf139, buf142, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf144 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf142, (192, 20*s0), (1, 192), 0), view_202, out=buf144)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_202
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf145 = buf77; del buf77  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf142, buf145, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf143 = reinterpret_tensor(buf141, (20*s0, 64), (64, 1), 0); del buf141  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf142, (20*s0, 192), (192, 1), 0), permute_233, out=buf143)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_233
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf146 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf145, buf146, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf150 = reinterpret_tensor(buf136, (64, 2), (1, 64), 0); del buf136  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf152 = buf129; del buf129  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf128, buf143, mul_2283, buf150, buf152, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf149 = buf128; del buf128  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf154 = reinterpret_tensor(buf140, (20, s0, 64), (64*s0, 64, 1), 0); del buf140  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf149, buf143, primals_152, mul_2283, div_8, gt_33, buf154, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_33
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2283
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_152
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf156 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf154, (64, 20*s0), (1, 64), 0), view_200, out=buf156)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_200
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf151 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf150, buf151, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf153 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf152, buf153, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf157 = reinterpret_tensor(buf152, (1, 64, 2), (128, 1, 64), 0); del buf152  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf154, buf157, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf158 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf157, buf158, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf94 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf91, buf94, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf93 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf91, (2048, 20*s0), (1, 2048), 0), view_226, out=buf93)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_226
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf95 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf94, buf95, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf113 = buf143; del buf143  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf112, (20*s0, 128), (128, 1), 0), permute_216, out=buf113)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_216
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf114 = reinterpret_tensor(buf125, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf112, (128, 20*s0), (1, 128), 0), view_187, out=buf114)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf155 = reinterpret_tensor(buf91, (20*s0, 2048), (2048, 1), 0); del buf91  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf154, (20*s0, 64), (64, 1), 0), permute_237, out=buf155)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_237
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf159 = reinterpret_tensor(buf155, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf155  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf159, le_2, gt_32, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_32
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf160 = reinterpret_tensor(buf154, (20*s0, 64), (64, 1), 0); del buf154  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf159, (20*s0, 2048), (2048, 1), 0), permute_241, out=buf160)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_241
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf167 = reinterpret_tensor(buf157, (64, 2), (1, 64), 0); del buf157  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf169 = buf150; del buf150  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf149, buf160, mul_2227, buf167, buf169, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf166 = buf149; del buf149  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf171 = reinterpret_tensor(buf139, (20, s0, 64), (64*s0, 64, 1), 0); del buf139  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf166, buf160, primals_146, mul_2227, div_9, gt_31, buf171, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_31
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2227
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_146
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf173 = reinterpret_tensor(buf94, (64, 64), (64, 1), 0); del buf94  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf171, (64, 20*s0), (1, 64), 0), view_196, out=buf173)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_196
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf168 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf167, buf168, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf170 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf169, buf170, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf174 = reinterpret_tensor(buf169, (1, 64, 2), (128, 1, 64), 0); del buf169  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf171, buf174, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf172 = buf160; del buf160  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf171, (20*s0, 64), (64, 1), 0), permute_245, out=buf172)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf171
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_245
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf176 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf172, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_193, view_194, view_195, None, getitem_118, getitem_119, getitem_120, getitem_121, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf172
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_118
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_119
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_120
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_121
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_193
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_194
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_195
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf175 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf174, buf175, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf177 = buf176[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf178 = buf176[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf179 = buf176[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf176
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf180 = buf112; del buf112  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf179, buf178, buf180, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf193 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf182 = reinterpret_tensor(buf193, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf180, (128, 20*s0), (1, 128), 0), view_187, out=buf182)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_187
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf185 = reinterpret_tensor(buf179, (20*s0, 64), (64, 1), 0); del buf179  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf177, buf185, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf187 = reinterpret_tensor(buf193, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf185, (64, 20*s0), (1, 64), 0), view_185, out=buf187)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_185
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf188 = buf174; del buf174  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf185, buf188, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf186 = reinterpret_tensor(buf177, (20*s0, 64), (64, 1), 0); del buf177  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf185, permute_258, out=buf186)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_258
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf192 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf190 = reinterpret_tensor(buf192, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf188, buf190, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf183 = buf115; del buf115  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf180, buf183, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf181 = buf185; del buf185  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf180, (20*s0, 128), (128, 1), 0), permute_254, out=buf181)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_254
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf191 = reinterpret_tensor(buf192, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf183, buf191, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf197 = reinterpret_tensor(buf188, (64, 2), (1, 64), 0); del buf188  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf199 = buf167; del buf167  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf166, buf186, mul_2102, buf197, buf199, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf196 = buf166; del buf166  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf201 = reinterpret_tensor(buf178, (20, s0, 64), (64*s0, 64, 1), 0); del buf178  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf196, buf186, primals_140, mul_2102, div_10, gt_30, buf201, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_30
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_2102
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_140
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf203 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf201, (64, 20*s0), (1, 64), 0), view_183, out=buf203)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_183
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf198 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf197, buf198, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf200 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf199, buf200, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf204 = reinterpret_tensor(buf199, (1, 64, 2), (128, 1, 64), 0); del buf199  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf201, buf204, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf202 = buf186; del buf186  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf201, (20*s0, 64), (64, 1), 0), permute_262, out=buf202)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_262
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf206 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf202, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_180, view_181, view_182, None, getitem_108, getitem_109, getitem_110, getitem_111, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_108
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_109
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_110
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_111
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_180
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_181
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_182
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf205 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf204, buf205, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf207 = buf206[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf208 = buf206[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf209 = buf206[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf206
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf210 = buf142; del buf142  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf209, buf208, buf207, buf210, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf213 = buf145; del buf145  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf210, buf213, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf214 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf213, buf214, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf211 = reinterpret_tensor(buf209, (20*s0, 64), (64, 1), 0); del buf209  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (20*s0, 192), (192, 1), 0), permute_271, out=buf211)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_271
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf212 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (192, 20*s0), (1, 192), 0), view_129, out=buf212)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf162 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf159, buf162, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf161 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf159, (2048, 20*s0), (1, 2048), 0), view_198, out=buf161)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_198
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf163 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf162, buf163, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf216 = reinterpret_tensor(buf208, (20, s0, 64), (64*s0, 64, 1), 0); del buf208  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf218 = reinterpret_tensor(buf207, (20, s0, 64), (64*s0, 64, 1), 0); del buf207  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf225 = reinterpret_tensor(buf202, (20, s0, 64), (64*s0, 64, 1), 0); del buf202  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf230 = buf201; del buf201  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_30, output_2], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24.run(mul_1980, primals_132, primals_133, getitem_107, rsqrt_23, buf45, buf113, buf181, primals_134, div_12, gt_29, buf216, buf218, buf225, buf230, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_107
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_29
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_132
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_133
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_134
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del rsqrt_23
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf232 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf230, (64, 20*s0), (1, 64), 0), view_172, out=buf232)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_172
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf219 = reinterpret_tensor(buf204, (64, 2), (1, 64), 0); del buf204  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf221 = buf197; del buf197  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_25_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_25.run(buf45, buf113, buf181, buf216, buf219, buf221, s0, 128, triton_red_fused_add_native_layer_norm_backward_25_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf113
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf181
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf216
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf45
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf226 = empty_strided_cuda((64, 2), (1, 64), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf228 = empty_strided_cuda((64, 2), (1, 64), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7.run(buf218, mul_1980, buf226, buf228, s0, 128, triton_red_fused_native_layer_norm_backward_7_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1980
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf220 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf219, buf220, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf222 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf221, buf222, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf227 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf226, buf227, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf229 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf228, buf229, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf233 = reinterpret_tensor(buf228, (1, 64, 2), (128, 1, 64), 0); del buf228  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf230, buf233, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf234 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf233, buf234, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf231 = reinterpret_tensor(buf159, (20*s0, 2048), (2048, 1), 0); del buf159  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf230, (20*s0, 64), (64, 1), 0), permute_275, out=buf231)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_275
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf235 = reinterpret_tensor(buf231, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf231  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf235, le_3, gt_28, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_28
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf236 = reinterpret_tensor(buf230, (20*s0, 64), (64, 1), 0); del buf230  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf235, (20*s0, 2048), (2048, 1), 0), permute_279, out=buf236)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_279
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf243 = reinterpret_tensor(buf233, (64, 2), (1, 64), 0); del buf233  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf245 = buf226; del buf226  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf225, buf236, mul_1924, buf243, buf245, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf242 = buf225; del buf225  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf247 = buf218; del buf218  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf242, buf236, primals_126, mul_1924, div_13, gt_27, buf247, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_13
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1924
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_126
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf249 = reinterpret_tensor(buf162, (64, 64), (64, 1), 0); del buf162  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf247, (64, 20*s0), (1, 64), 0), view_168, out=buf249)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_168
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf244 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf243, buf244, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf246 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf245, buf246, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf250 = reinterpret_tensor(buf245, (1, 64, 2), (128, 1, 64), 0); del buf245  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf247, buf250, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf248 = buf236; del buf236  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf247, (20*s0, 64), (64, 1), 0), permute_283, out=buf248)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf247
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_283
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf252 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf248, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_165, view_166, view_167, None, getitem_98, getitem_99, getitem_100, getitem_101, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf248
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_100
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_101
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_98
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_99
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_165
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_166
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_167
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf251 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf250, buf251, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf253 = buf252[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf254 = buf252[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf255 = buf252[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf252
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf256 = buf210; del buf210  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf255, buf254, buf253, buf256, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf253
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf258 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf256, (192, 20*s0), (1, 192), 0), view_159, out=buf258)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_159
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf259 = buf213; del buf213  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf256, buf259, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf257 = reinterpret_tensor(buf255, (20*s0, 64), (64, 1), 0); del buf255  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf256, (20*s0, 192), (192, 1), 0), permute_292, out=buf257)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_292
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf260 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf259, buf260, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf264 = reinterpret_tensor(buf250, (64, 2), (1, 64), 0); del buf250  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf266 = buf243; del buf243  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf242, buf257, mul_1807, buf264, buf266, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf263 = buf242; del buf242  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf268 = reinterpret_tensor(buf254, (20, s0, 64), (64*s0, 64, 1), 0); del buf254  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf263, buf257, primals_120, mul_1807, div_14, gt_26, buf268, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1807
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_120
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf270 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf268, (64, 20*s0), (1, 64), 0), view_157, out=buf270)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_157
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf265 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf264, buf265, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf267 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf266, buf267, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf271 = reinterpret_tensor(buf266, (1, 64, 2), (128, 1, 64), 0); del buf266  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf268, buf271, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf272 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf271, buf272, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf238 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf235, buf238, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf237 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf235, (2048, 20*s0), (1, 2048), 0), view_170, out=buf237)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_170
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf239 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf238, buf239, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf269 = reinterpret_tensor(buf235, (20*s0, 2048), (2048, 1), 0); del buf235  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf268, (20*s0, 64), (64, 1), 0), permute_296, out=buf269)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_296
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf273 = reinterpret_tensor(buf269, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf269  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf273, le_4, gt_25, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf274 = reinterpret_tensor(buf268, (20*s0, 64), (64, 1), 0); del buf268  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (20*s0, 2048), (2048, 1), 0), permute_300, out=buf274)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_300
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf281 = reinterpret_tensor(buf271, (64, 2), (1, 64), 0); del buf271  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf283 = buf264; del buf264  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf263, buf274, mul_1751, buf281, buf283, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf280 = buf263; del buf263  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf285 = reinterpret_tensor(buf257, (20, s0, 64), (64*s0, 64, 1), 0); del buf257  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf280, buf274, primals_114, mul_1751, div_15, gt_24, buf285, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_15
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1751
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_114
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf287 = reinterpret_tensor(buf238, (64, 64), (64, 1), 0); del buf238  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf285, (64, 20*s0), (1, 64), 0), view_153, out=buf287)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_153
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf282 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf281, buf282, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf284 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf283, buf284, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf288 = reinterpret_tensor(buf283, (1, 64, 2), (128, 1, 64), 0); del buf283  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf285, buf288, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf286 = buf274; del buf274  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf285, (20*s0, 64), (64, 1), 0), permute_304, out=buf286)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf285
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_304
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf290 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf286, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_150, view_151, view_152, None, getitem_90, getitem_91, getitem_92, getitem_93, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf286
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_90
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_91
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_92
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_93
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_150
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_151
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_152
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf289 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf288, buf289, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf291 = buf290[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf292 = buf290[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf293 = buf290[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf290
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf294 = buf256; del buf256  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf293, buf292, buf291, buf294, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf291
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf296 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf294, (192, 20*s0), (1, 192), 0), view_144, out=buf296)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_144
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf297 = buf259; del buf259  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf294, buf297, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf295 = reinterpret_tensor(buf293, (20*s0, 64), (64, 1), 0); del buf293  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf294, (20*s0, 192), (192, 1), 0), permute_313, out=buf295)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_313
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf298 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf297, buf298, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf302 = reinterpret_tensor(buf288, (64, 2), (1, 64), 0); del buf288  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf304 = buf281; del buf281  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf280, buf295, mul_1634, buf302, buf304, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf301 = buf280; del buf280  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf306 = reinterpret_tensor(buf292, (20, s0, 64), (64*s0, 64, 1), 0); del buf292  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf301, buf295, primals_108, mul_1634, div_16, gt_23, buf306, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_23
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1634
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_108
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf308 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf306, (64, 20*s0), (1, 64), 0), view_142, out=buf308)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_142
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf303 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf302, buf303, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf305 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf304, buf305, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf309 = reinterpret_tensor(buf304, (1, 64, 2), (128, 1, 64), 0); del buf304  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf306, buf309, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf310 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf309, buf310, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf276 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf273, buf276, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf275 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (2048, 20*s0), (1, 2048), 0), view_155, out=buf275)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_155
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf277 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf276, buf277, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf307 = reinterpret_tensor(buf273, (20*s0, 2048), (2048, 1), 0); del buf273  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf306, (20*s0, 64), (64, 1), 0), permute_317, out=buf307)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_317
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf311 = reinterpret_tensor(buf307, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf307  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf311, le_5, gt_22, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_22
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf312 = reinterpret_tensor(buf306, (20*s0, 64), (64, 1), 0); del buf306  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf311, (20*s0, 2048), (2048, 1), 0), permute_321, out=buf312)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_321
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf319 = reinterpret_tensor(buf309, (64, 2), (1, 64), 0); del buf309  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf321 = buf302; del buf302  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf301, buf312, mul_1578, buf319, buf321, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf318 = buf301; del buf301  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf323 = reinterpret_tensor(buf295, (20, s0, 64), (64*s0, 64, 1), 0); del buf295  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf318, buf312, primals_102, mul_1578, div_17, gt_21, buf323, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_17
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_21
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1578
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_102
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf325 = reinterpret_tensor(buf276, (64, 64), (64, 1), 0); del buf276  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (64, 20*s0), (1, 64), 0), view_138, out=buf325)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_138
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf320 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf319, buf320, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf322 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf321, buf322, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf326 = reinterpret_tensor(buf321, (1, 64, 2), (128, 1, 64), 0); del buf321  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf323, buf326, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf324 = buf312; del buf312  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (20*s0, 64), (64, 1), 0), permute_325, out=buf324)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_325
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf328 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf324, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_135, view_136, view_137, None, getitem_82, getitem_83, getitem_84, getitem_85, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_82
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_83
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_84
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_85
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_135
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_136
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_137
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf327 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf326, buf327, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf329 = buf328[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf330 = buf328[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf331 = buf328[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf328
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf332 = buf294; del buf294  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf331, buf330, buf329, buf332, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf334 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf332, (192, 20*s0), (1, 192), 0), view_129, out=buf334)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_129
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf335 = buf297; del buf297  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf332, buf335, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf333 = reinterpret_tensor(buf331, (20*s0, 64), (64, 1), 0); del buf331  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf332, (20*s0, 192), (192, 1), 0), permute_334, out=buf333)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_334
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf336 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf335, buf336, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf314 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf311, buf314, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf313 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf311, (2048, 20*s0), (1, 2048), 0), view_140, out=buf313)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_140
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf315 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf314, buf315, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf339 = reinterpret_tensor(buf330, (20, s0, 64), (64*s0, 64, 1), 0); del buf330  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf337 = reinterpret_tensor(buf329, (20, s0, 64), (64*s0, 64, 1), 0); del buf329  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf341 = buf337; del buf337  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf348 = reinterpret_tensor(buf324, (20, s0, 64), (64*s0, 64, 1), 0); del buf324  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf353 = buf323; del buf323  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, output_1], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26.run(buf341, mul_1452, primals_94, primals_95, getitem_81, rsqrt_16, buf196, buf211, buf318, buf333, primals_96, div_19, gt_20, buf339, buf348, buf353, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_26_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_81
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_94
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_95
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_96
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del rsqrt_16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf355 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf353, (64, 20*s0), (1, 64), 0), view_127, out=buf355)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_127
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf342 = reinterpret_tensor(buf326, (64, 2), (1, 64), 0); del buf326  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf344 = buf319; del buf319  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_27_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_27.run(buf196, buf211, buf318, buf333, buf339, buf342, buf344, s0, 128, triton_red_fused_add_native_layer_norm_backward_27_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf196
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf211
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf318
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf333
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf339
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf349 = buf221; del buf221  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf351 = buf219; del buf219  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7.run(buf341, mul_1452, buf349, buf351, s0, 128, triton_red_fused_native_layer_norm_backward_7_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1452
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf343 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf342, buf343, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf345 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf344, buf345, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf350 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf349, buf350, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf352 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf351, buf352, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf356 = reinterpret_tensor(buf351, (1, 64, 2), (128, 1, 64), 0); del buf351  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf353, buf356, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf357 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf356, buf357, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf354 = reinterpret_tensor(buf311, (20*s0, 2048), (2048, 1), 0); del buf311  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf353, (20*s0, 64), (64, 1), 0), permute_338, out=buf354)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_338
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf358 = reinterpret_tensor(buf354, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf354  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf358, le_6, gt_19, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf359 = reinterpret_tensor(buf353, (20*s0, 64), (64, 1), 0); del buf353  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (20*s0, 2048), (2048, 1), 0), permute_342, out=buf359)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_342
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf366 = reinterpret_tensor(buf356, (64, 2), (1, 64), 0); del buf356  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf368 = buf349; del buf349  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf348, buf359, mul_1396, buf366, buf368, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf365 = buf348; del buf348  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf370 = buf341; del buf341  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf365, buf359, primals_88, mul_1396, div_20, gt_18, buf370, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_18
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1396
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_88
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf372 = reinterpret_tensor(buf314, (64, 64), (64, 1), 0); del buf314  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf370, (64, 20*s0), (1, 64), 0), view_123, out=buf372)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_123
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf367 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf366, buf367, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf369 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf368, buf369, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf373 = reinterpret_tensor(buf368, (1, 64, 2), (128, 1, 64), 0); del buf368  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf370, buf373, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf371 = buf359; del buf359  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf370, (20*s0, 64), (64, 1), 0), permute_346, out=buf371)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf370
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_346
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf375 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf371, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_120, view_121, view_122, None, getitem_72, getitem_73, getitem_74, getitem_75, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf371
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_72
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_73
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_74
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_75
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_120
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_121
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_122
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf374 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf373, buf374, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf376 = buf375[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf377 = buf375[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf378 = buf375[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf375
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf379 = buf180; del buf180  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf378, buf377, buf379, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf377
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf384 = reinterpret_tensor(buf378, (20*s0, 64), (64, 1), 0); del buf378  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf376, buf384, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf392 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf386 = reinterpret_tensor(buf392, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf384, (64, 20*s0), (1, 64), 0), view_112, out=buf386)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_112
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf387 = buf373; del buf373  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf384, buf387, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf385 = reinterpret_tensor(buf376, (20*s0, 64), (64, 1), 0); del buf376  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf384, permute_359, out=buf385)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_359
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf391 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf389 = reinterpret_tensor(buf391, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf387, buf389, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf382 = buf183; del buf183  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf379, buf382, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf390 = reinterpret_tensor(buf391, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf382, buf390, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf396 = reinterpret_tensor(buf387, (64, 2), (1, 64), 0); del buf387  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf398 = buf366; del buf366  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf365, buf385, mul_1275, buf396, buf398, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf395 = buf365; del buf365  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf400 = reinterpret_tensor(buf384, (20, s0, 64), (64*s0, 64, 1), 0); del buf384  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf395, buf385, primals_82, mul_1275, div_21, gt_17, buf400, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_21
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_17
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1275
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_82
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf402 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf400, (64, 20*s0), (1, 64), 0), view_110, out=buf402)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_110
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf397 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf396, buf397, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf399 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf398, buf399, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf403 = reinterpret_tensor(buf398, (1, 64, 2), (128, 1, 64), 0); del buf398  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf400, buf403, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf401 = buf385; del buf385  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf400, (20*s0, 64), (64, 1), 0), permute_363, out=buf401)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf400
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_363
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf405 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf401, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_107, view_108, view_109, None, getitem_62, getitem_63, getitem_64, getitem_65, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf401
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_62
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_63
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_65
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_107
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_108
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_109
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf404 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf403, buf404, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf406 = buf405[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf407 = buf405[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf408 = buf405[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf405
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf409 = buf332; del buf332  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf408, buf407, buf406, buf409, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf411 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf409, (192, 20*s0), (1, 192), 0), view_101, out=buf411)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_101
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf412 = buf335; del buf335  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf409, buf412, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf410 = reinterpret_tensor(buf408, (20*s0, 64), (64, 1), 0); del buf408  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf409, (20*s0, 192), (192, 1), 0), permute_372, out=buf410)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_372
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf413 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf412, buf413, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf417 = reinterpret_tensor(buf403, (64, 2), (1, 64), 0); del buf403  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf419 = buf396; del buf396  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf395, buf410, mul_1158, buf417, buf419, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf416 = buf395; del buf395  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf421 = reinterpret_tensor(buf407, (20, s0, 64), (64*s0, 64, 1), 0); del buf407  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf416, buf410, primals_76, mul_1158, div_22, gt_16, buf421, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_22
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1158
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_76
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf423 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf421, (64, 20*s0), (1, 64), 0), view_99, out=buf423)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_99
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf418 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf417, buf418, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf420 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf419, buf420, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf424 = reinterpret_tensor(buf419, (1, 64, 2), (128, 1, 64), 0); del buf419  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf421, buf424, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf425 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf424, buf425, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf361 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf358, buf361, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf360 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (2048, 20*s0), (1, 2048), 0), view_125, out=buf360)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_125
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf362 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf361, buf362, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf380 = buf410; del buf410  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf379, (20*s0, 128), (128, 1), 0), permute_355, out=buf380)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_355
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf381 = reinterpret_tensor(buf392, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf379, (128, 20*s0), (1, 128), 0), view_58, out=buf381)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf422 = reinterpret_tensor(buf358, (20*s0, 2048), (2048, 1), 0); del buf358  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf421, (20*s0, 64), (64, 1), 0), permute_376, out=buf422)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_376
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf426 = reinterpret_tensor(buf422, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf422  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf426, le_7, gt_15, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_15
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf427 = reinterpret_tensor(buf421, (20*s0, 64), (64, 1), 0); del buf421  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf426, (20*s0, 2048), (2048, 1), 0), permute_380, out=buf427)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_380
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf434 = reinterpret_tensor(buf424, (64, 2), (1, 64), 0); del buf424  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf436 = buf417; del buf417  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf416, buf427, mul_1102, buf434, buf436, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf433 = buf416; del buf416  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf438 = reinterpret_tensor(buf406, (20, s0, 64), (64*s0, 64, 1), 0); del buf406  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf433, buf427, primals_70, mul_1102, div_23, gt_14, buf438, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_23
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_1102
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_70
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf440 = reinterpret_tensor(buf361, (64, 64), (64, 1), 0); del buf361  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf438, (64, 20*s0), (1, 64), 0), view_95, out=buf440)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_95
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf435 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf434, buf435, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf437 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf436, buf437, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf441 = reinterpret_tensor(buf436, (1, 64, 2), (128, 1, 64), 0); del buf436  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf438, buf441, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf439 = buf427; del buf427  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf438, (20*s0, 64), (64, 1), 0), permute_384, out=buf439)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf438
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_384
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf443 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf439, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_92, view_93, view_94, None, getitem_54, getitem_55, getitem_56, getitem_57, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf439
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_54
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_55
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_56
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_57
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_92
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_93
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_94
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf442 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf441, buf442, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf444 = buf443[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf445 = buf443[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf446 = buf443[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf443
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf447 = buf379; del buf379  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf446, buf445, buf447, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf445
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf452 = reinterpret_tensor(buf446, (20*s0, 64), (64, 1), 0); del buf446  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf444, buf452, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf460 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf454 = reinterpret_tensor(buf460, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf452, (64, 20*s0), (1, 64), 0), view_84, out=buf454)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_84
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf455 = buf441; del buf441  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf452, buf455, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf453 = reinterpret_tensor(buf444, (20*s0, 64), (64, 1), 0); del buf444  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf452, permute_397, out=buf453)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_397
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf459 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf457 = reinterpret_tensor(buf459, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf455, buf457, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf450 = buf382; del buf382  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf447, buf450, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf458 = reinterpret_tensor(buf459, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf450, buf458, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf464 = reinterpret_tensor(buf455, (64, 2), (1, 64), 0); del buf455  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf466 = buf434; del buf434  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf433, buf453, mul_981, buf464, buf466, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf463 = buf433; del buf433  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf468 = reinterpret_tensor(buf452, (20, s0, 64), (64*s0, 64, 1), 0); del buf452  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf463, buf453, primals_64, mul_981, div_24, gt_13, buf468, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_13
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_981
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf470 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf468, (64, 20*s0), (1, 64), 0), view_82, out=buf470)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_82
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf465 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf464, buf465, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf467 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf466, buf467, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf471 = reinterpret_tensor(buf466, (1, 64, 2), (128, 1, 64), 0); del buf466  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf468, buf471, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf469 = buf453; del buf453  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf468, (20*s0, 64), (64, 1), 0), permute_401, out=buf469)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf468
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_401
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf473 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf469, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_79, view_80, view_81, None, getitem_44, getitem_45, getitem_46, getitem_47, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf469
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_44
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_45
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_46
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_47
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_79
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_80
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_81
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf472 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf471, buf472, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf474 = buf473[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf475 = buf473[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf476 = buf473[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf473
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf477 = buf409; del buf409  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf476, buf475, buf474, buf477, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf479 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf477, (192, 20*s0), (1, 192), 0), view_73, out=buf479)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_73
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf480 = buf412; del buf412  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf477, buf480, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf478 = reinterpret_tensor(buf476, (20*s0, 64), (64, 1), 0); del buf476  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf477, (20*s0, 192), (192, 1), 0), permute_410, out=buf478)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_410
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf481 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf480, buf481, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf485 = reinterpret_tensor(buf471, (64, 2), (1, 64), 0); del buf471  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf487 = buf464; del buf464  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf463, buf478, mul_864, buf485, buf487, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf484 = buf463; del buf463  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf489 = reinterpret_tensor(buf475, (20, s0, 64), (64*s0, 64, 1), 0); del buf475  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf484, buf478, primals_58, mul_864, div_25, gt_12, buf489, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_12
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_864
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_58
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf491 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf489, (64, 20*s0), (1, 64), 0), view_71, out=buf491)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_71
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf486 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf485, buf486, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf488 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf487, buf488, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf492 = reinterpret_tensor(buf487, (1, 64, 2), (128, 1, 64), 0); del buf487  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf489, buf492, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf493 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf492, buf493, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf429 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf426, buf429, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf428 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf426, (2048, 20*s0), (1, 2048), 0), view_97, out=buf428)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_97
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf430 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf429, buf430, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf448 = buf478; del buf478  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf447, (20*s0, 128), (128, 1), 0), permute_393, out=buf448)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_393
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf449 = reinterpret_tensor(buf460, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf447, (128, 20*s0), (1, 128), 0), view_58, out=buf449)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf490 = reinterpret_tensor(buf426, (20*s0, 2048), (2048, 1), 0); del buf426  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf489, (20*s0, 64), (64, 1), 0), permute_414, out=buf490)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_414
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf494 = reinterpret_tensor(buf490, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf490  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf494, le_8, gt_11, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf495 = reinterpret_tensor(buf489, (20*s0, 64), (64, 1), 0); del buf489  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf494, (20*s0, 2048), (2048, 1), 0), permute_418, out=buf495)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_418
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf502 = reinterpret_tensor(buf492, (64, 2), (1, 64), 0); del buf492  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf504 = buf485; del buf485  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf484, buf495, mul_808, buf502, buf504, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf501 = buf484; del buf484  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf506 = reinterpret_tensor(buf474, (20, s0, 64), (64*s0, 64, 1), 0); del buf474  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf501, buf495, primals_52, mul_808, div_26, gt_10, buf506, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_808
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_52
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf508 = reinterpret_tensor(buf429, (64, 64), (64, 1), 0); del buf429  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf506, (64, 20*s0), (1, 64), 0), view_67, out=buf508)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_67
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf503 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf502, buf503, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf505 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf504, buf505, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf509 = reinterpret_tensor(buf504, (1, 64, 2), (128, 1, 64), 0); del buf504  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf506, buf509, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf507 = buf495; del buf495  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf506, (20*s0, 64), (64, 1), 0), permute_422, out=buf507)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf506
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_422
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf511 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf507, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_64, view_65, view_66, None, getitem_36, getitem_37, getitem_38, getitem_39, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf507
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_36
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_37
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_38
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_39
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_64
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_65
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_66
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf510 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf509, buf510, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf512 = buf511[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf513 = buf511[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf514 = buf511[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf511
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf515 = buf447; del buf447  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14_xnumel = 2560*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_14.run(buf514, buf513, buf515, s0, triton_poi_fused_clone_14_xnumel, grid=grid(triton_poi_fused_clone_14_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf513
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf528 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf517 = reinterpret_tensor(buf528, (128, 64), (64, 1), 4096)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf515, (128, 20*s0), (1, 128), 0), view_58, out=buf517)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_58
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf520 = reinterpret_tensor(buf514, (20*s0, 64), (64, 1), 0); del buf514  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15_xnumel = 1280*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_view_15.run(buf512, buf520, s0, triton_poi_fused_view_15_xnumel, grid=grid(triton_poi_fused_view_15_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf522 = reinterpret_tensor(buf528, (64, 64), (64, 1), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf520, (64, 20*s0), (1, 64), 0), view_56, out=buf522)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_56
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf523 = buf509; del buf509  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf520, buf523, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf521 = reinterpret_tensor(buf512, (20*s0, 64), (64, 1), 0); del buf512  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(buf520, permute_435, out=buf521)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_435
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf527 = empty_strided_cuda((192, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf525 = reinterpret_tensor(buf527, (64, ), (1, ), 0)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_16.run(buf523, buf525, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf518 = buf450; del buf450  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_17.run(buf515, buf518, s0, 256, triton_red_fused_sum_17_r0_numel, grid=grid(256), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf516 = buf520; del buf520  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf515, (20*s0, 128), (128, 1), 0), permute_431, out=buf516)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf515
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_431
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf526 = reinterpret_tensor(buf527, (128, ), (1, ), 64)  # alias
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_cat_sum_18.run(buf518, buf526, 128, 2, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf518
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf531 = reinterpret_tensor(buf523, (64, 2), (1, 64), 0); del buf523  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf533 = buf502; del buf502  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28.run(buf501, buf521, mul_3166, buf531, buf533, s0, 128, triton_red_fused_add_native_layer_norm_backward_28_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf535 = buf501; del buf501  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29.run(buf535, buf521, primals_46, mul_3166, div_27, gt_9, s0, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_3166
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_46
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf537 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf535, (64, 20*s0), (1, 64), 0), view_54, out=buf537)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_54
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf532 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf531, buf532, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf534 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf533, buf534, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf538 = reinterpret_tensor(buf533, (1, 64, 2), (128, 1, 64), 0); del buf533  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf535, buf538, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf536 = buf521; del buf521  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf535, (20*s0, 64), (64, 1), 0), permute_439, out=buf536)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf535
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_439
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf540 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf536, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_51, view_52, view_53, None, getitem_26, getitem_27, getitem_28, getitem_29, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_27
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_28
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_29
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_51
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_52
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_53
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf539 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf538, buf539, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf541 = buf540[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf542 = buf540[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf543 = buf540[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf540
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf544 = reinterpret_tensor(buf480, (1, 1, 192, 2), (384, 384, 1, 192), 0); del buf480  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_30_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_30.run(buf543, buf542, buf541, buf544, s0, 384, triton_red_fused_sum_30_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf545 = empty_strided_cuda((1, 1, 192), (192, 192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf544, buf545, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf546 = buf477; del buf477  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf543, buf542, buf541, buf546, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf547 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf546, (192, 20*s0), (1, 192), 0), view, out=buf547)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf497 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf494, buf497, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf496 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf494, (2048, 20*s0), (1, 2048), 0), view_69, out=buf496)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_69
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf498 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf497, buf498, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf549 = reinterpret_tensor(buf543, (20, s0, 64), (64*s0, 64, 1), 0); del buf543  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf551 = reinterpret_tensor(buf542, (20, s0, 64), (64*s0, 64, 1), 0); del buf542  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf558 = reinterpret_tensor(buf541, (20, s0, 64), (64*s0, 64, 1), 0); del buf541  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf563 = reinterpret_tensor(buf536, (20, s0, 64), (64*s0, 64, 1), 0); del buf536  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [x_9, output], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24.run(mul_536, primals_38, primals_39, getitem_25, rsqrt_6, buf380, buf448, buf516, primals_40, div_29, gt_8, buf549, buf551, buf558, buf563, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_24_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_29
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_25
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_38
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_39
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_40
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del rsqrt_6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf565 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf563, (64, 20*s0), (1, 64), 0), view_43, out=buf565)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_43
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf552 = reinterpret_tensor(buf538, (64, 2), (1, 64), 0); del buf538  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf554 = buf531; del buf531  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_25_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_25.run(buf380, buf448, buf516, buf549, buf552, buf554, s0, 128, triton_red_fused_add_native_layer_norm_backward_25_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf380
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf448
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf516
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf549
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf559 = buf344; del buf344  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf561 = buf342; del buf342  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_native_layer_norm_backward_7.run(buf551, mul_536, buf559, buf561, s0, 128, triton_red_fused_native_layer_norm_backward_7_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_536
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf553 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf552, buf553, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf552
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf555 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf554, buf555, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf554
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf560 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf559, buf560, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf562 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf561, buf562, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf566 = reinterpret_tensor(buf561, (1, 64, 2), (128, 1, 64), 0); del buf561  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf563, buf566, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf567 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf566, buf567, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf564 = reinterpret_tensor(buf494, (20*s0, 2048), (2048, 1), 0); del buf494  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf563, (20*s0, 64), (64, 1), 0), permute_451, out=buf564)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_451
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf568 = reinterpret_tensor(buf564, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf564  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf568, le_9, gt_7, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf569 = reinterpret_tensor(buf563, (20*s0, 64), (64, 1), 0); del buf563  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf568, (20*s0, 2048), (2048, 1), 0), permute_455, out=buf569)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_455
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf576 = reinterpret_tensor(buf566, (64, 2), (1, 64), 0); del buf566  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf578 = buf559; del buf559  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf558, buf569, mul_480, buf576, buf578, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf575 = buf558; del buf558  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf580 = buf551; del buf551  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf575, buf569, primals_32, mul_480, div_30, gt_6, buf580, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_30
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_480
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_32
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf582 = reinterpret_tensor(buf497, (64, 64), (64, 1), 0); del buf497  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf580, (64, 20*s0), (1, 64), 0), view_39, out=buf582)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_39
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf577 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf576, buf577, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf579 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf578, buf579, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf583 = reinterpret_tensor(buf578, (1, 64, 2), (128, 1, 64), 0); del buf578  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf580, buf583, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf581 = buf569; del buf569  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf580, (20*s0, 64), (64, 1), 0), permute_459, out=buf581)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf580
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_459
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf585 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf581, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_36, view_37, view_38, None, getitem_16, getitem_17, getitem_18, getitem_19, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf581
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_16
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_17
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_18
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_19
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_36
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_37
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_38
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf584 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf583, buf584, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf586 = buf585[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf587 = buf585[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf588 = buf585[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf585
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf589 = buf546; del buf546  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf588, buf587, buf586, buf589, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf586
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf591 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf589, (192, 20*s0), (1, 192), 0), view_30, out=buf591)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_30
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf592 = reinterpret_tensor(buf544, (1, 192, 2), (384, 1, 192), 0); del buf544  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf589, buf592, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf590 = reinterpret_tensor(buf588, (20*s0, 64), (64, 1), 0); del buf588  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf589, (20*s0, 192), (192, 1), 0), permute_468, out=buf590)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_468
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf593 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf592, buf593, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf597 = reinterpret_tensor(buf583, (64, 2), (1, 64), 0); del buf583  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf599 = buf576; del buf576  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf575, buf590, mul_363, buf597, buf599, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf596 = buf575; del buf575  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf601 = reinterpret_tensor(buf587, (20, s0, 64), (64*s0, 64, 1), 0); del buf587  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf596, buf590, primals_26, mul_363, div_31, gt_5, buf601, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_31
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_5
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_363
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf603 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf601, (64, 20*s0), (1, 64), 0), view_28, out=buf603)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_28
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf598 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf597, buf598, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf600 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf599, buf600, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf604 = reinterpret_tensor(buf599, (1, 64, 2), (128, 1, 64), 0); del buf599  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf601, buf604, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf605 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf604, buf605, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf571 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf568, buf571, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf570 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf568, (2048, 20*s0), (1, 2048), 0), view_41, out=buf570)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_41
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf572 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf571, buf572, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf602 = reinterpret_tensor(buf568, (20*s0, 2048), (2048, 1), 0); del buf568  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf601, (20*s0, 64), (64, 1), 0), permute_472, out=buf602)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_472
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf606 = reinterpret_tensor(buf602, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf602  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf606, le_10, gt_4, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_4
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf607 = reinterpret_tensor(buf601, (20*s0, 64), (64, 1), 0); del buf601  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf606, (20*s0, 2048), (2048, 1), 0), permute_476, out=buf607)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_476
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf614 = reinterpret_tensor(buf604, (64, 2), (1, 64), 0); del buf604  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf616 = buf597; del buf597  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf596, buf607, mul_307, buf614, buf616, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf613 = buf596; del buf596  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf618 = reinterpret_tensor(buf590, (20, s0, 64), (64*s0, 64, 1), 0); del buf590  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf613, buf607, primals_20, mul_307, div_32, gt_3, buf618, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_32
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_307
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_20
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf620 = reinterpret_tensor(buf571, (64, 64), (64, 1), 0); del buf571  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf618, (64, 20*s0), (1, 64), 0), view_24, out=buf620)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_24
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf615 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf614, buf615, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf617 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf616, buf617, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf621 = reinterpret_tensor(buf616, (1, 64, 2), (128, 1, 64), 0); del buf616  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf618, buf621, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf619 = buf607; del buf607  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf618, (20*s0, 64), (64, 1), 0), permute_480, out=buf619)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf618
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_480
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf623 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf619, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_21, view_22, view_23, None, getitem_8, getitem_9, getitem_10, getitem_11, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf619
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_21
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_22
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_23
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf622 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf621, buf622, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf624 = buf623[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf625 = buf623[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf626 = buf623[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf623
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf627 = buf589; del buf589  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf626, buf625, buf624, buf627, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf624
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf629 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf627, (192, 20*s0), (1, 192), 0), view_15, out=buf629)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_15
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf630 = buf592; del buf592  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_20.run(buf627, buf630, s0, 384, triton_red_fused_sum_20_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf628 = reinterpret_tensor(buf626, (20*s0, 64), (64, 1), 0); del buf626  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf627, (20*s0, 192), (192, 1), 0), permute_489, out=buf628)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_489
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf631 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf630, buf631, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf635 = reinterpret_tensor(buf621, (64, 2), (1, 64), 0); del buf621  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf637 = buf614; del buf614  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_12.run(buf613, buf628, mul_190, buf635, buf637, s0, 128, triton_red_fused_add_native_layer_norm_backward_12_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf634 = buf613; del buf613  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf639 = reinterpret_tensor(buf625, (20, s0, 64), (64*s0, 64, 1), 0); del buf625  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13.run(buf634, buf628, primals_14, mul_190, div_33, gt_2, buf639, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_13_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf628
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_33
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_190
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_14
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf641 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf639, (64, 20*s0), (1, 64), 0), view_13, out=buf641)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_13
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf636 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf635, buf636, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf638 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf637, buf638, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf642 = reinterpret_tensor(buf637, (1, 64, 2), (128, 1, 64), 0); del buf637  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf639, buf642, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf643 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf642, buf643, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf609 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf606, buf609, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf608 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf606, (2048, 20*s0), (1, 2048), 0), view_26, out=buf608)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_26
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf610 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf609, buf610, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf640 = reinterpret_tensor(buf606, (20*s0, 2048), (2048, 1), 0); del buf606  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf639, (20*s0, 64), (64, 1), 0), permute_493, out=buf640)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_493
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf644 = reinterpret_tensor(buf640, (20, s0, 2048), (2048*s0, 2048, 1), 0); del buf640  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel = 40960*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_11.run(buf644, le_11, gt_1, triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_11_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt_1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del le_11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf645 = reinterpret_tensor(buf639, (20*s0, 64), (64, 1), 0); del buf639  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf644, (20*s0, 2048), (2048, 1), 0), permute_497, out=buf645)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_497
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf651 = reinterpret_tensor(buf642, (64, 2), (1, 64), 0); del buf642  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf653 = buf635; del buf635  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28.run(buf634, buf645, mul_3233, buf651, buf653, s0, 128, triton_red_fused_add_native_layer_norm_backward_28_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf655 = buf634; del buf634  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel = 20*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29.run(buf655, buf645, primals_8, mul_3233, div_34, gt, s0, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del div_34
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del gt
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del mul_3233
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del primals_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf657 = reinterpret_tensor(buf609, (64, 64), (64, 1), 0); del buf609  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf655, (64, 20*s0), (1, 64), 0), view_9, out=buf657)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_9
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf652 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf651, buf652, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf651
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf654 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf653, buf654, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf658 = reinterpret_tensor(buf653, (1, 64, 2), (128, 1, 64), 0); del buf653  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_10.run(buf655, buf658, s0, 128, triton_red_fused_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf656 = buf645; del buf645  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf655, (20*s0, 64), (64, 1), 0), permute_501, out=buf656)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf655
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del permute_501
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf660 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf656, (s0, 8, 20, 8), (64, 8, 64*s0, 1), 0), view_6, view_7, view_8, None, getitem, getitem_1, getitem_2, getitem_3, 0.1, [True, True, True, False])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf656
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_1
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_2
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del getitem_3
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_6
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_7
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_8
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf659 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_native_layer_norm_backward_8.run(buf658, buf659, 64, 2, grid=grid(64), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf658
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf661 = buf660[0]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf662 = buf660[1]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf663 = buf660[2]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf660
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf664 = reinterpret_tensor(buf630, (1, 1, 192, 2), (384, 384, 1, 192), 0); del buf630  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_30_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_30.run(buf663, buf662, buf661, buf664, s0, 384, triton_red_fused_sum_30_r0_numel, grid=grid(384), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf665 = empty_strided_cuda((1, 1, 192), (192, 192, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_21.run(buf664, buf665, 192, 2, grid=grid(192), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf664
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf666 = buf627; del buf627  # reuse
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19_xnumel = 3840*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_poi_fused_clone_19.run(buf663, buf662, buf661, buf666, s0, triton_poi_fused_clone_19_xnumel, grid=grid(triton_poi_fused_clone_19_xnumel), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf661
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf662
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf663
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf667 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf666, (192, 20*s0), (1, 192), 0), view, out=buf667)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf666
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf647 = empty_strided_cuda((1, 2048, 2), (4096, 1, 2048), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22_r0_numel = 10*s0
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_red_fused_sum_22.run(buf644, buf647, s0, 4096, triton_red_fused_sum_22_r0_numel, grid=grid(4096), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf646 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf644, (2048, 20*s0), (1, 2048), 0), view_11, out=buf646)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf644
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del view_11
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         buf648 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         triton_per_fused_sum_23.run(buf647, buf648, 2048, 2, grid=grid(2048), stream=stream0)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]         del buf647
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     return (None, None, None, reinterpret_tensor(buf665, (192, ), (1, ), 0), buf667, buf657, reinterpret_tensor(buf659, (64, ), (1, ), 0), buf652, buf654, buf646, reinterpret_tensor(buf648, (2048, ), (1, ), 0), buf641, reinterpret_tensor(buf643, (64, ), (1, ), 0), buf636, buf638, reinterpret_tensor(buf631, (192, ), (1, ), 0), buf629, buf620, reinterpret_tensor(buf622, (64, ), (1, ), 0), buf615, buf617, buf608, reinterpret_tensor(buf610, (2048, ), (1, ), 0), buf603, reinterpret_tensor(buf605, (64, ), (1, ), 0), buf598, buf600, reinterpret_tensor(buf593, (192, ), (1, ), 0), buf591, buf582, reinterpret_tensor(buf584, (64, ), (1, ), 0), buf577, buf579, buf570, reinterpret_tensor(buf572, (2048, ), (1, ), 0), buf565, reinterpret_tensor(buf567, (64, ), (1, ), 0), buf560, buf562, buf553, buf555, reinterpret_tensor(buf545, (192, ), (1, ), 0), buf547, buf537, reinterpret_tensor(buf539, (64, ), (1, ), 0), buf532, buf534, buf528, buf527, buf508, reinterpret_tensor(buf510, (64, ), (1, ), 0), buf503, buf505, buf496, reinterpret_tensor(buf498, (2048, ), (1, ), 0), buf491, reinterpret_tensor(buf493, (64, ), (1, ), 0), buf486, buf488, reinterpret_tensor(buf481, (192, ), (1, ), 0), buf479, buf470, reinterpret_tensor(buf472, (64, ), (1, ), 0), buf465, buf467, buf460, buf459, buf440, reinterpret_tensor(buf442, (64, ), (1, ), 0), buf435, buf437, buf428, reinterpret_tensor(buf430, (2048, ), (1, ), 0), buf423, reinterpret_tensor(buf425, (64, ), (1, ), 0), buf418, buf420, reinterpret_tensor(buf413, (192, ), (1, ), 0), buf411, buf402, reinterpret_tensor(buf404, (64, ), (1, ), 0), buf397, buf399, buf392, buf391, buf372, reinterpret_tensor(buf374, (64, ), (1, ), 0), buf367, buf369, buf360, reinterpret_tensor(buf362, (2048, ), (1, ), 0), buf355, reinterpret_tensor(buf357, (64, ), (1, ), 0), buf350, buf352, buf343, buf345, reinterpret_tensor(buf336, (192, ), (1, ), 0), buf334, buf325, reinterpret_tensor(buf327, (64, ), (1, ), 0), buf320, buf322, buf313, reinterpret_tensor(buf315, (2048, ), (1, ), 0), buf308, reinterpret_tensor(buf310, (64, ), (1, ), 0), buf303, buf305, reinterpret_tensor(buf298, (192, ), (1, ), 0), buf296, buf287, reinterpret_tensor(buf289, (64, ), (1, ), 0), buf282, buf284, buf275, reinterpret_tensor(buf277, (2048, ), (1, ), 0), buf270, reinterpret_tensor(buf272, (64, ), (1, ), 0), buf265, buf267, reinterpret_tensor(buf260, (192, ), (1, ), 0), buf258, buf249, reinterpret_tensor(buf251, (64, ), (1, ), 0), buf244, buf246, buf237, reinterpret_tensor(buf239, (2048, ), (1, ), 0), buf232, reinterpret_tensor(buf234, (64, ), (1, ), 0), buf227, buf229, buf220, buf222, reinterpret_tensor(buf214, (192, ), (1, ), 0), buf212, buf203, reinterpret_tensor(buf205, (64, ), (1, ), 0), buf198, buf200, buf193, buf192, buf173, reinterpret_tensor(buf175, (64, ), (1, ), 0), buf168, buf170, buf161, reinterpret_tensor(buf163, (2048, ), (1, ), 0), buf156, reinterpret_tensor(buf158, (64, ), (1, ), 0), buf151, buf153, reinterpret_tensor(buf146, (192, ), (1, ), 0), buf144, buf135, reinterpret_tensor(buf137, (64, ), (1, ), 0), buf130, buf132, buf125, buf124, buf105, reinterpret_tensor(buf107, (64, ), (1, ), 0), buf100, buf102, buf93, reinterpret_tensor(buf95, (2048, ), (1, ), 0), buf88, reinterpret_tensor(buf90, (64, ), (1, ), 0), buf83, buf85, reinterpret_tensor(buf78, (192, ), (1, ), 0), buf76, buf67, reinterpret_tensor(buf69, (64, ), (1, ), 0), buf62, buf64, buf57, buf56, buf37, reinterpret_tensor(buf39, (64, ), (1, ), 0), buf32, buf34, buf25, reinterpret_tensor(buf27, (2048, ), (1, ), 0), buf20, reinterpret_tensor(buf22, (64, ), (1, ), 0), buf15, buf17, buf9, buf10, )
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_1 = 10
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_5 = 200
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_68 = 80
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_26 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_39 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_40 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_46 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_52 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_58 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_64 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_70 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_76 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_82 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_88 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_94 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_95 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_96 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_102 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_108 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_114 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_120 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_126 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_132 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_133 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_134 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_140 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_146 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_152 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_158 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_164 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     primals_190 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_6 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_7 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_8 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_1 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_2 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_3 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_9 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_11 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_1 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_13 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_2 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_190 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_15 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_21 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_22 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_23 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_8 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_9 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_10 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_11 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_24 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_3 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_307 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_26 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_4 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_28 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_5 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_363 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_30 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_36 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_37 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_38 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_16 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_17 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_18 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_19 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_39 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_6 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_480 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_41 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_7 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_43 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_8 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_536 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_25 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rsqrt_6 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_51 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_52 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_53 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_26 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_27 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_28 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_29 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_54 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_9 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_56 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_58 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_64 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_65 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_66 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_36 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_37 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_38 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_39 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_67 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_10 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_808 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_69 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_11 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_71 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_12 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_864 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_73 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_79 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_80 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_81 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_44 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_45 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_46 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_47 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_82 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_13 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_981 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_84 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_92 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_93 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_94 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_54 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_55 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_56 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_57 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_95 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_14 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1102 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_97 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_15 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_99 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_16 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1158 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_101 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_107 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_108 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_109 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_62 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_63 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_64 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_65 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_110 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_17 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1275 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_112 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_120 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_121 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_122 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_72 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_73 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_74 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_75 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_123 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_18 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1396 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_125 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_19 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_127 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_20 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1452 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_81 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rsqrt_16 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_129 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_135 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_136 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_137 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_82 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_83 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_84 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_85 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_138 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_21 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1578 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_140 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_22 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_142 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_23 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1634 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_144 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_150 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_151 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_152 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_90 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_91 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_92 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_93 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_153 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_24 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1751 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_155 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_25 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_157 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_26 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1807 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_159 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_165 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_166 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_167 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_98 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_99 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_100 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_101 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_168 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_27 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1924 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_170 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_28 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_172 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_29 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_1980 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_107 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rsqrt_23 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_180 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_181 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_182 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_108 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_109 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_110 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_111 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_183 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_30 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2102 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_185 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_187 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_193 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_194 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_195 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_118 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_119 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_120 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_121 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_196 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_31 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2227 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_198 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_32 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_200 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_33 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2283 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_202 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_208 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_209 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_210 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_126 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_127 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_128 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_129 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_211 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_34 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2400 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_213 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_221 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_222 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_223 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_136 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_137 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_138 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_139 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_224 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_35 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2521 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_226 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_36 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_228 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_37 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2577 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_230 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_236 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_237 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_238 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_144 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_145 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_146 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_147 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_239 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_38 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2694 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_241 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_249 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_250 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_251 = rand_strided((10, 8, 20, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_154 = rand_strided((10, 8, 20, 8), (1280, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_155 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_156 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_157 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_252 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_39 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2815 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_254 = rand_strided((200, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_40 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     view_256 = rand_strided((200, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     gt_41 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_2871 = rand_strided((20, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_163 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     rsqrt_33 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     unsqueeze_18 = rand_strided((10, 64, 1, 20), (64, 1, 12800, 640), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     getitem_165 = rand_strided((10, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.int8)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     sub_1585 = rand_strided((10, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_2 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_161 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_165 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_3 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_169 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_178 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_182 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_4 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_186 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_195 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_5 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_199 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_1 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_203 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_6 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_207 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_216 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_220 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_7 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_224 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_233 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_8 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_237 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_2 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_241 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_9 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_245 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_254 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_258 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_10 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_262 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_271 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_12 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_275 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_3 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_279 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_13 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_283 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_292 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_14 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_296 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_4 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_300 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_15 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_304 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_313 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_16 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_317 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_5 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_321 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_17 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_325 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_334 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_19 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_338 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_6 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_342 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_20 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_346 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_355 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_359 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_21 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_363 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_372 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_22 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_376 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_7 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_380 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_23 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_384 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_393 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_397 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_24 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_401 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_410 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_25 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_414 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_8 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_418 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_26 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_422 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_431 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_435 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_3166 = rand_strided((20, 10, 64), (64, 1280, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_27 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_439 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_29 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_451 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_9 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_455 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_30 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_459 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_468 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_31 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_472 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_10 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_476 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_32 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_480 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_489 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_33 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_493 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     le_11 = rand_strided((20, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_497 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     mul_3233 = rand_strided((20, 10, 64), (64, 1280, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     div_34 = rand_strided((20, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     permute_501 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     tangents_1 = rand_strided((), (), device='cuda:0', dtype=torch.float32)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     fn = lambda: call([primals_1, mul_5, mul_68, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, gt_1, view_13, gt_2, mul_190, view_15, view_21, view_22, view_23, getitem_8, getitem_9, getitem_10, getitem_11, view_24, gt_3, mul_307, view_26, gt_4, view_28, gt_5, mul_363, view_30, view_36, view_37, view_38, getitem_16, getitem_17, getitem_18, getitem_19, view_39, gt_6, mul_480, view_41, gt_7, view_43, gt_8, mul_536, getitem_25, rsqrt_6, view_51, view_52, view_53, getitem_26, getitem_27, getitem_28, getitem_29, view_54, gt_9, view_56, view_58, view_64, view_65, view_66, getitem_36, getitem_37, getitem_38, getitem_39, view_67, gt_10, mul_808, view_69, gt_11, view_71, gt_12, mul_864, view_73, view_79, view_80, view_81, getitem_44, getitem_45, getitem_46, getitem_47, view_82, gt_13, mul_981, view_84, view_92, view_93, view_94, getitem_54, getitem_55, getitem_56, getitem_57, view_95, gt_14, mul_1102, view_97, gt_15, view_99, gt_16, mul_1158, view_101, view_107, view_108, view_109, getitem_62, getitem_63, getitem_64, getitem_65, view_110, gt_17, mul_1275, view_112, view_120, view_121, view_122, getitem_72, getitem_73, getitem_74, getitem_75, view_123, gt_18, mul_1396, view_125, gt_19, view_127, gt_20, mul_1452, getitem_81, rsqrt_16, view_129, view_135, view_136, view_137, getitem_82, getitem_83, getitem_84, getitem_85, view_138, gt_21, mul_1578, view_140, gt_22, view_142, gt_23, mul_1634, view_144, view_150, view_151, view_152, getitem_90, getitem_91, getitem_92, getitem_93, view_153, gt_24, mul_1751, view_155, gt_25, view_157, gt_26, mul_1807, view_159, view_165, view_166, view_167, getitem_98, getitem_99, getitem_100, getitem_101, view_168, gt_27, mul_1924, view_170, gt_28, view_172, gt_29, mul_1980, getitem_107, rsqrt_23, view_180, view_181, view_182, getitem_108, getitem_109, getitem_110, getitem_111, view_183, gt_30, mul_2102, view_185, view_187, view_193, view_194, view_195, getitem_118, getitem_119, getitem_120, getitem_121, view_196, gt_31, mul_2227, view_198, gt_32, view_200, gt_33, mul_2283, view_202, view_208, view_209, view_210, getitem_126, getitem_127, getitem_128, getitem_129, view_211, gt_34, mul_2400, view_213, view_221, view_222, view_223, getitem_136, getitem_137, getitem_138, getitem_139, view_224, gt_35, mul_2521, view_226, gt_36, view_228, gt_37, mul_2577, view_230, view_236, view_237, view_238, getitem_144, getitem_145, getitem_146, getitem_147, view_239, gt_38, mul_2694, view_241, view_249, view_250, view_251, getitem_154, getitem_155, getitem_156, getitem_157, view_252, gt_39, mul_2815, view_254, gt_40, view_256, gt_41, mul_2871, getitem_163, rsqrt_33, unsqueeze_18, getitem_165, sub_1585, div_2, permute_161, le, permute_165, div_3, permute_169, permute_178, permute_182, div_4, permute_186, permute_195, div_5, permute_199, le_1, permute_203, div_6, permute_207, permute_216, permute_220, div_7, permute_224, permute_233, div_8, permute_237, le_2, permute_241, div_9, permute_245, permute_254, permute_258, div_10, permute_262, permute_271, div_12, permute_275, le_3, permute_279, div_13, permute_283, permute_292, div_14, permute_296, le_4, permute_300, div_15, permute_304, permute_313, div_16, permute_317, le_5, permute_321, div_17, permute_325, permute_334, div_19, permute_338, le_6, permute_342, div_20, permute_346, permute_355, permute_359, div_21, permute_363, permute_372, div_22, permute_376, le_7, permute_380, div_23, permute_384, permute_393, permute_397, div_24, permute_401, permute_410, div_25, permute_414, le_8, permute_418, div_26, permute_422, permute_431, permute_435, mul_3166, div_27, permute_439, div_29, permute_451, le_9, permute_455, div_30, permute_459, permute_468, div_31, permute_472, le_10, permute_476, div_32, permute_480, permute_489, div_33, permute_493, le_11, permute_497, mul_3233, div_34, permute_501, tangents_1])
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] if __name__ == "__main__":
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 14:28:42.554000 1612526 site-packages/torch/_inductor/graph.py:2014] [89/0] [__output_code] 
V0205 14:28:42.720000 1612526 site-packages/torch/_inductor/graph.py:2022] [89/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/6h/c6hmi7y5xmeq4lfswwrz2olvyftsl6wkmrlyehhhfljjnv3g45wl.py
I0205 14:28:43.633000 1612526 site-packages/torch/_inductor/graph.py:2056] [89/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/6h/c6hmi7y5xmeq4lfswwrz2olvyftsl6wkmrlyehhhfljjnv3g45wl.py
