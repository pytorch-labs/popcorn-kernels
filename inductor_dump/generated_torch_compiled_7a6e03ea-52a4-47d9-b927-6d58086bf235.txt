W0127 11:41:24.896000 703210 site-packages/torch/_inductor/utils.py:1611] [831/0_1] DeviceCopy in input program
W0127 11:41:24.898000 703210 site-packages/torch/_inductor/utils.py:1611] [831/0_1] DeviceCopy in input program
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] Output code: 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # AOT ID: ['203_forward']
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import torch
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import random
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import os
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import tempfile
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from math import inf, nan
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from cmath import nanj
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch import device, empty_strided
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     grid,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     split_scan_grid,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     grid_combo_kernels,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     start_graph,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     end_graph,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     cooperative_reduction_grid,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] aten = torch.ops.aten
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] _quantized = torch.ops._quantized
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] async_compile = AsyncCompile()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zn/czn64jutad7xvotflt5ob7ypuz3fgh3yt5lz62pyd2h2f6izgp4l.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [x, x_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_functional, aten.mean]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x => convolution
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_2 => add, add_3, mean, mean_1, mul, mul_6, rsqrt, sub, var_mean
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %convolution : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_3, %primals_1, %primals_2, [1], [0], [1], False, [0], 1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%unsqueeze_1, [0, 2, 3, 4]), kwargs = {correction: 0, keepdim: True})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %rsqrt : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%unsqueeze_1, %getitem_1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %rsqrt), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul, %unsqueeze_4), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_6, %unsqueeze_7), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_2, [0]), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_4, [0]), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_4, %mean), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_5, %mean_1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_per_fused__native_batch_norm_legit_functional_convolution_mean_0 = async_compile.triton('triton_per_fused__native_batch_norm_legit_functional_convolution_mean_0', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'out_ptr5': '*fp32', 'out_ptr7': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_convolution_mean_0', 'mutated_arg_names': ['in_out_ptr0', 'in_ptr3', 'in_ptr4', 'out_ptr5', 'out_ptr7'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_per_fused__native_batch_norm_legit_functional_convolution_mean_0(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr2, out_ptr3, out_ptr5, out_ptr7, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_numel = 126
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     rnumel = r0_numel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_offset = 0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     roffset = r0_offset
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     rindex = r0_index
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_1 = r0_index
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 126*x0), r0_mask & xmask, other=0.0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp26 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp28 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp32 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp41 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tl.where(r0_mask & xmask, tmp3, 0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = tl.where(r0_mask & xmask, tmp6, 0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = tl.full([XBLOCK, 1], 126, tl.int32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp11 = tmp10.to(tl.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp12 = tmp9 / tmp11
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp13 = tmp3 - tmp12
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp14 = tmp13 * tmp13
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp17 = tl.where(r0_mask & xmask, tmp15, 0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp18 = tl.sum(tmp17, 1)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp19 = tmp2 - tmp12
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp20 = 126.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp21 = tmp18 / tmp20
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp22 = 1e-05
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp23 = tmp21 + tmp22
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp24 = libdevice.rsqrt(tmp23)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp25 = tmp19 * tmp24
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp27 = tmp25 * tmp26
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp29 = tmp27 + tmp28
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp30 = 0.1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp31 = tmp12 * tmp30
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp33 = 0.9
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp34 = tmp32 * tmp33
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp35 = tmp31 + tmp34
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp36 = 1.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp37 = tmp35 / tmp36
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp38 = 1.008
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp39 = tmp21 * tmp38
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp40 = tmp39 * tmp30
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp42 = tmp41 * tmp33
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp43 = tmp40 + tmp42
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp44 = tmp43 / tmp36
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 126*x0), tmp2, r0_mask & xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr2 + (r0_1 + 126*x0), tmp29, r0_mask & xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr3 + (x0), tmp24, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr5 + (x0), tmp37, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr7 + (x0), tmp44, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ap/capvq6a56f2lzbofp2e2fzjg7smp47eyf4qhiady2v74bityfw3b.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_4, x_5], Original ATen: [aten.max_pool2d_with_indices, aten.mish]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_4 => getitem_3
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_5 => exp, gt, log1p, mul_7, tanh, where
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%squeeze_5,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %log1p : [num_users=1] = call_function[target=torch.ops.aten.log1p.default](args = (%exp,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%squeeze_5, 20), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%gt, %squeeze_5, %log1p), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %tanh : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%where,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_5, %tanh), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_max_pool2d_with_indices_mish_1 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_mish_1', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 2048}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*i8', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_mish_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_max_pool2d_with_indices_mish_1(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 2016
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp1 > tmp0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.full([1], 1, tl.int8)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tl.full([1], 0, tl.int8)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = triton_helpers.maximum(tmp1, tmp0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = 20.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = tmp6 > tmp7
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = tl_math.exp(tmp6)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = libdevice.log1p(tmp9)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp11 = tl.where(tmp8, tmp6, tmp10)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp12 = libdevice.tanh(tmp11)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp13 = tmp6 * tmp12
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp5, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr1 + (x0), tmp13, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ge/cgex6hn3ea6nz7win55ypulp6djj37irmomjssxtljeviaaa45vf.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [hx], Original ATen: [aten._to_copy]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   hx => full_default
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([1, 64], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused__to_copy_2 = async_compile.triton('triton_poi_fused__to_copy_2', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 64}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused__to_copy_2(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = 0.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/y6/cy6iqwhmn36scsoc7e2bean6nkfy5xxhi2qjppjuid5nqrdtb7xy.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret => mm_default_124
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_124 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_3 = async_compile.triton('triton_poi_fused_addmm_3', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_3(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yu/cyuw7ctatvejyyjgjkowtuqs23575hni7kfstmb4wlfw5qfgf4hv.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret => add_4, add_tensor_124, add_tensor_125, tanh_1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_7 => cat
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_tensor_125 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_125, %primals_11), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_tensor_124 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_124, %primals_10), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_125, %add_tensor_124), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %tanh_1 : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%add_4,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %cat : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%tanh_1, %tanh_2, %tanh_3, %tanh_4, %tanh_5, %tanh_6, %tanh_7, %tanh_8, %tanh_9, %tanh_10, %tanh_11, %tanh_12, %tanh_13, %tanh_14, %tanh_15, %tanh_16, %tanh_17, %tanh_18, %tanh_19, %tanh_20, %tanh_21, %tanh_22, %tanh_23, %tanh_24, %tanh_25, %tanh_26, %tanh_27, %tanh_28, %tanh_29, %tanh_30, %tanh_31, %tanh_32, %tanh_33, %tanh_34, %tanh_35, %tanh_36, %tanh_37, %tanh_38, %tanh_39, %tanh_40, %tanh_41, %tanh_42, %tanh_43, %tanh_44, %tanh_45, %tanh_46, %tanh_47, %tanh_48, %tanh_49, %tanh_50, %tanh_51, %tanh_52, %tanh_53, %tanh_54, %tanh_55, %tanh_56, %tanh_57, %tanh_58, %tanh_59, %tanh_60, %tanh_61, %tanh_62, %tanh_63],), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_add_addmm_stack_tanh_4 = async_compile.triton('triton_poi_fused_add_addmm_stack_tanh_4', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 64}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_stack_tanh_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_add_addmm_stack_tanh_4(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tmp3 + tmp4
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = tmp2 + tmp5
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp7, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp7, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vr/cvrj4y5tpialk6wd6t4pzdwns5i5iflnybzyfxhs266clbruvhli.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_1 => mm_default_122
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_122 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_1, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_5 = async_compile.triton('triton_poi_fused_addmm_5', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_5(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (1 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/is/cismiigr22yimy5odyx3wywgj3demueocnp2ywuif2fwla6uzqbw.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_2 => mm_default_120
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_120 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_2, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_6 = async_compile.triton('triton_poi_fused_addmm_6', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_6(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (2 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yv/cyvd4jp3kju7va5xbi35k3djdnsp6vapugcexcztzvabjq7lj4ea.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_3 => mm_default_118
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_118 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_3, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_7 = async_compile.triton('triton_poi_fused_addmm_7', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_7(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (3 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ga/cgaoso6wfukek3cacwhfbabitjcvhnwwzxno2pxqb6it7adqv5ud.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_4 => mm_default_116
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_116 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_4, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_8 = async_compile.triton('triton_poi_fused_addmm_8', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_8(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (4 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7n/c7nc6nfcnxy7dpbarcd44vcpg5tpedvo2kkiwthkokf4yyxneugw.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_5 => mm_default_114
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_114 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_5, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_9 = async_compile.triton('triton_poi_fused_addmm_9', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_9(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (5 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/m7/cm753hd6hke3xc3cigw4n4pw5pm6zzo2jqg56i6gbaqzmk5drjji.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_6 => mm_default_112
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_112 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_6, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_10 = async_compile.triton('triton_poi_fused_addmm_10', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_10(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (6 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ue/cueyg6vidimghdoihrg4zq6gj5wuqkljol7sfulfd2ls36i6oigy.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_7 => mm_default_110
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_110 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_7, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_11 = async_compile.triton('triton_poi_fused_addmm_11', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_11(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (7 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4h/c4h57vr2bqigcbizirrvdhocny33iquedpd7h2fzaib5gg7mjuoo.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_8 => mm_default_108
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_108 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_8, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_12 = async_compile.triton('triton_poi_fused_addmm_12', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_12(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (8 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pl/cplbi6eoxjojbkdkkv5nfroviu3ar6ugrrjv6njhoe4qubs3gcfn.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_9 => mm_default_106
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_106 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_9, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_13 = async_compile.triton('triton_poi_fused_addmm_13', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_13(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (9 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/i4/ci44s7kpskanju4x6im2dcnhmvzewcvkxddmhcvurjqk6ig6tchw.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_10 => mm_default_104
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_104 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_10, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_14 = async_compile.triton('triton_poi_fused_addmm_14', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_14(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (10 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/p5/cp5634tzxh6g2ucrbq6eeqefanyot5tjblul2nr7xpv2kvwlij6a.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_11 => mm_default_102
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_102 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_11, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_15 = async_compile.triton('triton_poi_fused_addmm_15', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_15(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (11 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ec/cec3l4agddnqc2gzmqvzpiytlual3scfobsspmzogvqwyvddqx6v.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_12 => mm_default_100
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_100 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_12, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_16 = async_compile.triton('triton_poi_fused_addmm_16', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_16(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (12 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/du/cdu2zaiqsnhvmyjv5vlzbwozfwmpe3xdjcdkloe5xwtemtivndsk.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_13 => mm_default_98
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_98 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_13, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_17 = async_compile.triton('triton_poi_fused_addmm_17', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_17(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (13 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3r/c3rui3dutoc7bu76xchxvnjluwtf5cn6px66vkdes32gs3gc3oy7.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_14 => mm_default_96
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_96 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_14, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_18 = async_compile.triton('triton_poi_fused_addmm_18', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_18(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (14 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sr/csrudfue4mikebd2ypxvzr4jnhuwjlxo5vczxkyugcpoq556cm2r.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_15 => mm_default_94
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_94 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_15, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_19 = async_compile.triton('triton_poi_fused_addmm_19', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_19(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (15 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zb/czba6ojg6dpc57k44siaqjlyfakalsyrfpj7xqxezhbjizbs3xtx.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_16 => mm_default_92
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_92 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_16, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_20 = async_compile.triton('triton_poi_fused_addmm_20', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_20(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (16 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/h4/ch4s5xuepb2wd3773lrnayedmdukwf6z3nxkoszr3bq543ynkypr.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_17 => mm_default_90
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_90 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_17, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_21 = async_compile.triton('triton_poi_fused_addmm_21', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_21(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (17 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jq/cjqf3sfoxsvcje2an7rvex7m2hv5573tkevolpqrolykmhbcrl4e.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_18 => mm_default_88
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_88 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_18, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_22 = async_compile.triton('triton_poi_fused_addmm_22', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_22(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (18 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6b/c6b3s7c6skzchpd5dzbx4dt7nf2ia3gxor3zorkniv25s32odzhz.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_19 => mm_default_86
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_86 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_19, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_23 = async_compile.triton('triton_poi_fused_addmm_23', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_23(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (19 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fe/cfe2y7zxrwsmrvfy56sycjg4ckfffhmxibblnlfuihjpwczra5yz.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_20 => mm_default_84
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_84 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_20, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_24 = async_compile.triton('triton_poi_fused_addmm_24', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_24(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (20 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3q/c3qxzhumn3gv5d5xzy2jracw22h7dhuj2gumbvie5ff4quocv4cq.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_21 => mm_default_82
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_82 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_21, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_25 = async_compile.triton('triton_poi_fused_addmm_25', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_25(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (21 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/f6/cf6mwez3mp6bofhxmfcehy4tj7b3uysn2hnuublvk6ehyoftea5n.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_22 => mm_default_80
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_80 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_22, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_26 = async_compile.triton('triton_poi_fused_addmm_26', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_26(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (22 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/na/cnahflnsr432zcqbmkie42dif3mwtvcawdyswlwqvspmypc7qhe4.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_23 => mm_default_78
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_78 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_23, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_27 = async_compile.triton('triton_poi_fused_addmm_27', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_27(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (23 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5r/c5r76m2guwx7zeo3nfobxkrdntskuhqwz2e2s2wp3tc5lsjogar7.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_24 => mm_default_76
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_76 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_24, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_28 = async_compile.triton('triton_poi_fused_addmm_28', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_28(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (24 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lx/clxdellmarjwxve6a4wpc5zsc2p5kr3ygrfqwfz6x33vz3oidxwr.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_25 => mm_default_74
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_74 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_25, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_29 = async_compile.triton('triton_poi_fused_addmm_29', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_29', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_29(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (25 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ra/craffd2e7sziervp7njspsm6qt724jqvrccivmqq54dbvcotayjy.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_26 => mm_default_72
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_72 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_26, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_30 = async_compile.triton('triton_poi_fused_addmm_30', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_30(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (26 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cu/ccufrxwzmohu3abrrql4r7exc4wyaj7w6txyqfhtr7uyxcfictax.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_27 => mm_default_70
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_70 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_27, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_31 = async_compile.triton('triton_poi_fused_addmm_31', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_31(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (27 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nv/cnvczoer4qstzluxiqzwqpyscsp2s7hc562idnptx546otyaol5h.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_28 => mm_default_68
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_68 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_28, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_32 = async_compile.triton('triton_poi_fused_addmm_32', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_32(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (28 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pd/cpdpe3dl3cjpfyt34dentxe4khf6vy4cs6wm6rwnt3qu4oebhznw.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_29 => mm_default_66
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_66 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_29, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_33 = async_compile.triton('triton_poi_fused_addmm_33', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_33(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (29 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gh/cghyw5tlkbzx75mrpkbu2racdzymyu2vmeheopsnoeuqlrlexn5e.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_30 => mm_default_64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_64 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_30, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_34 = async_compile.triton('triton_poi_fused_addmm_34', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_34', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_34(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (30 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hu/chusmromrcjjtuzgu2b7eypchfuq4fjglmi2pfnmzzlohyyuzq4z.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_31 => mm_default_62
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_62 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_31, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_35 = async_compile.triton('triton_poi_fused_addmm_35', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_35(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (31 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wb/cwbk4xpmoqzv6iq4flwclauf5mr4esrcqaa4kj25li3ky5oebpxq.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_32 => mm_default_60
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_60 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_32, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_36 = async_compile.triton('triton_poi_fused_addmm_36', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_36(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (32 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fv/cfvqpqp3psahavaqf4zxugykk6ttbsocxpy7fhlpvvmowawroyts.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_33 => mm_default_58
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_58 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_33, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_37 = async_compile.triton('triton_poi_fused_addmm_37', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_37', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_37(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (33 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bg/cbgbmznbk5n6ok6ivqla4dvem5bla63venmrj6dpq4audw7snrms.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_34 => mm_default_56
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_56 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_34, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_38 = async_compile.triton('triton_poi_fused_addmm_38', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_38(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (34 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3i/c3iwh46hpry4kkz6rcw5wpua34rjzyscklanp2jkhhkbtjrttk4t.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_35 => mm_default_54
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_54 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_35, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_39 = async_compile.triton('triton_poi_fused_addmm_39', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_39(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (35 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/h5/ch5lsiybnvhx2on7fse2ho524cpgmtzjrrbpx2vk5jsu4t5lsvwg.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_36 => mm_default_52
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_52 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_36, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_40 = async_compile.triton('triton_poi_fused_addmm_40', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_40', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_40(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (36 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wm/cwmopa2ami7gbucarwgz2k4htuz7hecrkiddne4lrkv5lvx5s32w.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_37 => mm_default_50
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_50 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_37, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_41 = async_compile.triton('triton_poi_fused_addmm_41', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_41', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_41(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (37 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zj/czjlqgchto2xmtiqi6fziw7huaaxql2y2jl4w5x3zjmpxppmbw55.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_38 => mm_default_48
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_48 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_38, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_42 = async_compile.triton('triton_poi_fused_addmm_42', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_42', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_42(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (38 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lf/clfzhfkmyd3na3uwc3l3jf3mrpufszdfaapshmq35fkxcbefftux.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_39 => mm_default_46
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_46 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_39, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_43 = async_compile.triton('triton_poi_fused_addmm_43', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_43', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_43(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (39 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/h6/ch6uwpic2opvzjodpxrnig2bat2ksa4pibgkpmjkgzh2sfr2cetw.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_40 => mm_default_44
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_44 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_40, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_44 = async_compile.triton('triton_poi_fused_addmm_44', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_44', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_44(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (40 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3g/c3gfxgeqsk4xfoqsytef6pk7olpg4ohzoyvamh3bacni2avumvgj.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_41 => mm_default_42
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_42 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_41, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_45 = async_compile.triton('triton_poi_fused_addmm_45', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_45', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_45(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (41 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sh/cshgynsqlcgnwbtvhv5phf3wqoscjkdwdnrp72k3bdnvdanhqkh2.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_42 => mm_default_40
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_40 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_42, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_46 = async_compile.triton('triton_poi_fused_addmm_46', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_46', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_46(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (42 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wg/cwg4f2mbgzrsjbnwmsqylumnfowzhjnhc5uzjbncy6azake45zbi.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_43 => mm_default_38
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_38 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_43, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_47 = async_compile.triton('triton_poi_fused_addmm_47', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_47', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_47(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (43 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uv/cuvpqgomxn7ydfoxg7jzp247naptxuwl5lsv4stgmveryqte7rt2.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_44 => mm_default_36
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_36 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_44, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_48 = async_compile.triton('triton_poi_fused_addmm_48', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_48', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_48(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (44 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/q4/cq4vumusq5zlfdonkqjgyfn5br3mt6kwz2pa5csmyk5ihuo65477.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_45 => mm_default_34
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_34 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_45, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_49 = async_compile.triton('triton_poi_fused_addmm_49', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_49', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_49(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (45 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zn/czn4lkajfmuziu72yxz4k74bvoj574xta2yut7p5yp2iq5mtkjhk.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_46 => mm_default_32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_32 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_46, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_50 = async_compile.triton('triton_poi_fused_addmm_50', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_50', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_50(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (46 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4r/c4r6td4st2ugashphadd5rvnsip6blcuhduwj6tplwzwzu7wlr6r.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_47 => mm_default_30
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_30 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_47, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_51 = async_compile.triton('triton_poi_fused_addmm_51', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_51', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_51(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (47 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/py/cpypcdaxp2l5adj6fqe23tlx5mwr64s2dbnn3enepkhamerneadp.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_48 => mm_default_28
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_28 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_48, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_52 = async_compile.triton('triton_poi_fused_addmm_52', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_52', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_52(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (48 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wp/cwpdjwzhjv5oiuvalw3vo5x3l2xzrwmsmt3ftfiz7o54moqadg7x.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_49 => mm_default_26
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_26 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_49, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_53 = async_compile.triton('triton_poi_fused_addmm_53', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_53', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_53(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (49 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/po/cpoh4hymsdqqi2o723by4u3kzjq7clsqcflprvjaafdkdzc67dui.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_50 => mm_default_24
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_24 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_50, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_54 = async_compile.triton('triton_poi_fused_addmm_54', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_54', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_54(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (50 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/il/cilskkbsmilmtguixtfow2h64m3bpg7mtvcnopidrrayc37ygw5s.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_51 => mm_default_22
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_22 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_51, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_55 = async_compile.triton('triton_poi_fused_addmm_55', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_55', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_55(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (51 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qo/cqoomusbhgpw4kmnfzrlade4guqex444n46kyc5hcjlbxdwzste3.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_52], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_52 => mm_default_20
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_20 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_52, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_56 = async_compile.triton('triton_poi_fused_addmm_56', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_56', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_56(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (52 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g5/cg56ht2y25shj4rsxh2otfvzyjmbmrrbjyv2qrcsdpjbtq3gsovt.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_53], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_53 => mm_default_18
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_18 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_53, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_57 = async_compile.triton('triton_poi_fused_addmm_57', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_57', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_57(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (53 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lu/cluaa7wbhmk7xu6nwcka6afqhhq6smmzcjtbj256rkqueitfo5ab.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_54], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_54 => mm_default_16
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_16 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_54, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_58 = async_compile.triton('triton_poi_fused_addmm_58', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_58', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_58(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (54 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vl/cvladvuvhnk534zjrpiq534nf6eyw5dc3pyjqfp5xcko4fxgzg64.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_55], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_55 => mm_default_14
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_14 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_55, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_59 = async_compile.triton('triton_poi_fused_addmm_59', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_59', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_59(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (55 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6w/c6wiiuhwzsu2awybhcubkfv6wbs3yboekp6mjgnenzyizgmxmuha.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_56], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_56 => mm_default_12
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_12 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_56, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_60 = async_compile.triton('triton_poi_fused_addmm_60', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_60', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_60(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (56 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dx/cdxh6eglmajk6haj5ndl33pdi2yaol5xw5fcbstrntwbjvvwbnor.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_57], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_57 => mm_default_10
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_10 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_57, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_61 = async_compile.triton('triton_poi_fused_addmm_61', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_61', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_61(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (57 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/si/csi543tlgrfsq4tnvvubd5egb35ulhu74g7cwpy6kqdcgoxj5w4u.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_58], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_58 => mm_default_8
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_8 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_58, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_62 = async_compile.triton('triton_poi_fused_addmm_62', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_62', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_62(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (58 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wg/cwggbxmaf6rv24m2vls7fdkf4lgrzavacalthik4gyuggotiqm6c.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_59], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_59 => mm_default_6
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_6 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_59, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_63 = async_compile.triton('triton_poi_fused_addmm_63', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_63', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_63(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (59 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5j/c5jdxcyaai53g6qrumf347a4hhfdpn5urqlnpb4k4gjyfmfxocqn.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_60], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_60 => mm_default_4
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_4 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_60, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_64 = async_compile.triton('triton_poi_fused_addmm_64', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_64', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_64(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (60 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ct/cct3esgyfzxf4zxx3msr433yq6fcjiw4xuehu3acfqrv7cnbff5c.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_61], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_61 => mm_default_2
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default_2 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_61, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_65 = async_compile.triton('triton_poi_fused_addmm_65', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_65', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_65(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (61 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yd/cydupkfosb7vuqs7abmqv3tsaeoiyntbs4qw2hzr35w6kdntexy3.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_62 => mm_default
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mm_default : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_62, %permute_2), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_addmm_66 = async_compile.triton('triton_poi_fused_addmm_66', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 32}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_66', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_addmm_66(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 32
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (62 + 63*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xb/cxbaqf5pxn5rvvacysd4u4bhonvaeclngpaswoevxl6admllgif5.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.tanh_backward]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   ret_62 => add_66, add_tensor, add_tensor_1, tanh_63
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_1, %primals_11), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_tensor : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default, %primals_10), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_66 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_1, %add_tensor), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %tanh_63 : [num_users=2] = call_function[target=torch.ops.aten.tanh.default](args = (%add_66,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh_63, %tanh_63), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub_5 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mul_13), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_add_addmm_tanh_tanh_backward_67 = async_compile.triton('triton_poi_fused_add_addmm_tanh_tanh_backward_67', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 64}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_tanh_tanh_backward_67', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_add_addmm_tanh_tanh_backward_67(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tl.load(in_ptr3 + (x0), xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tmp3 + tmp4
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = tmp2 + tmp5
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = tmp7 * tmp7
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = 1.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = tmp9 - tmp8
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp7, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr1 + (x0), tmp10, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] cpp_fused_randint_68 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*'], '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #include "/tmp/torchinductor_sahanp/3b/c3bi5gk6mslf6u4iaqafhxm64z6u65e3eain4xlary5blqnvv6xx.h"
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] extern "C"  void kernel(const int64_t* in_ptr0,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                        int64_t* out_ptr0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         #pragma GCC ivdep
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]             {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp1 = x0;
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp2 = c10::convert<int32_t>(tmp1);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp3 = static_cast<int64_t>(1);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp4 = static_cast<int64_t>(10);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     auto tmp5 = randint64_cpu(tmp0, tmp2, tmp3, tmp4);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                     out_ptr0[static_cast<int64_t>(x0)] = tmp5;
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]             }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] cpp_fused_randint_69 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*'], '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #include "/tmp/torchinductor_sahanp/3b/c3bi5gk6mslf6u4iaqafhxm64z6u65e3eain4xlary5blqnvv6xx.h"
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] extern "C"  void kernel(const int64_t* in_ptr0,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                        int64_t* out_ptr0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]             {
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 auto tmp0 = in_ptr0[static_cast<int64_t>(1L)];
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 auto tmp1 = static_cast<int32_t>(0);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 auto tmp2 = static_cast<int64_t>(1);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 auto tmp3 = static_cast<int64_t>(10);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 auto tmp4 = randint64_cpu(tmp0, tmp1, tmp2, tmp3);
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]                 out_ptr0[static_cast<int64_t>(0L)] = tmp4;
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]             }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] }
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ah/cah5bh2v4eq7daa7ukcskisuydkoha2jinpdkn5kmybfvo55gjtt.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_13], Original ATen: [aten._log_softmax]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_13 => amax_1, exp_2, sub_2, sum_2
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %amax_1 : [num_users=1] = call_function[target=torch.ops.aten.amax.default](args = (%squeeze_7, [2], True), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%squeeze_7, %amax_1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %exp_2 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%sub_2,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp_2, [2], True), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_per_fused__log_softmax_70 = async_compile.triton('triton_per_fused__log_softmax_70', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 64, 'r0_': 64},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__log_softmax_70', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_per_fused__log_softmax_70(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_numel = 63
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     rnumel = r0_numel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_offset = 0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     roffset = r0_offset
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     rindex = r0_index
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     r0_1 = r0_index
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.load(in_ptr1 + (0))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = 0.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp0 > tmp1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tmp4 * tmp0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = tl.where(tmp2, tmp0, tmp5)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = tmp6 - tmp6
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = tl_math.exp(tmp7)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = tmp8 / tmp8
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp12 = tl.where(r0_mask & xmask, tmp10, float("-inf"))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp13 = triton_helpers.max2(tmp12, 1)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp14 = tmp9 - tmp13
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp15 = tl_math.exp(tmp14)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp18 = tl.where(r0_mask & xmask, tmp16, 0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr1 + (x0), tmp19, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7r/c7rvflypsbiwn5vf3eogdsk7m3mwocdaim5nuuf4h5lwrqgmkqpj.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_13], Original ATen: [aten._log_softmax]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_13 => log, sub_2, sub_3
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%squeeze_7, %amax_1), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %log : [num_users=1] = call_function[target=torch.ops.aten.log.default](args = (%sum_2,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_2, %log), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused__log_softmax_71 = async_compile.triton('triton_poi_fused__log_softmax_71', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'y': 64, 'x': 64}, tile_hint=TileHint.DEFAULT,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__log_softmax_71', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused__log_softmax_71(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     ynumel = 63
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 64
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     ymask = yindex < ynumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x1 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     y0 = yindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1 + 64*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = tl.load(in_ptr1 + (0))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, YBLOCK])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp12 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = 0.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = tmp0 > tmp1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tmp4 * tmp0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = tl.where(tmp2, tmp0, tmp5)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = tmp6 - tmp6
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = tl_math.exp(tmp7)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = tmp8 / tmp8
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp11 = tmp9 - tmp10
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp13 = tl_math.log(tmp12)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp14 = tmp11 - tmp13
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (y0 + 63*x1), tmp14, xmask & ymask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nx/cnx5nrwnlqfq5n7j2ttn62uigrzvsupvlxqvvrr5zg3o4r42dtwf.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mish, aten.sigmoid, aten.mul, aten.fill, aten.sub, aten.add]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   x_5 => exp, gt, log1p, tanh, where
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%squeeze_5,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %log1p : [num_users=1] = call_function[target=torch.ops.aten.log1p.default](args = (%exp,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%squeeze_5, 20), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%gt, %squeeze_5, %log1p), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %tanh : [num_users=3] = call_function[target=torch.ops.aten.tanh.default](args = (%where,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%squeeze_5,), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_139 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tanh, %tanh), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %full_default_66 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1, 32, 63], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %sub_68 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%full_default_66, %mul_139), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_140 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_5, %sigmoid), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %mul_141 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_140, %sub_68), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %add_439 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%tanh, %mul_141), kwargs = {})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused_add_fill_mish_mul_sigmoid_sub_72 = async_compile.triton('triton_poi_fused_add_fill_mish_mul_sigmoid_sub_72', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 2048}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_fill_mish_mul_sigmoid_sub_72', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused_add_fill_mish_mul_sigmoid_sub_72(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 2016
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = xindex < xnumel
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     x0 = xindex
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0), xmask, eviction_policy='evict_last')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp3 = 20.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp5 = tl_math.exp(tmp2)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp6 = libdevice.log1p(tmp5)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp7 = tl.where(tmp4, tmp2, tmp6)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp8 = libdevice.tanh(tmp7)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp9 = tl.sigmoid(tmp2)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp10 = tmp2 * tmp9
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp11 = tmp8 * tmp8
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp12 = 1.0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp13 = tmp12 - tmp11
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp14 = tmp10 * tmp13
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp15 = tmp8 + tmp14
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp15, xmask)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/l5/cl5x2brviniu5zwugckukiw3vuovjcywyjq2tc7khemles6tmqqx.py
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Topologically Sorted Source Nodes: [input_lengths], Original ATen: [aten._to_copy]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Source node to ATen node mapping:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   input_lengths => full_default_1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] # Graph fragment:
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] #   %full_default_1 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1], 63), kwargs = {dtype: torch.int64, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_poi_fused__to_copy_73 = async_compile.triton('triton_poi_fused__to_copy_73', '''
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] import triton.language as tl
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton_heuristics.pointwise(
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     size_hints={'x': 1}, 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     filename=__file__,
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': (1,)}, 'cls': 'AttrsDescriptor'})]},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_73', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     min_elem_per_thread=0
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] @triton.jit
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def triton_poi_fused__to_copy_73(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xnumel = 1
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tmp0 = tl.full([1], 63, tl.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp0, None)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] ''', device_str='cuda')
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] async_compile.wait(globals())
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] del async_compile
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def call(args):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12 = args
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     args.clear()
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_1, (32, 1, 3), (3, 3, 1))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_2, (32, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_3, (1, 1, 128), (128, 128, 1))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_4, (32, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_5, (32, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_6, (32, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_7, (32, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_8, (64, 32), (32, 1))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_9, (64, 64), (64, 1))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_10, (64, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_11, (64, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     assert_size_stride(primals_12, (1, ), (1, ))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         torch.cuda.set_device(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.convolution]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf0 = extern_kernels.convolution(primals_3, primals_1, stride=(1,), padding=(0,), dilation=(1,), transposed=False, output_padding=(0,), groups=1, bias=None)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         assert_size_stride(buf0, (1, 32, 126), (4032, 126, 1))
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf1 = buf0; del buf0  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf2 = empty_strided_cuda((1, 32, 1, 1, 1), (32, 1, 32, 32, 32), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf6 = empty_strided_cuda((1, 32, 1, 1, 126), (4032, 126, 126, 126, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf5 = empty_strided_cuda((1, 32, 1, 1, 1), (32, 1, 32, 32, 32), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x, x_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_functional, aten.mean]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_per_fused__native_batch_norm_legit_functional_convolution_mean_0.run(buf1, primals_2, primals_6, primals_7, primals_4, primals_5, buf2, buf6, buf5, primals_4, primals_5, 32, 126, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_2
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_4
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_5
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_7
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf7 = empty_strided_cuda((1, 32, 1, 63), (2048, 63, 63, 1), torch.int8)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf9 = empty_strided_cuda((1, 32, 63), (2016, 63, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_4, x_5], Original ATen: [aten.max_pool2d_with_indices, aten.mish]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_max_pool2d_with_indices_mish_1.run(buf6, buf7, buf9, 2016, grid=grid(2016), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf8 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [hx], Original ATen: [aten._to_copy]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused__to_copy_2.run(buf8, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf10 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf8, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf10)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf11 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_3.run(buf9, buf11, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf12 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf11, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf12)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf13 = buf10; del buf10  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf324 = empty_strided_cuda((63, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf261 = reinterpret_tensor(buf324, (1, 64), (64, 1), 0)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf13, primals_11, buf12, primals_10, buf261, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf14 = buf12; del buf12  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf13, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf14)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf15 = buf11; del buf11  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_5.run(buf9, buf15, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf16 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf15, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf16)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf17 = buf14; del buf14  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf262 = reinterpret_tensor(buf324, (1, 64), (64, 1), 64)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_1, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf17, primals_11, buf16, primals_10, buf262, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf18 = buf16; del buf16  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf17, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf18)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf19 = buf15; del buf15  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_6.run(buf9, buf19, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf20 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf19, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf20)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf21 = buf18; del buf18  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf263 = reinterpret_tensor(buf324, (1, 64), (64, 1), 128)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_2, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf21, primals_11, buf20, primals_10, buf263, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf22 = buf20; del buf20  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf21, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf22)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf23 = buf19; del buf19  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_7.run(buf9, buf23, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf24 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf23, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf24)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf25 = buf22; del buf22  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf264 = reinterpret_tensor(buf324, (1, 64), (64, 1), 192)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_3, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf25, primals_11, buf24, primals_10, buf264, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf26 = buf24; del buf24  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf25, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf26)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf27 = buf23; del buf23  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_8.run(buf9, buf27, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf28 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf27, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf28)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf29 = buf26; del buf26  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf265 = reinterpret_tensor(buf324, (1, 64), (64, 1), 256)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_4, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf29, primals_11, buf28, primals_10, buf265, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf30 = buf28; del buf28  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf29, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf30)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf31 = buf27; del buf27  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_9.run(buf9, buf31, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf32 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf31, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf33 = buf30; del buf30  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf266 = reinterpret_tensor(buf324, (1, 64), (64, 1), 320)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_5, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf33, primals_11, buf32, primals_10, buf266, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf34 = buf32; del buf32  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf33, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf34)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf35 = buf31; del buf31  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_10.run(buf9, buf35, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf36 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf35, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf36)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf37 = buf34; del buf34  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf267 = reinterpret_tensor(buf324, (1, 64), (64, 1), 384)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_6, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf37, primals_11, buf36, primals_10, buf267, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf38 = buf36; del buf36  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf37, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf38)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf39 = buf35; del buf35  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_11.run(buf9, buf39, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf40 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf39, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf40)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf41 = buf38; del buf38  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf268 = reinterpret_tensor(buf324, (1, 64), (64, 1), 448)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_7, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf41, primals_11, buf40, primals_10, buf268, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf42 = buf40; del buf40  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf41, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf42)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf43 = buf39; del buf39  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_12.run(buf9, buf43, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf44 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf43, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf44)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf45 = buf42; del buf42  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf269 = reinterpret_tensor(buf324, (1, 64), (64, 1), 512)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_8, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf45, primals_11, buf44, primals_10, buf269, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf46 = buf44; del buf44  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf45, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf46)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf47 = buf43; del buf43  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_13.run(buf9, buf47, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf48 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf47, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf48)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf49 = buf46; del buf46  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf270 = reinterpret_tensor(buf324, (1, 64), (64, 1), 576)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_9, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf49, primals_11, buf48, primals_10, buf270, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf50 = buf48; del buf48  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf49, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf50)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf51 = buf47; del buf47  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_14.run(buf9, buf51, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf52 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf51, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf52)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf53 = buf50; del buf50  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf271 = reinterpret_tensor(buf324, (1, 64), (64, 1), 640)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_10, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf53, primals_11, buf52, primals_10, buf271, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf54 = buf52; del buf52  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf53, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf54)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf55 = buf51; del buf51  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_15.run(buf9, buf55, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf56 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf55, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf56)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf57 = buf54; del buf54  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf272 = reinterpret_tensor(buf324, (1, 64), (64, 1), 704)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_11, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf57, primals_11, buf56, primals_10, buf272, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf58 = buf56; del buf56  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf57, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf58)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf59 = buf55; del buf55  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_16.run(buf9, buf59, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf60 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf59, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf60)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf61 = buf58; del buf58  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf273 = reinterpret_tensor(buf324, (1, 64), (64, 1), 768)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_12, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf61, primals_11, buf60, primals_10, buf273, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf62 = buf60; del buf60  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf61, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf62)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf63 = buf59; del buf59  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_17.run(buf9, buf63, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf64 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf63, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf65 = buf62; del buf62  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf274 = reinterpret_tensor(buf324, (1, 64), (64, 1), 832)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_13, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf65, primals_11, buf64, primals_10, buf274, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf66 = buf64; del buf64  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf65, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf66)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf67 = buf63; del buf63  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_18.run(buf9, buf67, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf68 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf67, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf68)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf69 = buf66; del buf66  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf275 = reinterpret_tensor(buf324, (1, 64), (64, 1), 896)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_14, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf69, primals_11, buf68, primals_10, buf275, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf70 = buf68; del buf68  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf69, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf70)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf71 = buf67; del buf67  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_19.run(buf9, buf71, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf72 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf71, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf72)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf73 = buf70; del buf70  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf276 = reinterpret_tensor(buf324, (1, 64), (64, 1), 960)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_15, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf73, primals_11, buf72, primals_10, buf276, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf74 = buf72; del buf72  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf73, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf74)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf75 = buf71; del buf71  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_20.run(buf9, buf75, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf76 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf75, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf76)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf77 = buf74; del buf74  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf277 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1024)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_16, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf77, primals_11, buf76, primals_10, buf277, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf78 = buf76; del buf76  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf77, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf78)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf79 = buf75; del buf75  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_21.run(buf9, buf79, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf80 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf79, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf80)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf81 = buf78; del buf78  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf278 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1088)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_17, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf81, primals_11, buf80, primals_10, buf278, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf82 = buf80; del buf80  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf81, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf82)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf83 = buf79; del buf79  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_22.run(buf9, buf83, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf84 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf83, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf84)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf85 = buf82; del buf82  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf279 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1152)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_18, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf85, primals_11, buf84, primals_10, buf279, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf86 = buf84; del buf84  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf85, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf86)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf87 = buf83; del buf83  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_23.run(buf9, buf87, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf88 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf87, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf88)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf89 = buf86; del buf86  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf280 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1216)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_19, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf89, primals_11, buf88, primals_10, buf280, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf90 = buf88; del buf88  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf89, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf90)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf91 = buf87; del buf87  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_24.run(buf9, buf91, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf92 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf91, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf92)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf93 = buf90; del buf90  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf281 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1280)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_20, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf93, primals_11, buf92, primals_10, buf281, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf94 = buf92; del buf92  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf93, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf94)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf95 = buf91; del buf91  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_25.run(buf9, buf95, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf96 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf95, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf96)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf97 = buf94; del buf94  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf282 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1344)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_21, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf97, primals_11, buf96, primals_10, buf282, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf98 = buf96; del buf96  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf97, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf98)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf99 = buf95; del buf95  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_26.run(buf9, buf99, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf100 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf99, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf100)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf101 = buf98; del buf98  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf283 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1408)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_22, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf101, primals_11, buf100, primals_10, buf283, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf102 = buf100; del buf100  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf101, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf102)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf103 = buf99; del buf99  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_27.run(buf9, buf103, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf104 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf103, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf104)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf105 = buf102; del buf102  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf284 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1472)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_23, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf105, primals_11, buf104, primals_10, buf284, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf106 = buf104; del buf104  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf105, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf106)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf107 = buf103; del buf103  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_28.run(buf9, buf107, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf108 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf107, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf108)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf109 = buf106; del buf106  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf285 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1536)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_24, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf109, primals_11, buf108, primals_10, buf285, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf110 = buf108; del buf108  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf109, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf110)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf111 = buf107; del buf107  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_29.run(buf9, buf111, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf112 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf111, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf112)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf113 = buf110; del buf110  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf286 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1600)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_25, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf113, primals_11, buf112, primals_10, buf286, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf114 = buf112; del buf112  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf113, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf114)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf115 = buf111; del buf111  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_30.run(buf9, buf115, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf116 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf115, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf116)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf117 = buf114; del buf114  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf287 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1664)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_26, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf117, primals_11, buf116, primals_10, buf287, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf118 = buf116; del buf116  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf117, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf118)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf119 = buf115; del buf115  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_31.run(buf9, buf119, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf120 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf119, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf120)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf121 = buf118; del buf118  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf288 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1728)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_27, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf121, primals_11, buf120, primals_10, buf288, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf122 = buf120; del buf120  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf121, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf122)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf123 = buf119; del buf119  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_32.run(buf9, buf123, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf124 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf123, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf124)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf125 = buf122; del buf122  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf289 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1792)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_28, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf125, primals_11, buf124, primals_10, buf289, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf126 = buf124; del buf124  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf125, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf126)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf127 = buf123; del buf123  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_33.run(buf9, buf127, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf128 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf127, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf128)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf129 = buf126; del buf126  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf290 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1856)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_29, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf129, primals_11, buf128, primals_10, buf290, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf130 = buf128; del buf128  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf129, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf130)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf131 = buf127; del buf127  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_34.run(buf9, buf131, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf132 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf131, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf132)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf133 = buf130; del buf130  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf291 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1920)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_30, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf133, primals_11, buf132, primals_10, buf291, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf134 = buf132; del buf132  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf133, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf134)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf135 = buf131; del buf131  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_35.run(buf9, buf135, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf136 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf135, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf136)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf137 = buf134; del buf134  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf292 = reinterpret_tensor(buf324, (1, 64), (64, 1), 1984)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_31, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf137, primals_11, buf136, primals_10, buf292, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf138 = buf136; del buf136  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf137, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf138)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf139 = buf135; del buf135  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_36.run(buf9, buf139, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf140 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf139, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf140)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf141 = buf138; del buf138  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf293 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2048)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_32, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf141, primals_11, buf140, primals_10, buf293, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf142 = buf140; del buf140  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf141, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf142)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf143 = buf139; del buf139  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_37.run(buf9, buf143, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf144 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf143, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf144)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf145 = buf142; del buf142  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf294 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2112)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_33, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf145, primals_11, buf144, primals_10, buf294, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf146 = buf144; del buf144  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf145, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf146)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf147 = buf143; del buf143  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_38.run(buf9, buf147, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf148 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf147, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf148)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf149 = buf146; del buf146  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf295 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2176)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_34, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf149, primals_11, buf148, primals_10, buf295, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf150 = buf148; del buf148  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf149, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf150)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf151 = buf147; del buf147  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_39.run(buf9, buf151, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf152 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf151, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf152)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf153 = buf150; del buf150  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf296 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2240)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_35, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf153, primals_11, buf152, primals_10, buf296, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf154 = buf152; del buf152  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf153, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf154)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf155 = buf151; del buf151  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_40.run(buf9, buf155, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf156 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf155, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf156)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf157 = buf154; del buf154  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf297 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2304)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_36, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf157, primals_11, buf156, primals_10, buf297, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf158 = buf156; del buf156  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf157, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf158)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf159 = buf155; del buf155  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_41.run(buf9, buf159, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf160 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf159, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf160)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf161 = buf158; del buf158  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf298 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2368)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_37, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf161, primals_11, buf160, primals_10, buf298, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf162 = buf160; del buf160  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf161, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf162)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf163 = buf159; del buf159  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_42.run(buf9, buf163, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf164 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf163, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf164)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf165 = buf162; del buf162  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf299 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2432)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_38, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf165, primals_11, buf164, primals_10, buf299, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf166 = buf164; del buf164  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf165, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf166)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf167 = buf163; del buf163  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_43.run(buf9, buf167, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf168 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf167, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf168)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf169 = buf166; del buf166  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf300 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2496)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_39, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf169, primals_11, buf168, primals_10, buf300, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf170 = buf168; del buf168  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf169, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf170)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf171 = buf167; del buf167  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_44.run(buf9, buf171, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf172 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf171, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf172)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf173 = buf170; del buf170  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf301 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2560)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_40, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf173, primals_11, buf172, primals_10, buf301, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf174 = buf172; del buf172  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf173, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf174)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf175 = buf171; del buf171  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_45.run(buf9, buf175, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf176 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf175, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf176)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf177 = buf174; del buf174  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf302 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2624)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_41, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf177, primals_11, buf176, primals_10, buf302, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf178 = buf176; del buf176  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf177, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf178)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf179 = buf175; del buf175  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_46.run(buf9, buf179, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf180 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf179, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf180)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf181 = buf178; del buf178  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf303 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2688)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_42, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf181, primals_11, buf180, primals_10, buf303, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf182 = buf180; del buf180  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf181, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf182)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf183 = buf179; del buf179  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_47.run(buf9, buf183, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf184 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf183, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf184)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf185 = buf182; del buf182  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf304 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2752)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_43, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf185, primals_11, buf184, primals_10, buf304, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf186 = buf184; del buf184  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf185, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf186)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf187 = buf183; del buf183  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_48.run(buf9, buf187, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf188 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf187, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf188)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf189 = buf186; del buf186  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf305 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2816)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_44, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf189, primals_11, buf188, primals_10, buf305, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf190 = buf188; del buf188  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf189, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf190)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf191 = buf187; del buf187  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_49.run(buf9, buf191, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf192 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf191, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf192)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf193 = buf190; del buf190  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf306 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2880)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_45, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf193, primals_11, buf192, primals_10, buf306, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf194 = buf192; del buf192  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf193, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf194)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf195 = buf191; del buf191  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_50.run(buf9, buf195, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf196 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf195, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf196)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf197 = buf194; del buf194  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf307 = reinterpret_tensor(buf324, (1, 64), (64, 1), 2944)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_46, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf197, primals_11, buf196, primals_10, buf307, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf198 = buf196; del buf196  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf197, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf198)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf199 = buf195; del buf195  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_51.run(buf9, buf199, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf200 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf199, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf200)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf201 = buf198; del buf198  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf308 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3008)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_47, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf201, primals_11, buf200, primals_10, buf308, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf202 = buf200; del buf200  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf201, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf202)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf203 = buf199; del buf199  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_52.run(buf9, buf203, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf204 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf203, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf204)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf205 = buf202; del buf202  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf309 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3072)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_48, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf205, primals_11, buf204, primals_10, buf309, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf206 = buf204; del buf204  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf205, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf206)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf207 = buf203; del buf203  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_53.run(buf9, buf207, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf208 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf207, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf208)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf209 = buf206; del buf206  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf310 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3136)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_49, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf209, primals_11, buf208, primals_10, buf310, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf210 = buf208; del buf208  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf209, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf210)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf211 = buf207; del buf207  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_54.run(buf9, buf211, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf212 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf211, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf212)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf213 = buf210; del buf210  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf311 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3200)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_50, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf213, primals_11, buf212, primals_10, buf311, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf214 = buf212; del buf212  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf213, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf214)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf215 = buf211; del buf211  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_55.run(buf9, buf215, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf216 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf215, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf216)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf217 = buf214; del buf214  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf312 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3264)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_51, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf217, primals_11, buf216, primals_10, buf312, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf218 = buf216; del buf216  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_52], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf217, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf218)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf219 = buf215; del buf215  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_52], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_56.run(buf9, buf219, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf220 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_52], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf219, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf220)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf221 = buf218; del buf218  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf313 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3328)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_52, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf221, primals_11, buf220, primals_10, buf313, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf222 = buf220; del buf220  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_53], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf221, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf222)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf223 = buf219; del buf219  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_53], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_57.run(buf9, buf223, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf224 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_53], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf223, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf224)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf225 = buf222; del buf222  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf314 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3392)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_53, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf225, primals_11, buf224, primals_10, buf314, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf226 = buf224; del buf224  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_54], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf225, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf226)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf227 = buf223; del buf223  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_54], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_58.run(buf9, buf227, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf228 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_54], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf227, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf228)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf229 = buf226; del buf226  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf315 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3456)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_54, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf229, primals_11, buf228, primals_10, buf315, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf230 = buf228; del buf228  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_55], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf229, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf230)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf231 = buf227; del buf227  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_55], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_59.run(buf9, buf231, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf232 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_55], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf231, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf232)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf233 = buf230; del buf230  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf316 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3520)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_55, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf233, primals_11, buf232, primals_10, buf316, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf234 = buf232; del buf232  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_56], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf233, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf234)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf235 = buf231; del buf231  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_56], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_60.run(buf9, buf235, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf236 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_56], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf235, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf236)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf237 = buf234; del buf234  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf317 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3584)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_56, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf237, primals_11, buf236, primals_10, buf317, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf238 = buf236; del buf236  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_57], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf237, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf238)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf239 = buf235; del buf235  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_57], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_61.run(buf9, buf239, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf240 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_57], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf239, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf240)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf241 = buf238; del buf238  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf318 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3648)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_57, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf241, primals_11, buf240, primals_10, buf318, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf242 = buf240; del buf240  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_58], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf241, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf242)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf243 = buf239; del buf239  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_58], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_62.run(buf9, buf243, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf244 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_58], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf243, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf244)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf245 = buf242; del buf242  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf319 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3712)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_58, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf245, primals_11, buf244, primals_10, buf319, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf246 = buf244; del buf244  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_59], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf245, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf246)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf247 = buf243; del buf243  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_59], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_63.run(buf9, buf247, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf248 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_59], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf247, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf248)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf249 = buf246; del buf246  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf320 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3776)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_59, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf249, primals_11, buf248, primals_10, buf320, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf250 = buf248; del buf248  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_60], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf249, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf250)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf251 = buf247; del buf247  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_60], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_64.run(buf9, buf251, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf252 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_60], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf251, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf252)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf253 = buf250; del buf250  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf321 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3840)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_60, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf253, primals_11, buf252, primals_10, buf321, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf254 = buf252; del buf252  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_61], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf253, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf254)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf255 = buf251; del buf251  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_61], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_65.run(buf9, buf255, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf256 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_61], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf255, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf256)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf257 = buf254; del buf254  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf322 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3904)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_61, x_7], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.stack]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_stack_tanh_4.run(buf257, primals_11, buf256, primals_10, buf322, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf258 = buf256; del buf256  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf257, reinterpret_tensor(primals_9, (64, 64), (1, 64), 0), out=buf258)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf259 = buf255; del buf255  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_addmm_66.run(buf9, buf259, 32, grid=grid(32), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf260 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         extern_kernels.mm(buf259, reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf260)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del buf259
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf323 = reinterpret_tensor(buf324, (1, 64), (64, 1), 3968)  # alias
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf333 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [ret_62], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.tanh_backward]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_addmm_tanh_tanh_backward_67.run(buf258, primals_11, buf260, primals_10, buf323, buf333, 64, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_10
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del primals_11
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     buf325 = empty_strided_cpu((2, ), (1, ), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     aten.randint.low_out(-9223372036854775808, 9223372036854775807, [2], out=buf325)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     buf326 = empty_strided_cpu((1, 10), (10, 1), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     cpp_fused_randint_68(buf325, buf326)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         torch.cuda.set_device(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf327 = empty_strided_cuda((1, 10), (10, 1), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf327.copy_(buf326, False)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del buf326
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     buf328 = empty_strided_cpu((1, ), (1, ), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     cpp_fused_randint_69(buf325, buf328)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     del buf325
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         torch.cuda.set_device(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf329 = empty_strided_cuda((1, ), (1, ), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf329.copy_(buf328, False)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del buf328
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf330 = reinterpret_tensor(buf260, (1, 64, 1), (64, 1, 64), 0); del buf260  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf331 = reinterpret_tensor(buf258, (1, 64, 1), (64, 1, 64), 0); del buf258  # reuse
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_13], Original ATen: [aten._log_softmax]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_per_fused__log_softmax_70.run(buf324, primals_12, buf330, buf331, 64, 63, grid=grid(64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf332 = empty_strided_cuda((1, 64, 63), (4032, 63, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_13], Original ATen: [aten._log_softmax]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused__log_softmax_71.run(buf324, primals_12, buf330, buf331, buf332, 63, 64, grid=grid(63, 64), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del buf330
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         del buf331
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf334 = empty_strided_cuda((1, 32, 63), (2016, 63, 1), torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.mish, aten.sigmoid, aten.mul, aten.fill, aten.sub, aten.add]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused_add_fill_mish_mul_sigmoid_sub_72.run(buf6, buf334, 2016, grid=grid(2016), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         buf343 = empty_strided_cuda((1, ), (1, ), torch.int64)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         # Topologically Sorted Source Nodes: [input_lengths], Original ATen: [aten._to_copy]
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]         triton_poi_fused__to_copy_73.run(buf343, 1, grid=grid(1), stream=stream0)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     return (buf332, buf327, buf343, buf329, primals_1, primals_3, primals_6, primals_12, buf1, reinterpret_tensor(buf5, (32, ), (1, ), 0), reinterpret_tensor(buf6, (1, 32, 1, 126), (4032, 126, 126, 1), 0), buf7, buf8, reinterpret_tensor(buf9, (1, 32), (2016, 63), 0), buf13, reinterpret_tensor(buf9, (1, 32), (2016, 63), 1), buf17, reinterpret_tensor(buf9, (1, 32), (2016, 63), 2), buf21, reinterpret_tensor(buf9, (1, 32), (2016, 63), 3), buf25, reinterpret_tensor(buf9, (1, 32), (2016, 63), 4), buf29, reinterpret_tensor(buf9, (1, 32), (2016, 63), 5), buf33, reinterpret_tensor(buf9, (1, 32), (2016, 63), 6), buf37, reinterpret_tensor(buf9, (1, 32), (2016, 63), 7), buf41, reinterpret_tensor(buf9, (1, 32), (2016, 63), 8), buf45, reinterpret_tensor(buf9, (1, 32), (2016, 63), 9), buf49, reinterpret_tensor(buf9, (1, 32), (2016, 63), 10), buf53, reinterpret_tensor(buf9, (1, 32), (2016, 63), 11), buf57, reinterpret_tensor(buf9, (1, 32), (2016, 63), 12), buf61, reinterpret_tensor(buf9, (1, 32), (2016, 63), 13), buf65, reinterpret_tensor(buf9, (1, 32), (2016, 63), 14), buf69, reinterpret_tensor(buf9, (1, 32), (2016, 63), 15), buf73, reinterpret_tensor(buf9, (1, 32), (2016, 63), 16), buf77, reinterpret_tensor(buf9, (1, 32), (2016, 63), 17), buf81, reinterpret_tensor(buf9, (1, 32), (2016, 63), 18), buf85, reinterpret_tensor(buf9, (1, 32), (2016, 63), 19), buf89, reinterpret_tensor(buf9, (1, 32), (2016, 63), 20), buf93, reinterpret_tensor(buf9, (1, 32), (2016, 63), 21), buf97, reinterpret_tensor(buf9, (1, 32), (2016, 63), 22), buf101, reinterpret_tensor(buf9, (1, 32), (2016, 63), 23), buf105, reinterpret_tensor(buf9, (1, 32), (2016, 63), 24), buf109, reinterpret_tensor(buf9, (1, 32), (2016, 63), 25), buf113, reinterpret_tensor(buf9, (1, 32), (2016, 63), 26), buf117, reinterpret_tensor(buf9, (1, 32), (2016, 63), 27), buf121, reinterpret_tensor(buf9, (1, 32), (2016, 63), 28), buf125, reinterpret_tensor(buf9, (1, 32), (2016, 63), 29), buf129, reinterpret_tensor(buf9, (1, 32), (2016, 63), 30), buf133, reinterpret_tensor(buf9, (1, 32), (2016, 63), 31), buf137, reinterpret_tensor(buf9, (1, 32), (2016, 63), 32), buf141, reinterpret_tensor(buf9, (1, 32), (2016, 63), 33), buf145, reinterpret_tensor(buf9, (1, 32), (2016, 63), 34), buf149, reinterpret_tensor(buf9, (1, 32), (2016, 63), 35), buf153, reinterpret_tensor(buf9, (1, 32), (2016, 63), 36), buf157, reinterpret_tensor(buf9, (1, 32), (2016, 63), 37), buf161, reinterpret_tensor(buf9, (1, 32), (2016, 63), 38), buf165, reinterpret_tensor(buf9, (1, 32), (2016, 63), 39), buf169, reinterpret_tensor(buf9, (1, 32), (2016, 63), 40), buf173, reinterpret_tensor(buf9, (1, 32), (2016, 63), 41), buf177, reinterpret_tensor(buf9, (1, 32), (2016, 63), 42), buf181, reinterpret_tensor(buf9, (1, 32), (2016, 63), 43), buf185, reinterpret_tensor(buf9, (1, 32), (2016, 63), 44), buf189, reinterpret_tensor(buf9, (1, 32), (2016, 63), 45), buf193, reinterpret_tensor(buf9, (1, 32), (2016, 63), 46), buf197, reinterpret_tensor(buf9, (1, 32), (2016, 63), 47), buf201, reinterpret_tensor(buf9, (1, 32), (2016, 63), 48), buf205, reinterpret_tensor(buf9, (1, 32), (2016, 63), 49), buf209, reinterpret_tensor(buf9, (1, 32), (2016, 63), 50), buf213, reinterpret_tensor(buf9, (1, 32), (2016, 63), 51), buf217, reinterpret_tensor(buf9, (1, 32), (2016, 63), 52), buf221, reinterpret_tensor(buf9, (1, 32), (2016, 63), 53), buf225, reinterpret_tensor(buf9, (1, 32), (2016, 63), 54), buf229, reinterpret_tensor(buf9, (1, 32), (2016, 63), 55), buf233, reinterpret_tensor(buf9, (1, 32), (2016, 63), 56), buf237, reinterpret_tensor(buf9, (1, 32), (2016, 63), 57), buf241, reinterpret_tensor(buf9, (1, 32), (2016, 63), 58), buf245, reinterpret_tensor(buf9, (1, 32), (2016, 63), 59), buf249, reinterpret_tensor(buf9, (1, 32), (2016, 63), 60), buf253, reinterpret_tensor(buf9, (1, 32), (2016, 63), 61), buf257, reinterpret_tensor(buf9, (1, 32), (2016, 63), 62), buf324, buf332, buf333, primals_8, primals_9, buf334, reinterpret_tensor(buf2, (1, 32, 1, 1, 1), (32, 1, 1, 1, 1), 0), )
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_1 = rand_strided((32, 1, 3), (3, 3, 1), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_2 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_3 = rand_strided((1, 1, 128), (128, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_4 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_5 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_6 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_7 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_8 = rand_strided((64, 32), (32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_9 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_10 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_11 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     primals_12 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12])
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] if __name__ == "__main__":
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:41:26.564000 703210 site-packages/torch/_inductor/graph.py:2014] [831/0_1] [__output_code] 
V0127 11:41:26.649000 703210 site-packages/torch/_inductor/graph.py:2022] [831/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/75/c75bm5siznsku3sspxtuujohygcsef6ys2ngyogjwcfcx3tx4vfv.py
I0127 11:41:27.733000 703210 site-packages/torch/_inductor/graph.py:2056] [831/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/75/c75bm5siznsku3sspxtuujohygcsef6ys2ngyogjwcfcx3tx4vfv.py
