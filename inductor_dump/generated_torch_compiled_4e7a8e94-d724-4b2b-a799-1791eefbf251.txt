W0127 11:35:43.020000 703210 site-packages/torch/utils/_sympy/interp.py:176] [390/0] failed while executing pow_by_natural([VR[4, int_oo], VR[-1, -1]])
W0127 11:35:43.536000 703210 site-packages/torch/utils/_sympy/interp.py:176] [390/0] failed while executing pow_by_natural([VR[4, int_oo], VR[-1, -1]])
W0127 11:35:43.748000 703210 site-packages/torch/utils/_sympy/interp.py:176] [390/0] failed while executing pow_by_natural([VR[6, int_oo], VR[-1, -1]])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] Output code: 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # AOT ID: ['91_forward']
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import torch
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import random
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import os
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import tempfile
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from math import inf, nan
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from cmath import nanj
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch import device, empty_strided
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     grid,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     split_scan_grid,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     grid_combo_kernels,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     start_graph,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     end_graph,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     cooperative_reduction_grid,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] aten = torch.ops.aten
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] _quantized = torch.ops._quantized
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] async_compile = AsyncCompile()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hj/chjhkrghj3a6ll7czzk7p65plqemf3skqb5cpkbzlp4lc26pfhb4.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [x], Original ATen: [aten.bernoulli]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x => inductor_lookup_seed_default, inductor_random_default_5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default_5 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %primals_1, 1, 1, 1], %inductor_lookup_seed_default, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_bernoulli_0 = async_compile.triton('triton_poi_fused_bernoulli_0', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'out_ptr0': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bernoulli_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_bernoulli_0(in_ptr0, out_ptr0, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uq/cuqqn6yt2fljvgh23v5lyr5ww3u3qjl66f7rdqpoz3m4x5f6vao5.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.copy]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_1 => copy
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %copy : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_5, %slice_6), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_tensor_1, %copy, 2, 1, %add_30), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_tensor, %slice_scatter_default, 3, 1, %add_32), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%empty_1, %slice_scatter_default_1, 4, 1, %add_34), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_copy_1 = async_compile.triton('triton_poi_fused_copy_1', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 131072}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'ks7': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_copy_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_copy_1(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, ks7, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % ks2)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = ((xindex // ks4) % ks5)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex // ks7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x4 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = 1 + ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp0 < tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp2 & tmp4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp6 >= tmp7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.broadcast_to(1 + ks3, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp6 < tmp9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp8 & tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tmp11 & tmp5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = x2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp13 >= tmp14
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tl.broadcast_to(1 + ks6, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp13 < tmp16
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tmp15 & tmp17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tmp18 & tmp12
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tl.load(in_ptr0 + ((-1) + x0 + ((-1)*ks1) + ks1*x1 + ((-1)*ks1*ks3) + ks1*ks3*x2 + ks1*ks3*ks6*x3), tmp19 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tl.load(in_ptr1 + (x3), tmp19 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = 0.5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tmp21 < tmp22
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tmp23.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp25 = 2.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = tmp24 * tmp25
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tmp20 * tmp26
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = tl.where(tmp19, tmp27, tmp28)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tl.load(in_ptr2 + (x4), tmp12 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = tl.where(tmp18, tmp29, tmp30)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tl.full(tmp31.shape, 0.0, tmp31.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = tl.where(tmp12, tmp31, tmp32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tl.load(in_ptr2 + (x4), tmp5 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = tl.where(tmp11, tmp33, tmp34)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tl.full(tmp35.shape, 0.0, tmp35.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tl.where(tmp5, tmp35, tmp36)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = float("nan")
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = tl.where(tmp5, tmp37, tmp38)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp39, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6f/c6ffvnjeqtxlrpqrjm2i6754rtoqoqli2barisdrkmb5rjrmieuc.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_2, %slice_15, 4, 0, 1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_4 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_3, %slice_20, 4, %add_34, %add_35), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_5 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_4, %slice_25, 3, 0, 1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_2 = async_compile.triton('triton_poi_fused_2', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 131072}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_2(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % ks1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x4 = xindex // ks0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.broadcast_to(1 + ks2, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp3 >= tmp4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp5 & tmp2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = x0 + ((-1)*ks2)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tmp7 < tmp8
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp9 & tmp6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (ks2 + 2*ks3 + 2*x4 + ks2*ks3 + ks2*x4), tmp10 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.load(in_ptr0 + (x3 + ((-1)*ks2) + 2*ks3 + ks2*ks3), tmp6 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tl.where(tmp9, tmp11, tmp12)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tl.where(tmp6, tmp13, tmp14)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp3 < tmp16
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tmp17 & tmp2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tl.load(in_ptr0 + (ks2 + 2*ks3 + 2*x4 + ks2*ks3 + ks2*x4), tmp18 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tl.load(in_ptr0 + (x3 + 2*ks3 + ks2*ks3), tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tl.where(tmp17, tmp19, tmp20)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = tl.where(tmp5, tmp15, tmp21)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tl.where(tmp2, tmp22, tmp23)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp25 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = 1 + ks2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tmp25 >= tmp26
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = x0 + ((-1)*ks2)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tmp28 < tmp29
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = tmp30 & tmp27
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tl.load(in_ptr0 + (ks2 + 2*x4 + ks2*x4), tmp31 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = tl.load(in_ptr0 + (x3 + ((-1)*ks2)), tmp27 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tl.where(tmp30, tmp32, tmp33)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = tl.full(tmp34.shape, 0.0, tmp34.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tl.where(tmp27, tmp34, tmp35)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tmp25 < tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = tl.load(in_ptr0 + (ks2 + 2*x4 + ks2*x4), tmp37 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp40 = tl.where(tmp37, tmp38, tmp39)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp41 = tl.where(tmp27, tmp36, tmp40)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp42 = tl.where(tmp2, tmp24, tmp41)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp42, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rq/crqdgocbxl7rwr4mdjfabi2foeffouzmgvvgz66yvptthwqnukac.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.constant_pad_nd]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_2 => constant_pad_nd
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_6 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_5, %slice_30, 3, %add_32, %add_33), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_7 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_6, %slice_35, 2, 0, 1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_7, %slice_40, 2, %add_30, %add_31), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %constant_pad_nd : [num_users=5] = call_function[target=torch.ops.aten.constant_pad_nd.default](args = (%slice_scatter_default_8, [1, 1, 1, 1, 1, 1], 0.0), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_constant_pad_nd_3 = async_compile.triton('triton_poi_fused_constant_pad_nd_3', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'ks7': 'i32', 'ks8': 'i32', 'ks9': 'i32', 'ks10': 'i32', 'ks11': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_constant_pad_nd_3(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, ks7, ks8, ks9, ks10, ks11, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x6 = ((xindex // ks0) % ks1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks3) % ks4)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks3)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = ((xindex // ks9) % ks1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex // ks10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x8 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = (-1) + x6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = ks2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp0 < tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = (-1) + x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp5 >= tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = ks5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp5 < tmp7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = (-1) + x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp9 >= tmp1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = ks6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tmp9 < tmp11
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tmp2 & tmp4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tmp13 & tmp6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp14 & tmp8
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tmp15 & tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp16 & tmp12
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = (-1) + x6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tl.broadcast_to(1 + ks7, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp18 >= tmp19
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tmp20 & tmp17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = (-1) + x6 + ((-1)*ks7)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tmp22 < tmp23
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp25 = tmp24 & tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = (-1) + x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tl.broadcast_to(1 + ks8, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = tmp26 >= tmp27
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = tmp28 & tmp25
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tl.load(in_ptr0 + ((-3) + x0 + ((-1)*ks11) + ((-2)*ks8) + 4*x2 + 8*x3 + ((-1)*ks11*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp29 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = tl.load(in_ptr0 + ((-7) + x0 + ((-3)*ks11) + ((-2)*ks8) + 2*x1 + 4*x2 + 8*x3 + ks11*x1 + ((-1)*ks11*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tl.where(tmp28, tmp30, tmp31)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = tl.full(tmp32.shape, 0.0, tmp32.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tl.where(tmp25, tmp32, tmp33)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = (-1) + x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tl.broadcast_to(1 + ks8, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tmp35 >= tmp36
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = tmp37 & tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = tl.load(in_ptr0 + ((-3) + x0 + ((-1)*ks11) + ((-4)*ks7) + ((-2)*ks8) + 4*x2 + 8*x3 + ((-1)*ks11*ks8) + ((-2)*ks11*ks7) + ((-2)*ks7*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + ((-1)*ks11*ks7*ks8) + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp38 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp40 = tl.load(in_ptr0 + ((-7) + x0 + ((-4)*ks7) + ((-3)*ks11) + ((-2)*ks8) + 2*x1 + 4*x2 + 8*x3 + ks11*x1 + ((-1)*ks11*ks8) + ((-2)*ks11*ks7) + ((-2)*ks7*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + ((-1)*ks11*ks7*ks8) + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp21 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp41 = tl.where(tmp37, tmp39, tmp40)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp42 = tl.where(tmp24, tmp34, tmp41)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp43 = tl.full(tmp42.shape, 0.0, tmp42.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp44 = tl.where(tmp21, tmp42, tmp43)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp45 = tl.full([1], 1, tl.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp46 = tmp18 < tmp45
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp47 = tmp46 & tmp17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp48 = (-1) + x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp49 = tl.broadcast_to(1 + ks8, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp50 = tmp48 >= tmp49
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp51 = tmp50 & tmp47
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp52 = tl.load(in_ptr0 + ((-3) + x0 + ((-1)*ks11) + ((-2)*ks8) + 4*ks7 + 4*x2 + 8*x3 + ((-1)*ks11*ks8) + 2*ks11*ks7 + 2*ks11*x2 + 2*ks7*ks8 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks7*ks8 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp51 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp53 = tl.load(in_ptr0 + ((-7) + x0 + ((-3)*ks11) + ((-2)*ks8) + 2*x1 + 4*ks7 + 4*x2 + 8*x3 + ks11*x1 + ((-1)*ks11*ks8) + 2*ks11*ks7 + 2*ks11*x2 + 2*ks7*ks8 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks7*ks8 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp47 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp54 = tl.where(tmp50, tmp52, tmp53)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp55 = tl.full(tmp54.shape, 0.0, tmp54.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp56 = tl.where(tmp47, tmp54, tmp55)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp57 = (-1) + x1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp58 = tl.broadcast_to(1 + ks8, [XBLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp59 = tmp57 >= tmp58
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp60 = tmp59 & tmp17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp61 = tl.load(in_ptr0 + ((-3) + x0 + ((-1)*ks11) + ((-2)*ks8) + 4*x2 + 8*x3 + ((-1)*ks11*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp60 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp62 = tl.load(in_ptr0 + ((-7) + x0 + ((-3)*ks11) + ((-2)*ks8) + 2*x1 + 4*x2 + 8*x3 + ks11*x1 + ((-1)*ks11*ks8) + 2*ks11*x2 + 2*ks8*x2 + 4*ks11*x3 + 4*ks7*x3 + 4*ks8*x3 + ks11*ks8*x2 + 2*ks11*ks7*x3 + 2*ks11*ks8*x3 + 2*ks7*ks8*x3 + ks11*ks7*ks8*x3), tmp17 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp63 = tl.where(tmp59, tmp61, tmp62)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp64 = tl.where(tmp46, tmp56, tmp63)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp65 = tl.where(tmp20, tmp44, tmp64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp66 = tl.full(tmp65.shape, 0.0, tmp65.dtype)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp67 = tl.where(tmp17, tmp65, tmp66)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x8), tmp67, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3z/c3zuqrt7b7wtps75ehfbcouonvvx4puph5a7fs67q2ye3x22evo6.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [result, x_3, x_4], Original ATen: [aten.threshold, aten.bernoulli, aten._to_copy, aten.add, aten.mul, aten.silu]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   result => full_default, le_6, where
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_3 => add_261, add_282, add_313, convert_element_type_1, inductor_lookup_seed_default_1, inductor_random_default_4, lt_72, mul_278, mul_299, mul_305
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_4 => mul_326, sigmoid
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %le_6 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%constant_pad_nd, 0.5), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %full_default : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_6, %full_default, %constant_pad_nd), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %primals_1, %sym_size_int_13, %sym_size_int_14, %sym_size_int_15], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %lt_72 : [num_users=1] = call_function[target=torch.ops.aten.lt.Scalar](args = (%inductor_random_default_4, 0.5), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %convert_element_type_1 : [num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%lt_72, torch.float32), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_261 : [num_users=1] = call_function[target=torch.ops.aten.add.Scalar](args = (%convert_element_type_1, -1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_278 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%add_261, 1.558387861036063), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_282 : [num_users=1] = call_function[target=torch.ops.aten.add.Scalar](args = (%mul_278, 0.7791939305180315), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_299 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%convert_element_type_1, 0.8864048946659319), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_305 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where, %mul_299), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_313 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_305, %add_282), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_313,), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_326 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_313, %sigmoid), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4 = async_compile.triton('triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4(in_out_ptr0, in_ptr0, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = 0.5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp3 <= tmp4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = 0.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.where(tmp5, tmp6, tmp3)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp2 < tmp4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = 0.8864048946659319
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp9 * tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tmp7 * tmp11
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = -1.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tmp9 + tmp13
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = 1.558387861036063
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tmp14 * tmp15
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = 0.7791939305180315
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tmp16 + tmp17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tmp12 + tmp18
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tl.sigmoid(tmp19)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tmp19 * tmp20
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp21, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ii/ciis37vywsoh37vwyhhhq3srvt44fn3au2juw5t3r72s2pbeblja.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward => view_1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_1 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view, [%sym_size_int_16, %sym_size_int_17]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_5 = async_compile.triton('triton_poi_fused_view_5', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'ks7': 'i32', 'ks8': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_5(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, ks7, ks8, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*((((x0 + 64*x1) // ks3) % ks4)) + 16*((((x0 + 64*x1) // ks1) % ks2)) + 64*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks8*((((x0 + 64*x1) // ks3) % ks4)) + 4*ks7*((((x0 + 64*x1) // ks1) % ks2)) + 4*ks8*((((x0 + 64*x1) // ks1) % ks2)) + 16*ks6*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 16*ks7*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 16*ks8*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks7*ks8*((((x0 + 64*x1) // ks1) % ks2)) + 4*ks6*ks7*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 4*ks6*ks8*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 4*ks7*ks8*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks6*ks7*ks8*((((x0 + 64*x1) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + (((x0 + 64*x1) % ks3))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ds/cdskf7o2jmyiobhp7crjwohbcl7pj4b6mfi7qap3hfbot23mlwep.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward => clone
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %clone : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_clone_6 = async_compile.triton('triton_poi_fused_clone_6', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 524288}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_clone_6(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % ks1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + ks0*x2 + 3*ks0*x1), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jp/cjpgtxj7bttfhoclxfcryuzggrazcnkcgrw6zlozfzziwkbc5chq.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward => view_7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_7 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_3, [%sym_size_int_16, 8, 1, %floordiv]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_7 = async_compile.triton('triton_poi_fused_view_7', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_7(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % 8)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (((x0 + x1*(triton_helpers.div_floor_integer(64*ks3 + 16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6,  8*ks3 + 8*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64))) + 8*x2*(triton_helpers.div_floor_integer(64*ks3 + 16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6,  8*ks3 + 8*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64)))) % (ks2*ks3 + ks2*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64)))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jv/cjvackanlqyaevwzba2fu3b665kcty2f5wvner6guul3s6u6zb54.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward => view_8
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_8 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_4, [%sym_size_int_16, 8, 1, %floordiv]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_8 = async_compile.triton('triton_poi_fused_view_8', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_8(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % 8)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2*ks3 + ks2*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64) + (((x0 + ks0*x1 + 8*ks0*x2) % (ks2*ks3 + ks2*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64))))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zi/cziuxabqs2renzyqsiehyaqx54fhafcduatqvchlp4lxqdzgxmm2.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward => view_9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_9 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_5, [%sym_size_int_16, 8, 1, %floordiv]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_9 = async_compile.triton('triton_poi_fused_view_9', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_9(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, ks6, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % 8)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*ks2*ks3 + 2*ks2*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64) + (((x0 + ks0*x1 + 8*ks0*x2) % (ks2*ks3 + ks2*((16*ks3*ks4 + 16*ks3*ks5 + 16*ks3*ks6 + 4*ks3*ks4*ks5 + 4*ks3*ks4*ks6 + 4*ks3*ks5*ks6 + ks3*ks4*ks5*ks6) // 64))))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tj/ctjbtnmgwmk33jqxhv4ppprnom4clufopcynhk6a7xvighwwdxof.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   add => add_434
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   dropout => gt_26, inductor_lookup_seed_default_2, inductor_random_default_3, mul_423, mul_424
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_6 => add_438, add_439, mul_433, mul_434, rsqrt, sub_259, var_mean
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %sym_size_int_19, 64], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %gt_26 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_3, 0.1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_423 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_26, %view_11), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_424 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_423, 1.1111111111111112), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_434 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%view, %mul_424), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_434, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_438 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %rsqrt : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_438,), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_259 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_434, %getitem_5), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_433 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_259, %rsqrt), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_434 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_433, %primals_10), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_439 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_434, %primals_11), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt, %sym_size_int_17), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 64},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'ks6': 'i32', 'ks7': 'i32', 'ks8': 'i32', 'ks9': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 20), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, ks1, ks2, ks3, ks4, ks5, ks6, ks7, ks8, ks9, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (4*((((r0_1 + 64*x0) // ks3) % ks4)) + 16*((((r0_1 + 64*x0) // ks1) % ks2)) + 64*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks8*((((r0_1 + 64*x0) // ks3) % ks4)) + 4*ks7*((((r0_1 + 64*x0) // ks1) % ks2)) + 4*ks8*((((r0_1 + 64*x0) // ks1) % ks2)) + 16*ks6*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 16*ks7*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 16*ks8*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks7*ks8*((((r0_1 + 64*x0) // ks1) % ks2)) + 4*ks6*ks7*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 4*ks6*ks8*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + 4*ks7*ks8*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + ks6*ks7*ks8*((((r0_1 + 64*x0) // (64 + 16*ks6 + 16*ks7 + 16*ks8 + 4*ks6*ks7 + 4*ks6*ks8 + 4*ks7*ks8 + ks6*ks7*ks8)) % ks5)) + (((r0_1 + 64*x0) % ks3))), xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = 0.1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = 1.1111111111111112
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp8 * tmp9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp5 + tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.where(xmask, tmp12, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tl.where(xmask, tmp15, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tl.sum(tmp17, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp19.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tmp18 / tmp20
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = tmp12 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tmp22 * tmp22
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tl.broadcast_to(tmp23, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = tl.where(xmask, tmp24, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tl.sum(tmp26, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = tmp11 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = 64.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tmp27 / tmp29
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = 1e-05
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tmp30 + tmp31
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = libdevice.rsqrt(tmp32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tmp28 * tmp33
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tmp34 * tmp35
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = tmp36 + tmp37
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = ks9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp40 = tmp39.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp41 = tmp33 / tmp40
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + ks9*x0), tmp34, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 64*x0), tmp38, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr6 + (x0), tmp41, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zt/cztuhuain5yyxvzdgz3rvfog3lg5sh3eugfw4j56zubdtuzmh5vq.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward_1 => clone_1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %clone_1 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_1,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_clone_11 = async_compile.triton('triton_poi_fused_clone_11', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 524288}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_clone_11(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % ks1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + ks0*x2 + 2*ks0*x1), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jo/cjonl66zr4ppidbwsqutplb53leycclxpzqlzr52yqvgefw4ey4x.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward_1 => view_18
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_18 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%select_3, [1, %mul_375, %floordiv]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_12 = async_compile.triton('triton_poi_fused_view_12', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_12(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (((x0 + ks0*x1) % (ks1*ks2 + ks1*((16*ks2*ks3 + 16*ks2*ks4 + 16*ks2*ks5 + 4*ks2*ks3*ks4 + 4*ks2*ks3*ks5 + 4*ks2*ks4*ks5 + ks2*ks3*ks4*ks5) // 64)))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6n/c6nr7pdunsqm5ekospfbmlkrhvc7ah5jrx3jtln3vokaszmh5t2c.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   multi_head_attention_forward_1 => view_19
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %view_19 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%select_4, [1, %mul_375, %floordiv]), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_view_13 = async_compile.triton('triton_poi_fused_view_13', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_view_13(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks1*ks2 + ks1*((16*ks2*ks3 + 16*ks2*ks4 + 16*ks2*ks5 + 4*ks2*ks3*ks4 + 4*ks2*ks3*ks5 + 4*ks2*ks4*ks5 + ks2*ks3*ks4*ks5) // 64) + (((x0 + ks0*x1) % (ks1*ks2 + ks1*((16*ks2*ks3 + 16*ks2*ks4 + 16*ks2*ks5 + 4*ks2*ks3*ks4 + 4*ks2*ks3*ks5 + 4*ks2*ks4*ks5 + ks2*ks3*ks4*ks5) // 64))))), xmask, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/t3/ct3szgrmafdxb4oyf6ugyrcabdtczil4bcea5qtb4xubyrhrg5lb.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_1, add_1, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   add_1 => add_580
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   dropout_1 => gt_31, inductor_lookup_seed_default_3, inductor_random_default_2, mul_555, mul_556
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_7 => add_584, add_585, mul_565, mul_566, rsqrt_1, sub_329, var_mean_1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 3), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %sym_size_int_27, 64], %inductor_lookup_seed_default_3, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %gt_31 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_2, 0.1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_555 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_31, %view_24), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_556 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_555, 1.1111111111111112), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_580 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_439, %mul_556), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_580, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_584 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 1e-05), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %rsqrt_1 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_584,), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_329 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_580, %getitem_15), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_565 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_329, %rsqrt_1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_566 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_565, %primals_16), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_585 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_566, %primals_17), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, %sym_size_int_17), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 64},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = 0.1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = 1.1111111111111112
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp8 * tmp9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp5 + tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.where(xmask, tmp12, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tl.where(xmask, tmp15, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tl.sum(tmp17, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp19.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tmp18 / tmp20
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = tmp12 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tmp22 * tmp22
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tl.broadcast_to(tmp23, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = tl.where(xmask, tmp24, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tl.sum(tmp26, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = tmp11 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = 64.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tmp27 / tmp29
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = 1e-05
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tmp30 + tmp31
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = libdevice.rsqrt(tmp32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tmp28 * tmp33
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tmp34 * tmp35
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = tmp36 + tmp37
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp40 = tmp39.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp41 = tmp33 / tmp40
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + ks1*x0), tmp34, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 64*x0), tmp38, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr6 + (x0), tmp41, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ml/cmlc4o5e65l4gztswhyfqfbb3me4ehneccgc2zagpllmhwdimuz6.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   dropout_2 => gt_32, inductor_lookup_seed_default_4, inductor_random_default_1, mul_589, mul_590
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   relu => relu
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_26,), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 4), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %sym_size_int_28, 2048], %inductor_lookup_seed_default_4, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %gt_32 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_1, 0.1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_589 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_32, %relu), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_590 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_589, 1.1111111111111112), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %le_9 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_15 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_15', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 8388608}, 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_15(in_ptr0, in_ptr1, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = 0.1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.full([1], 0, tl.int32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp7, tmp6)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tmp5 * tmp8
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = 1.1111111111111112
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp9 * tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = 0.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tmp8 <= tmp12
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp11, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp13, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hu/chu7ijebcxwgggqlicedvmfdhbhsbfy5viglt545tkvce4qedwoi.py
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_3, add_2, x_9], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   add_2 => add_631
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   dropout_3 => gt_33, inductor_lookup_seed_default_5, inductor_random_default, mul_605, mul_606
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   x_9 => add_635, add_636, mul_615, mul_616, rsqrt_2, sub_349, var_mean_2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_lookup_seed_default_5 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 5), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %inductor_random_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, %sym_size_int_29, 64], %inductor_lookup_seed_default_5, rand), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %gt_33 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default, 0.1), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_605 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_33, %view_28), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_606 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_605, 1.1111111111111112), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_631 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_585, %mul_606), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %var_mean_2 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_631, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_635 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_16, 1e-05), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %rsqrt_2 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_635,), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_349 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_631, %getitem_17), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_615 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_349, %rsqrt_2), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_616 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_615, %primals_22), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_636 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_616, %primals_23), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_2, %sym_size_int_17), kwargs = {})
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16', '''
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 64},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp35 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp37 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = 0.1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = 1.1111111111111112
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp8 * tmp9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp5 + tmp10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.where(xmask, tmp12, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tl.where(xmask, tmp15, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tl.sum(tmp17, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp19.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp21 = tmp18 / tmp20
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp22 = tmp12 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp23 = tmp22 * tmp22
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp24 = tl.broadcast_to(tmp23, [XBLOCK, R0_BLOCK])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp26 = tl.where(xmask, tmp24, 0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp27 = tl.sum(tmp26, 1)[:, None]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp28 = tmp11 - tmp21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp29 = 64.0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp30 = tmp27 / tmp29
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp31 = 1e-05
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp32 = tmp30 + tmp31
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp33 = libdevice.rsqrt(tmp32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp34 = tmp28 * tmp33
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp36 = tmp34 * tmp35
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp38 = tmp36 + tmp37
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp39 = ks1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp40 = tmp39.to(tl.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp41 = tmp33 / tmp40
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + ks1*x0), tmp34, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + ks1*x0), tmp38, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr6 + (x0), tmp41, xmask)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] async_compile.wait(globals())
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] del async_compile
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def call(args):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23 = args
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     args.clear()
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s0 = primals_1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s1 = primals_2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s2 = primals_3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s3 = primals_4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_5, (1, s0, s1, s2, s3), (s0*s1*s2*s3, s1*s2*s3, s2*s3, s3, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_6, (192, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_7, (192, 64), (64, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_8, (64, 64), (64, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_10, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_11, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_12, (192, 64), (64, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_13, (192, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_14, (64, 64), (64, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_16, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_17, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_18, (2048, 64), (64, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_19, (2048, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_20, (64, 2048), (2048, 1))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_21, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_22, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_23, (64, ), (1, ))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf0 = empty_strided_cuda((6, ), (1, ), torch.int64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [6], out=buf0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf1 = empty_strided_cuda((1, s0, 1, 1, 1), (s0, 1, s0, s0, s0), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.bernoulli]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_bernoulli_0.run(buf0, buf1, 0, s0, grid=grid(s0), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf2 = empty_strided_cuda((1, s0, 2 + s1, 2 + s2, 2 + s3), (8*s0 + 4*s0*s1 + 4*s0*s2 + 4*s0*s3 + 2*s0*s1*s2 + 2*s0*s1*s3 + 2*s0*s2*s3 + s0*s1*s2*s3, 8 + 4*s1 + 4*s2 + 4*s3 + 2*s1*s2 + 2*s1*s3 + 2*s2*s3 + s1*s2*s3, 4 + 2*s2 + 2*s3 + s2*s3, 2 + s3, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps0 = 2 + s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps1 = 2 + s2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps2 = 4 + 2*s2 + 2*s3 + s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps3 = 2 + s1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps4 = 8 + 4*s1 + 4*s2 + 4*s3 + 2*s1*s2 + 2*s1*s3 + 2*s2*s3 + s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf3 = empty_strided_cuda((1, s0, 2 + s1, 2 + s2, 2 + s3), (8*s0 + 4*s0*s1 + 4*s0*s2 + 4*s0*s3 + 2*s0*s1*s2 + 2*s0*s1*s3 + 2*s0*s2*s3 + s0*s1*s2*s3, 8 + 4*s1 + 4*s2 + 4*s3 + 2*s1*s2 + 2*s1*s3 + 2*s2*s3 + s1*s2*s3, 4 + 2*s2 + 2*s3 + s2*s3, 2 + s3, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.copy]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_copy_1_xnumel = 8*s0 + 4*s0*s1 + 4*s0*s2 + 4*s0*s3 + 2*s0*s1*s2 + 2*s0*s1*s3 + 2*s0*s2*s3 + s0*s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_copy_1.run(primals_5, buf1, buf2, buf3, ps0, s3, ps1, s2, ps2, ps3, s1, ps4, triton_poi_fused_copy_1_xnumel, grid=grid(triton_poi_fused_copy_1_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_5
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf4 = buf2; del buf2  # reuse
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_2_xnumel = 8*s0 + 4*s0*s1 + 4*s0*s2 + 4*s0*s3 + 2*s0*s1*s2 + 2*s0*s1*s3 + 2*s0*s2*s3 + s0*s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_2.run(buf3, buf4, ps0, ps1, s3, s2, triton_poi_fused_2_xnumel, grid=grid(triton_poi_fused_2_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps5 = 16 + 4*s2 + 4*s3 + s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps6 = 4 + s1
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps7 = 4 + s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps8 = 4 + s2
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps9 = 16 + 4*s2 + 4*s3 + s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps10 = 64 + 16*s1 + 16*s2 + 16*s3 + 4*s1*s2 + 4*s1*s3 + 4*s2*s3 + s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf5 = empty_strided_cuda((1, s0, 4 + s1, 4 + s2, 4 + s3), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3, 64 + 16*s1 + 16*s2 + 16*s3 + 4*s1*s2 + 4*s1*s3 + 4*s2*s3 + s1*s2*s3, 16 + 4*s2 + 4*s3 + s2*s3, 4 + s3, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.constant_pad_nd]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_constant_pad_nd_3_xnumel = 64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_constant_pad_nd_3.run(buf4, buf5, ps5, ps6, ps3, ps7, ps8, ps1, ps0, s1, s2, ps9, ps10, s3, triton_poi_fused_constant_pad_nd_3_xnumel, grid=grid(triton_poi_fused_constant_pad_nd_3_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf4
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf7 = buf5; del buf5  # reuse
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [result, x_3, x_4], Original ATen: [aten.threshold, aten.bernoulli, aten._to_copy, aten.add, aten.mul, aten.silu]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4_xnumel = 64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4.run(buf7, buf0, 1, triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4_xnumel, grid=grid(triton_poi_fused__to_copy_add_bernoulli_mul_silu_threshold_4_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps11 = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf8 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_5_xnumel = s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_5.run(buf7, buf8, ps11, ps5, ps6, ps7, ps8, s0, s1, s2, s3, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf9 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 192), (192, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(primals_6, buf8, reinterpret_tensor(primals_7, (64, 192), (1, 64), 0), alpha=1, beta=1, out=buf9)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_6
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps12 = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps13 = s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf10 = empty_strided_cuda((3, 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_6_xnumel = 3*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 3*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_6.run(buf9, buf10, ps11, ps12, ps13, triton_poi_fused_clone_6_xnumel, grid=grid(triton_poi_fused_clone_6_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps14 = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps15 = 8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf11 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_7_xnumel = 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_7.run(buf10, buf11, ps14, ps15, ps11, s0, s1, s2, s3, triton_poi_fused_view_7_xnumel, grid=grid(triton_poi_fused_view_7_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf12 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_8_xnumel = 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_8.run(buf10, buf12, ps14, ps15, ps11, s0, s1, s2, s3, triton_poi_fused_view_8_xnumel, grid=grid(triton_poi_fused_view_8_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf13 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_9_xnumel = 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_9.run(buf10, buf13, ps14, ps15, ps11, s0, s1, s2, s3, triton_poi_fused_view_9_xnumel, grid=grid(triton_poi_fused_view_9_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf10
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf14 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf11, buf12, buf13, None, True, 0.1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf15 = buf14[0]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf16 = buf14[1]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf17 = buf14[2]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf18 = buf14[3]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf14
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf19 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(primals_9, reinterpret_tensor(buf15, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), reinterpret_tensor(primals_8, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf19)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_9
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf21 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1), torch.bool)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf25 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf26 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf60 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf0, buf7, buf19, primals_10, primals_11, buf21, buf25, buf26, buf60, 2, ps5, ps6, ps7, ps8, s0, s1, s2, s3, ps11, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf7
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_11
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf27 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_13, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), 0), reinterpret_tensor(buf26, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64, 1), 0), reinterpret_tensor(primals_12, (64, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (1, 64), 0), alpha=1, beta=1, out=buf27)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf28 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))), (2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_13, (2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ), (1, ), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), buf8, reinterpret_tensor(primals_12, (64, 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))), (1, 64), 64*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))), alpha=1, beta=1, out=buf28)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_13
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf29 = empty_strided_cuda((2, 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 2*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 2*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_11.run(buf28, buf29, ps11, ps12, ps13, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf28
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf30 = empty_strided_cuda((1, 8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_12_xnumel = 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_12.run(buf29, buf30, ps14, ps11, s0, s1, s2, s3, triton_poi_fused_view_12_xnumel, grid=grid(triton_poi_fused_view_12_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf31 = empty_strided_cuda((1, 8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_13_xnumel = 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_view_13.run(buf29, buf31, ps14, ps11, s0, s1, s2, s3, triton_poi_fused_view_13_xnumel, grid=grid(triton_poi_fused_view_13_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf29
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf32 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf27, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), reinterpret_tensor(buf30, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), reinterpret_tensor(buf31, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), None, True, 0.1)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf33 = buf32[0]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf34 = buf32[1]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf35 = buf32[2]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf36 = buf32[3]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf32
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf37 = buf19; del buf19  # reuse
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(primals_15, reinterpret_tensor(buf33, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), reinterpret_tensor(primals_14, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf37)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_15
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf39 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1), torch.bool)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf43 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf44 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf59 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_1, add_1, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14.run(buf0, buf26, buf37, primals_16, primals_17, buf39, buf43, buf44, buf59, 3, ps11, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_14_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_17
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf45 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(primals_19, reinterpret_tensor(buf44, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64, 1), 0), reinterpret_tensor(primals_18, (64, 2048), (1, 64), 0), alpha=1, beta=1, out=buf45)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_19
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf47 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1), torch.bool)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf48 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf58 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1), torch.bool)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_15_xnumel = 2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_15.run(buf0, buf45, buf47, buf48, buf58, 4, triton_poi_fused_native_dropout_relu_threshold_backward_15_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_15_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf45
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf49 = buf37; del buf37  # reuse
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.addmm]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.addmm(primals_21, reinterpret_tensor(buf48, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1), 0), reinterpret_tensor(primals_20, (2048, 64), (1, 2048), 0), alpha=1, beta=1, out=buf49)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_21
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf51 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1), torch.bool)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf55 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf56 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf57 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1), torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_9], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16.run(buf0, buf44, buf49, primals_22, primals_23, buf51, buf55, buf56, buf57, 5, ps11, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_16_xnumel), stream=stream0)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf0
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf49
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_23
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     return (buf56, primals_10, primals_16, primals_22, buf8, buf11, buf12, buf13, buf15, buf16, buf17, buf18, buf21, buf25, reinterpret_tensor(buf26, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64, 1), 0), reinterpret_tensor(buf27, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), buf30, buf31, buf33, buf34, buf35, buf36, buf39, buf43, reinterpret_tensor(buf44, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64, 1), 0), buf47, reinterpret_tensor(buf48, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1), 0), buf51, buf55, buf57, primals_20, buf58, primals_18, buf59, primals_14, reinterpret_tensor(primals_12, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 64), (64, 1), 0), buf60, primals_8, s0, s1, s2, s3, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), )
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_1 = 3
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_2 = 32
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_3 = 32
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_4 = 32
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_5 = rand_strided((1, 3, 32, 32, 32), (98304, 32768, 1024, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_6 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_7 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_8 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_10 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_11 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_12 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_13 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_14 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_16 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_17 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_18 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_19 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_20 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_22 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_23 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23])
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] if __name__ == "__main__":
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:35:49.717000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:49.752000 703210 site-packages/torch/_inductor/graph.py:2022] [390/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/37/c37tkgfqqoc4sxsv5l2j5ap4a2fpovggosry7qhd3wep7pawgd4x.py
I0127 11:35:50.763000 703210 site-packages/torch/_inductor/graph.py:2056] [390/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/37/c37tkgfqqoc4sxsv5l2j5ap4a2fpovggosry7qhd3wep7pawgd4x.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] Output code: 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # AOT ID: ['91_backward']
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import torch
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import random
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import os
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import tempfile
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from math import inf, nan
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from cmath import nanj
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch import device, empty_strided
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     grid,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     split_scan_grid,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     grid_combo_kernels,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     start_graph,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     end_graph,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     cooperative_reduction_grid,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] aten = torch.ops.aten
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] _quantized = torch.ops._quantized
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] async_compile = AsyncCompile()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sl/csldmm55ylfleluawyticsp45kvao5zpzyflcmowmj2mbjqpr2fn.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_630 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, %mul_615), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_630, [0, 1]), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%tangents_1, [0, 1]), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_native_layer_norm_backward_0 = async_compile.triton('triton_red_fused_native_layer_norm_backward_0', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 64, 'r0_': 4096},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_native_layer_norm_backward_0(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, ks2, ks3, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp7 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + r0_1*(triton_helpers.div_floor_integer(64*ks0 + 16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3,  ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + r0_1*(triton_helpers.div_floor_integer(64*ks0 + 16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3,  ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 * tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp8 = _tmp7 + tmp6
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp7 = tl.where(r0_mask & xmask, tmp8, _tmp7)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.sum(_tmp7, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp7, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sv/csvihfrctta7w3vspn44ppnm3jxhsc6vlglnntp2bxjwvzsolg6m.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_625 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, %primals_22), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_625, [2], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_627 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_625, %mul_615), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_627, [2], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_native_layer_norm_backward_1 = async_compile.triton('triton_red_fused_native_layer_norm_backward_1', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 64},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_native_layer_norm_backward_1(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, ks2, ks3, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + x0*(triton_helpers.div_floor_integer(64*ks0 + 16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3,  ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (r0_1 + x0*(triton_helpers.div_floor_integer(64*ks0 + 16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3,  ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 * tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp7 = tmp2 * tmp6
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp8 = tl.broadcast_to(tmp7, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp9, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/p6/cp6l65whsckb2dr2hcb5ok7ykvwchhu3zehtfnwjbsphaefye2fa.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_625 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, %primals_22), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_626 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_625, %sym_size_int_17), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_628 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_615, %sum_2), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_355 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_626, %sum_1), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_356 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_355, %mul_628), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_629 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %sub_356), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %convert_element_type_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_33, torch.float32), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_631 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 1.1111111111111112), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_632 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_629, %mul_631), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2 = async_compile.triton('triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*i1', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.load(in_ptr5 + (x0 + 64*x1), xmask, eviction_policy='evict_last').to(tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp3 * tmp5
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp6 - tmp7
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tmp9 * tmp10
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tmp8 - tmp11
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tmp0 * tmp12
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp14.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = 1.1111111111111112
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp15 * tmp16
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = tmp13 * tmp17
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp13, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp18, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bx/cbxbwftfuert3xiysnawt5w4mpihuatm7my6nkb6aam77gqe2cbg.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_29, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_sum_3 = async_compile.triton('triton_red_fused_sum_3', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 2048, 'r0_': 128},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_sum_3(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 1152
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // 64
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_2 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = r0_2 + x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + ks4*r0_2 + ks4*x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nm/cnm3ixr35jqy2hlxg5egiekzeylmrssszy6olm64jaz4iwhcu53p.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_29, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_sum_4 = async_compile.triton('triton_per_fused_sum_4', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 64, 'r0_': 32},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_sum_4(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 64
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mv/cmvrlze2lfwgm3xe3v776h7knzmi6yy2rbwe3xn3v3jsxqcprmj3.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [result], Original ATen: [aten.native_dropout_backward, aten.threshold, aten.threshold_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   result => full_default
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_32, torch.float32), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_633 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, 1.1111111111111112), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_634 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_31, %mul_633), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %full_default : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %where_1 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_9, %full_default, %mul_634), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5 = async_compile.triton('triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 8388608}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask).to(tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), xmask).to(tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = 1.1111111111111112
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tmp1 * tmp5
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = 0.0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/aw/cawmhp74zitnh6t46myqszmdgv4r7ixxsani7ju2tfnp65hji5qj.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_32, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_sum_6 = async_compile.triton('triton_red_fused_sum_6', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 65536, 'r0_': 128},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_sum_6(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 36864
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // 2048
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % 2048)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_2 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = r0_2 + x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 2048*r0_2 + 2048*x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))), r0_mask & tmp2, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp5 = tl.where(r0_mask, tmp6, _tmp5)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, None)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mn/cmnozewjvy2mv7dcyyg4f3e6kf4n6l5bhiwgbpui46imux365v3l.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_32, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_sum_7 = async_compile.triton('triton_per_fused_sum_7', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 2048, 'r0_': 32},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_sum_7(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 2048
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), r0_mask & xmask, other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4r/c4rt6brlfi7dfbn667s3oeh2omdb6o6yrswixxu3knjd45rzdndg.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_646 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_629, %view_34), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_641 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_646, %mul_565), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_641, [0, 1]), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_646, [0, 1]), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_8 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_8', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 64, 'r0_': 4096},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_8(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + ks0*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + ks0*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + ks0*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 + tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tmp2 * tmp3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp9, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fx/cfx4npgl52jq7ximt3f4talqnl6fospum5fcugvpeifxl4yewijp.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_646 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_629, %view_34), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_636 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_646, %primals_16), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_636, [2], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_638 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_636, %mul_565), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_638, [2], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_9 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_9', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 64},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_9', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_9(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + ks0*x0), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r0_1 + ks0*x0), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r0_1 + ks0*x0), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 + tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tmp2 * tmp3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp9 = tmp4 * tmp8
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp11, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vm/cvmgo5ouyhnqrn5h67hoyoprkau4y4zg56z2f3pr5phigmlujgmy.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_646 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_629, %view_34), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_636 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_646, %primals_16), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_637 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_636, %sym_size_int_17), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_639 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_565, %sum_8), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_358 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_637, %sum_7), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_359 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_358, %mul_639), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_640 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_2, %sub_359), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %convert_element_type_4 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_31, torch.float32), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_642 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_4, 1.1111111111111112), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_643 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_640, %mul_642), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10 = async_compile.triton('triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*i1', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tl.load(in_ptr6 + (x0 + 64*x1), xmask, eviction_policy='evict_last').to(tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tmp1 + tmp2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tmp6.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp5 * tmp7
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp8 - tmp9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tmp10 - tmp13
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp0 * tmp14
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = 1.1111111111111112
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tmp17 * tmp18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp15 * tmp19
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp15, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp20, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6v/c6v2diwcsfxsansqmsr44sn5au2pp7iuvtnxvy7zwbd7wzacvqim.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %clone_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_2,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_clone_11 = async_compile.triton('triton_poi_fused_clone_11', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 524288}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_clone_11(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // ks0) % 2)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // ks1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0 + ks0*x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (x0 + ks0*x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = x1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = 0.0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp10, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3v/c3v3novdzipr74lanmss65wzu7vt6ujenzzme7zfudqxgszylcca.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_47, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_sum_12 = async_compile.triton('triton_red_fused_sum_12', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 2048, 'r0_': 128},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_12', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_sum_12(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_2 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = r0_2 + x1*(triton_helpers.div_floor_integer(17 + ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64),  18))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + ks0*r0_2 + ks0*x1*(triton_helpers.div_floor_integer(17 + ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64),  18))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tv/ctvsgyhgjy7ssqf2pug2eck2wxtyoienjtsv5iq6uchtyqdtkpmk.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_47, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_48, %view_46],), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_cat_sum_13 = async_compile.triton('triton_per_fused_cat_sum_13', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 64, 'r0_': 32},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_cat_sum_13(in_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + ks0*r0_1), r0_mask & xmask, other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/go/cgoipbfldq353lo4vljeqb6wxougjuqswquvwqkd7uhiw4weljwn.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_45, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_sum_14 = async_compile.triton('triton_red_fused_sum_14', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 128},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'ks4': 'i32', 'ks5': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_sum_14(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, ks4, ks5, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_2 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = r0_2 + x1*(triton_helpers.div_floor_integer(17 + ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64),  18))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 2*ks5*r0_2 + 2*ks5*x1*(triton_helpers.div_floor_integer(17 + ks1 + ((16*ks1*ks2 + 16*ks1*ks3 + 16*ks1*ks4 + 4*ks1*ks2*ks3 + 4*ks1*ks2*ks4 + 4*ks1*ks3*ks4 + ks1*ks2*ks3*ks4) // 64),  18))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b6/cb6ih5tspee4wf6ioywubaolgiebhfrgtoertbmcbt3o7dhj4alk.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_45, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_48, %view_46],), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_cat_sum_15 = async_compile.triton('triton_per_fused_cat_sum_15', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_cat_sum_15(in_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2*ks0*r0_1), r0_mask & xmask, other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oj/coja5q33ljtkzr5sxikekobtyfdukwn5vtiiita6ckbk5au5nrxi.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %add_648 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_640, %view_49), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_645 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_648, %primals_10), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_646 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_645, %sym_size_int_17), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_648 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_433, %sum_15), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_361 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_646, %sum_14), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sub_362 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_361, %mul_648), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_649 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_3, %sub_362), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %convert_element_type_5 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_26, torch.float32), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_651 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_5, 1.1111111111111112), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %mul_652 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_649, %mul_651), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16 = async_compile.triton('triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 262144}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*i1', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp16 = tl.load(in_ptr6 + (x0 + 64*x1), xmask, eviction_policy='evict_last').to(tl.int1)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tmp1 + tmp2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = ks0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tmp6.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tmp5 * tmp7
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp8 - tmp9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tmp10 - tmp13
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp0 * tmp14
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp18 = 1.1111111111111112
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp19 = tmp17 * tmp18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp20 = tmp15 * tmp19
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp20, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ck/cckrnqixzisx7dqo4pworbayivu5aixg6jtc2z64o3avfzf72di2.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %clone_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_3,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_poi_fused_clone_17 = async_compile.triton('triton_poi_fused_clone_17', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 524288}, 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     min_elem_per_thread=0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_poi_fused_clone_17(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = ((xindex // 64) % 3)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x2 = xindex // 192
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = x1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = 0.0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp12 = tmp0 == tmp11
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp15, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/a5/ca5627kark5mk5i6qmq2w6ipg2bbzxlno4bjckxg6w3geeeeavge.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_19 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_60, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_red_fused_sum_18 = async_compile.triton('triton_red_fused_sum_18', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 4096, 'r0_': 128},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_red_fused_sum_18(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 3456
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rbase = r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x1 = xindex // 192
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = (xindex % 192)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x3 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         r0_2 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp0 = r0_2 + x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp1 = ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 192*r0_2 + 192*x1*(triton_helpers.div_floor_integer(17 + ks0 + ((16*ks0*ks1 + 16*ks0*ks2 + 16*ks0*ks3 + 4*ks0*ks1*ks2 + 4*ks0*ks1*ks3 + 4*ks0*ks2*ks3 + ks0*ks1*ks2*ks3) // 64),  18))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qh/cqhfyn5grxpktzkiqsylet4iuy5o7rtts7wjv74zjhlkkog7b34z.py
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Source node to ATen node mapping:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] # Graph fragment:
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] #   %sum_19 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_60, [0], True), kwargs = {})
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_per_fused_sum_19 = async_compile.triton('triton_per_fused_sum_19', '''
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] import triton.language as tl
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     size_hints={'x': 256, 'r0_': 32},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     filename=__file__,
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] @triton.jit
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def triton_per_fused_sum_19(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xnumel = 192
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_numel = 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rnumel = r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     xmask = xindex < xnumel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_offset = 0
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     roffset = r0_offset
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     rindex = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     r0_1 = r0_index
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     x0 = xindex
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 192*r0_1), r0_mask & xmask, other=0.0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] ''', device_str='cuda')
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] async_compile.wait(globals())
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] del async_compile
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def call(args):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, sym_size_int_16, sym_size_int_17, floordiv, sym_size_int_18, mul_375, mul_443, sym_size_int_21, sym_size_int_22, sym_size_int_28, primals_10, primals_16, primals_22, view_1, view_7, view_8, view_9, getitem, getitem_1, getitem_2, getitem_3, gt_26, mul_433, view_12, view_13, view_18, view_19, getitem_10, getitem_11, getitem_12, getitem_13, gt_31, mul_565, view_25, gt_32, view_27, gt_33, mul_615, div_1, permute_18, le_9, permute_22, div_2, permute_26, permute_38, div_3, permute_42, tangents_1 = args
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     args.clear()
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s0 = primals_1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s1 = primals_2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s2 = primals_3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     s3 = primals_4
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_10, (64, ), (1, ))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_16, (64, ), (1, ))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(primals_22, (64, ), (1, ))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_1, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_7, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, 8), (64, 8, 64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_8, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, 8), (64, 8, 64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_9, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, 8), (64, 8, 64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, 8), (64, 8, 64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_1, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 32), (256, 32, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_2, (), ())
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_3, (), ())
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(gt_26, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(mul_433, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_12, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_13, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_18, (1, 8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_19, (1, 8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_10, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_11, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 32), (256, 32, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_12, (), ())
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(getitem_13, (), ())
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(gt_31, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(mul_565, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_25, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(gt_32, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(view_27, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(gt_33, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(mul_615, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(div_1, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(permute_18, (64, 2048), (2048, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(le_9, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(permute_22, (2048, 64), (64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(div_2, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(permute_26, (64, 64), (64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(permute_38, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 64), (64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(div_3, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(permute_42, (64, 64), (64, 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     assert_size_stride(tangents_1, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf3 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf4 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_0_xnumel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_0_r0_numel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_0.run(tangents_1, mul_615, buf3, buf4, s0, s1, s2, s3, triton_red_fused_native_layer_norm_backward_0_xnumel, triton_red_fused_native_layer_norm_backward_0_r0_numel, grid=grid(triton_red_fused_native_layer_norm_backward_0_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf0 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf1 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_1_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_1_r0_numel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_native_layer_norm_backward_1.run(tangents_1, primals_22, mul_615, buf0, buf1, s0, s1, s2, s3, triton_red_fused_native_layer_norm_backward_1_xnumel, triton_red_fused_native_layer_norm_backward_1_r0_numel, grid=grid(triton_red_fused_native_layer_norm_backward_1_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps0 = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf2 = reinterpret_tensor(mul_615, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0); del mul_615  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf5 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2_xnumel = s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2.run(buf2, div_1, tangents_1, primals_22, buf0, buf1, gt_33, buf5, ps0, triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_native_layer_norm_backward_2_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del div_1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del gt_33
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_22
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del tangents_1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf7 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf5, (64, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 0), view_27, out=buf7)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_27
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf8 = empty_strided_cuda((1, 64, 18), (1152, 1, 64), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3.run(buf5, buf8, s0, s1, s2, s3, ps0, 1152, triton_red_fused_sum_3_r0_numel, grid=grid(1152), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf9 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_sum_4.run(buf8, buf9, 64, 18, grid=grid(64), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf6 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf5, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), permute_18, out=buf6)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del permute_18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf10 = reinterpret_tensor(buf6, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048, 1), 0); del buf6  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [result], Original ATen: [aten.native_dropout_backward, aten.threshold, aten.threshold_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5_xnumel = 2048*s0 + 2048*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5.run(buf10, le_9, gt_32, triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_threshold_backward_5_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del gt_32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del le_9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf12 = empty_strided_cuda((2048, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf10, (2048, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, 2048), 0), view_25, out=buf12)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_25
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf11 = empty_strided_cuda((s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), (64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf10, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2048), (2048, 1), 0), permute_22, out=buf11)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del permute_22
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf13 = empty_strided_cuda((1, 2048, 18), (36864, 1, 2048), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_6.run(buf10, buf13, s0, s1, s2, s3, 36864, triton_red_fused_sum_6_r0_numel, grid=grid(36864), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf10
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf14 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_sum_7.run(buf13, buf14, 2048, 18, grid=grid(2048), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf13
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf18 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf19 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_xnumel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf2, buf11, mul_565, buf18, buf19, ps0, triton_red_fused_add_native_layer_norm_backward_8_xnumel, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(triton_red_fused_add_native_layer_norm_backward_8_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf15 = reinterpret_tensor(buf1, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 0); del buf1  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf16 = reinterpret_tensor(buf0, (1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 0); del buf0  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9_r0_numel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9.run(buf2, buf11, primals_16, mul_565, buf15, buf16, ps0, triton_red_fused_add_native_layer_norm_backward_9_xnumel, triton_red_fused_add_native_layer_norm_backward_9_r0_numel, grid=grid(triton_red_fused_add_native_layer_norm_backward_9_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf17 = buf2; del buf2  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf20 = buf5; del buf5  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10_xnumel = s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10.run(buf17, div_2, buf11, primals_16, buf15, mul_565, buf16, gt_31, buf20, ps0, triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10_xnumel, grid=grid(triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_10_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del div_2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del gt_31
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del mul_565
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_16
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf23 = buf8; del buf8  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3.run(buf20, buf23, s0, s1, s2, s3, ps0, 1152, triton_red_fused_sum_3_r0_numel, grid=grid(1152), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf24 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_sum_4.run(buf23, buf24, 64, 18, grid=grid(64), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf22 = empty_strided_cuda((64, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf20, (64, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 0), reinterpret_tensor(getitem_10, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), out=buf22)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf21 = buf11; del buf11  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf20, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), permute_26, out=buf21)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf20
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del permute_26
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf25 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf21, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 8*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), reinterpret_tensor(view_13, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), reinterpret_tensor(view_18, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), reinterpret_tensor(view_19, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (8*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (8*s0 + 8*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1), 0), None, getitem_10, getitem_11, getitem_12, getitem_13, 0.1, [True, True, True, False])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_10
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_11
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_12
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_13
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_13
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_19
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf26 = buf25[0]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf40 = empty_strided_cuda((3*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf34 = reinterpret_tensor(buf40, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0)  # alias
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf26, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 0), view_12, out=buf34)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_12
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf27 = buf25[1]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf28 = buf25[2]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf25
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         ps1 = 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf29 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 2, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (2*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 2*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 2*s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + 2*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_11.run(buf28, buf27, buf29, ps0, ps1, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf27
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf28
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf35 = empty_strided_cuda((1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 18), (18*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_12_xnumel = 18*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_12_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_12.run(buf26, buf35, ps0, s0, s1, s2, s3, triton_red_fused_sum_12_xnumel, triton_red_fused_sum_12_r0_numel, grid=grid(triton_red_fused_sum_12_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf33 = buf21; del buf21  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf26, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), permute_38, out=buf33)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf26
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del permute_38
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf39 = empty_strided_cuda((3*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf37 = reinterpret_tensor(buf39, ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), 0)  # alias
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_cat_sum_13_xnumel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_cat_sum_13.run(buf35, buf37, ps0, triton_per_fused_cat_sum_13_xnumel, 18, grid=grid(triton_per_fused_cat_sum_13_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf35
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf43 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf44 = empty_strided_cuda(((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), ), (1, ), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_xnumel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf17, buf33, mul_433, buf43, buf44, ps0, triton_red_fused_add_native_layer_norm_backward_8_xnumel, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(triton_red_fused_add_native_layer_norm_backward_8_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf31 = empty_strided_cuda((1, 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 18), (36*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 1, 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_14_xnumel = 36*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_14_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_14.run(buf29, buf31, ps1, s0, s1, s2, s3, ps0, triton_red_fused_sum_14_xnumel, triton_red_fused_sum_14_r0_numel, grid=grid(triton_red_fused_sum_14_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf30 = reinterpret_tensor(buf40, (2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))))  # alias
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf29, (2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))), 0), view_1, out=buf30)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf29
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf38 = reinterpret_tensor(buf39, (2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ), (1, ), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))  # alias
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_cat_sum_15_xnumel = 2*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_cat_sum_15.run(buf31, buf38, ps0, triton_per_fused_cat_sum_15_xnumel, 18, grid=grid(triton_per_fused_cat_sum_15_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf31
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf41 = buf16; del buf16  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf42 = buf15; del buf15  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9_xnumel = s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9_r0_numel = (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_9.run(buf17, buf33, primals_10, mul_433, buf41, buf42, ps0, triton_red_fused_add_native_layer_norm_backward_9_xnumel, triton_red_fused_add_native_layer_norm_backward_9_r0_numel, grid=grid(triton_red_fused_add_native_layer_norm_backward_9_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf45 = buf17; del buf17  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16_xnumel = s0*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))) + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)*((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)))
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16.run(buf45, div_3, buf33, primals_10, buf41, mul_433, buf42, gt_26, ps0, triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16_xnumel, grid=grid(triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_16_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf41
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf42
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del div_3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del gt_26
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del mul_433
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del primals_10
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf48 = buf23; del buf23  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_3.run(buf45, buf48, s0, s1, s2, s3, ps0, 1152, triton_red_fused_sum_3_r0_numel, grid=grid(1152), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf49 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_sum_4.run(buf48, buf49, 64, 18, grid=grid(64), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf48
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf47 = empty_strided_cuda((64, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), (64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf45, (64, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), 0), reinterpret_tensor(getitem, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), out=buf47)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf46 = buf33; del buf33  # reuse
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf45, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 64), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), 0), permute_42, out=buf46)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf45
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del permute_42
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf50 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf46, (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 8, 1, 8), (64, 8, 64*s0 + 64*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 1), 0), view_7, view_8, view_9, None, getitem, getitem_1, getitem_2, getitem_3, 0.1, [True, True, True, False])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf46
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_2
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del getitem_3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_7
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_8
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_9
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf51 = buf50[0]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf52 = buf50[1]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf53 = buf50[2]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf50
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf54 = empty_strided_cuda((1, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 3, 64), (192*s0 + 192*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64), 192, 64, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_17_xnumel = 192*s0 + 192*((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_poi_fused_clone_17.run(buf53, buf52, buf51, buf54, triton_poi_fused_clone_17_xnumel, grid=grid(triton_poi_fused_clone_17_xnumel), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf51
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf52
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf53
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf55 = empty_strided_cuda((192, (64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64))), ((64*s0 + 16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // (s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf54, (192, s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)), (1, 192), 0), view_1, out=buf55)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del view_1
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf56 = empty_strided_cuda((1, 192, 18), (3456, 1, 192), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (17 + s0 + ((16*s0*s1 + 16*s0*s2 + 16*s0*s3 + 4*s0*s1*s2 + 4*s0*s1*s3 + 4*s0*s2*s3 + s0*s1*s2*s3) // 64)) // 18
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_red_fused_sum_18.run(buf54, buf56, s0, s1, s2, s3, 3456, triton_red_fused_sum_18_r0_numel, grid=grid(3456), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf54
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         buf57 = empty_strided_cuda((1, 192), (192, 1), torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         triton_per_fused_sum_19.run(buf56, buf57, 192, 18, grid=grid(192), stream=stream0)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]         del buf56
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     return (None, None, None, None, None, reinterpret_tensor(buf57, (192, ), (1, ), 0), buf55, buf47, reinterpret_tensor(buf49, (64, ), (1, ), 0), buf43, buf44, buf40, buf39, buf22, reinterpret_tensor(buf24, (64, ), (1, ), 0), buf18, buf19, buf12, reinterpret_tensor(buf14, (2048, ), (1, ), 0), buf7, reinterpret_tensor(buf9, (64, ), (1, ), 0), buf3, buf4, )
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_1 = 3
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_2 = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_3 = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_4 = 32
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_16 = 2187
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_17 = 64
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     floordiv = 8
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_18 = 2187
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     mul_375 = 17496
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     mul_443 = 128
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_21 = 2187
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_22 = 64
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     sym_size_int_28 = 2187
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_10 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_16 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     primals_22 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_1 = rand_strided((2187, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_7 = rand_strided((2187, 8, 1, 8), (64, 8, 139968, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_8 = rand_strided((2187, 8, 1, 8), (64, 8, 139968, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_9 = rand_strided((2187, 8, 1, 8), (64, 8, 139968, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem = rand_strided((2187, 8, 1, 8), (64, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_1 = rand_strided((2187, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_2 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_3 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     gt_26 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     mul_433 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_12 = rand_strided((2187, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_13 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_18 = rand_strided((1, 17496, 8), (139968, 8, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_19 = rand_strided((1, 17496, 8), (139968, 8, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_10 = rand_strided((2187, 8, 1, 8), (64, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_11 = rand_strided((2187, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_12 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     getitem_13 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     gt_31 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     mul_565 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_25 = rand_strided((2187, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     gt_32 = rand_strided((1, 2187, 2048), (4478976, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     view_27 = rand_strided((2187, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     gt_33 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     mul_615 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     div_1 = rand_strided((1, 2187, 1), (2187, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     permute_18 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     le_9 = rand_strided((1, 2187, 2048), (4478976, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     permute_22 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     div_2 = rand_strided((1, 2187, 1), (2187, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     permute_26 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     permute_38 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     div_3 = rand_strided((1, 2187, 1), (2187, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     permute_42 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     tangents_1 = rand_strided((1, 2187, 64), (139968, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, sym_size_int_16, sym_size_int_17, floordiv, sym_size_int_18, mul_375, mul_443, sym_size_int_21, sym_size_int_22, sym_size_int_28, primals_10, primals_16, primals_22, view_1, view_7, view_8, view_9, getitem, getitem_1, getitem_2, getitem_3, gt_26, mul_433, view_12, view_13, view_18, view_19, getitem_10, getitem_11, getitem_12, getitem_13, gt_31, mul_565, view_25, gt_32, view_27, gt_33, mul_615, div_1, permute_18, le_9, permute_22, div_2, permute_26, permute_38, div_3, permute_42, tangents_1])
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] if __name__ == "__main__":
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:35:56.399000 703210 site-packages/torch/_inductor/graph.py:2014] [390/0] [__output_code] 
V0127 11:35:56.438000 703210 site-packages/torch/_inductor/graph.py:2022] [390/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/wx/cwxko77usiuqxwm7ekueoq4szubfb56h6h6gpkuus3twxmfj6dto.py
I0127 11:35:56.731000 703210 site-packages/torch/_inductor/graph.py:2056] [390/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/wx/cwxko77usiuqxwm7ekueoq4szubfb56h6h6gpkuus3twxmfj6dto.py
