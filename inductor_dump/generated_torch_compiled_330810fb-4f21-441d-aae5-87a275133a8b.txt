V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] Output code: 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # AOT ID: ['24_forward']
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import torch
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import random
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import os
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import tempfile
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from math import inf, nan
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from cmath import nanj
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch import device, empty_strided
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     grid,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     split_scan_grid,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     grid_combo_kernels,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     start_graph,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     end_graph,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     cooperative_reduction_grid,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] aten = torch.ops.aten
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] _quantized = torch.ops._quantized
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] async_compile = AsyncCompile()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3y/c3ya45jwlpah3x6v3corvgcb45bo75k3yprw4jwriuvj3nf7n7eu.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.arange, aten.add, aten.mul, aten._to_copy]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_4 => add_35, add_36, convert_element_type, convert_element_type_1, iota, mul_29, mul_30
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %iota : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (2,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%iota, 1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_35 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_29, 0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_35, torch.float32), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_36 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type, 0.0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_36, 0.5), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type_1 : [num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mul_30, torch.int64), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused__to_copy_add_arange_mul_0 = async_compile.triton('triton_poi_fused__to_copy_add_arange_mul_0', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 2}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_mul_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused__to_copy_add_arange_mul_0(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = 0.5
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp3.to(tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nd/cndlscduca6jnilsmzdwv7x5ewk5t6ty42oxod6kledgk2orf3kl.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [normalize], Original ATen: [aten.linalg_vector_norm, aten.clamp_min]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   normalize => clamp_min, pow_1, pow_2, sum_1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%view, 2.0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%pow_1, [-1], True), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %pow_2 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sum_1, 0.5), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clamp_min : [num_users=2] = call_function[target=torch.ops.aten.clamp_min.default](args = (%pow_2, 1e-12), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_clamp_min_linalg_vector_norm_1 = async_compile.triton('triton_per_fused_clamp_min_linalg_vector_norm_1', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 16, 'r0_': 128},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_clamp_min_linalg_vector_norm_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_clamp_min_linalg_vector_norm_1(in_out_ptr0, in_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl_math.abs(tmp0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = 1.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp1 + tmp2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp0 / tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp4 * tmp4
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = libdevice.sqrt(tmp9)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = 1e-12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp10, tmp11)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.debug_barrier()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp12, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gg/cgg765gkffkzmu6yjgpocptemgm7qlkcgyyk4z5tbsxrcuoymopn.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward => clone
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_2 = async_compile.triton('triton_poi_fused_clone_2', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_2(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // ks0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = (xindex % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % ks1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = x2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = 0.5
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp3.to(tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl_math.abs(tmp5)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = 1.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp5 / tmp8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tmp9 / tmp10
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = 11.313708498984761
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tmp13 * tmp14
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp15, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/og/cog2zcuv7ybxmkixnvth4vss24uytahwtvjvs3jet4y5yw3ibtij.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [memory], Original ATen: [aten.zeros_like]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   memory => full
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([2, %primals_1, 128], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_zeros_like_3 = async_compile.triton('triton_poi_fused_zeros_like_3', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_zeros_like_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_zeros_like_3(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = 0.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6u/c6uzz62ukfyyqf35ohbhkwvx5xbhxftmuvdtmnq2cfzic74bhude.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward_1 => clone_4
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_4 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_1,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_4 = async_compile.triton('triton_poi_fused_clone_4', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 8192}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_4(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x2 + 256*x1), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (128 + x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vp/cvp3c52a3grjghcl3czr57mqmeu2gman36tj7datp3gmufh65hfg.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward_1 => view_21
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %view_21 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_13, [%primals_1, 8, 2, 16]), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_view_5 = async_compile.triton('triton_poi_fused_view_5', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_view_5(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 16)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 16) % 8)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 16*x1 + 128*((((x0 + 16*x1 + 128*x2) // 128) % ks0)) + 128*ks0*((((x0 + 16*x1 + 128*x2 + 128*ks0*x3) // ks1) % 2))), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b3/cb3iahex42yeuhti76yqzwdvq7dipkmljczesrknkcyftxfi6yv7.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward_1 => view_22
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %view_22 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_14, [%primals_1, 8, 2, 16]), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_view_6 = async_compile.triton('triton_poi_fused_view_6', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_view_6(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 16)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 16) % 8)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 16*x1 + 128*((((x0 + 16*x1 + 128*x2) // 128) % ks0)) + 128*ks0*((((x0 + 16*x1 + 128*x2 + 128*ks0*x3) // ks1) % 2))), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yp/cyprjrnn7hhlex4gxx4q7iybdfljp34pjtgic35f5txsxkl7i5z3.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward => clone_1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_1 : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_7 = async_compile.triton('triton_poi_fused_clone_7', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 8192}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_7(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x2 + 384*x1), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xf/cxfwhtb6yiuuaqhoigo7fgse4v4cg23wqxc6h7ir4tq7vqefbyaq.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward => view_9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %view_9 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_6, [%primals_1, 8, 2, 16]), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_view_8 = async_compile.triton('triton_poi_fused_view_8', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_view_8(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 16)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 16) % 8)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 16*x1 + 128*((((x0 + 16*x1 + 128*x2) // 128) % ks0)) + 512*ks0 + 128*ks0*((((x0 + 16*x1 + 128*x2 + 128*ks0*x3) // ks1) % 2))), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fq/cfq4giujbra3i7qrehq35xvjdphvfuxzelnphaniqnkz5tyms4zu.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   multi_head_attention_forward => clone_2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_9 = async_compile.triton('triton_poi_fused_clone_9', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_9(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % ks0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x2 + 256*x1), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mr/cmrciuvo2r4sbfsgtvzhzw7hwpgvc25rxe657sw537njlxrsrrei.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   add => add_183
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout => gt, inductor_lookup_seed_default, inductor_random_default_11, mul_133, mul_134
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_6 => add_187, add_188, clone_3, mul_140, mul_141, rsqrt, sub_47, var_mean
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default_11 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 128], %inductor_lookup_seed_default, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_11, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_133 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt, %view_11), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_133, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_183 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute_1, %mul_134), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_3 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_183,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_3, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_187 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %rsqrt : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_187,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_47 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_3, %getitem_5), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_140 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_47, %rsqrt), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_141 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_140, %primals_8), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_188 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_141, %primals_9), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_15 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt, 128), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr1, out_ptr2, out_ptr3, out_ptr4, out_ptr5, load_seed_offset, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // ks1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = (xindex % ks1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tl.load(in_ptr1 + (r0_1 + 128*x2), xmask, eviction_policy='evict_last', other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tl.load(in_out_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp52 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp54 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = r0_1 + 128*x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = x3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp5.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = 0.5
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl_math.abs(tmp10)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = 1.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp11 + tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tmp10 / tmp13
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tmp14 / tmp15
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp18 = tmp16 * tmp17
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = 11.313708498984761
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tmp18 * tmp19
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = tmp22 + tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp21 * tmp24
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp27 = tmp25 * tmp26
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp28 = tmp20 + tmp27
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp31 = tl.where(xmask, tmp29, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp32 = tl.broadcast_to(tmp29, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp34 = tl.where(xmask, tmp32, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp35 = tl.sum(tmp34, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp36 = tl.full([XBLOCK, 1], 128, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp37 = tmp36.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp38 = tmp35 / tmp37
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp39 = tmp29 - tmp38
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp40 = tmp39 * tmp39
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp43 = tl.where(xmask, tmp41, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp44 = tl.sum(tmp43, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp45 = tmp28 - tmp38
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp46 = 128.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp47 = tmp44 / tmp46
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp48 = 1e-05
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp49 = tmp47 + tmp48
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp50 = libdevice.rsqrt(tmp49)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp51 = tmp45 * tmp50
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp53 = tmp51 * tmp52
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp55 = tmp53 + tmp54
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp56 = 0.0078125
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp57 = tmp50 * tmp56
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 128*x0), tmp4, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 128*x0), tmp28, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 128*x0), tmp55, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp57, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp38, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp44, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3w/c3wuli2tbxtmbqpllcqvfrrv76cnptopvf4mivosyuxyplhk72xw.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [x_6], Original ATen: [aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_6 => add_187, clone_3, rsqrt, var_mean
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_3 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_183,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_3, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_187 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %rsqrt : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_187,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_315 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_183, %getitem_5), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_821 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_315, %rsqrt), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_native_layer_norm_native_layer_norm_backward_11 = async_compile.triton('triton_poi_fused_native_layer_norm_native_layer_norm_backward_11', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'y': 2, 'x': 2048}, tile_hint=TileHint.DEFAULT,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_native_layer_norm_backward_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_native_layer_norm_native_layer_norm_backward_11(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     ynumel = 2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     ymask = yindex < ynumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     y0 = yindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3 + 128*ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 - tmp1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = 128.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp3 / tmp4
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = 1e-05
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tmp5 + tmp6
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = libdevice.rsqrt(tmp7)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp2 * tmp8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (y0 + 2*x3), tmp9, xmask & ymask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cs/ccsz6iexwy6ogc6tfqqbewuk6ajg5tqt6hqkps45c4z5mzbpu7op.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_1, add_1, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   add_1 => add_333
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout_1 => gt_1, inductor_lookup_seed_default_1, inductor_random_default_10, mul_227, mul_228
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_7 => add_338, add_339, mul_234, mul_235, rsqrt_1, sub_84, var_mean_1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default_10 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 128], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt_1 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_10, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_227 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_1, %view_24), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_228 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_227, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_333 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_188, %mul_228), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_333, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_338 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 1e-05), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %rsqrt_1 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_338,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_84 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_333, %getitem_15), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_234 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_84, %rsqrt_1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_235 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_234, %primals_14), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_339 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_235, %primals_15), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_14 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, 128), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': (9,)}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = r0_1 + 128*x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 128, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp31 = 128.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp33 = 1e-05
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp38 = tmp36 * tmp37
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp40 = tmp38 + tmp39
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp41 = 0.0078125
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp42 = tmp35 * tmp41
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 128*x0), tmp4, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 128*x0), tmp36, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 128*x0), tmp40, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yf/cyfumezvlpgvipfyuoqtewidkuzisp4jaxcrwdjykcxp2padjpox.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   relu => relu
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_26,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %le_2 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_relu_threshold_backward_13 = async_compile.triton('triton_poi_fused_relu_threshold_backward_13', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 65536}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_threshold_backward_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_relu_threshold_backward_13(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 2048)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = 0.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ji/cjinl3mszcpvhhjipkl2h34ohdsi7f7sexgamtfvqshbn6dlkksb.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout_2 => gt_2, inductor_lookup_seed_default_2, inductor_random_default_9, mul_255, mul_256
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   relu => relu
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_26,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default_9 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 2048], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt_2 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_9, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_255 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_2, %relu), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_256 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_255, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_native_dropout_relu_14 = async_compile.triton('triton_poi_fused_native_dropout_relu_14', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 65536}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_native_dropout_relu_14(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = (xindex % 2048)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tmp5 * tmp10
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mi/cmi5sj4siet5lq7g24xz3aflclpg356h2k4uzkerlu5jlz4643jq.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_3, add_2, x_9], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   add_2 => add_396
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout_3 => gt_3, inductor_lookup_seed_default_3, inductor_random_default_8, mul_271, mul_272
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_9 => add_401, add_402, mul_278, mul_279, rsqrt_2, sub_101, var_mean_2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 3), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default_8 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 128], %inductor_lookup_seed_default_3, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt_3 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_8, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_271 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_3, %view_28), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_272 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_271, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_396 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_339, %mul_272), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %var_mean_2 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_396, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_401 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_16, 1e-05), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %rsqrt_2 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_401,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_101 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_396, %getitem_17), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_278 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_101, %rsqrt_2), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_279 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_278, %primals_20), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_402 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_279, %primals_21), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_13 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_2, 128), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = r0_1 + 128*x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 128, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp31 = 128.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp33 = 1e-05
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp38 = tmp36 * tmp37
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp40 = tmp38 + tmp39
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp41 = 0.0078125
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp42 = tmp35 * tmp41
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 128*x0), tmp4, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 128*x0), tmp36, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 128*x0), tmp40, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kh/ckh5avsddxtcrcdxtflshvmct37u76kc3fowy7edrnyasjv64ylh.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [relu_1, dropout_6], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout_6 => gt_6, inductor_lookup_seed_default_6, inductor_random_default_5, mul_475, mul_476
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   relu_1 => relu_1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_54,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default_6 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 6), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default_5 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 2048], %inductor_lookup_seed_default_6, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt_6 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_5, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_475 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_6, %relu_1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_476 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_475, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %le_1 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_1, 0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_16 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_16', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 65536}, 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_16(in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = (xindex % 2048)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tmp5 * tmp10
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = 0.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tmp10 <= tmp14
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp15, None)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ec/cecjvwtdnvkq6w2zsg62l4x6k3sfot673fav5yeghmqgvbgjo65e.py
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_11, add_8, x_17, normalize_1, mul_2, x_18], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.linalg_vector_norm, aten.div, aten.mul, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   add_8 => add_1114
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   dropout_11 => gt_11, inductor_lookup_seed_default_11, inductor_random_default, mul_711, mul_712
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   mul_2 => mul_730
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   normalize_1 => div_2, pow_3, pow_4, sum_2
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_17 => add_1119, add_1120, mul_718, mul_719, rsqrt_8, sub_279, var_mean_8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_18 => mul_733
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_lookup_seed_default_11 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 11), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %inductor_random_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([2, %primals_1, 128], %inductor_lookup_seed_default_11, rand), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %gt_11 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default, 0.1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_711 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_11, %view_84), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_712 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_711, 1.1111111111111112), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1114 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1057, %mul_712), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %var_mean_8 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1114, [2]), kwargs = {correction: 0, keepdim: True})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1119 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_52, 1e-05), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %rsqrt_8 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1119,), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_279 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1114, %getitem_53), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_718 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_279, %rsqrt_8), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_719 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_718, %primals_56), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1120 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_719, %primals_57), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %pow_3 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%add_1120, 2.0), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%pow_3, [-1], True), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %pow_4 : [num_users=2] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sum_2, 0.5), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_1120, %expand_1), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_730 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_2, %primals_58), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_733 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_730, 11.313708498984761), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_7 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_8, 128), kwargs = {})
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17 = async_compile.triton('triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17', '''
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 5, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp52 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = r0_1 + 128*x0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = 0.1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 128, tl.int32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp31 = 128.0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp33 = 1e-05
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp38 = tmp36 * tmp37
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp40 = tmp38 + tmp39
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp41 = tmp40 * tmp40
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp42 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp44 = tl.where(xmask, tmp42, 0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp45 = tl.sum(tmp44, 1)[:, None]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp46 = libdevice.sqrt(tmp45)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp47 = 0.0078125
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp48 = tmp35 * tmp47
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp49 = 1e-12
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp50 = triton_helpers.maximum(tmp46, tmp49)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp51 = tmp40 / tmp50
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp53 = tmp51 * tmp52
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp54 = 11.313708498984761
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp55 = tmp53 * tmp54
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 128*x0), tmp4, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 128*x0), tmp36, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.debug_barrier()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp46, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 128*x0), tmp55, xmask)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] async_compile.wait(globals())
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] del async_compile
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def call(args):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58 = args
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     args.clear()
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     s0 = primals_1
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_2, (s0, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_3, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_4, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_5, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_6, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_7, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_8, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_9, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_10, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_11, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_12, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_13, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_14, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_15, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_16, (2048, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_17, (2048, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_18, (128, 2048), (2048, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_19, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_20, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_21, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_22, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_23, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_24, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_25, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_26, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_27, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_28, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_29, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_30, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_31, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_32, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_33, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_34, (2048, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_35, (2048, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_36, (128, 2048), (2048, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_37, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_38, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_39, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_40, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_41, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_42, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_43, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_44, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_45, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_46, (384, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_47, (384, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_48, (128, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_49, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_50, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_51, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_52, (2048, 128), (128, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_53, (2048, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_54, (128, 2048), (2048, 1))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_55, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_56, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_57, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_58, (128, ), (1, ))
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf2 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.arange, aten.add, aten.mul, aten._to_copy]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused__to_copy_add_arange_mul_0.run(buf2, 2, grid=grid(2), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf0 = empty_strided_cuda((1, s0, 1), (s0, 1, s0), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf1 = reinterpret_tensor(buf0, (1, s0, 1), (s0, 1, 1), 0); del buf0  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [normalize], Original ATen: [aten.linalg_vector_norm, aten.clamp_min]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_clamp_min_linalg_vector_norm_1.run(buf1, primals_2, s0, 128, grid=grid(s0), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf16 = empty_strided_cuda((12, ), (1, ), torch.int64)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [12], out=buf16)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         ps0 = 128*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf3 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_2_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_2.run(primals_2, buf1, primals_3, buf3, ps0, s0, triton_poi_fused_clone_2_xnumel, grid=grid(triton_poi_fused_clone_2_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf25 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [memory], Original ATen: [aten.zeros_like]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_zeros_like_3_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_zeros_like_3.run(buf25, triton_poi_fused_zeros_like_3_xnumel, grid=grid(triton_poi_fused_zeros_like_3_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf26 = empty_strided_cuda((2*s0, 256), (256, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf25, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_10, (128, 256), (1, 128), 16384), out=buf26)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         ps1 = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         ps2 = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf27 = empty_strided_cuda((2, 2, s0, 128), (256*s0, 128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4_xnumel = 512*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4.run(buf26, primals_11, buf27, ps1, ps2, triton_poi_fused_clone_4_xnumel, grid=grid(triton_poi_fused_clone_4_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf28 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf27, buf28, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf29 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf27, buf29, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf76 = reinterpret_tensor(buf27, (2*s0, 256), (256, 1), 0); del buf27  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf25, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_28, (128, 256), (1, 128), 16384), out=buf76)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf77 = reinterpret_tensor(buf26, (2, 2, s0, 128), (256*s0, 128*s0, 128, 1), 0); del buf26  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4_xnumel = 512*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4.run(buf76, primals_29, buf77, ps1, ps2, triton_poi_fused_clone_4_xnumel, grid=grid(triton_poi_fused_clone_4_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf78 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf77, buf78, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf79 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf77, buf79, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf126 = reinterpret_tensor(buf77, (2*s0, 256), (256, 1), 0); del buf77  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf25, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_46, (128, 256), (1, 128), 16384), out=buf126)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf127 = reinterpret_tensor(buf76, (2, 2, s0, 128), (256*s0, 128*s0, 128, 1), 0); del buf76  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4_xnumel = 512*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_4.run(buf126, primals_47, buf127, ps1, ps2, triton_poi_fused_clone_4_xnumel, grid=grid(triton_poi_fused_clone_4_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf126
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf128 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf127, buf128, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf129 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf127, buf129, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf127
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf4 = empty_strided_cuda((2*s0, 384), (384, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf3, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_5, (128, 384), (1, 128), 0), out=buf4)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf5 = empty_strided_cuda((3, 2, s0, 128), (256*s0, 128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 768*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf4, primals_4, buf5, ps1, ps2, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_4
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf6 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf5, buf6, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf7 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf5, buf7, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf8 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8.run(buf5, buf8, s0, ps0, triton_poi_fused_view_8_xnumel, grid=grid(triton_poi_fused_view_8_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf9 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf6, buf7, buf8, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf10 = buf9[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf11 = buf9[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf12 = buf9[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf13 = buf9[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf14 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf10, buf14, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf15 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf14, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_6, (128, 128), (1, 128), 0), out=buf15)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf18 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf19 = reinterpret_tensor(buf15, (2, s0, 128), (128*s0, 128, 1), 0); del buf15  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf20 = empty_strided_cuda((2, s0, 1), (s0, 1, 2*s0), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf21 = empty_strided_cuda((2, s0, 1), (s0, 1, 2*s0), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf23 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf170 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf19, buf16, primals_2, buf1, primals_3, primals_7, primals_8, primals_9, buf18, buf20, buf21, buf23, buf170, 0, s0, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_3
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_7
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_9
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf169 = empty_strided_cuda((2, s0, 128), (1, 256, 2), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_6], Original ATen: [aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_layer_norm_native_layer_norm_backward_11_xnumel = 128*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_layer_norm_native_layer_norm_backward_11.run(buf19, buf20, buf21, buf169, s0, 2, triton_poi_fused_native_layer_norm_native_layer_norm_backward_11_xnumel, grid=grid(2, triton_poi_fused_native_layer_norm_native_layer_norm_backward_11_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf24 = reinterpret_tensor(buf19, (2*s0, 128), (128, 1), 0); del buf19  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_11, (128, ), (1, ), 0), reinterpret_tensor(buf23, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_10, (128, 128), (1, 128), 0), alpha=1, beta=1, out=buf24)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_11
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf30 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf24, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf28, buf29, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf31 = buf30[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf32 = buf30[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf33 = buf30[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf34 = buf30[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf30
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf35 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf31, buf35, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf36 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_12, (128, 128), (1, 128), 0), out=buf36)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf38 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf42 = reinterpret_tensor(buf36, (2, s0, 128), (128*s0, 128, 1), 0); del buf36  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf43 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf168 = reinterpret_tensor(buf21, (2, s0, 1), (s0, 1, 1), 0); del buf21  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_1, add_1, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12.run(buf42, buf16, buf23, primals_13, primals_14, primals_15, buf38, buf43, buf168, 1, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_13
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_15
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf44 = empty_strided_cuda((2*s0, 2048), (2048, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf43, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_16, (128, 2048), (1, 128), 0), out=buf44)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf167 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_relu_threshold_backward_13_xnumel = 4096*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_relu_threshold_backward_13.run(buf44, primals_17, buf167, triton_poi_fused_relu_threshold_backward_13_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_13_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf46 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf47 = reinterpret_tensor(buf44, (2, s0, 2048), (2048*s0, 2048, 1), 0); del buf44  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_14_xnumel = 4096*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_14.run(buf47, buf16, primals_17, buf46, 2, triton_poi_fused_native_dropout_relu_14_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_14_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_17
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf48 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf47, (2*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_18, (2048, 128), (1, 2048), 0), out=buf48)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf50 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf54 = reinterpret_tensor(buf48, (2, s0, 128), (128*s0, 128, 1), 0); del buf48  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf55 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf166 = reinterpret_tensor(buf20, (2, s0, 1), (s0, 1, 1), 0); del buf20  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_9], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf54, buf16, buf43, primals_19, primals_20, primals_21, buf50, buf55, buf166, 3, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_19
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_21
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf56 = reinterpret_tensor(buf5, (2*s0, 384), (384, 1), 0); del buf5  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf55, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_23, (128, 384), (1, 128), 0), out=buf56)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf57 = reinterpret_tensor(buf4, (3, 2, s0, 128), (256*s0, 128*s0, 128, 1), 0); del buf4  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 768*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf56, primals_22, buf57, ps1, ps2, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_22
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf58 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf57, buf58, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf59 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf57, buf59, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf60 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8.run(buf57, buf60, s0, ps0, triton_poi_fused_view_8_xnumel, grid=grid(triton_poi_fused_view_8_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf61 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf58, buf59, buf60, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf62 = buf61[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf63 = buf61[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf64 = buf61[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf65 = buf61[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf61
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf66 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf62, buf66, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf67 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf66, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_24, (128, 128), (1, 128), 0), out=buf67)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf69 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf73 = reinterpret_tensor(buf67, (2, s0, 128), (128*s0, 128, 1), 0); del buf67  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf74 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf165 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_4, add_3, x_10], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf73, buf16, buf55, primals_25, primals_26, primals_27, buf69, buf74, buf165, 4, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_25
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_27
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf75 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_29, (128, ), (1, ), 0), reinterpret_tensor(buf74, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_28, (128, 128), (1, 128), 0), alpha=1, beta=1, out=buf75)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_29
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf80 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf75, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf78, buf79, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf81 = buf80[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf82 = buf80[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf83 = buf80[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf84 = buf80[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf80
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf85 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf81, buf85, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf86 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf85, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_30, (128, 128), (1, 128), 0), out=buf86)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf88 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf92 = reinterpret_tensor(buf86, (2, s0, 128), (128*s0, 128, 1), 0); del buf86  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf93 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf164 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_5, add_4, x_11], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf92, buf16, buf74, primals_31, primals_32, primals_33, buf88, buf93, buf164, 5, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_31
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_33
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf94 = empty_strided_cuda((2*s0, 2048), (2048, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf93, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_34, (128, 2048), (1, 128), 0), out=buf94)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf96 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf97 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf163 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1, dropout_6], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel = 4096*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_16.run(buf16, buf94, primals_35, buf96, buf97, buf163, 6, triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_35
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf98 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf97, (2*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_36, (2048, 128), (1, 2048), 0), out=buf98)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf100 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf104 = reinterpret_tensor(buf98, (2, s0, 128), (128*s0, 128, 1), 0); del buf98  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf105 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf162 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_7, add_5, x_13], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf104, buf16, buf93, primals_37, primals_38, primals_39, buf100, buf105, buf162, 7, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_37
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_39
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf106 = reinterpret_tensor(buf57, (2*s0, 384), (384, 1), 0); del buf57  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf105, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_41, (128, 384), (1, 128), 0), out=buf106)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf107 = reinterpret_tensor(buf56, (3, 2, s0, 128), (256*s0, 128*s0, 128, 1), 0); del buf56  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 768*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf106, primals_40, buf107, ps1, ps2, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf106
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_40
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf108 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_5.run(buf107, buf108, s0, ps0, triton_poi_fused_view_5_xnumel, grid=grid(triton_poi_fused_view_5_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf109 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_6.run(buf107, buf109, s0, ps0, ps2, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf110 = empty_strided_cuda((s0, 8, 2, 16), (128, 16, 128*s0, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_8.run(buf107, buf110, s0, ps0, triton_poi_fused_view_8_xnumel, grid=grid(triton_poi_fused_view_8_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf107
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf111 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf108, buf109, buf110, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf112 = buf111[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf113 = buf111[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf114 = buf111[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf115 = buf111[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf111
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf116 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf112, buf116, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf117 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_42, (128, 128), (1, 128), 0), out=buf117)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf119 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf123 = reinterpret_tensor(buf117, (2, s0, 128), (128*s0, 128, 1), 0); del buf117  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf124 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf161 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_8, add_6, x_14], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf123, buf16, buf105, primals_43, primals_44, primals_45, buf119, buf124, buf161, 8, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_43
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_45
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf125 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_47, (128, ), (1, ), 0), reinterpret_tensor(buf124, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_46, (128, 128), (1, 128), 0), alpha=1, beta=1, out=buf125)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_47
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf130 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf125, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf128, buf129, None, True, 0.1)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf131 = buf130[0]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf132 = buf130[1]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf133 = buf130[2]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf134 = buf130[3]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf130
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf135 = empty_strided_cuda((2, s0, 8, 16), (128*s0, 128, 16, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9_xnumel = 256*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_9.run(buf131, buf135, s0, ps0, triton_poi_fused_clone_9_xnumel, grid=grid(triton_poi_fused_clone_9_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf136 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf135, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_48, (128, 128), (1, 128), 0), out=buf136)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf138 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf142 = reinterpret_tensor(buf136, (2, s0, 128), (128*s0, 128, 1), 0); del buf136  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf143 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf160 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_9, add_7, x_15], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15.run(buf142, buf16, buf124, primals_49, primals_50, primals_51, buf138, buf143, buf160, 9, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_15_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_49
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_51
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf144 = buf94; del buf94  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_4], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf143, (2*s0, 128), (128, 1), 0), reinterpret_tensor(primals_52, (128, 2048), (1, 128), 0), out=buf144)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf146 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf147 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf159 = empty_strided_cuda((2, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2, dropout_10], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel = 4096*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_16.run(buf16, buf144, primals_53, buf146, buf147, buf159, 10, triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_16_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf144
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_53
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf148 = empty_strided_cuda((2*s0, 128), (128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_16], Original ATen: [aten.addmm]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf147, (2*s0, 2048), (2048, 1), 0), reinterpret_tensor(primals_54, (2048, 128), (1, 2048), 0), out=buf148)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf150 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.bool)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf154 = reinterpret_tensor(buf148, (2, s0, 128), (128*s0, 128, 1), 0); del buf148  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf155 = empty_strided_cuda((2, s0, 1), (s0, 1, 2*s0), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf156 = reinterpret_tensor(buf155, (2, s0, 1), (s0, 1, 1), 0); del buf155  # reuse
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf158 = empty_strided_cuda((2, s0, 1), (s0, 1, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf157 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_11, add_8, x_17, normalize_1, mul_2, x_18], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.linalg_vector_norm, aten.div, aten.mul, aten.native_layer_norm_backward]
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17_xnumel = 2*s0
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17.run(buf154, buf156, buf16, buf143, primals_55, primals_56, primals_57, primals_58, buf150, buf158, buf157, 11, triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17_xnumel, 128, grid=grid(triton_per_fused_add_div_linalg_vector_norm_mul_native_dropout_native_layer_norm_native_layer_norm_backward_17_xnumel), stream=stream0)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf16
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_55
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     return (reinterpret_tensor(buf157, (s0, 2, 128), (128, 128*s0, 1), 0), primals_2, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_44, primals_50, primals_56, primals_57, primals_58, buf1, buf2, reinterpret_tensor(buf3, (2*s0, 128), (128, 1), 0), buf6, buf7, buf8, buf10, buf11, buf12, buf13, reinterpret_tensor(buf14, (2*s0, 128), (128, 1), 0), buf18, reinterpret_tensor(buf23, (2*s0, 128), (128, 1), 0), reinterpret_tensor(buf25, (2*s0, 128), (128, 1), 0), reinterpret_tensor(buf24, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf28, buf29, buf31, buf32, buf33, buf34, reinterpret_tensor(buf35, (2*s0, 128), (128, 1), 0), buf38, buf42, reinterpret_tensor(buf43, (2*s0, 128), (128, 1), 0), buf46, reinterpret_tensor(buf47, (2*s0, 2048), (2048, 1), 0), buf50, buf54, reinterpret_tensor(buf55, (2*s0, 128), (128, 1), 0), buf58, buf59, buf60, buf62, buf63, buf64, buf65, reinterpret_tensor(buf66, (2*s0, 128), (128, 1), 0), buf69, buf73, reinterpret_tensor(buf74, (2*s0, 128), (128, 1), 0), reinterpret_tensor(buf75, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf78, buf79, buf81, buf82, buf83, buf84, reinterpret_tensor(buf85, (2*s0, 128), (128, 1), 0), buf88, buf92, reinterpret_tensor(buf93, (2*s0, 128), (128, 1), 0), buf96, reinterpret_tensor(buf97, (2*s0, 2048), (2048, 1), 0), buf100, buf104, reinterpret_tensor(buf105, (2*s0, 128), (128, 1), 0), buf108, buf109, buf110, buf112, buf113, buf114, buf115, reinterpret_tensor(buf116, (2*s0, 128), (128, 1), 0), buf119, buf123, reinterpret_tensor(buf124, (2*s0, 128), (128, 1), 0), reinterpret_tensor(buf125, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), buf128, buf129, buf131, buf132, buf133, buf134, reinterpret_tensor(buf135, (2*s0, 128), (128, 1), 0), buf138, buf142, reinterpret_tensor(buf143, (2*s0, 128), (128, 1), 0), buf146, reinterpret_tensor(buf147, (2*s0, 2048), (2048, 1), 0), buf150, buf154, buf156, buf158, primals_54, buf159, primals_52, buf160, primals_48, reinterpret_tensor(primals_46, (128, 128), (128, 1), 0), buf161, primals_42, primals_41, buf162, primals_36, buf163, primals_34, buf164, primals_30, reinterpret_tensor(primals_28, (128, 128), (128, 1), 0), buf165, primals_24, primals_23, buf166, primals_18, buf167, primals_16, buf168, primals_12, reinterpret_tensor(primals_10, (128, 128), (128, 1), 0), buf169, buf170, primals_6, primals_5, s0, 2*s0, 8*s0, )
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_1 = 10
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_2 = rand_strided((10, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_3 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_4 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_5 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_6 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_7 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_8 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_9 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_10 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_11 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_12 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_13 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_14 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_15 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_16 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_17 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_18 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_19 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_20 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_21 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_22 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_23 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_24 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_25 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_26 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_27 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_28 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_29 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_30 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_31 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_32 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_33 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_34 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_35 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_36 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_37 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_38 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_39 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_40 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_41 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_42 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_43 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_44 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_45 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_46 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_47 = rand_strided((384, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_48 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_49 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_50 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_51 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_52 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_53 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_54 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_55 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_56 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_57 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_58 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58])
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] if __name__ == "__main__":
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:30:59.547000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:30:59.586000 703210 site-packages/torch/_inductor/graph.py:2022] [109/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/cx/ccxfvc2bweuyz724kvhg46oqznd3ghgpldhxyxuqg67scik4apfj.py
I0127 11:31:00.526000 703210 site-packages/torch/_inductor/graph.py:2056] [109/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/cx/ccxfvc2bweuyz724kvhg46oqznd3ghgpldhxyxuqg67scik4apfj.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] Output code: 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # AOT ID: ['24_backward']
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import torch
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import random
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import os
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import tempfile
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from math import inf, nan
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from cmath import nanj
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch import device, empty_strided
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     grid,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     split_scan_grid,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     grid_combo_kernels,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     start_graph,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     end_graph,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     cooperative_reduction_grid,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] aten = torch.ops.aten
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] _quantized = torch.ops._quantized
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] async_compile = AsyncCompile()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/v4/cv4xjdieu5qxebkmdgs552lzrfwfpocqgcpbfop5grwmw6dcflnm.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [x_17, normalize_1], Original ATen: [aten.mul, aten.native_layer_norm, aten.div, aten.neg, aten.sum, aten.scalar_tensor, aten.ge, aten.where, aten.eq, aten.masked_fill, aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   normalize_1 => div_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_17 => add_1120, mul_719
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_738 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_54, 11.313708498984761), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_719 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_718, %primals_56), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1120 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_719, %primals_57), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_2 : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_1120, %expand_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_740 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_738, %primals_58), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_4 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%div_2, %expand_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %neg : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_740,), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_741 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%neg, %div_4), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_5 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%mul_740, %expand_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_741, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %full_default : [num_users=5] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %ge_39 : [num_users=1] = call_function[target=torch.ops.aten.ge.Scalar](args = (%pow_4, 1e-12), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%ge_39, %sum_4, %full_default), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_6 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_1120, %pow_4), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %eq_348 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%pow_4, 0), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %where_1 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%eq_348, %full_default, %div_6), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_742 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where, %where_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1165 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%div_5, %mul_742), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_744 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1165, %primals_56), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_745 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_744, 128), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_744, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_746 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_744, %mul_718), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_746, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_747 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_718, %sum_6), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_292 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_745, %sum_5), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_293 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_292, %mul_747), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_748 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_7, %sub_293), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_11, torch.float32), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_750 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 1.1111111111111112), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_751 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_748, %mul_750), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0 = async_compile.triton('triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*i1', 'out_ptr1': '*fp32', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr1, out_ptr4, out_ptr5, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_2 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = xindex // ks0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_2 + 128*x1 + 256*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_2), None, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.load(in_ptr2 + (r0_2 + 128*x3), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_ptr3 + (r0_2), None, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.load(in_ptr4 + (r0_2), None, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl.load(in_ptr5 + (x3), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp40 = tl.load(in_ptr6 + (x3), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp47 = tl.load(in_ptr7 + (r0_2 + 128*x3), xmask, other=0.0).to(tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = 11.313708498984761
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 * tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = -tmp4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp8 + tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = 1e-12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = triton_helpers.maximum(tmp11, tmp12)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tmp10 / tmp13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tmp14 / tmp13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tmp5 * tmp15
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tmp4 / tmp13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tmp11 >= tmp12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = tl.where(tmp22, tmp20, tmp23)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp11 == tmp23
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = tmp10 / tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp27 = tl.where(tmp25, tmp23, tmp26)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp28 = tmp24 * tmp27
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp29 = tmp21 + tmp28
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp30 = tmp29 * tmp7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp31 = tl.broadcast_to(tmp30, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp33 = tl.where(xmask, tmp31, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp34 = tl.sum(tmp33, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp35 = tmp30 * tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp36 = tl.broadcast_to(tmp35, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp38 = tl.where(xmask, tmp36, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp39 = tl.sum(tmp38, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp41 = 128.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp42 = tmp30 * tmp41
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp43 = tmp42 - tmp34
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp44 = tmp6 * tmp39
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp45 = tmp43 - tmp44
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp46 = tmp40 * tmp45
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp48 = tmp47.to(tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp49 = 1.1111111111111112
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp50 = tmp48 * tmp49
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp51 = tmp46 * tmp50
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (r0_2 + 128*x3), tmp29, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr4 + (r0_2 + 128*x3), tmp46, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr5 + (r0_2 + 128*x3), tmp51, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fd/cfd3rvpdhyeptuzeyd64cp3etuw6omirh6emaz2olglpqa76e22s.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [x_17, normalize_1], Original ATen: [aten.mul, aten.native_layer_norm, aten.div, aten.sum, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   normalize_1 => div_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   x_17 => add_1120, mul_719
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_738 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_54, 11.313708498984761), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_719 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_718, %primals_56), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1120 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_719, %primals_57), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_2 : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_1120, %expand_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_739 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_738, %div_2), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_739, [0, 1], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_749 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1165, %mul_718), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_749, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_1165, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1 = async_compile.triton('triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 10), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 3, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp14 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp19 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = (r0_index % ks0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_2 = r0_index // ks0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_3 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_2 + 256*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = tl.load(in_ptr1 + (x0 + 128*r0_3), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp8 = tl.load(in_ptr4 + (r0_3), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp16 = tl.load(in_ptr5 + (x0 + 128*r0_3), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = 11.313708498984761
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp2 = tmp0 * tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp5 = tmp3 * tmp4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp7 = tmp5 + tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp9 = 1e-12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp10 = triton_helpers.maximum(tmp8, tmp9)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp11 = tmp7 / tmp10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp12 = tmp2 * tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp13 = tl.broadcast_to(tmp12, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp15 = _tmp14 + tmp13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp14 = tl.where(r0_mask & xmask, tmp15, _tmp14)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp17 = tmp16 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp18 = tl.broadcast_to(tmp17, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp20 = _tmp19 + tmp18
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp19 = tl.where(r0_mask & xmask, tmp20, _tmp19)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp21 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.sum(_tmp14, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tl.sum(_tmp19, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp19, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp22, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ia/cia4blj5qrhul44op6jcs34i5eqmza435fbe4j2ukb6jcp54uvp3.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_86, [0], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_sum_2 = async_compile.triton('triton_red_fused_sum_2', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_sum_2(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lm/clmziurt63svxags4uygxiu3xmhirtrgmjbtpyqonljdrdyae7il.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %full_default : [num_users=5] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_10, torch.float32), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_752 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, 1.1111111111111112), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_753 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_88, %mul_752), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %where_2 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default, %mul_753), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3 = async_compile.triton('triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 65536}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), None).to(tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), None)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), None).to(tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = 1.1111111111111112
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tmp1 * tmp5
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, None)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6k/c6kl4pqk6ysywo7lp7ndygjfl2to5oayhydzuluitc3qc5tircgw.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_89, [0], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_sum_4 = async_compile.triton('triton_red_fused_sum_4', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 2048, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_sum_4(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 2048
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ol/colsutt2of5qwncv3wogdunlku2jeknekxjfoaeei6mhvwpu4vwh.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1166 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_748, %view_91), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_755 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1166, %primals_50), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_756 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_755, 128), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_755, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_757 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_755, %mul_674), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_757, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_758 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_674, %sum_12), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_295 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_756, %sum_11), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_296 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_295, %mul_758), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_759 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_8, %sub_296), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type_4 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_9, torch.float32), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_761 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_4, 1.1111111111111112), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_762 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_759, %mul_761), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr2, out_ptr3, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (r0_1 + 128*x0), xmask, other=0.0).to(tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp4 * tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = 128.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tmp4 * tmp16
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp18 = tmp17 - tmp8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tmp9 * tmp14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp20 = tmp18 - tmp19
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp21 = tmp15 * tmp20
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp24 = 1.1111111111111112
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp25 = tmp23 * tmp24
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp26 = tmp21 * tmp25
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 128*x0), tmp21, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 128*x0), tmp26, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wv/cwvempddodijfxvw52uzjmilsj6ndyoffxqgznqtifovxzi6uz7s.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1166 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_748, %view_91), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_760 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1166, %mul_674), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_760, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_1166, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_6 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_6', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_6(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp2 = tmp0 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp4 = tmp2 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp9, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hc/chcoh6cbhjektjbzopagwgyw3fq55i5ga5tqvnv4tog6p3xypjxk.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_6,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_7 = async_compile.triton('triton_poi_fused_clone_7', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 8192}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_7(in_ptr0, in_ptr1, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % 2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = ((xindex // 256) % 2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // 512
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = (xindex % 256)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16*((((((x0 + 128*x3) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*x3 + 128*ks0*x2) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*x3) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (16*((((((x0 + 128*x3) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*x3 + 128*ks0*x2) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*x3) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = x1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4 + 256*x3 + 256*ks0*x2), tmp10, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sf/csf5rvw65yuhipb7mbglbr5ibjdha2purwia3itqbe3rlum7eyis.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_102, [0], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_105, %view_103],), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_cat_sum_8 = async_compile.triton('triton_red_fused_cat_sum_8', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 256, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_cat_sum_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_cat_sum_8(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 256
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 256*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp2, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oj/coj4henyfngyuqkujeradhdwt52cjldsq4mzudwgbjke5boyoqac.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %view_104 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view_100, [%mul_39, 128]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_view_9 = async_compile.triton('triton_poi_fused_view_9', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_9', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_view_9(in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = xindex // 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (16*((((((x0 + 128*((x1 % ks0))) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*((x1 % ks0)) + 128*ks0*(x1 // ks0)) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*((x1 % ks0))) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uo/cuo4fuyz3htwh6yqfaynpij5fm2277deqk3o3ncl6uwo4jtakn26.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_104, [0], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_105, %view_103],), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_cat_sum_10 = async_compile.triton('triton_red_fused_cat_sum_10', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_cat_sum_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_cat_sum_10(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp2, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/er/cerwcvpelg6ji3saclbcluwom6xu4ccm5ddpssewf6voq5vnx5xt.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %clone_31 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_7,), kwargs = {memory_format: torch.contiguous_format})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_clone_11 = async_compile.triton('triton_poi_fused_clone_11', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 8192}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_clone_11(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = ((xindex // 128) % 3)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % 128)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = ((xindex // 384) % 2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // 768
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x4 = (xindex % 384)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16*((((((x0 + 128*x3) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*x3 + 128*ks0*x2) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*x3) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (16*((((((x0 + 128*x3) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*x3 + 128*ks0*x2) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*x3) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (16*((((((x0 + 128*x3) // 16) % (8*ks0))) % 8)) + 128*((((x0 + 128*x3 + 128*ks0*x2) // (128*ks0)) % 2)) + 256*(((((((x0 + 128*x3) // 16) % (8*ks0))) // 8) % ks0)) + ((x0 % 16))), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = x1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tmp0 == tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x4 + 384*x3 + 384*ks0*x2), tmp15, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kg/ckgefpktmti4zebieo5rrpkm5qqmsf247dxnjaxs5olmiffdfohz.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_117, [0], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_sum_12 = async_compile.triton('triton_red_fused_sum_12', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 512, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_12', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_sum_12(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 384
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 384*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c4/cc4z7inxsfcqyomqz2eywnubuztfqazgq5bbgch43cjdcogosxjj.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1180 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_817, %view_174), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_822 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1180, %primals_8), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_56 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_822, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_824 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_822, %mul_821), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_57 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_824, [2], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_per_fused_add_native_layer_norm_backward_13 = async_compile.triton('triton_per_fused_add_native_layer_norm_backward_13', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_layer_norm_backward_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_per_fused_add_native_layer_norm_backward_13(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_numel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_offset = 0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = (xindex % ks0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex // ks0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1 + 128*x0), xmask, other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (x3 + 2*r0_1 + 256*x2), xmask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tmp4 * tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp14, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kn/cknny2nm7l6gdilzrc6ymkuoas3rnenmli2ky4uhy64ysh3cfeyr.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1180 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_817, %view_174), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_822 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1180, %primals_8), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_823 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_822, 128), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_825 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_821, %sum_57), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_316 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_823, %sum_56), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sub_317 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_316, %mul_825), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_826 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_15, %sub_317), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %convert_element_type_13 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt, torch.float32), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_828 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_13, 1.1111111111111112), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_829 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_826, %mul_828), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14 = async_compile.triton('triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'y': 2, 'x': 2048}, tile_hint=TileHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*i1', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, ks0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     ynumel = 2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     ymask = yindex < ynumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex // 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     y0 = yindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x3 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = (xindex % 128)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x3 + 128*ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tl.load(in_ptr2 + (x3 + 128*ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tl.load(in_ptr4 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp10 = tl.load(in_ptr5 + (y0 + 2*x3), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp11 = tl.load(in_ptr6 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp15 = tl.load(in_ptr7 + (x3 + 128*ks0*y0), xmask & ymask, eviction_policy='evict_last').to(tl.int1)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp1 + tmp2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = 128.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tmp5 * tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tmp7 - tmp8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp13 = tmp9 - tmp12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp14 = tmp0 * tmp13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp16 = tmp15.to(tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = 1.1111111111111112
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp18 = tmp16 * tmp17
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp19 = tmp14 * tmp18
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x3 + 128*ks0*y0), tmp14, xmask & ymask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x3 + 128*ks0*y0), tmp19, xmask & ymask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hc/chcqth2pjuh7djlfbmi4yxbnantzwmjlvs3uak5lqkts2hu7ulzg.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %add_1180 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_817, %view_174), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_827 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1180, %mul_821), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_58 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_827, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_59 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_1180, [0, 1]), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_15 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_15', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_15(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp6 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_3 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = (r0_index % ks0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_2 = r0_index // ks0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_3), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0 + 128*r0_3), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = tl.load(in_ptr2 + (r0_2 + 2*x0 + 256*r0_1), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp2 = tmp0 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp4 = tmp2 * tmp3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp7 = _tmp6 + tmp5
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp6 = tl.where(r0_mask & xmask, tmp7, _tmp6)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp8 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.sum(_tmp6, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp9, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tp/ctpbxamiema6yi327woyaz362krqug2hqug7dp7fop7pdkdamse7.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_61 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_184, [0, 1], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_sum_16 = async_compile.triton('triton_red_fused_sum_16', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 512, 'r0_': 32},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_sum_16(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 384
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp17 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = (r0_index % 2)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_2 = r0_index // 2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (16*((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) % 8)) + 128*((((128*r0_2 + 128*ks0*r0_1 + ((x0 % 128))) // (128*ks0)) % 2)) + 256*(((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) // 8) % ks0)) + ((((x0 % 128)) % 16))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp8 = tl.load(in_ptr1 + (16*((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) % 8)) + 128*((((128*r0_2 + 128*ks0*r0_1 + ((x0 % 128))) // (128*ks0)) % 2)) + 256*(((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) // 8) % ks0)) + ((((x0 % 128)) % 16))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp13 = tl.load(in_ptr2 + (16*((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) % 8)) + 128*((((128*r0_2 + 128*ks0*r0_1 + ((x0 % 128))) // (128*ks0)) % 2)) + 256*(((((((128*r0_2 + ((x0 % 128))) // 16) % (8*ks0))) // 8) % ks0)) + ((((x0 % 128)) % 16))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = x0 // 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = tl.full([1, 1], 2, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp2 = tmp0 == tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp4 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp6 = tl.full([1, 1], 1, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp7 = tmp0 == tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp10 = tmp5 + tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp11 = tl.full([1, 1], 0, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp12 = tmp0 == tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp14 = tl.where(tmp12, tmp13, tmp4)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp15 = tmp10 + tmp14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp18 = _tmp17 + tmp16
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp17 = tl.where(r0_mask & xmask, tmp18, _tmp17)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp17 = tl.sum(_tmp17, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp17, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hd/chd5ftgwq5ae7vxs2k26wg5vj4clkvdymaw66izzokxhipuyawc5.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %full_default_20 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 128, 1], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused_new_zeros_17 = async_compile.triton('triton_poi_fused_new_zeros_17', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 2048}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_new_zeros_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused_new_zeros_17(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = 0.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5y/c5ymv7bdkubpj4llf64kw2bdou7owlfi2xajcdstuzpbayk7dblq.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros, aten._unsafe_index_put]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %full_default_20 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 128, 1], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %index_put : [num_users=1] = call_function[target=torch.ops.aten.index_put_.default](args = (%full_default_20, [None, None, %convert_element_type_1], %permute_166, True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_poi_fused__unsafe_index_put_new_zeros_18 = async_compile.triton('triton_poi_fused__unsafe_index_put_new_zeros_18', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 4096}, 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_new_zeros_18', 'mutated_arg_names': ['out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     min_elem_per_thread=0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_poi_fused__unsafe_index_put_new_zeros_18(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x1 = xindex // ks0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x2 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = (xindex % ks0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp3 = tmp0 < 0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.device_assert(((0 <= tmp4) & (tmp4 < 1)) | ~(xmask), "index out of bounds: 0 <= tmp4 < 1")
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.atomic_add(out_ptr0 + (x0), tmp8, xmask, sem='relaxed')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rs/crslefz4xwyawtuk6isx2hqm6mwmdc752beadkbboejvvui5frtv.py
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Topologically Sorted Source Nodes: [normalize], Original ATen: [aten.mul, aten.div, aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Source node to ATen node mapping:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   normalize => div_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] # Graph fragment:
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_830 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_167, 11.313708498984761), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%view, %expand), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %mul_831 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_830, %div_1), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] #   %sum_62 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_831, [0, 1], True), kwargs = {})
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_red_fused_div_mul_sum_19 = async_compile.triton('triton_red_fused_div_mul_sum_19', '''
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] import triton.language as tl
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton_heuristics.reduction(
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     size_hints={'x': 128, 'r0_': 16},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     filename=__file__,
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_div_mul_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] @triton.jit
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def triton_red_fused_div_mul_sum_19(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xnumel = 128
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rnumel = r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     xmask = xindex < xnumel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     rbase = r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     x0 = xindex
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     _tmp12 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         roffset = r0_offset
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         rindex = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         r0_1 = r0_index
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp3 = tl.load(in_ptr1 + (x0 + 128*r0_1), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (r0_1), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp1 = 11.313708498984761
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp2 = tmp0 * tmp1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp4 = tl_math.abs(tmp3)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp5 = 1.0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp6 = tmp4 + tmp5
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp7 = tmp3 / tmp6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp9 = tmp7 / tmp8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp10 = tmp2 * tmp9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         tmp13 = _tmp12 + tmp11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         _tmp12 = tl.where(r0_mask & xmask, tmp13, _tmp12)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tmp12 = tl.sum(_tmp12, 1)[:, None]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] ''', device_str='cuda')
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] async_compile.wait(globals())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] del async_compile
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def call(args):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_1, mul_39, mul_92, primals_2, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_44, primals_50, primals_56, primals_57, primals_58, clamp_min, convert_element_type_1, view_1, view_7, view_8, view_9, getitem, getitem_1, getitem_2, getitem_3, view_10, gt, view_12, view_14, view_20, view_21, view_22, getitem_10, getitem_11, getitem_12, getitem_13, view_23, gt_1, mul_234, view_25, gt_2, view_27, gt_3, mul_278, view_29, view_35, view_36, view_37, getitem_18, getitem_19, getitem_20, getitem_21, view_38, gt_4, mul_364, view_40, view_48, view_49, view_50, getitem_28, getitem_29, getitem_30, getitem_31, view_51, gt_5, mul_454, view_53, gt_6, view_55, gt_7, mul_498, view_57, view_63, view_64, view_65, getitem_36, getitem_37, getitem_38, getitem_39, view_66, gt_8, mul_584, view_68, view_76, view_77, view_78, getitem_46, getitem_47, getitem_48, getitem_49, view_79, gt_9, mul_674, view_81, gt_10, view_83, gt_11, mul_718, pow_4, div_7, permute_55, le, permute_59, div_8, permute_63, permute_75, div_9, permute_79, permute_88, div_10, permute_92, le_1, permute_96, div_11, permute_100, permute_112, div_12, permute_116, permute_125, div_13, permute_129, le_2, permute_133, div_14, permute_137, permute_149, mul_821, div_15, permute_153, permute_164, tangents_1 = args
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     args.clear()
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     s0 = primals_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_2, (s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_8, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_14, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_20, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_26, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_32, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_38, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_44, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_50, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_56, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_57, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(primals_58, (128, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(clamp_min, (1, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(convert_element_type_1, (2, ), (1, ))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_1, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_7, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_8, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_9, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_1, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_2, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_3, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_10, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_12, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_14, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_20, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_21, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_22, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_10, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_11, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_12, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_13, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_23, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_1, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_234, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_25, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_2, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_27, (2*s0, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_3, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_278, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_29, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_35, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_36, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_37, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_18, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_19, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_20, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_21, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_38, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_4, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_364, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_40, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_48, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_49, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_50, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_28, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_29, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_30, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_31, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_51, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_5, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_454, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_53, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_6, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_55, (2*s0, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_7, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_498, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_57, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_63, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_64, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_65, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_36, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_37, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_38, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_39, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_66, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_8, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_584, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_68, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_76, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_77, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_78, (s0, 8, 2, 16), (128, 16, 128*s0, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_46, (s0, 8, 2, 16), (256, 16, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_47, (s0, 8, 32), (256, 32, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_48, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(getitem_49, (), ())
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_79, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_9, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_674, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_81, (2*s0, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_10, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(view_83, (2*s0, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(gt_11, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_718, (2, s0, 128), (128*s0, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(pow_4, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_7, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_55, (128, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(le, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_59, (2048, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_8, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_63, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_75, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_9, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_79, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_88, (384, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_10, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_92, (128, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(le_1, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_96, (2048, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_11, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_100, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_112, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_12, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_116, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_125, (384, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_13, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_129, (128, 2048), (2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(le_2, (2, s0, 2048), (2048*s0, 2048, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_133, (2048, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_14, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_137, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_149, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(mul_821, (2, s0, 128), (1, 256, 2))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(div_15, (2, s0, 1), (s0, 1, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_153, (128, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(permute_164, (384, 128), (128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     assert_size_stride(tangents_1, (s0, 2, 128), (256, 128, 1))
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf2 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf5 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf8 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_17, normalize_1], Original ATen: [aten.mul, aten.native_layer_norm, aten.div, aten.neg, aten.sum, aten.scalar_tensor, aten.ge, aten.where, aten.eq, aten.masked_fill, aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0.run(tangents_1, primals_58, mul_718, primals_56, primals_57, pow_4, div_7, gt_11, buf2, buf5, buf8, s0, triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0_xnumel, 128, grid=grid(triton_per_fused_add_div_eq_ge_masked_fill_mul_native_dropout_backward_native_layer_norm_native_layer_norm_backward_neg_scalar_tensor_sum_where_0_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_58
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf0 = empty_strided_cuda((1, 1, 128), (128, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf6 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf7 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [x_17, normalize_1], Original ATen: [aten.mul, aten.native_layer_norm, aten.div, aten.sum, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1.run(tangents_1, mul_718, primals_56, primals_57, pow_4, buf2, buf0, buf6, buf7, s0, 128, triton_red_fused_div_mul_native_layer_norm_native_layer_norm_backward_sum_1_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_718
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del pow_4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_56
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_57
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del tangents_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf9 = empty_strided_cuda((2*s0, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf8, (2*s0, 128), (128, 1), 0), permute_55, out=buf9)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_55
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf10 = empty_strided_cuda((128, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf8, (128, 2*s0), (1, 128), 0), view_83, out=buf10)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_83
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf11 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf8, buf11, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf12 = reinterpret_tensor(buf9, (2, s0, 2048), (2048*s0, 2048, 1), 0); del buf9  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel = 4096*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3.run(buf12, le, gt_10, triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del le
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf13 = reinterpret_tensor(buf8, (2*s0, 128), (128, 1), 0); del buf8  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf12, (2*s0, 2048), (2048, 1), 0), permute_59, out=buf13)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_59
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf14 = empty_strided_cuda((2048, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf12, (2048, 2*s0), (1, 2048), 0), view_81, out=buf14)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_81
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf15 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4.run(buf12, buf15, 2048, triton_red_fused_sum_4_r0_numel, grid=grid(2048), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf18 = buf2; del buf2  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf21 = empty_strided_cuda((2, s0, 128), (128*s0, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf5, buf13, primals_50, mul_674, div_8, gt_9, buf18, buf21, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_50
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf19 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf20 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf5, buf13, mul_674, buf19, buf20, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_674
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf22 = reinterpret_tensor(buf5, (2*s0, 128), (128, 1), 0); del buf5  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf21, (2*s0, 128), (128, 1), 0), permute_63, out=buf22)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_63
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf23 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf21, (128, 2*s0), (1, 128), 0), view_79, out=buf23)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_79
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf24 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf21, buf24, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf21
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf25 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf22, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_76, view_77, view_78, None, getitem_46, getitem_47, getitem_48, getitem_49, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf22
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_46
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_47
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_48
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_49
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_76
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_77
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_78
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf26 = buf25[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf27 = buf25[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf28 = buf25[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf25
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf29 = empty_strided_cuda((2, s0, 2, 128), (256*s0, 256, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 512*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf28, buf27, buf29, s0, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf39 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf30 = reinterpret_tensor(buf39, (256, 128), (128, 1), 16384)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf29, (256, 2*s0), (1, 256), 0), view_14, out=buf30)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf38 = empty_strided_cuda((384, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf37 = reinterpret_tensor(buf38, (256, ), (1, ), 128)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8.run(buf29, buf37, 256, triton_red_fused_cat_sum_8_r0_numel, grid=grid(256), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf32 = reinterpret_tensor(buf28, (2*s0, 128), (128, 1), 0); del buf28  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9_xnumel = 256*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9.run(buf26, buf32, s0, triton_poi_fused_view_9_xnumel, grid=grid(triton_poi_fused_view_9_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf33 = reinterpret_tensor(buf26, (2*s0, 128), (128, 1), 0); del buf26  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(buf32, permute_75, out=buf33)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_75
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf34 = reinterpret_tensor(buf39, (128, 128), (128, 1), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf32, (128, 2*s0), (1, 128), 0), view_68, out=buf34)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_68
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf36 = reinterpret_tensor(buf38, (128, ), (1, ), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10.run(buf32, buf36, 128, triton_red_fused_cat_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf42 = reinterpret_tensor(buf32, (2, s0, 128), (128*s0, 128, 1), 0); del buf32  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf45 = reinterpret_tensor(buf27, (2, s0, 128), (128*s0, 128, 1), 0); del buf27  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf18, buf33, primals_44, mul_584, div_9, gt_8, buf42, buf45, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_44
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf43 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf44 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf18, buf33, mul_584, buf43, buf44, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf18
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_584
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf46 = buf33; del buf33  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf45, (2*s0, 128), (128, 1), 0), permute_79, out=buf46)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_79
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf47 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf45, (128, 2*s0), (1, 128), 0), view_66, out=buf47)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_66
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf48 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf45, buf48, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf45
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf49 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf46, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_63, view_64, view_65, None, getitem_36, getitem_37, getitem_38, getitem_39, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf46
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_36
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_37
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_38
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_39
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_63
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_64
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_65
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf50 = buf49[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf51 = buf49[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf52 = buf49[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf49
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf53 = empty_strided_cuda((2, s0, 3, 128), (384*s0, 384, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 768*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11.run(buf52, buf51, buf50, buf53, s0, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf54 = reinterpret_tensor(buf52, (2*s0, 128), (128, 1), 0); del buf52  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf53, (2*s0, 384), (384, 1), 0), permute_88, out=buf54)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_88
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf55 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf53, (384, 2*s0), (1, 384), 0), view_57, out=buf55)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_57
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf56 = empty_strided_cuda((1, 384), (384, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_12_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_12.run(buf53, buf56, 384, triton_red_fused_sum_12_r0_numel, grid=grid(384), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf59 = reinterpret_tensor(buf51, (2, s0, 128), (128*s0, 128, 1), 0); del buf51  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf62 = reinterpret_tensor(buf50, (2, s0, 128), (128*s0, 128, 1), 0); del buf50  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf42, buf54, primals_38, mul_498, div_10, gt_7, buf59, buf62, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_38
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf60 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf61 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf42, buf54, mul_498, buf60, buf61, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_498
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf63 = reinterpret_tensor(buf12, (2*s0, 2048), (2048, 1), 0); del buf12  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf62, (2*s0, 128), (128, 1), 0), permute_92, out=buf63)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_92
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf64 = empty_strided_cuda((128, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf62, (128, 2*s0), (1, 128), 0), view_55, out=buf64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_55
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf65 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf62, buf65, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf66 = reinterpret_tensor(buf63, (2, s0, 2048), (2048*s0, 2048, 1), 0); del buf63  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel = 4096*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3.run(buf66, le_1, gt_6, triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_6
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del le_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf67 = reinterpret_tensor(buf62, (2*s0, 128), (128, 1), 0); del buf62  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf66, (2*s0, 2048), (2048, 1), 0), permute_96, out=buf67)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_96
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf68 = empty_strided_cuda((2048, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf66, (2048, 2*s0), (1, 2048), 0), view_53, out=buf68)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_53
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf69 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4.run(buf66, buf69, 2048, triton_red_fused_sum_4_r0_numel, grid=grid(2048), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf72 = reinterpret_tensor(buf54, (2, s0, 128), (128*s0, 128, 1), 0); del buf54  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf75 = buf42; del buf42  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf59, buf67, primals_32, mul_454, div_11, gt_5, buf72, buf75, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_5
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_32
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf73 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf74 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf59, buf67, mul_454, buf73, buf74, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf59
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_454
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf76 = buf67; del buf67  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf75, (2*s0, 128), (128, 1), 0), permute_100, out=buf76)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_100
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf77 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf75, (128, 2*s0), (1, 128), 0), view_51, out=buf77)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_51
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf78 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf75, buf78, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf75
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf79 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf76, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_48, view_49, view_50, None, getitem_28, getitem_29, getitem_30, getitem_31, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf76
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_28
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_29
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_30
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_31
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_48
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_49
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_50
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf80 = buf79[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf81 = buf79[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf82 = buf79[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf79
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf83 = buf29; del buf29  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 512*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf82, buf81, buf83, s0, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf93 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf84 = reinterpret_tensor(buf93, (256, 128), (128, 1), 16384)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf83, (256, 2*s0), (1, 256), 0), view_14, out=buf84)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf92 = empty_strided_cuda((384, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf91 = reinterpret_tensor(buf92, (256, ), (1, ), 128)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8.run(buf83, buf91, 256, triton_red_fused_cat_sum_8_r0_numel, grid=grid(256), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf86 = reinterpret_tensor(buf82, (2*s0, 128), (128, 1), 0); del buf82  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9_xnumel = 256*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9.run(buf80, buf86, s0, triton_poi_fused_view_9_xnumel, grid=grid(triton_poi_fused_view_9_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf87 = reinterpret_tensor(buf80, (2*s0, 128), (128, 1), 0); del buf80  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(buf86, permute_112, out=buf87)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_112
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf88 = reinterpret_tensor(buf93, (128, 128), (128, 1), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf86, (128, 2*s0), (1, 128), 0), view_40, out=buf88)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_40
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf90 = reinterpret_tensor(buf92, (128, ), (1, ), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10.run(buf86, buf90, 128, triton_red_fused_cat_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf96 = reinterpret_tensor(buf86, (2, s0, 128), (128*s0, 128, 1), 0); del buf86  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf99 = reinterpret_tensor(buf81, (2, s0, 128), (128*s0, 128, 1), 0); del buf81  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf72, buf87, primals_26, mul_364, div_12, gt_4, buf96, buf99, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_4
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_26
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf97 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf98 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf72, buf87, mul_364, buf97, buf98, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf72
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_364
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf100 = buf87; del buf87  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf99, (2*s0, 128), (128, 1), 0), permute_116, out=buf100)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_116
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf101 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf99, (128, 2*s0), (1, 128), 0), view_38, out=buf101)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_38
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf102 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf99, buf102, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf99
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf103 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf100, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_35, view_36, view_37, None, getitem_18, getitem_19, getitem_20, getitem_21, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf100
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_18
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_19
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_20
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_21
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_35
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_36
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_37
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf104 = buf103[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf105 = buf103[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf106 = buf103[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf103
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf107 = buf53; del buf53  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 768*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11.run(buf106, buf105, buf104, buf107, s0, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf108 = reinterpret_tensor(buf106, (2*s0, 128), (128, 1), 0); del buf106  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (2*s0, 384), (384, 1), 0), permute_125, out=buf108)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_125
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf109 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (384, 2*s0), (1, 384), 0), view_29, out=buf109)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_29
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf110 = empty_strided_cuda((1, 384), (384, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_12_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_12.run(buf107, buf110, 384, triton_red_fused_sum_12_r0_numel, grid=grid(384), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf113 = reinterpret_tensor(buf105, (2, s0, 128), (128*s0, 128, 1), 0); del buf105  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf116 = reinterpret_tensor(buf104, (2, s0, 128), (128*s0, 128, 1), 0); del buf104  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf96, buf108, primals_20, mul_278, div_13, gt_3, buf113, buf116, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_20
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf114 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf115 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf96, buf108, mul_278, buf114, buf115, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_278
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf117 = reinterpret_tensor(buf66, (2*s0, 2048), (2048, 1), 0); del buf66  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (2*s0, 128), (128, 1), 0), permute_129, out=buf117)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_129
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf118 = empty_strided_cuda((128, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (128, 2*s0), (1, 128), 0), view_27, out=buf118)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_27
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf119 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf116, buf119, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf120 = reinterpret_tensor(buf117, (2, s0, 2048), (2048*s0, 2048, 1), 0); del buf117  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel = 4096*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3.run(buf120, le_2, gt_2, triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_3_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del le_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf121 = reinterpret_tensor(buf116, (2*s0, 128), (128, 1), 0); del buf116  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf120, (2*s0, 2048), (2048, 1), 0), permute_133, out=buf121)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_133
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf122 = empty_strided_cuda((2048, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf120, (2048, 2*s0), (1, 2048), 0), view_25, out=buf122)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_25
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf123 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_4.run(buf120, buf123, 2048, triton_red_fused_sum_4_r0_numel, grid=grid(2048), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf120
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf126 = buf96; del buf96  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf129 = reinterpret_tensor(buf108, (2, s0, 128), (128*s0, 128, 1), 0); del buf108  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5.run(buf113, buf121, primals_14, mul_234, div_14, gt_1, buf126, buf129, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel, 128, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf127 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf128 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_6.run(buf113, buf121, mul_234, buf127, buf128, 128, triton_red_fused_add_native_layer_norm_backward_6_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf113
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_234
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf130 = buf121; del buf121  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf129, (2*s0, 128), (128, 1), 0), permute_137, out=buf130)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_137
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf131 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf129, (128, 2*s0), (1, 128), 0), view_23, out=buf131)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_23
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf132 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf129, buf132, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf129
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf133 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf130, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_20, view_21, view_22, None, getitem_10, getitem_11, getitem_12, getitem_13, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf130
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_11
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_13
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_20
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_21
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_22
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf134 = buf133[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf135 = buf133[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf136 = buf133[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf133
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf137 = buf83; del buf83  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 512*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_7.run(buf136, buf135, buf137, s0, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf147 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf138 = reinterpret_tensor(buf147, (256, 128), (128, 1), 16384)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf137, (256, 2*s0), (1, 256), 0), view_14, out=buf138)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_14
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf146 = empty_strided_cuda((384, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf145 = reinterpret_tensor(buf146, (256, ), (1, ), 128)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_8.run(buf137, buf145, 256, triton_red_fused_cat_sum_8_r0_numel, grid=grid(256), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf137
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf140 = reinterpret_tensor(buf136, (2*s0, 128), (128, 1), 0); del buf136  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9_xnumel = 256*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_view_9.run(buf134, buf140, s0, triton_poi_fused_view_9_xnumel, grid=grid(triton_poi_fused_view_9_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf141 = reinterpret_tensor(buf134, (2*s0, 128), (128, 1), 0); del buf134  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(buf140, permute_149, out=buf141)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_149
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf142 = reinterpret_tensor(buf147, (128, 128), (128, 1), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf140, (128, 2*s0), (1, 128), 0), view_12, out=buf142)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_12
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf144 = reinterpret_tensor(buf146, (128, ), (1, ), 0)  # alias
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_cat_sum_10.run(buf140, buf144, 128, triton_red_fused_cat_sum_10_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf148 = empty_strided_cuda((2, s0, 1), (s0, 1, 2*s0), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf149 = empty_strided_cuda((2, s0, 1), (s0, 1, 2*s0), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_layer_norm_backward_13_xnumel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_per_fused_add_native_layer_norm_backward_13.run(buf126, buf141, primals_8, mul_821, buf148, buf149, s0, triton_per_fused_add_native_layer_norm_backward_13_xnumel, 128, grid=grid(triton_per_fused_add_native_layer_norm_backward_13_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf150 = reinterpret_tensor(buf140, (2, s0, 128), (128*s0, 128, 1), 0); del buf140  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf153 = reinterpret_tensor(buf135, (2, s0, 128), (128*s0, 128, 1), 0); del buf135  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14_xnumel = 128*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14.run(div_15, buf126, buf141, primals_8, buf148, mul_821, buf149, gt, buf150, buf153, s0, 2, triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14_xnumel, grid=grid(2, triton_poi_fused_add_native_dropout_backward_native_layer_norm_backward_14_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf148
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf149
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del div_15
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del gt
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf151 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf152 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_15_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_15.run(buf126, buf141, mul_821, buf151, buf152, s0, 128, triton_red_fused_add_native_layer_norm_backward_15_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf126
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del mul_821
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf154 = buf141; del buf141  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf153, (2*s0, 128), (128, 1), 0), permute_153, out=buf154)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_153
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf155 = empty_strided_cuda((128, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf153, (128, 2*s0), (1, 128), 0), view_10, out=buf155)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf156 = empty_strided_cuda((1, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_2.run(buf153, buf156, 128, triton_red_fused_sum_2_r0_numel, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf153
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf157 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf154, (s0, 8, 2, 16), (128, 16, 128*s0, 1), 0), view_7, view_8, view_9, None, getitem, getitem_1, getitem_2, getitem_3, 0.1, [True, True, True, False])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf154
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del getitem_3
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_7
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_8
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_9
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf158 = buf157[0]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf159 = buf157[1]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf160 = buf157[2]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf157
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf161 = empty_strided_cuda((1, 1, 384), (384, 384, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_16_r0_numel = 2*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_sum_16.run(buf160, buf159, buf158, buf161, s0, 384, triton_red_fused_sum_16_r0_numel, grid=grid(384), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf162 = buf107; del buf107  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 768*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_clone_11.run(buf160, buf159, buf158, buf162, s0, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf158
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf159
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf163 = empty_strided_cuda((384, 128), (128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf162, (384, 2*s0), (1, 384), 0), view_1, out=buf163)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del view_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf164 = reinterpret_tensor(buf160, (2*s0, 128), (128, 1), 0); del buf160  # reuse
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf162, (2*s0, 384), (384, 1), 0), permute_164, out=buf164)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf162
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del permute_164
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf165 = empty_strided_cuda((s0, 128, 1), (128, 1, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_new_zeros_17_xnumel = 128*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused_new_zeros_17.run(buf165, triton_poi_fused_new_zeros_17_xnumel, grid=grid(triton_poi_fused_new_zeros_17_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         ps0 = 128*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros, aten._unsafe_index_put]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused__unsafe_index_put_new_zeros_18_xnumel = 256*s0
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_poi_fused__unsafe_index_put_new_zeros_18.run(convert_element_type_1, buf150, buf164, buf165, ps0, triton_poi_fused__unsafe_index_put_new_zeros_18_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_new_zeros_18_xnumel), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf150
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf164
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del convert_element_type_1
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         buf167 = empty_strided_cuda((1, 1, 128), (128, 128, 1), torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         # Topologically Sorted Source Nodes: [normalize], Original ATen: [aten.mul, aten.div, aten.sum]
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         triton_red_fused_div_mul_sum_19.run(buf165, primals_2, clamp_min, buf167, 128, s0, grid=grid(128), stream=stream0)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del buf165
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del clamp_min
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]         del primals_2
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     return (None, None, reinterpret_tensor(buf167, (128, ), (1, ), 0), reinterpret_tensor(buf161, (384, ), (1, ), 0), buf163, buf155, reinterpret_tensor(buf156, (128, ), (1, ), 0), buf151, buf152, buf147, buf146, buf131, reinterpret_tensor(buf132, (128, ), (1, ), 0), buf127, buf128, buf122, reinterpret_tensor(buf123, (2048, ), (1, ), 0), buf118, reinterpret_tensor(buf119, (128, ), (1, ), 0), buf114, buf115, reinterpret_tensor(buf110, (384, ), (1, ), 0), buf109, buf101, reinterpret_tensor(buf102, (128, ), (1, ), 0), buf97, buf98, buf93, buf92, buf77, reinterpret_tensor(buf78, (128, ), (1, ), 0), buf73, buf74, buf68, reinterpret_tensor(buf69, (2048, ), (1, ), 0), buf64, reinterpret_tensor(buf65, (128, ), (1, ), 0), buf60, buf61, reinterpret_tensor(buf56, (384, ), (1, ), 0), buf55, buf47, reinterpret_tensor(buf48, (128, ), (1, ), 0), buf43, buf44, buf39, buf38, buf23, reinterpret_tensor(buf24, (128, ), (1, ), 0), buf19, buf20, buf14, reinterpret_tensor(buf15, (2048, ), (1, ), 0), buf10, reinterpret_tensor(buf11, (128, ), (1, ), 0), buf6, buf7, reinterpret_tensor(buf0, (128, ), (1, ), 0), )
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_1 = 10
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_39 = 20
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_92 = 80
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_2 = rand_strided((10, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_8 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_14 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_20 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_26 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_32 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_38 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_44 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_50 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_56 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_57 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     primals_58 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     clamp_min = rand_strided((1, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     convert_element_type_1 = rand_strided((2, ), (1, ), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_1 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_7 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_8 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_9 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_1 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_2 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_3 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_10 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_12 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_14 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_20 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_21 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_22 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_10 = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_11 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_12 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_13 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_23 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_1 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_234 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_25 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_2 = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_27 = rand_strided((20, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_3 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_278 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_29 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_35 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_36 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_37 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_18 = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_19 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_20 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_21 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_38 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_4 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_364 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_40 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_48 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_49 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_50 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_28 = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_29 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_30 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_31 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_51 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_5 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_454 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_53 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_6 = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_55 = rand_strided((20, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_7 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_498 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_57 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_63 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_64 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_65 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_36 = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_37 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_38 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_39 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_66 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_8 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_584 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_68 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_76 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_77 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_78 = rand_strided((10, 8, 2, 16), (128, 16, 1280, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_46 = rand_strided((10, 8, 2, 16), (256, 16, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_47 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_48 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     getitem_49 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_79 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_9 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_674 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_81 = rand_strided((20, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_10 = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     view_83 = rand_strided((20, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     gt_11 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_718 = rand_strided((2, 10, 128), (1280, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     pow_4 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_7 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_55 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     le = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_59 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_8 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_63 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_75 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_9 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_79 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_88 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_10 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_92 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     le_1 = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_96 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_11 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_100 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_112 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_12 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_116 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_125 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_13 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_129 = rand_strided((128, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     le_2 = rand_strided((2, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_133 = rand_strided((2048, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_14 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_137 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_149 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     mul_821 = rand_strided((2, 10, 128), (1, 256, 2), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     div_15 = rand_strided((2, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_153 = rand_strided((128, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     permute_164 = rand_strided((384, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     tangents_1 = rand_strided((10, 2, 128), (256, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     fn = lambda: call([primals_1, mul_39, mul_92, primals_2, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_44, primals_50, primals_56, primals_57, primals_58, clamp_min, convert_element_type_1, view_1, view_7, view_8, view_9, getitem, getitem_1, getitem_2, getitem_3, view_10, gt, view_12, view_14, view_20, view_21, view_22, getitem_10, getitem_11, getitem_12, getitem_13, view_23, gt_1, mul_234, view_25, gt_2, view_27, gt_3, mul_278, view_29, view_35, view_36, view_37, getitem_18, getitem_19, getitem_20, getitem_21, view_38, gt_4, mul_364, view_40, view_48, view_49, view_50, getitem_28, getitem_29, getitem_30, getitem_31, view_51, gt_5, mul_454, view_53, gt_6, view_55, gt_7, mul_498, view_57, view_63, view_64, view_65, getitem_36, getitem_37, getitem_38, getitem_39, view_66, gt_8, mul_584, view_68, view_76, view_77, view_78, getitem_46, getitem_47, getitem_48, getitem_49, view_79, gt_9, mul_674, view_81, gt_10, view_83, gt_11, mul_718, pow_4, div_7, permute_55, le, permute_59, div_8, permute_63, permute_75, div_9, permute_79, permute_88, div_10, permute_92, le_1, permute_96, div_11, permute_100, permute_112, div_12, permute_116, permute_125, div_13, permute_129, le_2, permute_133, div_14, permute_137, permute_149, mul_821, div_15, permute_153, permute_164, tangents_1])
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] if __name__ == "__main__":
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:31:03.575000 703210 site-packages/torch/_inductor/graph.py:2014] [109/0] [__output_code] 
V0127 11:31:03.623000 703210 site-packages/torch/_inductor/graph.py:2022] [109/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/kn/ckncmkndp3spq2kbfgmhtvg4ywfbvmp4krown5gb6irocb5daqpu.py
I0127 11:31:04.614000 703210 site-packages/torch/_inductor/graph.py:2056] [109/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/kn/ckncmkndp3spq2kbfgmhtvg4ywfbvmp4krown5gb6irocb5daqpu.py
