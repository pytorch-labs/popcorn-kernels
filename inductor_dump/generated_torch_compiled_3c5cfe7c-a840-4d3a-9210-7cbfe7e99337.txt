V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] Output code: 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # AOT ID: ['48_forward']
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import torch
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import random
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import os
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import tempfile
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from math import inf, nan
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from cmath import nanj
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch import device, empty_strided
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     grid,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     split_scan_grid,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     grid_combo_kernels,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     start_graph,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     end_graph,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     cooperative_reduction_grid,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] aten = torch.ops.aten
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] _quantized = torch.ops._quantized
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] async_compile = AsyncCompile()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dy/cdydpbyb2eu3o56dmr75xvkx3b2k7klrfzm2ei7ztizq2vlhwfqo.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward => clone
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_clone_0 = async_compile.triton('triton_poi_fused_clone_0', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_clone_0(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 64*ks2*x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lo/cloifxmrr35fbfqwi7rkcn66vxzj37y33qkgwwjysazal6yifbhk.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward => clone_1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_1 : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_clone_1 = async_compile.triton('triton_poi_fused_clone_1', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 65536}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_clone_1(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 192*x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6j/c6jxgax4simhuumtrxxq5txqh5fqp6sri37fnajde2drjeko7pfq.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward => view_6
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %view_6 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_3, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_view_2 = async_compile.triton('triton_poi_fused_view_2', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_view_2(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks2))), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xn/cxnpwfobm2wvcwqlpuspk5sceruh36pefbrf6jtt5lmn33gjd4vc.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward => view_7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %view_7 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_4, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_view_3 = async_compile.triton('triton_poi_fused_view_3', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_view_3(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks3))), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3e/c3emcvt4ftwyksvluh4zhn4zeco477fzymgetbmp3xtxuqasy3hi.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward => view_8
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %view_8 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_5, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_view_4 = async_compile.triton('triton_poi_fused_view_4', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_view_4(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks2)) + 128*ks0*ks2), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/44/c44uwf7ipgpnjkazgroidbc7yj5uxcczlzdndunzsex72menvwmb.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_1, dropout_9, add_6, x_10], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   add => add_140
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   add_6 => add_790
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout => gt, inductor_lookup_seed_default, inductor_random_default_41, mul_124, mul_125
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_9 => gt_9, inductor_lookup_seed_default_9, inductor_random_default_32, mul_673, mul_674
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_1 => add_145, add_146, clone_3, mul_134, mul_135, rsqrt, sub_64, var_mean
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_10 => add_795, add_796, clone_11, mul_683, mul_684, rsqrt_7, sub_357, var_mean_7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_41 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_41, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_124 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt, %view_10), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_125 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_124, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_140 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute, %mul_125), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_3 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_140,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_3, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_145 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_145,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_64 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_3, %getitem_5), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_64, %rsqrt), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_135 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_134, %primals_8), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_146 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_135, %primals_9), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_9 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 9), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_32 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_9, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_9 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_32, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_673 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_9, %view_55), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_674 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_673, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_790 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute, %mul_674), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_11 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_790,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_7 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_11, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_795 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_30, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_7 : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_795,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_357 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_11, %getitem_31), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_683 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_357, %rsqrt_7), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_684 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_683, %primals_46), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_796 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_684, %primals_47), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1663 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_790, %getitem_31), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3165 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1663, %rsqrt_7), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_28 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_7, 64), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1684 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_140, %getitem_5), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3232 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1684, %rsqrt), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_35 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt, 64), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'out_ptr1': '*i1', 'out_ptr3': '*i1', 'out_ptr6': '*fp32', 'out_ptr9': '*fp32', 'out_ptr10': '*fp32', 'out_ptr11': '*fp32', 'out_ptr12': '*fp32', 'out_ptr13': '*fp32', 'load_seed_offset': 'i32', 'load_seed_offset1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 23), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 9, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, out_ptr1, out_ptr3, out_ptr6, out_ptr9, out_ptr10, out_ptr11, out_ptr12, out_ptr13, load_seed_offset, load_seed_offset1, ks2, ks3, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = (xindex % ks2)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks2
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (r0_1 + 64*x3 + 64*ks3*x2), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp40 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp42 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp45 = tl.load(in_ptr6 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp46 = tl.load(in_ptr7 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp70 = tl.load(in_ptr8 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp72 = tl.load(in_ptr9 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr0 + load_seed_offset1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.rand(tmp5, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tmp6 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tmp7.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp9 * tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tmp8 + tmp15
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.broadcast_to(tmp17, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.where(xmask, tmp20, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tl.sum(tmp22, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = tl.full([XBLOCK, 1], 64, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp24.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tmp23 / tmp25
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp27 = tmp17 - tmp26
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tmp27 * tmp27
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tl.broadcast_to(tmp28, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = tl.where(xmask, tmp29, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tl.sum(tmp31, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = tmp16 - tmp26
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = 64.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = tmp32 / tmp34
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = 1e-05
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tmp35 + tmp36
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = libdevice.rsqrt(tmp37)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp39 = tmp33 * tmp38
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = tmp39 * tmp40
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp43 = tmp41 + tmp42
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp44 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp47 = tmp45 + tmp46
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp48 = tmp44 * tmp47
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp49 = tmp48 * tmp14
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp50 = tmp8 + tmp49
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp54 = tl.broadcast_to(tmp51, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp56 = tl.where(xmask, tmp54, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp57 = tl.sum(tmp56, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp58 = tmp57 / tmp25
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp59 = tmp51 - tmp58
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp60 = tmp59 * tmp59
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp61 = tl.broadcast_to(tmp60, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp63 = tl.where(xmask, tmp61, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp64 = tl.sum(tmp63, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp65 = tmp50 - tmp58
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp66 = tmp64 / tmp34
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp67 = tmp66 + tmp36
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp68 = libdevice.rsqrt(tmp67)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp69 = tmp65 * tmp68
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp71 = tmp69 * tmp70
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp73 = tmp71 + tmp72
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp74 = 0.015625
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp75 = tmp68 * tmp74
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp76 = tmp38 * tmp74
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 64*x0), tmp7, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp43, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr9 + (r0_1 + 64*x0), tmp73, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr10 + (r0_1 + 64*x3 + 64*ks3*x2), tmp69, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr11 + (r0_1 + 64*x3 + 64*ks3*x2), tmp39, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr12 + (x0), tmp75, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr13 + (x0), tmp76, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hj/chjljwli3njwm274neif3qtcvu24fseocelfvnw4xmiqz3jbd4s2.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   relu => relu
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_12,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %le_12 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_relu_threshold_backward_6 = async_compile.triton('triton_poi_fused_relu_threshold_backward_6', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_threshold_backward_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_relu_threshold_backward_6(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 2048)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = 0.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vz/cvzahwzljbhdiqyley2mjsnxc47pwnr4xfllx4pbbv2pcmknyj7m.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_1 => gt_1, inductor_lookup_seed_default_1, inductor_random_default_40, mul_161, mul_162
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   relu => relu
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_12,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_40 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 2048], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_1 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_40, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_161 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_1, %relu), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_162 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_161, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_native_dropout_relu_7 = async_compile.triton('triton_poi_fused_native_dropout_relu_7', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': (4,)}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_7', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_native_dropout_relu_7(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = (xindex % 2048)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tmp5 * tmp10
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bu/cbufizbqox2zztntenrtr7nka2d6abfibc2ezmppq2my73s6krrz.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_2, add_1, x_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   add_1 => add_203
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_2 => gt_2, inductor_lookup_seed_default_2, inductor_random_default_39, mul_180, mul_181
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_3 => add_208, add_209, mul_190, mul_191, rsqrt_1, sub_93, var_mean_1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_39 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_2 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_39, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_180 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_2, %view_14), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_181 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_180, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_203 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_146, %mul_181), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_203, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_208 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_1 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_208,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_93 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_203, %getitem_7), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_190 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_93, %rsqrt_1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_191 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_190, %primals_14), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_209 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_191, %primals_15), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_34 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, 64), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = 64.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = 1e-05
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = 0.015625
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp42 = tmp35 * tmp41
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 64*x0), tmp40, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4h/c4hcdmkjm6vkmt2jwnjdnbye4353b2huhef2tigtiajccpkfac33.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [relu_1, dropout_4], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_4 => gt_4, inductor_lookup_seed_default_4, inductor_random_default_37, mul_334, mul_335
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   relu_1 => relu_1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_27,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 4), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_37 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 2048], %inductor_lookup_seed_default_4, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_4 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_37, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_334 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_4, %relu_1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_335 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_334, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_native_dropout_relu_9 = async_compile.triton('triton_poi_fused_native_dropout_relu_9', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_native_dropout_relu_9(in_out_ptr0, in_ptr0, in_ptr1, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = (xindex % 2048)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tmp5 * tmp10
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sr/csrwod4tirqawvm2ef6hb25n5bjptlvqgwrhvh6z22noh7tjwsjc.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_8, add_5, x_9, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   add_5 => add_621
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_8 => gt_8, inductor_lookup_seed_default_8, inductor_random_default_33, mul_526, mul_527
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   output => add_640, add_641, mul_545, mul_546, rsqrt_6, sub_288, var_mean_6
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_9 => add_626, add_627, mul_536, mul_537, rsqrt_5, sub_281, var_mean_5
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_8 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 8), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_33 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_8, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_8 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_33, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_526 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_8, %view_44), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_527 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_526, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_621 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_564, %mul_527), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_5 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_621, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_626 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_22, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_5 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_626,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_281 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_621, %getitem_23), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_536 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_281, %rsqrt_5), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_537 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_536, %primals_38), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_627 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_537, %primals_39), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_6 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_627, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_640 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_24, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_6 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_640,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_288 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_627, %getitem_25), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_545 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_288, %rsqrt_6), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_546 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_545, %primals_40), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_641 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_546, %primals_41), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_30 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_5, 64), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp62 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp64 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = 64.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = 1e-05
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp43 = tl.where(xmask, tmp41, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp44 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp46 = tl.where(xmask, tmp44, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp47 = tl.sum(tmp46, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp48 = tmp47 / tmp22
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp49 = tmp41 - tmp48
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp50 = tmp49 * tmp49
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp55 = tmp54 / tmp31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp56 = tmp55 + tmp33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp57 = libdevice.rsqrt(tmp56)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp58 = 0.015625
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp59 = tmp35 * tmp58
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp60 = tmp40 - tmp48
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp61 = tmp60 * tmp57
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp63 = tmp61 * tmp62
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp65 = tmp63 + tmp64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.debug_barrier()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp57, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp59, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp65, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/go/cgowq4oudk7uubixhhfxapjsodoujrnhrrsdsyklg3kvxxum2hkd.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   multi_head_attention_forward_4 => clone_12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_12 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_4,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_clone_11 = async_compile.triton('triton_poi_fused_clone_11', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 65536}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_clone_11(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 128*x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (64 + x0 + 64*x2), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gq/cgqjz5wh4kevsrgdcep2btti4byioaisds32xon4qutsmgvpul57.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_20, add_14, x_21, output_1, x_22], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.hardswish, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   add_14 => add_1727
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_20 => gt_20, inductor_lookup_seed_default_20, inductor_random_default_21, mul_1442, mul_1443
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   output_1 => add_1746, add_1747, mul_1461, mul_1462, rsqrt_16, sub_782, var_mean_16
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_21 => add_1732, add_1733, mul_1452, mul_1453, rsqrt_15, sub_775, var_mean_15
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_22 => add_1760, clamp_max, clamp_min, div, mul_1470
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_20 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 20), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_21 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_20, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_20 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_21, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1442 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_20, %view_128), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1443 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1442, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1727 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1670, %mul_1443), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_15 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1727, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1732 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_78, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_15 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1732,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_775 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1727, %getitem_79), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1452 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_775, %rsqrt_15), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1452, %primals_94), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1733 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1453, %primals_95), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %var_mean_16 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_1733, [2]), kwargs = {correction: 0, keepdim: True})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1746 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_80, 1e-05), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %rsqrt_16 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1746,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_782 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1733, %getitem_81), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1461 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_782, %rsqrt_16), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1462 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1461, %primals_96), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1747 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1462, %primals_97), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1760 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1747, 3), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clamp_min : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%add_1760, 0), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clamp_max : [num_users=1] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min, 6), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1470 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_1747, %clamp_max), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div : [num_users=3] = call_function[target=torch.ops.aten.div.Tensor](args = (%mul_1470, 6), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_20 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_15, 64), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12 = async_compile.triton('triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_out_ptr2': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1', 'in_out_ptr2'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 8, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12(in_out_ptr0, in_out_ptr1, in_out_ptr2, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp62 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp64 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp6 * tmp9
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp5 + tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp20 / tmp22
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = tmp14 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp24 * tmp24
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = tmp13 - tmp23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = 64.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp29 / tmp31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = 1e-05
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = tmp32 + tmp33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tmp30 * tmp35
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = tmp36 * tmp37
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp40 = tmp38 + tmp39
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = tl.broadcast_to(tmp40, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp43 = tl.where(xmask, tmp41, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp44 = tl.broadcast_to(tmp41, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp46 = tl.where(xmask, tmp44, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp47 = tl.sum(tmp46, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp48 = tmp47 / tmp22
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp49 = tmp41 - tmp48
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp50 = tmp49 * tmp49
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp55 = tmp54 / tmp31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp56 = tmp55 + tmp33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp57 = libdevice.rsqrt(tmp56)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp58 = 0.015625
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp59 = tmp35 * tmp58
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp60 = tmp40 - tmp48
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp61 = tmp60 * tmp57
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp63 = tmp61 * tmp62
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp65 = tmp63 + tmp64
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp66 = 3.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp67 = tmp65 + tmp66
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp68 = 0.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp69 = triton_helpers.maximum(tmp67, tmp68)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp70 = 6.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp71 = triton_helpers.minimum(tmp69, tmp70)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp72 = tmp65 * tmp71
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp73 = 0.16666666666666666
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp74 = tmp72 * tmp73
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.debug_barrier()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp57, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp59, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr2 + (r0_1 + 64*x0), tmp74, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp48, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3g/c3gdcsqcrq53pkb2rwrbzclpds322wgeatye2isww7sjscliuaaj.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [relu_10, dropout_36], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   dropout_36 => gt_36, inductor_lookup_seed_default_36, inductor_random_default_5, mul_2552, mul_2553
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   relu_10 => relu_10
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %relu_10 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_227,), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_lookup_seed_default_36 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 36), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %inductor_random_default_5 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 2048], %inductor_lookup_seed_default_36, rand), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %gt_36 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_5, 0.1), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2552 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_36, %relu_10), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2553 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2552, 1.1111111111111112), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %le_1 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_10, 0), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_13 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_13', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_13(in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = (xindex % 2048)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = x0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = 0.1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 > tmp3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tmp5 * tmp10
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = 1.1111111111111112
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp11 * tmp12
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = 0.0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tmp10 <= tmp14
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp15, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rd/crdiqyolqefswpo4yyvi6td34ehue7mihbjjxingegldavblsdyu.py
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [x_47], Original ATen: [aten.replication_pad3d]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_47 => _unsafe_index, _unsafe_index_1, _unsafe_index_2, clone_40
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %_unsafe_index : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%unsqueeze_19, [None, None, %clamp_max_1, None, None]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %_unsafe_index_1 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%_unsafe_index, [None, None, None, %clamp_max_2, None]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %_unsafe_index_2 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%_unsafe_index_1, [None, None, None, None, %clamp_max_3]), kwargs = {})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_40 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%_unsafe_index_2,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_replication_pad3d_14 = async_compile.triton('triton_poi_fused_replication_pad3d_14', '''
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 131072}, 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_replication_pad3d_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_replication_pad3d_14(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 66)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 66) % ks0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = xindex
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (64*x3 + 64*ks2*(((-1) + ks3) * (((-1) + ks3) <= (((0) * ((0) >= ((-1) + x1)) + ((-1) + x1) * (((-1) + x1) > (0))))) + (((0) * ((0) >= ((-1) + x1)) + ((-1) + x1) * (((-1) + x1) > (0)))) * ((((0) * ((0) >= ((-1) + x1)) + ((-1) + x1) * (((-1) + x1) > (0)))) < ((-1) + ks3))) + ((63) * ((63) <= (((0) * ((0) >= ((-1) + x0)) + ((-1) + x0) * (((-1) + x0) > (0))))) + (((0) * ((0) >= ((-1) + x0)) + ((-1) + x0) * (((-1) + x0) > (0)))) * ((((0) * ((0) >= ((-1) + x0)) + ((-1) + x0) * (((-1) + x0) > (0)))) < (63)))), xmask, eviction_policy='evict_last')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] async_compile.wait(globals())
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] del async_compile
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def call(args):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191 = args
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     args.clear()
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     s0 = primals_1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     s1 = primals_2
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_3, (s0, s1, 64), (64*s1, 64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_4, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_5, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_6, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_7, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_10, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_11, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_12, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_13, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_16, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_17, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_18, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_19, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_21, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_22, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_23, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_24, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_25, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_26, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_27, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_28, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_29, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_30, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_31, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_32, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_33, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_34, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_35, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_36, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_37, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_38, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_39, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_40, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_41, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_42, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_43, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_44, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_45, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_46, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_47, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_48, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_49, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_50, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_51, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_52, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_53, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_54, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_55, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_56, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_57, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_58, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_59, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_60, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_61, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_62, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_63, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_64, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_65, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_66, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_67, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_68, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_69, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_70, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_71, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_72, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_73, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_74, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_75, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_76, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_77, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_78, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_79, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_80, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_81, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_82, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_83, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_84, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_85, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_86, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_87, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_88, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_89, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_90, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_91, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_92, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_93, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_94, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_95, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_96, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_97, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_98, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_99, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_100, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_101, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_102, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_103, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_104, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_105, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_106, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_107, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_108, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_109, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_110, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_111, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_112, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_113, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_114, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_115, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_116, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_117, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_118, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_119, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_120, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_121, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_122, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_123, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_124, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_125, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_126, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_127, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_128, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_129, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_130, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_131, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_132, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_133, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_134, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_135, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_136, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_137, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_138, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_139, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_140, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_141, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_142, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_143, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_144, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_145, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_146, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_147, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_148, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_149, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_150, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_151, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_152, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_153, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_154, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_155, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_156, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_157, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_158, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_159, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_160, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_161, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_162, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_163, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_164, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_165, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_166, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_167, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_168, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_169, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_171, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_172, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_173, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_174, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_175, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_177, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_178, (192, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_179, (192, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_180, (64, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_181, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_183, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_184, (2048, 64), (64, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_185, (2048, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_186, (64, 2048), (2048, 1))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_187, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_190, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_191, (64, ), (1, ))
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         torch.cuda.set_device(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf13 = empty_strided_cuda((42, ), (1, ), torch.int64)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [42], out=buf13)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps0 = 64*s0
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf0 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(primals_3, buf0, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf1 = empty_strided_cuda((s0*s1, 192), (192, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf0, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_5, (64, 192), (1, 64), 0), out=buf1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_5
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps1 = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps2 = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf2 = empty_strided_cuda((3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf1, primals_4, buf2, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_4
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf3 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf2, buf3, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf4 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf2, buf4, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf5 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf2, buf5, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf6 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf3, buf4, buf5, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf7 = buf6[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf8 = buf6[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf9 = buf6[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf10 = buf6[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf6
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf11 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf7, buf11, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf12 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf11, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_6, (64, 64), (1, 64), 0), out=buf12)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf97 = reinterpret_tensor(buf2, (s0*s1, 192), (192, 1), 0); del buf2  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.mm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf0, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_43, (64, 192), (1, 64), 0), out=buf97)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_43
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf98 = reinterpret_tensor(buf1, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf1  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf97, primals_42, buf98, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_42
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf100 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf98, buf100, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf101 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf98, buf101, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf99 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf98, buf99, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf102 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf99, buf100, buf101, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf103 = buf102[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf104 = buf102[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf105 = buf102[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf106 = buf102[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf102
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf107 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf103, buf107, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf108 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_3], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf107, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_44, (64, 64), (1, 64), 0), out=buf108)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf110 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf15 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf19 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf114 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf536 = empty_strided_cuda((s1, s0, 64), (64, 64*s1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf546 = empty_strided_cuda((s1, s0, 64), (64, 64*s1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf537 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf547 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_1, dropout_9, add_6, x_10], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5.run(buf13, primals_3, buf12, primals_7, primals_8, primals_9, buf108, primals_45, primals_46, primals_47, buf110, buf15, buf19, buf114, buf536, buf546, buf537, buf547, 9, 0, s0, s1, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_3
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_45
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_47
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_7
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_9
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf115 = buf12; del buf12  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_49, (64, ), (1, ), 0), reinterpret_tensor(buf114, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_48, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf115)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf20 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf19, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_10, (64, 2048), (1, 64), 0), out=buf20)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf545 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf20, primals_11, buf545, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf22 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf23 = reinterpret_tensor(buf20, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf20  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_1], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_7_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_7.run(buf23, buf13, primals_11, buf22, 1, triton_poi_fused_native_dropout_relu_7_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_7_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_11
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf24 = buf108; del buf108  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_12, (2048, 64), (1, 2048), 0), out=buf24)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf26 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf30 = reinterpret_tensor(buf24, (s1, s0, 64), (64*s0, 64, 1), 0); del buf24  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf31 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf544 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_2, add_1, x_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf30, buf13, buf19, primals_13, primals_14, primals_15, buf26, buf31, buf544, 2, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_13
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_15
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf32 = reinterpret_tensor(buf98, (s0*s1, 192), (192, 1), 0); del buf98  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf31, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_17, (64, 192), (1, 64), 0), out=buf32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf33 = reinterpret_tensor(buf97, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf97  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf32, primals_16, buf33, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_16
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf34 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf33, buf34, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf35 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf33, buf35, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf36 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf33, buf36, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf37 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf34, buf35, buf36, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf38 = buf37[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf39 = buf37[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf40 = buf37[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf41 = buf37[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf37
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf42 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf38, buf42, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf43 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf42, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_18, (64, 64), (1, 64), 0), out=buf43)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf45 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf49 = reinterpret_tensor(buf43, (s1, s0, 64), (64*s0, 64, 1), 0); del buf43  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf50 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf543 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_4], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf49, buf13, buf31, primals_19, primals_20, primals_21, buf45, buf50, buf543, 3, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_19
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_21
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf51 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf50, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_22, (64, 2048), (1, 64), 0), out=buf51)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf542 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf51, primals_23, buf542, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf53 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf54 = reinterpret_tensor(buf51, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf51  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_1, dropout_4], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf54, buf13, primals_23, buf53, 4, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_23
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf55 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf54, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_24, (2048, 64), (1, 2048), 0), out=buf55)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf57 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf61 = reinterpret_tensor(buf55, (s1, s0, 64), (64*s0, 64, 1), 0); del buf55  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf62 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf541 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_5, add_3, x_6], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf61, buf13, buf50, primals_25, primals_26, primals_27, buf57, buf62, buf541, 5, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_25
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_27
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf63 = reinterpret_tensor(buf33, (s0*s1, 192), (192, 1), 0); del buf33  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf62, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_29, (64, 192), (1, 64), 0), out=buf63)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf64 = reinterpret_tensor(buf32, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf32  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf63, primals_28, buf64, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_28
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf65 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf64, buf65, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf66 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf64, buf66, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf67 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf64, buf67, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf68 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf65, buf66, buf67, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf69 = buf68[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf70 = buf68[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf71 = buf68[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf72 = buf68[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf68
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf73 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf69, buf73, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf74 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_2], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf73, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_30, (64, 64), (1, 64), 0), out=buf74)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf76 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf80 = reinterpret_tensor(buf74, (s1, s0, 64), (64*s0, 64, 1), 0); del buf74  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf81 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf540 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_6, add_4, x_7], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf80, buf13, buf62, primals_31, primals_32, primals_33, buf76, buf81, buf540, 6, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_31
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_33
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf82 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_4], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf81, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_34, (64, 2048), (1, 64), 0), out=buf82)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf539 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf82, primals_35, buf539, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf84 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf85 = reinterpret_tensor(buf82, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf82  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_2, dropout_7], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf85, buf13, primals_35, buf84, 7, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_35
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf86 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf85, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_36, (2048, 64), (1, 2048), 0), out=buf86)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf88 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf92 = reinterpret_tensor(buf86, (s1, s0, 64), (64*s0, 64, 1), 0); del buf86  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf93 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf94 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf96 = reinterpret_tensor(buf94, (s1, s0, 1), (s0, 1, 1), 0); del buf94  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf538 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf116 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_8, add_5, x_9, output], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf92, buf96, buf13, buf81, primals_37, primals_38, primals_39, primals_40, primals_41, buf88, buf93, buf538, buf116, 8, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_37
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_41
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf117 = empty_strided_cuda((s0*s1, 128), (128, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_48, (64, 128), (1, 64), 4096), out=buf117)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf118 = empty_strided_cuda((2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf117, primals_49, buf118, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_49
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf119 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf118, buf119, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf120 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf118, buf120, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf121 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf115, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf119, buf120, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf122 = buf121[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf123 = buf121[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf124 = buf121[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf125 = buf121[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf121
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf126 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf122, buf126, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf127 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_4], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf126, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_50, (64, 64), (1, 64), 0), out=buf127)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf129 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf133 = reinterpret_tensor(buf127, (s1, s0, 64), (64*s0, 64, 1), 0); del buf127  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf134 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf535 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_10, add_7, x_11], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf133, buf13, buf114, primals_51, primals_52, primals_53, buf129, buf134, buf535, 10, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_51
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_53
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf167 = reinterpret_tensor(buf118, (s0*s1, 128), (128, 1), 0); del buf118  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_66, (64, 128), (1, 64), 4096), out=buf167)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf168 = reinterpret_tensor(buf117, (2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf117  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf167, primals_67, buf168, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf169 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf168, buf169, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf170 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf168, buf170, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf217 = reinterpret_tensor(buf168, (s0*s1, 128), (128, 1), 0); del buf168  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf116, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_84, (64, 128), (1, 64), 4096), out=buf217)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf218 = reinterpret_tensor(buf167, (2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf167  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf217, primals_85, buf218, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf219 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf218, buf219, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf220 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf218, buf220, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf135 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf134, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_54, (64, 2048), (1, 64), 0), out=buf135)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf534 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_3], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf135, primals_55, buf534, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf137 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf138 = reinterpret_tensor(buf135, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf135  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_3, dropout_11], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf138, buf13, primals_55, buf137, 11, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_55
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf139 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf138, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_56, (2048, 64), (1, 2048), 0), out=buf139)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf141 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf145 = reinterpret_tensor(buf139, (s1, s0, 64), (64*s0, 64, 1), 0); del buf139  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf146 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf533 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_12, add_8, x_13], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf145, buf13, buf134, primals_57, primals_58, primals_59, buf141, buf146, buf533, 12, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_57
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_59
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf147 = reinterpret_tensor(buf64, (s0*s1, 192), (192, 1), 0); del buf64  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf146, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_61, (64, 192), (1, 64), 0), out=buf147)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf148 = reinterpret_tensor(buf63, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf63  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf147, primals_60, buf148, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_60
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf149 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf148, buf149, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf150 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf148, buf150, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf151 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf148, buf151, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf152 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf149, buf150, buf151, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf153 = buf152[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf154 = buf152[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf155 = buf152[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf156 = buf152[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf152
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf157 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf153, buf157, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf158 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_5], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf157, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_62, (64, 64), (1, 64), 0), out=buf158)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf160 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf164 = reinterpret_tensor(buf158, (s1, s0, 64), (64*s0, 64, 1), 0); del buf158  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf165 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf532 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_13, add_9, x_14], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf164, buf13, buf146, primals_63, primals_64, primals_65, buf160, buf165, buf532, 13, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_63
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_65
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf166 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_67, (64, ), (1, ), 0), reinterpret_tensor(buf165, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_66, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf166)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_67
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf171 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf166, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf169, buf170, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf172 = buf171[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf173 = buf171[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf174 = buf171[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf175 = buf171[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf171
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf176 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf172, buf176, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf177 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_6], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf176, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_68, (64, 64), (1, 64), 0), out=buf177)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf179 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf183 = reinterpret_tensor(buf177, (s1, s0, 64), (64*s0, 64, 1), 0); del buf177  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf184 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf531 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_14, add_10, x_15], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf183, buf13, buf165, primals_69, primals_70, primals_71, buf179, buf184, buf531, 14, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_69
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_71
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf185 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf184, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_72, (64, 2048), (1, 64), 0), out=buf185)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf530 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_4], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf185, primals_73, buf530, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf187 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf188 = reinterpret_tensor(buf185, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf185  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_4, dropout_15], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf188, buf13, primals_73, buf187, 15, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_73
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf189 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_16], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf188, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_74, (2048, 64), (1, 2048), 0), out=buf189)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf191 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf195 = reinterpret_tensor(buf189, (s1, s0, 64), (64*s0, 64, 1), 0); del buf189  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf196 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf529 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_16, add_11, x_17], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf195, buf13, buf184, primals_75, primals_76, primals_77, buf191, buf196, buf529, 16, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_75
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_77
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf197 = reinterpret_tensor(buf148, (s0*s1, 192), (192, 1), 0); del buf148  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf196, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_79, (64, 192), (1, 64), 0), out=buf197)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf198 = reinterpret_tensor(buf147, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf147  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf197, primals_78, buf198, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_78
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf199 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf198, buf199, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf200 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf198, buf200, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf201 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf198, buf201, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf202 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf199, buf200, buf201, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf203 = buf202[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf204 = buf202[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf205 = buf202[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf206 = buf202[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf202
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf207 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf203, buf207, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf208 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_7], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf207, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_80, (64, 64), (1, 64), 0), out=buf208)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf210 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf214 = reinterpret_tensor(buf208, (s1, s0, 64), (64*s0, 64, 1), 0); del buf208  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf215 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf528 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_17, add_12, x_18], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf214, buf13, buf196, primals_81, primals_82, primals_83, buf210, buf215, buf528, 17, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_81
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_83
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf216 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_85, (64, ), (1, ), 0), reinterpret_tensor(buf215, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_84, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf216)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_85
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf221 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf216, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf219, buf220, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf222 = buf221[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf223 = buf221[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf224 = buf221[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf225 = buf221[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf221
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf226 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf222, buf226, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf227 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_8], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf226, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_86, (64, 64), (1, 64), 0), out=buf227)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf229 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf233 = reinterpret_tensor(buf227, (s1, s0, 64), (64*s0, 64, 1), 0); del buf227  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf234 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf527 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_18, add_13, x_19], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf233, buf13, buf215, primals_87, primals_88, primals_89, buf229, buf234, buf527, 18, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_87
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_89
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf235 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_10], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf234, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_90, (64, 2048), (1, 64), 0), out=buf235)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf526 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_5], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf235, primals_91, buf526, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf237 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf238 = reinterpret_tensor(buf235, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf235  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_5, dropout_19], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf238, buf13, primals_91, buf237, 19, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_91
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf239 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_20], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf238, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_92, (2048, 64), (1, 2048), 0), out=buf239)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf241 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf245 = reinterpret_tensor(buf239, (s1, s0, 64), (64*s0, 64, 1), 0); del buf239  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf246 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf247 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf249 = reinterpret_tensor(buf247, (s1, s0, 1), (s0, 1, 1), 0); del buf247  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf525 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf250 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf251 = buf250; del buf250  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_20, add_14, x_21, output_1, x_22], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.hardswish, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12.run(buf245, buf249, buf251, buf13, buf234, primals_93, primals_94, primals_95, primals_96, primals_97, buf241, buf246, buf525, 20, triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel, 64, grid=grid(triton_per_fused_add_hardswish_native_dropout_native_layer_norm_native_layer_norm_backward_12_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_93
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf252 = reinterpret_tensor(buf198, (s0*s1, 192), (192, 1), 0); del buf198  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf251, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_99, (64, 192), (1, 64), 0), out=buf252)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf253 = reinterpret_tensor(buf197, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf197  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf252, primals_98, buf253, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_98
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf254 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf253, buf254, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf255 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf253, buf255, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf256 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf253, buf256, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf257 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf254, buf255, buf256, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf258 = buf257[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf259 = buf257[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf260 = buf257[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf261 = buf257[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf257
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf262 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf258, buf262, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf263 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_9], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf262, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_100, (64, 64), (1, 64), 0), out=buf263)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf265 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf269 = reinterpret_tensor(buf263, (s1, s0, 64), (64*s0, 64, 1), 0); del buf263  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf270 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf524 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_21, add_15, x_23], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf269, buf13, buf251, primals_101, primals_102, primals_103, buf265, buf270, buf524, 21, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_101
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_103
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf348 = reinterpret_tensor(buf253, (s0*s1, 192), (192, 1), 0); del buf253  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf251, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_137, (64, 192), (1, 64), 0), out=buf348)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf349 = reinterpret_tensor(buf252, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf252  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf348, primals_136, buf349, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_136
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf350 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf349, buf350, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf351 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf349, buf351, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf352 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf349, buf352, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf353 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf350, buf351, buf352, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf354 = buf353[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf355 = buf353[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf356 = buf353[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf357 = buf353[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf353
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf358 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf354, buf358, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf359 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_12], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_138, (64, 64), (1, 64), 0), out=buf359)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf361 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf365 = reinterpret_tensor(buf359, (s1, s0, 64), (64*s0, 64, 1), 0); del buf359  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf366 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf515 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_30, add_21, x_32], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf365, buf13, buf251, primals_139, primals_140, primals_141, buf361, buf366, buf515, 30, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_139
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_141
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf367 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_143, (64, ), (1, ), 0), reinterpret_tensor(buf366, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_142, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf367)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf271 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_12], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf270, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_104, (64, 2048), (1, 64), 0), out=buf271)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf523 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_6], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf271, primals_105, buf523, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf273 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf274 = reinterpret_tensor(buf271, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf271  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_6, dropout_22], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf274, buf13, primals_105, buf273, 22, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_105
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf275 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_24], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf274, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_106, (2048, 64), (1, 2048), 0), out=buf275)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf277 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf281 = reinterpret_tensor(buf275, (s1, s0, 64), (64*s0, 64, 1), 0); del buf275  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf282 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf522 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_23, add_16, x_25], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf281, buf13, buf270, primals_107, primals_108, primals_109, buf277, buf282, buf522, 23, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_107
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_109
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf283 = reinterpret_tensor(buf349, (s0*s1, 192), (192, 1), 0); del buf349  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf282, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_111, (64, 192), (1, 64), 0), out=buf283)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf284 = reinterpret_tensor(buf348, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf348  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf283, primals_110, buf284, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_110
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf285 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf284, buf285, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf286 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf284, buf286, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf287 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf284, buf287, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf288 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf285, buf286, buf287, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf289 = buf288[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf290 = buf288[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf291 = buf288[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf292 = buf288[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf288
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf293 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf289, buf293, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf294 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_10], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf293, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_112, (64, 64), (1, 64), 0), out=buf294)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf296 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf300 = reinterpret_tensor(buf294, (s1, s0, 64), (64*s0, 64, 1), 0); del buf294  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf301 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf521 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_24, add_17, x_26], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf300, buf13, buf282, primals_113, primals_114, primals_115, buf296, buf301, buf521, 24, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_113
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_115
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf302 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_14], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf301, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_116, (64, 2048), (1, 64), 0), out=buf302)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf520 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_7], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf302, primals_117, buf520, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf304 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf305 = reinterpret_tensor(buf302, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf302  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_7, dropout_25], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf305, buf13, primals_117, buf304, 25, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_117
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf306 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_27], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf305, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_118, (2048, 64), (1, 2048), 0), out=buf306)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf308 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf312 = reinterpret_tensor(buf306, (s1, s0, 64), (64*s0, 64, 1), 0); del buf306  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf313 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf519 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_26, add_18, x_28], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf312, buf13, buf301, primals_119, primals_120, primals_121, buf308, buf313, buf519, 26, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_119
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_121
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf314 = reinterpret_tensor(buf284, (s0*s1, 192), (192, 1), 0); del buf284  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf313, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_123, (64, 192), (1, 64), 0), out=buf314)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf315 = reinterpret_tensor(buf283, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf283  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf314, primals_122, buf315, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_122
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf316 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf315, buf316, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf317 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf315, buf317, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf318 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf315, buf318, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf319 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf316, buf317, buf318, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf320 = buf319[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf321 = buf319[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf322 = buf319[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf323 = buf319[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf319
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf324 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf320, buf324, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf325 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_11], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf324, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_124, (64, 64), (1, 64), 0), out=buf325)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf327 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf331 = reinterpret_tensor(buf325, (s1, s0, 64), (64*s0, 64, 1), 0); del buf325  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf332 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf518 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_27, add_19, x_29], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf331, buf13, buf313, primals_125, primals_126, primals_127, buf327, buf332, buf518, 27, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_125
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_127
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf333 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_16], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf332, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_128, (64, 2048), (1, 64), 0), out=buf333)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf517 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_8], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf333, primals_129, buf517, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf335 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf336 = reinterpret_tensor(buf333, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf333  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_8, dropout_28], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf336, buf13, primals_129, buf335, 28, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_129
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf337 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_30], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf336, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_130, (2048, 64), (1, 2048), 0), out=buf337)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf339 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf343 = reinterpret_tensor(buf337, (s1, s0, 64), (64*s0, 64, 1), 0); del buf337  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf344 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf345 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf347 = reinterpret_tensor(buf345, (s1, s0, 1), (s0, 1, 1), 0); del buf345  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf516 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf368 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_29, add_20, x_31, output_2], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf343, buf347, buf13, buf332, primals_131, primals_132, primals_133, primals_134, primals_135, buf339, buf344, buf516, buf368, 29, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_131
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_135
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf369 = reinterpret_tensor(buf218, (s0*s1, 128), (128, 1), 0); del buf218  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf368, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_142, (64, 128), (1, 64), 4096), out=buf369)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf370 = reinterpret_tensor(buf217, (2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf217  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf369, primals_143, buf370, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_143
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf371 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf370, buf371, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf372 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf370, buf372, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf373 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf367, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf371, buf372, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf374 = buf373[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf375 = buf373[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf376 = buf373[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf377 = buf373[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf373
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf378 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf374, buf378, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf379 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_13], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf378, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_144, (64, 64), (1, 64), 0), out=buf379)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf381 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf385 = reinterpret_tensor(buf379, (s1, s0, 64), (64*s0, 64, 1), 0); del buf379  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf386 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf514 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_31, add_22, x_33], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf385, buf13, buf366, primals_145, primals_146, primals_147, buf381, buf386, buf514, 31, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_145
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_147
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf419 = reinterpret_tensor(buf370, (s0*s1, 128), (128, 1), 0); del buf370  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf368, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_160, (64, 128), (1, 64), 4096), out=buf419)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf420 = reinterpret_tensor(buf369, (2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf369  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf419, primals_161, buf420, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf421 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf420, buf421, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf422 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf420, buf422, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf469 = reinterpret_tensor(buf420, (s0*s1, 128), (128, 1), 0); del buf420  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf368, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_178, (64, 128), (1, 64), 4096), out=buf469)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf470 = reinterpret_tensor(buf419, (2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf419  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11_xnumel = 128*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_11.run(buf469, primals_179, buf470, ps1, ps2, triton_poi_fused_clone_11_xnumel, grid=grid(triton_poi_fused_clone_11_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf469
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf471 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf470, buf471, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf472 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf470, buf472, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf470
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf387 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_18], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf386, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_148, (64, 2048), (1, 64), 0), out=buf387)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf513 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_9], Original ATen: [aten.relu, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_relu_threshold_backward_6.run(buf387, primals_149, buf513, triton_poi_fused_relu_threshold_backward_6_xnumel, grid=grid(triton_poi_fused_relu_threshold_backward_6_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf389 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf390 = reinterpret_tensor(buf387, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf387  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_9, dropout_32], Original ATen: [aten.relu, aten.native_dropout]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_9.run(buf390, buf13, primals_149, buf389, 32, triton_poi_fused_native_dropout_relu_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_9_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_149
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf391 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_34], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf390, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_150, (2048, 64), (1, 2048), 0), out=buf391)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf393 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf397 = reinterpret_tensor(buf391, (s1, s0, 64), (64*s0, 64, 1), 0); del buf391  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf398 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf512 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_33, add_23, x_35], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf397, buf13, buf386, primals_151, primals_152, primals_153, buf393, buf398, buf512, 33, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_151
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_153
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf399 = reinterpret_tensor(buf315, (s0*s1, 192), (192, 1), 0); del buf315  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf398, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_155, (64, 192), (1, 64), 0), out=buf399)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf400 = reinterpret_tensor(buf314, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf314  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf399, primals_154, buf400, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_154
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf401 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf400, buf401, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf402 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf400, buf402, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf403 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf400, buf403, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf404 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf401, buf402, buf403, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf405 = buf404[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf406 = buf404[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf407 = buf404[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf408 = buf404[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf404
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf409 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf405, buf409, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf410 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_14], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf409, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_156, (64, 64), (1, 64), 0), out=buf410)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf412 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf416 = reinterpret_tensor(buf410, (s1, s0, 64), (64*s0, 64, 1), 0); del buf410  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf417 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf511 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_34, add_24, x_36], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf416, buf13, buf398, primals_157, primals_158, primals_159, buf412, buf417, buf511, 34, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_157
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_159
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf418 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_161, (64, ), (1, ), 0), reinterpret_tensor(buf417, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_160, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf418)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_161
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf423 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf418, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf421, buf422, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf424 = buf423[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf425 = buf423[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf426 = buf423[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf427 = buf423[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf423
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf428 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf424, buf428, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf429 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_15], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf428, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_162, (64, 64), (1, 64), 0), out=buf429)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf431 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf435 = reinterpret_tensor(buf429, (s1, s0, 64), (64*s0, 64, 1), 0); del buf429  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf436 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf510 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_35, add_25, x_37], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf435, buf13, buf417, primals_163, primals_164, primals_165, buf431, buf436, buf510, 35, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_163
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_165
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf437 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_20], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf436, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_166, (64, 2048), (1, 64), 0), out=buf437)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf439 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf440 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf509 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_10, dropout_36], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13.run(buf13, buf437, primals_167, buf439, buf440, buf509, 36, triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_167
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf441 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_38], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf440, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_168, (2048, 64), (1, 2048), 0), out=buf441)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf443 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf447 = reinterpret_tensor(buf441, (s1, s0, 64), (64*s0, 64, 1), 0); del buf441  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf448 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf508 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_37, add_26, x_39], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf447, buf13, buf436, primals_169, primals_170, primals_171, buf443, buf448, buf508, 37, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_169
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_171
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf449 = reinterpret_tensor(buf400, (s0*s1, 192), (192, 1), 0); del buf400  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf448, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_173, (64, 192), (1, 64), 0), out=buf449)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf450 = reinterpret_tensor(buf399, (3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), 0); del buf399  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_1.run(buf449, primals_172, buf450, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf449
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_172
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf451 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_2.run(buf450, buf451, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf452 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_3.run(buf450, buf452, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf453 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.view]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_4.run(buf450, buf453, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf450
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf454 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf451, buf452, buf453, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf455 = buf454[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf456 = buf454[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf457 = buf454[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf458 = buf454[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf454
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf459 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf455, buf459, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf460 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_16], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf459, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_174, (64, 64), (1, 64), 0), out=buf460)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf462 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf466 = reinterpret_tensor(buf460, (s1, s0, 64), (64*s0, 64, 1), 0); del buf460  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf467 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf507 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_38, add_27, x_40], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf466, buf13, buf448, primals_175, primals_176, primals_177, buf462, buf467, buf507, 38, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_175
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_177
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf468 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_179, (64, ), (1, ), 0), reinterpret_tensor(buf467, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_178, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf468)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_179
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf473 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf468, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf471, buf472, None, True, 0.1)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf474 = buf473[0]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf475 = buf473[1]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf476 = buf473[2]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf477 = buf473[3]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf473
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf478 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.clone]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_0.run(buf474, buf478, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf479 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_17], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf478, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_180, (64, 64), (1, 64), 0), out=buf479)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf481 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf485 = reinterpret_tensor(buf479, (s1, s0, 64), (64*s0, 64, 1), 0); del buf479  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf486 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf506 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_39, add_28, x_41], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf485, buf13, buf467, primals_181, primals_182, primals_183, buf481, buf486, buf506, 39, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_181
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_183
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf487 = buf437; del buf437  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [linear_22], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf486, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_184, (64, 2048), (1, 64), 0), out=buf487)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf489 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf490 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf505 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [relu_11, dropout_40], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel = 2048*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_13.run(buf13, buf487, primals_185, buf489, buf490, buf505, 40, triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_13_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf487
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_185
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf491 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_42], Original ATen: [aten.addmm]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf490, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_186, (2048, 64), (1, 2048), 0), out=buf491)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf493 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf497 = reinterpret_tensor(buf491, (s1, s0, 64), (64*s0, 64, 1), 0); del buf491  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf498 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf499 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf501 = reinterpret_tensor(buf499, (s1, s0, 1), (s0, 1, 1), 0); del buf499  # reuse
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf504 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf502 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_41, add_29, x_43, output_3], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf497, buf501, buf13, buf486, primals_187, primals_188, primals_189, primals_190, primals_191, buf493, buf498, buf504, buf502, 41, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf13
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_187
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_191
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps3 = 2 + s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps4 = 396 + 198*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf503 = empty_strided_cuda((s0, 1, 3, 2 + s1, 66), (396 + 198*s1, 1, 132 + 66*s1, 66, 1), torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_47], Original ATen: [aten.replication_pad3d]
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_replication_pad3d_14_xnumel = 396*s0 + 198*s0*s1
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_replication_pad3d_14.run(buf502, buf503, ps3, ps4, s0, s1, triton_poi_fused_replication_pad3d_14_xnumel, grid=grid(triton_poi_fused_replication_pad3d_14_xnumel), stream=stream0)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     return (reinterpret_tensor(buf503, (s0, 3, 2 + s1, 66), (396 + 198*s1, 132 + 66*s1, 66, 1), 0), primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_97, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, reinterpret_tensor(buf0, (s0*s1, 64), (64, 1), 0), buf3, buf4, buf5, buf7, buf8, buf9, buf10, reinterpret_tensor(buf11, (s0*s1, 64), (64, 1), 0), buf15, reinterpret_tensor(buf19, (s0*s1, 64), (64, 1), 0), buf22, reinterpret_tensor(buf23, (s0*s1, 2048), (2048, 1), 0), buf26, buf30, reinterpret_tensor(buf31, (s0*s1, 64), (64, 1), 0), buf34, buf35, buf36, buf38, buf39, buf40, buf41, reinterpret_tensor(buf42, (s0*s1, 64), (64, 1), 0), buf45, buf49, reinterpret_tensor(buf50, (s0*s1, 64), (64, 1), 0), buf53, reinterpret_tensor(buf54, (s0*s1, 2048), (2048, 1), 0), buf57, buf61, reinterpret_tensor(buf62, (s0*s1, 64), (64, 1), 0), buf65, buf66, buf67, buf69, buf70, buf71, buf72, reinterpret_tensor(buf73, (s0*s1, 64), (64, 1), 0), buf76, buf80, reinterpret_tensor(buf81, (s0*s1, 64), (64, 1), 0), buf84, reinterpret_tensor(buf85, (s0*s1, 2048), (2048, 1), 0), buf88, buf92, buf93, buf96, buf99, buf100, buf101, buf103, buf104, buf105, buf106, reinterpret_tensor(buf107, (s0*s1, 64), (64, 1), 0), buf110, reinterpret_tensor(buf114, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf116, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf115, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf119, buf120, buf122, buf123, buf124, buf125, reinterpret_tensor(buf126, (s0*s1, 64), (64, 1), 0), buf129, buf133, reinterpret_tensor(buf134, (s0*s1, 64), (64, 1), 0), buf137, reinterpret_tensor(buf138, (s0*s1, 2048), (2048, 1), 0), buf141, buf145, reinterpret_tensor(buf146, (s0*s1, 64), (64, 1), 0), buf149, buf150, buf151, buf153, buf154, buf155, buf156, reinterpret_tensor(buf157, (s0*s1, 64), (64, 1), 0), buf160, buf164, reinterpret_tensor(buf165, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf166, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf169, buf170, buf172, buf173, buf174, buf175, reinterpret_tensor(buf176, (s0*s1, 64), (64, 1), 0), buf179, buf183, reinterpret_tensor(buf184, (s0*s1, 64), (64, 1), 0), buf187, reinterpret_tensor(buf188, (s0*s1, 2048), (2048, 1), 0), buf191, buf195, reinterpret_tensor(buf196, (s0*s1, 64), (64, 1), 0), buf199, buf200, buf201, buf203, buf204, buf205, buf206, reinterpret_tensor(buf207, (s0*s1, 64), (64, 1), 0), buf210, buf214, reinterpret_tensor(buf215, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf216, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf219, buf220, buf222, buf223, buf224, buf225, reinterpret_tensor(buf226, (s0*s1, 64), (64, 1), 0), buf229, buf233, reinterpret_tensor(buf234, (s0*s1, 64), (64, 1), 0), buf237, reinterpret_tensor(buf238, (s0*s1, 2048), (2048, 1), 0), buf241, buf245, buf246, buf249, reinterpret_tensor(buf251, (s0*s1, 64), (64, 1), 0), buf254, buf255, buf256, buf258, buf259, buf260, buf261, reinterpret_tensor(buf262, (s0*s1, 64), (64, 1), 0), buf265, buf269, reinterpret_tensor(buf270, (s0*s1, 64), (64, 1), 0), buf273, reinterpret_tensor(buf274, (s0*s1, 2048), (2048, 1), 0), buf277, buf281, reinterpret_tensor(buf282, (s0*s1, 64), (64, 1), 0), buf285, buf286, buf287, buf289, buf290, buf291, buf292, reinterpret_tensor(buf293, (s0*s1, 64), (64, 1), 0), buf296, buf300, reinterpret_tensor(buf301, (s0*s1, 64), (64, 1), 0), buf304, reinterpret_tensor(buf305, (s0*s1, 2048), (2048, 1), 0), buf308, buf312, reinterpret_tensor(buf313, (s0*s1, 64), (64, 1), 0), buf316, buf317, buf318, buf320, buf321, buf322, buf323, reinterpret_tensor(buf324, (s0*s1, 64), (64, 1), 0), buf327, buf331, reinterpret_tensor(buf332, (s0*s1, 64), (64, 1), 0), buf335, reinterpret_tensor(buf336, (s0*s1, 2048), (2048, 1), 0), buf339, buf343, buf344, buf347, buf350, buf351, buf352, buf354, buf355, buf356, buf357, reinterpret_tensor(buf358, (s0*s1, 64), (64, 1), 0), buf361, buf365, reinterpret_tensor(buf366, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf368, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf367, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf371, buf372, buf374, buf375, buf376, buf377, reinterpret_tensor(buf378, (s0*s1, 64), (64, 1), 0), buf381, buf385, reinterpret_tensor(buf386, (s0*s1, 64), (64, 1), 0), buf389, reinterpret_tensor(buf390, (s0*s1, 2048), (2048, 1), 0), buf393, buf397, reinterpret_tensor(buf398, (s0*s1, 64), (64, 1), 0), buf401, buf402, buf403, buf405, buf406, buf407, buf408, reinterpret_tensor(buf409, (s0*s1, 64), (64, 1), 0), buf412, buf416, reinterpret_tensor(buf417, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf418, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf421, buf422, buf424, buf425, buf426, buf427, reinterpret_tensor(buf428, (s0*s1, 64), (64, 1), 0), buf431, buf435, reinterpret_tensor(buf436, (s0*s1, 64), (64, 1), 0), buf439, reinterpret_tensor(buf440, (s0*s1, 2048), (2048, 1), 0), buf443, buf447, reinterpret_tensor(buf448, (s0*s1, 64), (64, 1), 0), buf451, buf452, buf453, buf455, buf456, buf457, buf458, reinterpret_tensor(buf459, (s0*s1, 64), (64, 1), 0), buf462, buf466, reinterpret_tensor(buf467, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(buf468, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf471, buf472, buf474, buf475, buf476, buf477, reinterpret_tensor(buf478, (s0*s1, 64), (64, 1), 0), buf481, buf485, reinterpret_tensor(buf486, (s0*s1, 64), (64, 1), 0), buf489, reinterpret_tensor(buf490, (s0*s1, 2048), (2048, 1), 0), buf493, buf497, buf498, buf501, reinterpret_tensor(buf502, (s0, 1, 1, s1, 64), (64, 64*s0*s1, 64*s0*s1, 64*s0, 1), 0), buf504, primals_186, buf505, primals_184, buf506, primals_180, reinterpret_tensor(primals_178, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_178, (64, 64), (64, 1), 0), buf507, primals_174, primals_173, buf508, primals_168, buf509, primals_166, buf510, primals_162, reinterpret_tensor(primals_160, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_160, (64, 64), (64, 1), 0), buf511, primals_156, primals_155, buf512, primals_150, buf513, primals_148, buf514, primals_144, reinterpret_tensor(primals_142, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_142, (64, 64), (64, 1), 0), buf515, primals_138, primals_137, buf516, primals_130, buf517, primals_128, buf518, primals_124, primals_123, buf519, primals_118, buf520, primals_116, buf521, primals_112, primals_111, buf522, primals_106, buf523, primals_104, buf524, primals_100, primals_99, buf525, primals_92, buf526, primals_90, buf527, primals_86, reinterpret_tensor(primals_84, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_84, (64, 64), (64, 1), 0), buf528, primals_80, primals_79, buf529, primals_74, buf530, primals_72, buf531, primals_68, reinterpret_tensor(primals_66, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_66, (64, 64), (64, 1), 0), buf532, primals_62, primals_61, buf533, primals_56, buf534, primals_54, buf535, primals_50, reinterpret_tensor(primals_48, (128, 64), (64, 1), 4096), reinterpret_tensor(primals_48, (64, 64), (64, 1), 0), buf536, buf537, primals_44, buf538, primals_36, buf539, primals_34, buf540, primals_30, primals_29, buf541, primals_24, buf542, primals_22, buf543, primals_18, primals_17, buf544, primals_12, buf545, primals_10, buf546, buf547, primals_6, s0, s1, s0*s1, 8*s0, )
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_1 = 10
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_2 = 32
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_3 = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_4 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_5 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_6 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_10 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_11 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_12 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_13 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_16 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_17 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_18 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_19 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_22 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_23 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_24 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_25 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_26 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_27 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_28 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_29 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_30 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_31 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_33 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_34 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_35 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_36 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_37 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_39 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_40 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_41 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_42 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_43 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_44 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_45 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_46 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_47 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_48 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_49 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_50 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_51 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_52 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_53 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_54 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_55 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_56 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_57 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_58 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_59 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_60 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_61 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_62 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_63 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_64 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_65 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_66 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_67 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_68 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_69 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_70 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_71 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_72 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_73 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_74 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_75 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_76 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_77 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_78 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_79 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_80 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_81 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_82 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_83 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_84 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_85 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_86 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_87 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_88 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_89 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_90 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_91 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_92 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_93 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_94 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_95 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_96 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_97 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_98 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_99 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_100 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_101 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_102 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_103 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_104 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_105 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_106 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_107 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_108 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_109 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_110 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_111 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_112 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_113 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_114 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_115 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_116 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_117 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_118 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_119 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_120 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_121 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_122 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_123 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_124 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_125 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_126 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_127 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_128 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_129 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_130 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_131 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_132 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_133 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_134 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_135 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_136 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_137 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_138 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_139 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_140 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_141 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_142 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_143 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_144 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_145 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_146 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_147 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_148 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_149 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_150 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_151 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_152 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_153 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_154 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_155 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_156 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_157 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_158 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_159 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_160 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_161 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_162 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_163 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_164 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_165 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_166 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_167 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_168 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_169 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_171 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_172 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_173 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_174 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_175 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_177 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_178 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_179 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_180 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_181 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_183 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_184 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_185 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_186 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_187 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_190 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_191 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191])
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] if __name__ == "__main__":
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:53:56.186000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:53:56.244000 2742634 site-packages/torch/_inductor/graph.py:2022] [213/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/v7/cv7sjws3x2kel5julz32i7b76rfb732yknmulkov5yss4b4d4jao.py
I0204 20:53:57.278000 2742634 site-packages/torch/_inductor/graph.py:2056] [213/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/v7/cv7sjws3x2kel5julz32i7b76rfb732yknmulkov5yss4b4d4jao.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] Output code: 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # AOT ID: ['48_backward']
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import torch
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import random
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import os
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import tempfile
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from math import inf, nan
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from cmath import nanj
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch import device, empty_strided
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     grid,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     split_scan_grid,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     grid_combo_kernels,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     start_graph,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     end_graph,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     cooperative_reduction_grid,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] aten = torch.ops.aten
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] _quantized = torch.ops._quantized
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] async_compile = AsyncCompile()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wt/cwt3c24q25v3wbwug7bkzloqu6tchar2pzvz6ovwpruj5t7erc6b.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.replication_pad3d_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %replication_pad3d_backward : [num_users=1] = call_function[target=torch.ops.aten.replication_pad3d_backward.default](args = (%unsqueeze_20, %unsqueeze_19, [1, 1, 1, 1, 1, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_replication_pad3d_backward_0 = async_compile.triton('triton_poi_fused_replication_pad3d_backward_0', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_replication_pad3d_backward_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_replication_pad3d_backward_0(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex // ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 64*ks2*x1), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fq/cfqcqtvmedn2axwllis7gwxv2d6khvzwkcar4nhhc5gxa32eaqut.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [x_43, output_3], Original ATen: [aten.native_layer_norm_backward, aten.native_layer_norm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   output_3 => mul_2884, sub_1563
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_43 => add_3476, mul_2876
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2919 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_158, %primals_190), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2919, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2876 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2875, %primals_188), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3476 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2876, %primals_189), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1563 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_3476, %getitem_163), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2884 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1563, %rsqrt_33), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2921 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2919, %mul_2884), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2921, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_native_layer_norm_native_layer_norm_backward_1 = async_compile.triton('triton_per_fused_native_layer_norm_native_layer_norm_backward_1', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 13), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_native_layer_norm_backward_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_native_layer_norm_native_layer_norm_backward_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = (xindex % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.load(in_ptr5 + (r0_1 + 64*x3 + 64*ks1*x2), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tmp9 * tmp10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.where(xmask, tmp12, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tl.sum(tmp14, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tmp16 * tmp10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tmp17 * tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.where(xmask, tmp19, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.sum(tmp21, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp15, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp22, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2w/c2w4bvmtwigbohqueimykwsa5uikwlmb5lrszqjsv3seggnxlq4x.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2924 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_158, %mul_2884), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2924, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%permute_158, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_native_layer_norm_backward_2 = async_compile.triton('triton_red_fused_native_layer_norm_backward_2', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_native_layer_norm_backward_2(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp12 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + 64*ks1*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 * tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = tl.where(tmp2, tmp5, tmp6)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.broadcast_to(tmp7, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp11 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp13 = _tmp12 + tmp11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp12 = tl.where(r0_mask & xmask, tmp13, _tmp12)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tl.sum(_tmp12, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp9, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp12, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nq/cnqzdgcmljbsndm3wkvbcjy72e45gig7jnsgeqngkbt4jj3ts2px.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2924 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_158, %mul_2884), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2924, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_native_layer_norm_backward_3 = async_compile.triton('triton_per_fused_native_layer_norm_backward_3', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 64, 'r0_': 4},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_native_layer_norm_backward_3(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kv/ckv5mjkpbqyiqwuszih4vohl6o3vwzzv5ekpvi776mbwydarksxg.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2919 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_158, %primals_190), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2920 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2919, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2922 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2884, %sum_2), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1586 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2920, %sum_1), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1587 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1586, %mul_2922), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_33, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2923 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %sub_1587), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2926 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2923, %primals_188), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2927 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2926, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2926, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2928 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2926, %mul_2875), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2928, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2929 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2875, %sum_6), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1589 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2927, %sum_5), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1590 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1589, %mul_2929), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2930 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_2, %sub_1590), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_41, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2932 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2933 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2930, %mul_2932), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_native_dropout_backward_native_layer_norm_backward_4 = async_compile.triton('triton_per_fused_native_dropout_backward_native_layer_norm_backward_4', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_dropout_backward_native_layer_norm_backward_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 10, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_native_dropout_backward_native_layer_norm_backward_4(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr2, out_ptr3, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // ks0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_2 + 64*x1 + 64*ks1*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (r0_2), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr3 + (x1 + ks1*x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tl.load(in_out_ptr0 + (r0_2 + 64*x3), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x3), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tl.load(in_ptr5 + (r0_2), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.load(in_ptr6 + (r0_2 + 64*x3), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp27 = tl.load(in_ptr7 + (x3), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = tl.load(in_ptr8 + (r0_2 + 64*x3), xmask, other=0.0).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = 0.015625
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = 64.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tmp5 * tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tmp7 - tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp9 - tmp12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tmp2 * tmp13
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tmp16 * tmp21
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tl.broadcast_to(tmp22, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tl.where(xmask, tmp23, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tl.sum(tmp25, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tmp16 * tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tmp28 - tmp20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = tmp21 * tmp26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = tmp29 - tmp30
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp27 * tmp31
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = tmp33.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tmp32 * tmp36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_2 + 64*x3), tmp14, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr2 + (r0_2 + 64*x3), tmp32, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr3 + (r0_2 + 64*x3), tmp37, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wo/cwo5haoxmftxthtpcuzgwnlprsy7lpcehngplprld6lx4nfqrtvp.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2931 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2923, %mul_2875), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2931, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2923, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_native_layer_norm_backward_5 = async_compile.triton('triton_red_fused_native_layer_norm_backward_5', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_native_layer_norm_backward_5(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp9 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp12 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 * tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = tl.where(tmp2, tmp5, tmp6)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.broadcast_to(tmp7, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = _tmp9 + tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp9 = tl.where(r0_mask & xmask, tmp10, _tmp9)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp11 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp13 = _tmp12 + tmp11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp12 = tl.where(r0_mask & xmask, tmp13, _tmp12)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.sum(_tmp9, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tl.sum(_tmp12, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp9, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp12, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ki/cki26n53xjvyu635bpexx5dq73q3qeurzk4qq4rf3ab2jvlqn56y.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_258, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_sum_6 = async_compile.triton('triton_red_fused_sum_6', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_sum_6(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*r0_2 + 64*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/24/c247xvqyipfujunjf6h3ainpsl2dgmxk2c6vwa3whpvmiytvkmr6.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten.threshold_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_40, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2934 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_1, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2935 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_260, %mul_2934), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %full_default : [num_users=13] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default, %mul_2935), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_native_dropout_backward_threshold_backward_7 = async_compile.triton('triton_poi_fused_native_dropout_backward_threshold_backward_7', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_threshold_backward_7', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_native_dropout_backward_threshold_backward_7(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), xmask).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp1 * tmp5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = 0.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ip/cipv2rdt3om3hee34rcnttfntmurwbeqvkpzamp4jwm5djauwxzm.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3536 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2930, %view_263), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2942 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3536, %mul_2819), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2942, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3536, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_8 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_8', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_8(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp16 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = tmp5 * tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp9 = tl.where(tmp2, tmp7, tmp8)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp13 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp14 = tl.where(tmp2, tmp5, tmp13)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp17 = _tmp16 + tmp15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp16 = tl.where(r0_mask & xmask, tmp17, _tmp16)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.sum(_tmp16, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp11, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j7/cj7ueo4oos7aahkfajtcg62iecmm2yno3fumy5zw7rmmq3qllkfy.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3536 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2930, %view_263), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2937 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3536, %primals_182), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2938 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2937, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2937, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2939 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2937, %mul_2819), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2939, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2940 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2819, %sum_12), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1592 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2938, %sum_11), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1593 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1592, %mul_2940), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2941 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_3, %sub_1593), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_39, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2943 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_2944 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_2941, %mul_2943), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp4 * tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = 64.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tmp4 * tmp16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tmp17 - tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tmp9 * tmp14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tmp18 - tmp19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tmp15 * tmp20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp23 * tmp24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tmp21 * tmp25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp21, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 64*x0), tmp26, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ry/cryqmdyd6wbe2jgxc4urnbfd5rw6jkdsl3mhaivqmhytu3wzei3w.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_50 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_22,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_clone_10 = async_compile.triton('triton_poi_fused_clone_10', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 65536}, 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_clone_10(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % 2)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = ((xindex // 128) % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = (xindex % 128)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = x1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 == tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = 0.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tmp0 == tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp5 + tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4 + 128*x3 + 128*ks2*x2), tmp10, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/eb/cebb2whgiwd27swle777pd6qcp6gaoynouybr7nmpl7if22cfgjp.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %view_277 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view_272, [%mul_5, 64]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_view_11 = async_compile.triton('triton_poi_fused_view_11', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 32768}, 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_view_11(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*((x1 % ks0)) + 64*ks0*(x1 // ks0)) // (64*ks0)) % ks1)) + 64*ks1*(((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ax/caxwmkspx4cchzdjhuovae4p4626sqrqdau55shajfq4rtu7dpzi.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_277, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_278, %view_275],), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_cat_sum_12 = async_compile.triton('triton_per_fused_cat_sum_12', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 64, 'r0_': 4},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_12', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_cat_sum_12(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e6/ce6ko2ui4phusk24524x64nn7cuiyivbdoduouimzupeb4miulk3.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_274, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_sum_13 = async_compile.triton('triton_red_fused_sum_13', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_sum_13(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 384
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 128
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 128)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 128*r0_2 + 128*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4t/c4tr7ox6z5c3v2hass3a2zigq4v7xcgsvn5jlzv2kbas3ruo6x3i.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_274, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_278, %view_275],), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_cat_sum_14 = async_compile.triton('triton_per_fused_cat_sum_14', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 128, 'r0_': 4},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_cat_sum_14(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 128
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/li/clicx6zfqcwesrwjjzdthvlu4ffuf22o2xmevp6wvuuolnvkhpeh.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %clone_58 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_23,), kwargs = {memory_format: torch.contiguous_format})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_poi_fused_clone_15 = async_compile.triton('triton_poi_fused_clone_15', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.pointwise(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 65536}, 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     min_elem_per_thread=0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_poi_fused_clone_15(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = ((xindex // 64) % 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = ((xindex // 192) % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x4 = (xindex % 192)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = x1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 == tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = 0.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tmp0 == tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp5 + tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp0 == tmp11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tmp10 + tmp14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x4 + 192*x3 + 192*ks2*x2), tmp15, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g3/cg3kwplnxw7aga32wevjbrdulzl5b6lazjfhb4okajtj75lst42w.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_290, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_sum_16 = async_compile.triton('triton_red_fused_sum_16', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1024, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_sum_16(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 576
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 192)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 192*r0_2 + 192*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3b/c3b4dxgj7zmuwa7ig6poyvrcdpfoklef6uavaeacu7jmxsil2e65.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_290, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_sum_17 = async_compile.triton('triton_per_fused_sum_17', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 4},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_sum_17(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 192*r0_1), r0_mask & xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4x/c4x4lej5dmlob3llv446b2mdc7tkoe7fdb3jvzu3wo2ajye6uh4e.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_261, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_sum_18 = async_compile.triton('triton_red_fused_sum_18', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 8192, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_sum_18(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 6144
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 2048
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 2048)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 2048*r0_2 + 2048*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/op/copxfozokssvstshz24nqrswndnvdg7ldglwcwzi7gybxssjmnwx.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_261, [0], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_sum_19 = async_compile.triton('triton_per_fused_sum_19', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 2048, 'r0_': 4},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_sum_19(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 2048
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), r0_mask & xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/h4/ch4gvhmz7ee2cn32bfikerow5vwml4oosvap7y6mvk7g34d5o6tb.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [x_31, output_2], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   output_2 => mul_1993, sub_1073
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_31 => add_2379, mul_1985
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3544 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_276, %view_311), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3551 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3544, %view_346), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3013 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3551, %primals_134), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3014 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3013, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_62 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3013, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1985 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1984, %primals_132), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_2379 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1985, %primals_133), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1073 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_2379, %getitem_107), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1993 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1073, %rsqrt_23), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3015 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3013, %mul_1993), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_63 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3015, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3016 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1993, %sum_63), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1616 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3014, %sum_62), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1617 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1616, %mul_3016), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_11 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_23, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3017 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_11, %sub_1617), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3020 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3017, %primals_132), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3021 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3020, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_66 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3020, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3022 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3020, %mul_1984), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_67 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3022, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3023 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1984, %sum_67), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1619 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3021, %sum_66), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1620 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1619, %mul_3023), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3024 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_12, %sub_1620), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type_12 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_29, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3026 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_12, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3027 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3024, %mul_3026), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*i1', 'out_ptr0': '*fp32', 'out_ptr3': '*fp32', 'out_ptr6': '*fp32', 'out_ptr7': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 11, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, out_ptr0, out_ptr3, out_ptr6, out_ptr7, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tl.load(in_ptr6 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tl.load(in_ptr7 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.load(in_ptr8 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp43 = tl.load(in_ptr9 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp49 = tl.load(in_ptr10 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tmp11 + tmp12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tl.where(xmask, tmp16, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tmp15 * tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tl.where(xmask, tmp21, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = tl.sum(tmp23, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = 0.015625
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tmp7 * tmp25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp27 = 64.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tmp15 * tmp27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tmp28 - tmp19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = tmp8 * tmp24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = tmp29 - tmp30
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp26 * tmp31
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = tmp32 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp34 = tl.broadcast_to(tmp33, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tl.where(xmask, tmp34, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tl.sum(tmp36, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = tmp33 * tmp0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp39 = tl.broadcast_to(tmp38, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = tl.where(xmask, tmp39, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp42 = tl.sum(tmp41, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp44 = tmp33 * tmp27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp45 = tmp44 - tmp37
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp46 = tmp0 * tmp42
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp47 = tmp45 - tmp46
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp48 = tmp43 * tmp47
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp50 = tmp49.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp51 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp52 = tmp50 * tmp51
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp53 = tmp48 * tmp52
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 64*x0), tmp32, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp48, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr7 + (r0_1 + 64*x0), tmp53, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/53/c53uwk33h2fy7r466re6w63toupde6vnopiyh6bt4hebsxg6453v.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3544 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_276, %view_311), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3551 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3544, %view_346), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3018 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3551, %mul_1993), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_64 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3018, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_65 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3551, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_21 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_21', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_21(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp13 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp18 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = tmp5 + tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp9 = tmp7 * tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = tl.full(tmp9.shape, 0, tmp9.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp11 = tl.where(tmp2, tmp9, tmp10)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp12 = tl.broadcast_to(tmp11, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp14 = _tmp13 + tmp12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp13 = tl.where(r0_mask & xmask, tmp14, _tmp13)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp15 = tl.full(tmp7.shape, 0, tmp7.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp16 = tl.where(tmp2, tmp7, tmp15)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp17 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp19 = _tmp18 + tmp17
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp18 = tl.where(r0_mask & xmask, tmp19, _tmp18)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tl.sum(_tmp13, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tl.sum(_tmp18, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp13, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp18, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6k/c6k6qxtuufagkxgkp3qsrdq3sndbnj5k46fblldygjvli3k234yf.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, output_1], Original ATen: [aten.threshold_backward, aten.add, aten.native_layer_norm, aten.hardswish_backward, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   output_1 => add_1747, mul_1461, mul_1462, sub_782
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   x_21 => add_1733, mul_1453
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %full_default : [num_users=13] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3555 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3008, %view_362), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3565 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3555, %mul_3075), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3568 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3565, %view_419), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1452, %primals_94), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1733 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1453, %primals_95), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_782 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_1733, %getitem_81), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1461 : [num_users=4] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_782, %rsqrt_16), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_1462 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1461, %primals_96), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_1747 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_1462, %primals_97), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %lt_13 : [num_users=1] = call_function[target=torch.ops.aten.lt.Scalar](args = (%add_1747, -3), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %le_6 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%add_1747, 3), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_18 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_1747, 3), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3569 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%div_18, 0.5), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3079 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3568, %add_3569), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %where_6 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_6, %mul_3079, %add_3568), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %where_7 : [num_users=3] = call_function[target=torch.ops.aten.where.self](args = (%lt_13, %full_default, %where_6), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3081 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where_7, %primals_96), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3082 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3081, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_102 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3081, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3083 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3081, %mul_1461), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_103 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3083, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3084 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1461, %sum_103), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1637 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3082, %sum_102), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1638 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1637, %mul_3084), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %div_19 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_16, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3085 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_19, %sub_1638), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3088 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3085, %primals_94), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3089 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3088, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_106 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3088, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3090 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3088, %mul_1452), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_107 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3090, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3091 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1452, %sum_107), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1640 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3089, %sum_106), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1641 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1640, %mul_3091), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3092 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_20, %sub_1641), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type_21 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_20, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3094 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_21, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3095 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3092, %mul_3094), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22 = async_compile.triton('triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'in_ptr8': '*fp32', 'in_ptr9': '*fp32', 'in_ptr10': '*fp32', 'in_ptr11': '*i1', 'out_ptr0': '*fp32', 'out_ptr3': '*fp32', 'out_ptr6': '*fp32', 'out_ptr7': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 13, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, out_ptr0, out_ptr3, out_ptr6, out_ptr7, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.load(in_ptr6 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tl.load(in_ptr7 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tl.load(in_ptr8 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.load(in_ptr9 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp60 = tl.load(in_ptr10 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp66 = tl.load(in_ptr11 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp6 = tmp4 - tmp5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp8 * tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = -3.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tmp12 < tmp13
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = 3.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tmp12 <= tmp15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tmp17 + tmp18
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp21 + tmp22
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = 0.3333333333333333
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp12 * tmp24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = 0.5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp27 = tmp25 + tmp26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp28 = tmp23 * tmp27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp29 = tl.where(tmp16, tmp28, tmp23)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp30 = 0.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp31 = tl.where(tmp14, tmp30, tmp29)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp32 = tmp31 * tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp33 = tl.broadcast_to(tmp32, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp35 = tl.where(xmask, tmp33, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp36 = tl.sum(tmp35, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp37 = tmp32 * tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp38 = tl.broadcast_to(tmp37, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp40 = tl.where(xmask, tmp38, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp41 = tl.sum(tmp40, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp42 = 0.015625
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp43 = tmp7 * tmp42
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp44 = 64.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp45 = tmp32 * tmp44
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp46 = tmp45 - tmp36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp47 = tmp8 * tmp41
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp48 = tmp46 - tmp47
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp49 = tmp43 * tmp48
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp50 = tmp49 * tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp51 = tl.broadcast_to(tmp50, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp53 = tl.where(xmask, tmp51, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp54 = tl.sum(tmp53, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp55 = tmp50 * tmp0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp56 = tl.broadcast_to(tmp55, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp58 = tl.where(xmask, tmp56, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp59 = tl.sum(tmp58, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp61 = tmp50 * tmp44
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp62 = tmp61 - tmp54
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp63 = tmp0 * tmp59
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp64 = tmp62 - tmp63
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp65 = tmp60 * tmp64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp67 = tmp66.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp68 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp69 = tmp67 * tmp68
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp70 = tmp65 * tmp69
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (r0_1 + 64*x0), tmp8, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp31, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr3 + (r0_1 + 64*x0), tmp49, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr6 + (r0_1 + 64*x0), tmp65, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr7 + (r0_1 + 64*x0), tmp70, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e5/ce5rcumyadd3kd7zeigowggk7vjauhkjfyn54ixomxo4qc7y37sl.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3586 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3161, %view_511), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3171 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3586, %mul_3165), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_159 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3171, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_160 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_3586, [0, 1]), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_23 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_23', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_23(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp16 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 + tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (x0 + 64*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + 64*ks1*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = tmp5 * tmp6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp9 = tl.where(tmp2, tmp7, tmp8)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp13 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp14 = tl.where(tmp2, tmp5, tmp13)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp17 = _tmp16 + tmp15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp16 = tl.where(r0_mask & xmask, tmp17, _tmp16)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = tl.sum(_tmp16, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp11, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/on/conlhq3nlmxbisoujykkjeswizabiewr6qddthj5vhpsjydckymx.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %add_3586 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_3161, %view_511), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3166 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_3586, %primals_46), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3167 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3166, 64), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_157 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3166, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3168 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3166, %mul_3165), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_158 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_3168, [2], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3169 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3165, %sum_158), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1664 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_3167, %sum_157), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sub_1665 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_1664, %mul_3169), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3170 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_28, %sub_1665), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %convert_element_type_32 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_9, torch.float32), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3172 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_32, 1.1111111111111112), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %mul_3173 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3170, %mul_3172), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_numel = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_offset = 0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_1 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x2 = (xindex % ks0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex // ks0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x3 + 64*ks1*x2), xmask, other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp10 = tmp4 * tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp16 = 64.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp17 = tmp4 * tmp16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp18 = tmp17 - tmp8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp19 = tmp9 * tmp14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp20 = tmp18 - tmp19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp21 = tmp15 * tmp20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp24 = 1.1111111111111112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp25 = tmp23 * tmp24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp26 = tmp21 * tmp25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp26, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ay/cay3ftq5gcplxiv7nfcacwy7wt234ybiucairwuzcvtmnamc4pye.py
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Source node to ATen node mapping:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] # Graph fragment:
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] #   %sum_162 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_521, [0, 1], True), kwargs = {})
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_red_fused_sum_25 = async_compile.triton('triton_red_fused_sum_25', '''
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] import triton.language as tl
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton_heuristics.reduction(
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     size_hints={'x': 1024, 'r0_': 128},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     filename=__file__,
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_25', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] @triton.jit
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def triton_red_fused_sum_25(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xnumel = 576
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rnumel = r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     xmask = xindex < xnumel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rbase = r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x1 = xindex // 192
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x0 = (xindex % 192)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     x3 = xindex
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         roffset = r0_offset
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         rindex = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         r0_2 = r0_index
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp1 = ks0*ks1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp3 = tl.broadcast_to(x0 // 64, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp4 = tl.full([1, 1], 2, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp5 = tmp3 == tmp4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp6 = tl.load(in_ptr0 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp7 = 0.0
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp8 = tl.where(tmp5, tmp6, tmp7)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp9 = tl.full([1, 1], 1, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp10 = tmp3 == tmp9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp11 = tl.load(in_ptr1 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp12 = tl.where(tmp10, tmp11, tmp7)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp13 = tmp8 + tmp12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp14 = tl.full([1, 1], 0, tl.int32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp15 = tmp3 == tmp14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp16 = tl.load(in_ptr2 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp17 = tl.where(tmp15, tmp16, tmp7)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp18 = tmp13 + tmp17
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp19 = tl.full(tmp18.shape, 0, tmp18.dtype)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp20 = tl.where(tmp2, tmp18, tmp19)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp22, xmask)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] ''', device_str='cuda')
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] async_compile.wait(globals())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] del async_compile
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def call(args):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_1, primals_2, mul_5, mul_68, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_97, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, gt_1, view_13, gt_2, mul_190, view_15, view_21, view_22, view_23, getitem_8, getitem_9, getitem_10, getitem_11, view_24, gt_3, mul_307, view_26, gt_4, view_28, gt_5, mul_363, view_30, view_36, view_37, view_38, getitem_16, getitem_17, getitem_18, getitem_19, view_39, gt_6, mul_480, view_41, gt_7, view_43, gt_8, mul_536, getitem_25, rsqrt_6, view_51, view_52, view_53, getitem_26, getitem_27, getitem_28, getitem_29, view_54, gt_9, view_56, view_58, view_64, view_65, view_66, getitem_36, getitem_37, getitem_38, getitem_39, view_67, gt_10, mul_808, view_69, gt_11, view_71, gt_12, mul_864, view_73, view_79, view_80, view_81, getitem_44, getitem_45, getitem_46, getitem_47, view_82, gt_13, mul_981, view_84, view_92, view_93, view_94, getitem_54, getitem_55, getitem_56, getitem_57, view_95, gt_14, mul_1102, view_97, gt_15, view_99, gt_16, mul_1158, view_101, view_107, view_108, view_109, getitem_62, getitem_63, getitem_64, getitem_65, view_110, gt_17, mul_1275, view_112, view_120, view_121, view_122, getitem_72, getitem_73, getitem_74, getitem_75, view_123, gt_18, mul_1396, view_125, gt_19, view_127, gt_20, mul_1452, getitem_81, rsqrt_16, view_129, view_135, view_136, view_137, getitem_82, getitem_83, getitem_84, getitem_85, view_138, gt_21, mul_1582, view_140, gt_22, view_142, gt_23, mul_1638, view_144, view_150, view_151, view_152, getitem_90, getitem_91, getitem_92, getitem_93, view_153, gt_24, mul_1755, view_155, gt_25, view_157, gt_26, mul_1811, view_159, view_165, view_166, view_167, getitem_98, getitem_99, getitem_100, getitem_101, view_168, gt_27, mul_1928, view_170, gt_28, view_172, gt_29, mul_1984, getitem_107, rsqrt_23, view_180, view_181, view_182, getitem_108, getitem_109, getitem_110, getitem_111, view_183, gt_30, mul_2106, view_185, view_187, view_193, view_194, view_195, getitem_118, getitem_119, getitem_120, getitem_121, view_196, gt_31, mul_2231, view_198, gt_32, view_200, gt_33, mul_2287, view_202, view_208, view_209, view_210, getitem_126, getitem_127, getitem_128, getitem_129, view_211, gt_34, mul_2404, view_213, view_221, view_222, view_223, getitem_136, getitem_137, getitem_138, getitem_139, view_224, gt_35, mul_2525, view_226, gt_36, view_228, gt_37, mul_2581, view_230, view_236, view_237, view_238, getitem_144, getitem_145, getitem_146, getitem_147, view_239, gt_38, mul_2698, view_241, view_249, view_250, view_251, getitem_154, getitem_155, getitem_156, getitem_157, view_252, gt_39, mul_2819, view_254, gt_40, view_256, gt_41, mul_2875, getitem_163, rsqrt_33, unsqueeze_19, div_2, permute_159, le, permute_163, div_3, permute_167, permute_176, permute_180, div_4, permute_184, permute_193, div_5, permute_197, le_1, permute_201, div_6, permute_205, permute_214, permute_218, div_7, permute_222, permute_231, div_8, permute_235, le_2, permute_239, div_9, permute_243, permute_252, permute_256, div_10, permute_260, permute_269, div_12, permute_273, le_3, permute_277, div_13, permute_281, permute_290, div_14, permute_294, le_4, permute_298, div_15, permute_302, permute_311, div_16, permute_315, le_5, permute_319, div_17, permute_323, permute_332, div_20, permute_336, le_7, permute_340, div_21, permute_344, permute_353, permute_357, div_22, permute_361, permute_370, div_23, permute_374, le_8, permute_378, div_24, permute_382, permute_391, permute_395, div_25, permute_399, permute_408, div_26, permute_412, le_9, permute_416, div_27, permute_420, permute_429, permute_433, mul_3165, div_28, permute_437, div_30, permute_449, le_10, permute_453, div_31, permute_457, permute_466, div_32, permute_470, le_11, permute_474, div_33, permute_478, permute_487, div_34, permute_491, le_12, permute_495, mul_3232, div_35, permute_499, tangents_1 = args
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     args.clear()
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     s0 = primals_1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     s1 = primals_2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_26, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_32, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_38, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_39, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_40, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_46, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_52, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_58, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_64, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_70, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_76, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_82, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_88, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_94, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_95, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_96, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_97, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_102, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_108, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_114, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_120, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_126, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_132, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_133, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_134, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_140, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_146, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_152, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_158, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_164, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(primals_190, (64, ), (1, ))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_6, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_7, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_8, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_1, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_2, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_3, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_9, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_11, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_1, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_13, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_2, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_190, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_15, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_21, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_22, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_23, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_8, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_9, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_10, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_11, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_24, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_3, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_307, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_26, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_4, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_28, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_5, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_363, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_30, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_36, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_37, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_38, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_16, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_17, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_18, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_19, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_39, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_6, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_480, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_41, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_7, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_43, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_8, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_536, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_25, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(rsqrt_6, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_51, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_52, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_53, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_26, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_27, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_28, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_29, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_54, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_9, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_56, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_58, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_64, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_65, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_66, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_36, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_37, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_38, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_39, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_67, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_10, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_808, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_69, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_11, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_71, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_12, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_864, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_73, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_79, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_80, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_81, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_44, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_45, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_46, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_47, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_82, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_13, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_981, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_84, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_92, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_93, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_94, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_54, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_55, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_56, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_57, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_95, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_14, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1102, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_97, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_15, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_99, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_16, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1158, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_101, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_107, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_108, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_109, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_62, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_63, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_64, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_65, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_110, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_17, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1275, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_112, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_120, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_121, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_122, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_72, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_73, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_74, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_75, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_123, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_18, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1396, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_125, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_19, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_127, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_20, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1452, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_81, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(rsqrt_16, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_129, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_135, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_136, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_137, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_82, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_83, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_84, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_85, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_138, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_21, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1582, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_140, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_22, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_142, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_23, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1638, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_144, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_150, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_151, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_152, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_90, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_91, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_92, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_93, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_153, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_24, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1755, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_155, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_25, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_157, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_26, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1811, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_159, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_165, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_166, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_167, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_98, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_99, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_100, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_101, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_168, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_27, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1928, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_170, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_28, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_172, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_29, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_1984, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_107, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(rsqrt_23, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_180, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_181, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_182, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_108, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_109, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_110, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_111, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_183, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_30, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2106, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_185, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_187, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_193, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_194, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_195, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_118, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_119, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_120, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_121, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_196, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_31, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2231, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_198, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_32, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_200, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_33, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2287, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_202, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_208, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_209, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_210, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_126, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_127, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_128, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_129, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_211, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_34, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2404, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_213, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_221, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_222, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_223, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_136, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_137, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_138, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_139, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_224, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_35, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2525, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_226, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_36, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_228, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_37, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2581, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_230, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_236, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_237, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_238, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_144, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_145, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_146, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_147, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_239, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_38, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2698, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_241, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_249, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_250, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_251, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_154, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_155, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_156, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_157, (), ())
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_252, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_39, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2819, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_254, (s0*s1, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_40, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(view_256, (s0*s1, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(gt_41, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_2875, (s1, s0, 64), (64*s0, 64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(getitem_163, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(rsqrt_33, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(unsqueeze_19, (s0, 1, 1, s1, 64), (64, 64*s0*s1, 64*s0*s1, 64*s0, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_2, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_159, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_163, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_3, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_167, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_176, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_180, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_4, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_184, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_193, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_5, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_197, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_1, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_201, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_6, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_205, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_214, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_218, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_7, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_222, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_231, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_8, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_235, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_2, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_239, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_9, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_243, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_252, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_256, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_10, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_260, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_269, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_12, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_273, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_3, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_277, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_13, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_281, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_290, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_14, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_294, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_4, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_298, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_15, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_302, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_311, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_16, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_315, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_5, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_319, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_17, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_323, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_332, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_20, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_336, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_7, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_340, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_21, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_344, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_353, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_357, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_22, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_361, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_370, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_23, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_374, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_8, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_378, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_24, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_382, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_391, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_395, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_25, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_399, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_408, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_26, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_412, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_9, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_416, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_27, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_420, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_429, (128, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_433, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_3165, (s1, s0, 64), (64, 64*s1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_28, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_437, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_30, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_449, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_10, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_453, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_31, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_457, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_466, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_32, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_470, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_11, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_474, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_33, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_478, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_487, (192, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_34, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_491, (64, 2048), (2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(le_12, (s1, s0, 2048), (2048*s0, 2048, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_495, (2048, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(mul_3232, (s1, s0, 64), (64, 64*s1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(div_35, (s1, s0, 1), (s0, 1, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(permute_499, (64, 64), (64, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     assert_size_stride(tangents_1, (s0, 3, 2 + s1, 66), (396 + 198*s1, 132 + 66*s1, 66, 1))
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         torch.cuda.set_device(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps0 = 64*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf0 = empty_strided_cuda((s0, 1, 1, s1, 64), (64*s1, 64*s1, 64*s1, 64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.replication_pad3d_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_replication_pad3d_backward_0_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_replication_pad3d_backward_0.run(unsqueeze_19, buf0, s1, ps0, s0, triton_poi_fused_replication_pad3d_backward_0_xnumel, grid=grid(triton_poi_fused_replication_pad3d_backward_0_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del unsqueeze_19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.replication_pad3d_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf1 = torch.ops.aten.replication_pad3d_backward.default(reinterpret_tensor(tangents_1, (s0, 1, 3, 2 + s1, 66), (396 + 198*s1, 396 + 198*s1, 132 + 66*s1, 66, 1), 0), buf0, [1, 1, 1, 1, 1, 1])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del tangents_1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf2 = buf1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf4 = reinterpret_tensor(buf0, (s1, s0, 64), (64*s0, 64, 1), 0); del buf0  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf3 = empty_strided_cuda((s1, s0, 1), (1, s1, s0*s1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf5 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_43, output_3], Original ATen: [aten.native_layer_norm_backward, aten.native_layer_norm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_native_layer_norm_backward_1_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_native_layer_norm_backward_1.run(mul_2875, primals_188, primals_189, getitem_163, rsqrt_33, buf2, primals_190, buf4, buf3, buf5, s0, s1, triton_per_fused_native_layer_norm_native_layer_norm_backward_1_xnumel, 64, grid=grid(triton_per_fused_native_layer_norm_native_layer_norm_backward_1_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_163
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_189
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf7 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf9 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_2_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_2.run(buf2, buf4, buf7, buf9, s0, s1, 192, triton_red_fused_native_layer_norm_backward_2_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf8 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf7, buf8, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf10 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf9, buf10, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf6 = buf4; del buf4  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf13 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf18 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_4_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_dropout_backward_native_layer_norm_backward_4.run(buf6, rsqrt_33, buf2, primals_190, buf3, buf5, primals_188, mul_2875, div_2, gt_41, buf13, buf18, s0, s1, triton_per_fused_native_dropout_backward_native_layer_norm_backward_4_xnumel, 64, grid=grid(triton_per_fused_native_dropout_backward_native_layer_norm_backward_4_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_41
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_188
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_190
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del rsqrt_33
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf14 = buf9; del buf9  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf16 = buf7; del buf7  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5.run(buf6, mul_2875, buf14, buf16, s0, s1, 192, triton_red_fused_native_layer_norm_backward_5_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2875
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf15 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf14, buf15, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf17 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf16, buf17, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf21 = reinterpret_tensor(buf16, (1, 64, 3), (192, 1, 64), 0); del buf16  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf18, buf21, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf22 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf21, buf22, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf20 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (64, s0*s1), (1, 64), 0), view_256, out=buf20)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_256
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf19 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf18, (s0*s1, 64), (64, 1), 0), permute_159, out=buf19)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_159
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf23 = reinterpret_tensor(buf19, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf19  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_dropout_backward, aten.threshold_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf23, le, gt_40, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_40
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf24 = reinterpret_tensor(buf18, (s0*s1, 64), (64, 1), 0); del buf18  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (s0*s1, 2048), (2048, 1), 0), permute_163, out=buf24)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_163
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf31 = reinterpret_tensor(buf21, (64, 3), (1, 64), 0); del buf21  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf33 = buf14; del buf14  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf13, buf24, mul_2819, buf31, buf33, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf30 = buf13; del buf13  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf35 = buf6; del buf6  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf30, buf24, primals_182, mul_2819, div_3, gt_39, buf35, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_39
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2819
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_182
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf37 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (64, s0*s1), (1, 64), 0), view_252, out=buf37)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_252
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf32 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf31, buf32, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf34 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf33, buf34, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf38 = reinterpret_tensor(buf33, (1, 64, 3), (192, 1, 64), 0); del buf33  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf35, buf38, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf36 = buf24; del buf24  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf35, (s0*s1, 64), (64, 1), 0), permute_167, out=buf36)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf35
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_167
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf40 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf36, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_249, view_250, view_251, None, getitem_154, getitem_155, getitem_156, getitem_157, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_154
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_155
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_156
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_157
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_249
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_250
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_251
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf39 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf38, buf39, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf41 = buf40[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf42 = buf40[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf43 = buf40[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf40
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps1 = 128*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf44 = empty_strided_cuda((s1, s0, 2, 64), (128*s0, 128, 64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf43, buf42, buf44, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf42
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf49 = reinterpret_tensor(buf43, (s0*s1, 64), (64, 1), 0); del buf43  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf41, buf49, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf57 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf51 = reinterpret_tensor(buf57, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf49, (64, s0*s1), (1, 64), 0), view_241, out=buf51)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_241
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf52 = buf38; del buf38  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf49, buf52, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf50 = reinterpret_tensor(buf41, (s0*s1, 64), (64, 1), 0); del buf41  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf49, permute_180, out=buf50)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_180
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf56 = reinterpret_tensor(buf31, (192, ), (1, ), 0); del buf31  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf54 = reinterpret_tensor(buf56, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf52, buf54, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf47 = empty_strided_cuda((1, 128, 3), (384, 1, 128), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf44, buf47, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf55 = reinterpret_tensor(buf56, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf47, buf55, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf61 = reinterpret_tensor(buf52, (64, 3), (1, 64), 0); del buf52  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf63 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf30, buf50, mul_2698, buf61, buf63, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf60 = buf30; del buf30  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf65 = reinterpret_tensor(buf49, (s1, s0, 64), (64*s0, 64, 1), 0); del buf49  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf60, buf50, primals_176, mul_2698, div_4, gt_38, buf65, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_38
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2698
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_176
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf67 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf65, (64, s0*s1), (1, 64), 0), view_239, out=buf67)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_239
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf62 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf61, buf62, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf64 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf63, buf64, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf68 = reinterpret_tensor(buf63, (1, 64, 3), (192, 1, 64), 0); del buf63  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf65, buf68, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf66 = buf50; del buf50  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf65, (s0*s1, 64), (64, 1), 0), permute_184, out=buf66)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf65
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_184
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf70 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf66, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_236, view_237, view_238, None, getitem_144, getitem_145, getitem_146, getitem_147, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf66
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_144
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_145
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_146
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_147
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_236
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_237
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_238
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf69 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf68, buf69, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf71 = buf70[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf72 = buf70[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf73 = buf70[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf70
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         ps2 = 192*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf74 = empty_strided_cuda((s1, s0, 3, 64), (192*s0, 192, 64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf73, buf72, buf71, buf74, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf76 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf74, (192, s0*s1), (1, 192), 0), view_230, out=buf76)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_230
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf77 = empty_strided_cuda((1, 192, 3), (576, 1, 192), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf74, buf77, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf75 = reinterpret_tensor(buf73, (s0*s1, 64), (64, 1), 0); del buf73  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf74, (s0*s1, 192), (192, 1), 0), permute_193, out=buf75)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_193
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf78 = reinterpret_tensor(buf68, (1, 192), (192, 1), 0); del buf68  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf77, buf78, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf82 = buf61; del buf61  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf84 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf60, buf75, mul_2581, buf82, buf84, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf81 = buf60; del buf60  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf86 = reinterpret_tensor(buf72, (s1, s0, 64), (64*s0, 64, 1), 0); del buf72  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf81, buf75, primals_170, mul_2581, div_5, gt_37, buf86, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_37
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2581
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_170
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf88 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf86, (64, s0*s1), (1, 64), 0), view_228, out=buf88)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_228
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf83 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf82, buf83, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf85 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf84, buf85, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf89 = reinterpret_tensor(buf84, (1, 64, 3), (192, 1, 64), 0); del buf84  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf86, buf89, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf90 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf89, buf90, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf26 = empty_strided_cuda((1, 2048, 3), (6144, 1, 2048), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf23, buf26, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf25 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf23, (2048, s0*s1), (1, 2048), 0), view_254, out=buf25)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_254
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf27 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf26, buf27, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf46 = reinterpret_tensor(buf57, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (128, s0*s1), (1, 128), 0), view_187, out=buf46)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf45 = buf75; del buf75  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (s0*s1, 128), (128, 1), 0), permute_176, out=buf45)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_176
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf87 = reinterpret_tensor(buf23, (s0*s1, 2048), (2048, 1), 0); del buf23  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf86, (s0*s1, 64), (64, 1), 0), permute_197, out=buf87)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_197
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf91 = reinterpret_tensor(buf87, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf87  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf91, le_1, gt_36, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf92 = reinterpret_tensor(buf86, (s0*s1, 64), (64, 1), 0); del buf86  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf91, (s0*s1, 2048), (2048, 1), 0), permute_201, out=buf92)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_201
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf99 = reinterpret_tensor(buf89, (64, 3), (1, 64), 0); del buf89  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf101 = buf82; del buf82  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf81, buf92, mul_2525, buf99, buf101, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf98 = buf81; del buf81  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf103 = reinterpret_tensor(buf71, (s1, s0, 64), (64*s0, 64, 1), 0); del buf71  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf98, buf92, primals_164, mul_2525, div_6, gt_35, buf103, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_35
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2525
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_164
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf105 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf103, (64, s0*s1), (1, 64), 0), view_224, out=buf105)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_224
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf100 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf99, buf100, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf102 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf101, buf102, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf106 = reinterpret_tensor(buf101, (1, 64, 3), (192, 1, 64), 0); del buf101  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf103, buf106, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf104 = buf92; del buf92  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf103, (s0*s1, 64), (64, 1), 0), permute_205, out=buf104)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf103
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_205
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf108 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf104, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_221, view_222, view_223, None, getitem_136, getitem_137, getitem_138, getitem_139, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf104
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_136
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_137
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_138
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_139
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_221
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_222
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_223
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf107 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf106, buf107, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf109 = buf108[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf110 = buf108[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf111 = buf108[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf108
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf112 = buf44; del buf44  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf111, buf110, buf112, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf110
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf117 = reinterpret_tensor(buf111, (s0*s1, 64), (64, 1), 0); del buf111  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf109, buf117, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf125 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf119 = reinterpret_tensor(buf125, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf117, (64, s0*s1), (1, 64), 0), view_213, out=buf119)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_213
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf120 = buf106; del buf106  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf117, buf120, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf118 = reinterpret_tensor(buf109, (s0*s1, 64), (64, 1), 0); del buf109  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf117, permute_218, out=buf118)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_218
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf124 = reinterpret_tensor(buf99, (192, ), (1, ), 0); del buf99  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf122 = reinterpret_tensor(buf124, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf120, buf122, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf115 = buf47; del buf47  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf112, buf115, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf123 = reinterpret_tensor(buf124, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf115, buf123, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf129 = reinterpret_tensor(buf120, (64, 3), (1, 64), 0); del buf120  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf131 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf98, buf118, mul_2404, buf129, buf131, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf128 = buf98; del buf98  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf133 = reinterpret_tensor(buf117, (s1, s0, 64), (64*s0, 64, 1), 0); del buf117  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf128, buf118, primals_158, mul_2404, div_7, gt_34, buf133, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_34
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2404
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_158
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf135 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf133, (64, s0*s1), (1, 64), 0), view_211, out=buf135)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_211
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf130 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf129, buf130, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf132 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf131, buf132, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf136 = reinterpret_tensor(buf131, (1, 64, 3), (192, 1, 64), 0); del buf131  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf133, buf136, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf134 = buf118; del buf118  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf133, (s0*s1, 64), (64, 1), 0), permute_222, out=buf134)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf133
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_222
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf138 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf134, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_208, view_209, view_210, None, getitem_126, getitem_127, getitem_128, getitem_129, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf134
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_126
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_127
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_128
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_129
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_208
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_209
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_210
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf137 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf136, buf137, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf139 = buf138[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf140 = buf138[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf141 = buf138[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf138
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf142 = buf74; del buf74  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf141, buf140, buf139, buf142, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf144 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf142, (192, s0*s1), (1, 192), 0), view_202, out=buf144)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_202
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf145 = buf77; del buf77  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf142, buf145, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf143 = reinterpret_tensor(buf141, (s0*s1, 64), (64, 1), 0); del buf141  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf142, (s0*s1, 192), (192, 1), 0), permute_231, out=buf143)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_231
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf146 = reinterpret_tensor(buf136, (1, 192), (192, 1), 0); del buf136  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf145, buf146, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf150 = buf129; del buf129  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf152 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf128, buf143, mul_2287, buf150, buf152, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf149 = buf128; del buf128  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf154 = reinterpret_tensor(buf140, (s1, s0, 64), (64*s0, 64, 1), 0); del buf140  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf149, buf143, primals_152, mul_2287, div_8, gt_33, buf154, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_33
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2287
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_152
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf156 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf154, (64, s0*s1), (1, 64), 0), view_200, out=buf156)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_200
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf151 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf150, buf151, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf153 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf152, buf153, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf157 = reinterpret_tensor(buf152, (1, 64, 3), (192, 1, 64), 0); del buf152  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf154, buf157, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf158 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf157, buf158, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf94 = buf26; del buf26  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf91, buf94, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf93 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf91, (2048, s0*s1), (1, 2048), 0), view_226, out=buf93)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_226
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf95 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf94, buf95, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf114 = reinterpret_tensor(buf125, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf112, (128, s0*s1), (1, 128), 0), view_187, out=buf114)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf113 = buf143; del buf143  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf112, (s0*s1, 128), (128, 1), 0), permute_214, out=buf113)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_214
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf155 = reinterpret_tensor(buf91, (s0*s1, 2048), (2048, 1), 0); del buf91  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf154, (s0*s1, 64), (64, 1), 0), permute_235, out=buf155)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_235
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf159 = reinterpret_tensor(buf155, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf155  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf159, le_2, gt_32, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_32
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf160 = reinterpret_tensor(buf154, (s0*s1, 64), (64, 1), 0); del buf154  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf159, (s0*s1, 2048), (2048, 1), 0), permute_239, out=buf160)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_239
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf167 = reinterpret_tensor(buf157, (64, 3), (1, 64), 0); del buf157  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf169 = buf150; del buf150  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf149, buf160, mul_2231, buf167, buf169, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf166 = buf149; del buf149  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf171 = reinterpret_tensor(buf139, (s1, s0, 64), (64*s0, 64, 1), 0); del buf139  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf166, buf160, primals_146, mul_2231, div_9, gt_31, buf171, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_31
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2231
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_146
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf173 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf171, (64, s0*s1), (1, 64), 0), view_196, out=buf173)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_196
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf168 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf167, buf168, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf170 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf169, buf170, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf174 = reinterpret_tensor(buf169, (1, 64, 3), (192, 1, 64), 0); del buf169  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf171, buf174, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf172 = buf160; del buf160  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf171, (s0*s1, 64), (64, 1), 0), permute_243, out=buf172)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf171
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_243
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf176 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf172, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_193, view_194, view_195, None, getitem_118, getitem_119, getitem_120, getitem_121, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf172
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_118
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_119
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_120
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_121
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_193
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_194
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_195
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf175 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf174, buf175, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf177 = buf176[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf178 = buf176[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf179 = buf176[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf176
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf180 = buf112; del buf112  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf179, buf178, buf180, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf193 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf182 = reinterpret_tensor(buf193, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf180, (128, s0*s1), (1, 128), 0), view_187, out=buf182)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_187
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf185 = reinterpret_tensor(buf179, (s0*s1, 64), (64, 1), 0); del buf179  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf177, buf185, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf187 = reinterpret_tensor(buf193, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf185, (64, s0*s1), (1, 64), 0), view_185, out=buf187)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_185
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf188 = buf174; del buf174  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf185, buf188, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf186 = reinterpret_tensor(buf177, (s0*s1, 64), (64, 1), 0); del buf177  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf185, permute_256, out=buf186)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_256
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf192 = reinterpret_tensor(buf167, (192, ), (1, ), 0); del buf167  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf190 = reinterpret_tensor(buf192, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf188, buf190, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf183 = buf115; del buf115  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf180, buf183, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf181 = buf185; del buf185  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf180, (s0*s1, 128), (128, 1), 0), permute_252, out=buf181)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_252
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf191 = reinterpret_tensor(buf192, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf183, buf191, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf197 = reinterpret_tensor(buf188, (64, 3), (1, 64), 0); del buf188  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf199 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf166, buf186, mul_2106, buf197, buf199, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf196 = buf166; del buf166  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf201 = reinterpret_tensor(buf178, (s1, s0, 64), (64*s0, 64, 1), 0); del buf178  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf196, buf186, primals_140, mul_2106, div_10, gt_30, buf201, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_30
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_2106
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_140
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf203 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf201, (64, s0*s1), (1, 64), 0), view_183, out=buf203)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_183
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf198 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf197, buf198, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf200 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf199, buf200, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf204 = reinterpret_tensor(buf199, (1, 64, 3), (192, 1, 64), 0); del buf199  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf201, buf204, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf202 = buf186; del buf186  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf201, (s0*s1, 64), (64, 1), 0), permute_260, out=buf202)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_260
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf206 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf202, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_180, view_181, view_182, None, getitem_108, getitem_109, getitem_110, getitem_111, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_108
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_109
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_110
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_111
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_180
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_181
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_182
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf205 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf204, buf205, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf207 = buf206[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf208 = buf206[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf209 = buf206[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf206
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf210 = buf142; del buf142  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf209, buf208, buf207, buf210, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf213 = buf145; del buf145  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf210, buf213, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf214 = reinterpret_tensor(buf204, (1, 192), (192, 1), 0); del buf204  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf213, buf214, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf162 = buf94; del buf94  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf159, buf162, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf161 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf159, (2048, s0*s1), (1, 2048), 0), view_198, out=buf161)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_198
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf163 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf162, buf163, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf211 = reinterpret_tensor(buf209, (s0*s1, 64), (64, 1), 0); del buf209  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (s0*s1, 192), (192, 1), 0), permute_269, out=buf211)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_269
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf212 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf210, (192, s0*s1), (1, 192), 0), view_129, out=buf212)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf216 = reinterpret_tensor(buf208, (s1, s0, 64), (64*s0, 64, 1), 0); del buf208  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf218 = reinterpret_tensor(buf207, (s1, s0, 64), (64*s0, 64, 1), 0); del buf207  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf225 = reinterpret_tensor(buf202, (s1, s0, 64), (64*s0, 64, 1), 0); del buf202  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf230 = buf201; del buf201  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_31, output_2], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20.run(mul_1984, primals_132, primals_133, getitem_107, rsqrt_23, buf45, buf113, buf181, primals_134, div_12, gt_29, buf216, buf218, buf225, buf230, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_107
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_29
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_132
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_133
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_134
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del rsqrt_23
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf232 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf230, (64, s0*s1), (1, 64), 0), view_172, out=buf232)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_172
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf219 = buf197; del buf197  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf221 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21.run(buf45, buf113, buf181, buf216, buf219, buf221, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_21_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf113
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf181
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf216
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf45
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf226 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf228 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5.run(buf218, mul_1984, buf226, buf228, s0, s1, 192, triton_red_fused_native_layer_norm_backward_5_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1984
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf220 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf219, buf220, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf222 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf221, buf222, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf227 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf226, buf227, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf229 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf228, buf229, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf233 = reinterpret_tensor(buf228, (1, 64, 3), (192, 1, 64), 0); del buf228  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf230, buf233, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf234 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf233, buf234, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf231 = reinterpret_tensor(buf159, (s0*s1, 2048), (2048, 1), 0); del buf159  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf230, (s0*s1, 64), (64, 1), 0), permute_273, out=buf231)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_273
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf235 = reinterpret_tensor(buf231, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf231  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf235, le_3, gt_28, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_28
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf236 = reinterpret_tensor(buf230, (s0*s1, 64), (64, 1), 0); del buf230  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf235, (s0*s1, 2048), (2048, 1), 0), permute_277, out=buf236)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_277
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf243 = reinterpret_tensor(buf233, (64, 3), (1, 64), 0); del buf233  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf245 = buf226; del buf226  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf225, buf236, mul_1928, buf243, buf245, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf242 = buf225; del buf225  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf247 = buf218; del buf218  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf242, buf236, primals_126, mul_1928, div_13, gt_27, buf247, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_13
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1928
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_126
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf249 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf247, (64, s0*s1), (1, 64), 0), view_168, out=buf249)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_168
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf244 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf243, buf244, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf246 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf245, buf246, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf250 = reinterpret_tensor(buf245, (1, 64, 3), (192, 1, 64), 0); del buf245  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf247, buf250, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf248 = buf236; del buf236  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf247, (s0*s1, 64), (64, 1), 0), permute_281, out=buf248)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf247
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_281
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf252 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf248, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_165, view_166, view_167, None, getitem_98, getitem_99, getitem_100, getitem_101, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf248
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_100
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_101
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_98
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_99
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_165
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_166
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_167
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf251 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf250, buf251, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf253 = buf252[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf254 = buf252[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf255 = buf252[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf252
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf256 = buf210; del buf210  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf255, buf254, buf253, buf256, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf253
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf258 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf256, (192, s0*s1), (1, 192), 0), view_159, out=buf258)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_159
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf259 = buf213; del buf213  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf256, buf259, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf257 = reinterpret_tensor(buf255, (s0*s1, 64), (64, 1), 0); del buf255  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf256, (s0*s1, 192), (192, 1), 0), permute_290, out=buf257)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_290
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf260 = reinterpret_tensor(buf250, (1, 192), (192, 1), 0); del buf250  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf259, buf260, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf264 = buf243; del buf243  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf266 = buf221; del buf221  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf242, buf257, mul_1811, buf264, buf266, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf263 = buf242; del buf242  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf268 = reinterpret_tensor(buf254, (s1, s0, 64), (64*s0, 64, 1), 0); del buf254  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf263, buf257, primals_120, mul_1811, div_14, gt_26, buf268, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1811
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_120
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf270 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf268, (64, s0*s1), (1, 64), 0), view_157, out=buf270)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_157
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf265 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf264, buf265, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf267 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf266, buf267, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf271 = reinterpret_tensor(buf266, (1, 64, 3), (192, 1, 64), 0); del buf266  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf268, buf271, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf272 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf271, buf272, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf238 = buf162; del buf162  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf235, buf238, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf237 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf235, (2048, s0*s1), (1, 2048), 0), view_170, out=buf237)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_170
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf239 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf238, buf239, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf269 = reinterpret_tensor(buf235, (s0*s1, 2048), (2048, 1), 0); del buf235  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf268, (s0*s1, 64), (64, 1), 0), permute_294, out=buf269)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_294
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf273 = reinterpret_tensor(buf269, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf269  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf273, le_4, gt_25, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf274 = reinterpret_tensor(buf268, (s0*s1, 64), (64, 1), 0); del buf268  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (s0*s1, 2048), (2048, 1), 0), permute_298, out=buf274)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_298
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf281 = reinterpret_tensor(buf271, (64, 3), (1, 64), 0); del buf271  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf283 = buf264; del buf264  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf263, buf274, mul_1755, buf281, buf283, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf280 = buf263; del buf263  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf285 = reinterpret_tensor(buf257, (s1, s0, 64), (64*s0, 64, 1), 0); del buf257  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf280, buf274, primals_114, mul_1755, div_15, gt_24, buf285, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1755
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_114
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf287 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf285, (64, s0*s1), (1, 64), 0), view_153, out=buf287)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_153
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf282 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf281, buf282, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf284 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf283, buf284, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf288 = reinterpret_tensor(buf283, (1, 64, 3), (192, 1, 64), 0); del buf283  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf285, buf288, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf286 = buf274; del buf274  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf285, (s0*s1, 64), (64, 1), 0), permute_302, out=buf286)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf285
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_302
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf290 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf286, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_150, view_151, view_152, None, getitem_90, getitem_91, getitem_92, getitem_93, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf286
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_90
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_91
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_92
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_93
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_150
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_151
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_152
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf289 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf288, buf289, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf291 = buf290[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf292 = buf290[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf293 = buf290[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf290
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf294 = buf256; del buf256  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf293, buf292, buf291, buf294, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf291
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf296 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf294, (192, s0*s1), (1, 192), 0), view_144, out=buf296)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_144
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf297 = buf259; del buf259  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf294, buf297, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf295 = reinterpret_tensor(buf293, (s0*s1, 64), (64, 1), 0); del buf293  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf294, (s0*s1, 192), (192, 1), 0), permute_311, out=buf295)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_311
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf298 = reinterpret_tensor(buf288, (1, 192), (192, 1), 0); del buf288  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf297, buf298, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf302 = buf281; del buf281  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf304 = buf219; del buf219  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf280, buf295, mul_1638, buf302, buf304, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf301 = buf280; del buf280  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf306 = reinterpret_tensor(buf292, (s1, s0, 64), (64*s0, 64, 1), 0); del buf292  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf301, buf295, primals_108, mul_1638, div_16, gt_23, buf306, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_23
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1638
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_108
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf308 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf306, (64, s0*s1), (1, 64), 0), view_142, out=buf308)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_142
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf303 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf302, buf303, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf305 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf304, buf305, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf309 = reinterpret_tensor(buf304, (1, 64, 3), (192, 1, 64), 0); del buf304  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf306, buf309, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf310 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf309, buf310, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf276 = buf238; del buf238  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf273, buf276, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf275 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf273, (2048, s0*s1), (1, 2048), 0), view_155, out=buf275)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_155
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf277 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf276, buf277, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf307 = reinterpret_tensor(buf273, (s0*s1, 2048), (2048, 1), 0); del buf273  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf306, (s0*s1, 64), (64, 1), 0), permute_315, out=buf307)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_315
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf311 = reinterpret_tensor(buf307, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf307  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf311, le_5, gt_22, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_22
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf312 = reinterpret_tensor(buf306, (s0*s1, 64), (64, 1), 0); del buf306  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf311, (s0*s1, 2048), (2048, 1), 0), permute_319, out=buf312)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_319
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf319 = reinterpret_tensor(buf309, (64, 3), (1, 64), 0); del buf309  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf321 = buf302; del buf302  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf301, buf312, mul_1582, buf319, buf321, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf318 = buf301; del buf301  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf323 = reinterpret_tensor(buf295, (s1, s0, 64), (64*s0, 64, 1), 0); del buf295  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf318, buf312, primals_102, mul_1582, div_17, gt_21, buf323, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_17
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_21
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1582
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_102
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf325 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (64, s0*s1), (1, 64), 0), view_138, out=buf325)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_138
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf320 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf319, buf320, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf322 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf321, buf322, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf326 = reinterpret_tensor(buf321, (1, 64, 3), (192, 1, 64), 0); del buf321  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf323, buf326, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf324 = buf312; del buf312  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf323, (s0*s1, 64), (64, 1), 0), permute_323, out=buf324)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_323
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf328 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf324, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_135, view_136, view_137, None, getitem_82, getitem_83, getitem_84, getitem_85, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_82
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_83
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_84
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_85
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_135
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_136
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_137
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf327 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf326, buf327, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf329 = buf328[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf330 = buf328[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf331 = buf328[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf328
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf332 = buf294; del buf294  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf331, buf330, buf329, buf332, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf334 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf332, (192, s0*s1), (1, 192), 0), view_129, out=buf334)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_129
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf335 = buf297; del buf297  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf332, buf335, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf333 = reinterpret_tensor(buf331, (s0*s1, 64), (64, 1), 0); del buf331  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf332, (s0*s1, 192), (192, 1), 0), permute_332, out=buf333)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_332
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf336 = reinterpret_tensor(buf326, (1, 192), (192, 1), 0); del buf326  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf335, buf336, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf314 = buf276; del buf276  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf311, buf314, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf313 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf311, (2048, s0*s1), (1, 2048), 0), view_140, out=buf313)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_140
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf315 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf314, buf315, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf337 = reinterpret_tensor(buf330, (s1, s0, 64), (64*s0, 64, 1), 0); del buf330  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf338 = buf196; del buf196  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf341 = reinterpret_tensor(buf329, (s1, s0, 64), (64*s0, 64, 1), 0); del buf329  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf348 = reinterpret_tensor(buf324, (s1, s0, 64), (64*s0, 64, 1), 0); del buf324  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf353 = buf323; del buf323  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, output_1], Original ATen: [aten.threshold_backward, aten.add, aten.native_layer_norm, aten.hardswish_backward, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22.run(buf338, mul_1452, primals_94, primals_95, getitem_81, rsqrt_16, primals_96, primals_97, buf211, buf318, buf333, div_20, gt_20, buf337, buf341, buf348, buf353, triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22_xnumel, 64, grid=grid(triton_per_fused_add_hardswish_backward_native_dropout_backward_native_layer_norm_native_layer_norm_backward_threshold_backward_22_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf211
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf318
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf333
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_81
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_94
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_95
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_96
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_97
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del rsqrt_16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf355 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf353, (64, s0*s1), (1, 64), 0), view_127, out=buf355)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_127
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf349 = buf319; del buf319  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf351 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5.run(buf341, mul_1452, buf349, buf351, s0, s1, 192, triton_red_fused_native_layer_norm_backward_5_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf341
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1452
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf342 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf344 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5.run(buf338, buf337, buf342, buf344, s0, s1, 192, triton_red_fused_native_layer_norm_backward_5_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf337
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf343 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf342, buf343, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf345 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf344, buf345, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf350 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf349, buf350, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf352 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf351, buf352, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf356 = reinterpret_tensor(buf351, (1, 64, 3), (192, 1, 64), 0); del buf351  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf353, buf356, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf357 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf356, buf357, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf354 = reinterpret_tensor(buf311, (s0*s1, 2048), (2048, 1), 0); del buf311  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf353, (s0*s1, 64), (64, 1), 0), permute_336, out=buf354)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_336
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf358 = reinterpret_tensor(buf354, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf354  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf358, le_7, gt_19, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf359 = reinterpret_tensor(buf353, (s0*s1, 64), (64, 1), 0); del buf353  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (s0*s1, 2048), (2048, 1), 0), permute_340, out=buf359)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_340
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf366 = reinterpret_tensor(buf356, (64, 3), (1, 64), 0); del buf356  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf368 = buf349; del buf349  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf348, buf359, mul_1396, buf366, buf368, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf365 = buf348; del buf348  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf370 = buf338; del buf338  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf365, buf359, primals_88, mul_1396, div_21, gt_18, buf370, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_21
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_18
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1396
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_88
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf372 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf370, (64, s0*s1), (1, 64), 0), view_123, out=buf372)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_123
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf367 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf366, buf367, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf369 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf368, buf369, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf373 = reinterpret_tensor(buf368, (1, 64, 3), (192, 1, 64), 0); del buf368  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf370, buf373, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf371 = buf359; del buf359  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf370, (s0*s1, 64), (64, 1), 0), permute_344, out=buf371)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf370
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_344
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf375 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf371, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_120, view_121, view_122, None, getitem_72, getitem_73, getitem_74, getitem_75, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf371
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_72
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_73
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_74
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_75
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_120
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_121
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_122
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf374 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf373, buf374, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf376 = buf375[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf377 = buf375[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf378 = buf375[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf375
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf379 = buf180; del buf180  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf378, buf377, buf379, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf377
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf384 = reinterpret_tensor(buf378, (s0*s1, 64), (64, 1), 0); del buf378  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf376, buf384, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf392 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf386 = reinterpret_tensor(buf392, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf384, (64, s0*s1), (1, 64), 0), view_112, out=buf386)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_112
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf387 = buf373; del buf373  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf384, buf387, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf385 = reinterpret_tensor(buf376, (s0*s1, 64), (64, 1), 0); del buf376  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf384, permute_357, out=buf385)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_357
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf391 = reinterpret_tensor(buf366, (192, ), (1, ), 0); del buf366  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf389 = reinterpret_tensor(buf391, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf387, buf389, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf382 = buf183; del buf183  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf379, buf382, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf390 = reinterpret_tensor(buf391, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf382, buf390, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf396 = reinterpret_tensor(buf387, (64, 3), (1, 64), 0); del buf387  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf398 = buf344; del buf344  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf365, buf385, mul_1275, buf396, buf398, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf395 = buf365; del buf365  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf400 = reinterpret_tensor(buf384, (s1, s0, 64), (64*s0, 64, 1), 0); del buf384  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf395, buf385, primals_82, mul_1275, div_22, gt_17, buf400, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_22
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_17
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1275
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_82
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf402 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf400, (64, s0*s1), (1, 64), 0), view_110, out=buf402)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_110
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf397 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf396, buf397, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf399 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf398, buf399, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf403 = reinterpret_tensor(buf398, (1, 64, 3), (192, 1, 64), 0); del buf398  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf400, buf403, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf401 = buf385; del buf385  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf400, (s0*s1, 64), (64, 1), 0), permute_361, out=buf401)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf400
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_361
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf405 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf401, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_107, view_108, view_109, None, getitem_62, getitem_63, getitem_64, getitem_65, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf401
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_62
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_63
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_65
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_107
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_108
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_109
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf404 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf403, buf404, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf406 = buf405[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf407 = buf405[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf408 = buf405[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf405
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf409 = buf332; del buf332  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf408, buf407, buf406, buf409, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf411 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf409, (192, s0*s1), (1, 192), 0), view_101, out=buf411)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_101
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf412 = buf335; del buf335  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf409, buf412, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf410 = reinterpret_tensor(buf408, (s0*s1, 64), (64, 1), 0); del buf408  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf409, (s0*s1, 192), (192, 1), 0), permute_370, out=buf410)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_370
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf413 = reinterpret_tensor(buf403, (1, 192), (192, 1), 0); del buf403  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf412, buf413, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf417 = buf396; del buf396  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf419 = buf342; del buf342  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf395, buf410, mul_1158, buf417, buf419, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf416 = buf395; del buf395  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf421 = reinterpret_tensor(buf407, (s1, s0, 64), (64*s0, 64, 1), 0); del buf407  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf416, buf410, primals_76, mul_1158, div_23, gt_16, buf421, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_23
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1158
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_76
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf423 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf421, (64, s0*s1), (1, 64), 0), view_99, out=buf423)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_99
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf418 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf417, buf418, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf420 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf419, buf420, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf424 = reinterpret_tensor(buf419, (1, 64, 3), (192, 1, 64), 0); del buf419  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf421, buf424, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf425 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf424, buf425, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf361 = buf314; del buf314  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf358, buf361, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf360 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (2048, s0*s1), (1, 2048), 0), view_125, out=buf360)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_125
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf362 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf361, buf362, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf381 = reinterpret_tensor(buf392, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf379, (128, s0*s1), (1, 128), 0), view_58, out=buf381)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf380 = buf410; del buf410  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf379, (s0*s1, 128), (128, 1), 0), permute_353, out=buf380)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_353
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf422 = reinterpret_tensor(buf358, (s0*s1, 2048), (2048, 1), 0); del buf358  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf421, (s0*s1, 64), (64, 1), 0), permute_374, out=buf422)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_374
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf426 = reinterpret_tensor(buf422, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf422  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf426, le_8, gt_15, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf427 = reinterpret_tensor(buf421, (s0*s1, 64), (64, 1), 0); del buf421  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf426, (s0*s1, 2048), (2048, 1), 0), permute_378, out=buf427)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_378
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf434 = reinterpret_tensor(buf424, (64, 3), (1, 64), 0); del buf424  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf436 = buf417; del buf417  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf416, buf427, mul_1102, buf434, buf436, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf433 = buf416; del buf416  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf438 = reinterpret_tensor(buf406, (s1, s0, 64), (64*s0, 64, 1), 0); del buf406  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf433, buf427, primals_70, mul_1102, div_24, gt_14, buf438, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_1102
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_70
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf440 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf438, (64, s0*s1), (1, 64), 0), view_95, out=buf440)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_95
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf435 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf434, buf435, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf437 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf436, buf437, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf441 = reinterpret_tensor(buf436, (1, 64, 3), (192, 1, 64), 0); del buf436  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf438, buf441, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf439 = buf427; del buf427  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf438, (s0*s1, 64), (64, 1), 0), permute_382, out=buf439)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf438
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_382
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf443 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf439, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_92, view_93, view_94, None, getitem_54, getitem_55, getitem_56, getitem_57, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf439
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_54
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_55
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_56
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_57
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_92
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_93
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_94
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf442 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf441, buf442, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf444 = buf443[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf445 = buf443[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf446 = buf443[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf443
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf447 = buf379; del buf379  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf446, buf445, buf447, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf445
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf452 = reinterpret_tensor(buf446, (s0*s1, 64), (64, 1), 0); del buf446  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf444, buf452, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf460 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf454 = reinterpret_tensor(buf460, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf452, (64, s0*s1), (1, 64), 0), view_84, out=buf454)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_84
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf455 = buf441; del buf441  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf452, buf455, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf453 = reinterpret_tensor(buf444, (s0*s1, 64), (64, 1), 0); del buf444  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf452, permute_395, out=buf453)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_395
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf459 = reinterpret_tensor(buf434, (192, ), (1, ), 0); del buf434  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf457 = reinterpret_tensor(buf459, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf455, buf457, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf450 = buf382; del buf382  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf447, buf450, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf458 = reinterpret_tensor(buf459, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf450, buf458, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf464 = reinterpret_tensor(buf455, (64, 3), (1, 64), 0); del buf455  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf466 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf433, buf453, mul_981, buf464, buf466, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf463 = buf433; del buf433  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf468 = reinterpret_tensor(buf452, (s1, s0, 64), (64*s0, 64, 1), 0); del buf452  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf463, buf453, primals_64, mul_981, div_25, gt_13, buf468, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_13
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_981
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf470 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf468, (64, s0*s1), (1, 64), 0), view_82, out=buf470)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_82
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf465 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf464, buf465, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf467 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf466, buf467, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf471 = reinterpret_tensor(buf466, (1, 64, 3), (192, 1, 64), 0); del buf466  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf468, buf471, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf469 = buf453; del buf453  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf468, (s0*s1, 64), (64, 1), 0), permute_399, out=buf469)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf468
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_399
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf473 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf469, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_79, view_80, view_81, None, getitem_44, getitem_45, getitem_46, getitem_47, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf469
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_44
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_45
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_46
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_47
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_79
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_80
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_81
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf472 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf471, buf472, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf474 = buf473[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf475 = buf473[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf476 = buf473[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf473
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf477 = buf409; del buf409  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf476, buf475, buf474, buf477, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf479 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf477, (192, s0*s1), (1, 192), 0), view_73, out=buf479)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_73
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf480 = buf412; del buf412  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf477, buf480, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf478 = reinterpret_tensor(buf476, (s0*s1, 64), (64, 1), 0); del buf476  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf477, (s0*s1, 192), (192, 1), 0), permute_408, out=buf478)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_408
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf481 = reinterpret_tensor(buf471, (1, 192), (192, 1), 0); del buf471  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf480, buf481, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf485 = buf464; del buf464  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf487 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf463, buf478, mul_864, buf485, buf487, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf484 = buf463; del buf463  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf489 = reinterpret_tensor(buf475, (s1, s0, 64), (64*s0, 64, 1), 0); del buf475  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf484, buf478, primals_58, mul_864, div_26, gt_12, buf489, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_864
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_58
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf491 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf489, (64, s0*s1), (1, 64), 0), view_71, out=buf491)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_71
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf486 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf485, buf486, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf488 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf487, buf488, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf492 = reinterpret_tensor(buf487, (1, 64, 3), (192, 1, 64), 0); del buf487  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf489, buf492, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf493 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf492, buf493, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf429 = buf361; del buf361  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf426, buf429, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf428 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf426, (2048, s0*s1), (1, 2048), 0), view_97, out=buf428)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_97
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf430 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf429, buf430, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf449 = reinterpret_tensor(buf460, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf447, (128, s0*s1), (1, 128), 0), view_58, out=buf449)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf448 = buf478; del buf478  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf447, (s0*s1, 128), (128, 1), 0), permute_391, out=buf448)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_391
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf490 = reinterpret_tensor(buf426, (s0*s1, 2048), (2048, 1), 0); del buf426  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf489, (s0*s1, 64), (64, 1), 0), permute_412, out=buf490)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_412
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf494 = reinterpret_tensor(buf490, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf490  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf494, le_9, gt_11, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf495 = reinterpret_tensor(buf489, (s0*s1, 64), (64, 1), 0); del buf489  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf494, (s0*s1, 2048), (2048, 1), 0), permute_416, out=buf495)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_416
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf502 = reinterpret_tensor(buf492, (64, 3), (1, 64), 0); del buf492  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf504 = buf485; del buf485  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf484, buf495, mul_808, buf502, buf504, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf501 = buf484; del buf484  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf506 = reinterpret_tensor(buf474, (s1, s0, 64), (64*s0, 64, 1), 0); del buf474  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf501, buf495, primals_52, mul_808, div_27, gt_10, buf506, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_808
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_52
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf508 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf506, (64, s0*s1), (1, 64), 0), view_67, out=buf508)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_67
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf503 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf502, buf503, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf505 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf504, buf505, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf509 = reinterpret_tensor(buf504, (1, 64, 3), (192, 1, 64), 0); del buf504  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf506, buf509, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf507 = buf495; del buf495  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf506, (s0*s1, 64), (64, 1), 0), permute_420, out=buf507)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf506
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_420
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf511 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf507, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_64, view_65, view_66, None, getitem_36, getitem_37, getitem_38, getitem_39, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf507
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_37
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_38
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_39
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_64
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_65
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_66
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf510 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf509, buf510, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf512 = buf511[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf513 = buf511[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf514 = buf511[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf511
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf515 = buf447; del buf447  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10_xnumel = 128*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_10.run(buf514, buf513, buf515, s1, ps1, s0, triton_poi_fused_clone_10_xnumel, grid=grid(triton_poi_fused_clone_10_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf513
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf528 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf517 = reinterpret_tensor(buf528, (128, 64), (64, 1), 4096)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf515, (128, s0*s1), (1, 128), 0), view_58, out=buf517)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_58
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf520 = reinterpret_tensor(buf514, (s0*s1, 64), (64, 1), 0); del buf514  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11_xnumel = 64*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_view_11.run(buf512, buf520, s0, s1, triton_poi_fused_view_11_xnumel, grid=grid(triton_poi_fused_view_11_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf522 = reinterpret_tensor(buf528, (64, 64), (64, 1), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf520, (64, s0*s1), (1, 64), 0), view_56, out=buf522)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_56
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf523 = buf509; del buf509  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf520, buf523, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf521 = reinterpret_tensor(buf512, (s0*s1, 64), (64, 1), 0); del buf512  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(buf520, permute_433, out=buf521)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_433
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf527 = reinterpret_tensor(buf502, (192, ), (1, ), 0); del buf502  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf525 = reinterpret_tensor(buf527, (64, ), (1, ), 0)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_12.run(buf523, buf525, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf518 = buf450; del buf450  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_13.run(buf515, buf518, s0, s1, 384, triton_red_fused_sum_13_r0_numel, grid=grid(384), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf516 = buf520; del buf520  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf515, (s0*s1, 128), (128, 1), 0), permute_429, out=buf516)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf515
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_429
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf526 = reinterpret_tensor(buf527, (128, ), (1, ), 64)  # alias
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_cat_sum_14.run(buf518, buf526, 128, 3, grid=grid(128), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf518
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf531 = reinterpret_tensor(buf523, (64, 3), (1, 64), 0); del buf523  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf533 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_23_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_23.run(buf501, buf521, mul_3165, buf531, buf533, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_23_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf535 = buf501; del buf501  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24.run(buf535, buf521, primals_46, mul_3165, div_28, gt_9, s0, s1, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_28
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_3165
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_46
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf537 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf535, (64, s0*s1), (1, 64), 0), view_54, out=buf537)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_54
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf532 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf531, buf532, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf534 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf533, buf534, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf538 = reinterpret_tensor(buf533, (1, 64, 3), (192, 1, 64), 0); del buf533  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf535, buf538, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf536 = buf521; del buf521  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf535, (s0*s1, 64), (64, 1), 0), permute_437, out=buf536)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf535
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_437
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf540 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf536, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_51, view_52, view_53, None, getitem_26, getitem_27, getitem_28, getitem_29, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_27
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_28
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_29
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_51
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_52
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_53
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf539 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf538, buf539, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf541 = buf540[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf542 = buf540[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf543 = buf540[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf540
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf544 = reinterpret_tensor(buf480, (1, 1, 192, 3), (576, 576, 1, 192), 0); del buf480  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_25_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_25.run(buf543, buf542, buf541, buf544, s0, s1, 576, triton_red_fused_sum_25_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf545 = reinterpret_tensor(buf538, (1, 1, 192), (192, 192, 1), 0); del buf538  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf544, buf545, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf546 = buf477; del buf477  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf543, buf542, buf541, buf546, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf547 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf546, (192, s0*s1), (1, 192), 0), view, out=buf547)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf497 = buf429; del buf429  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf494, buf497, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf496 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf494, (2048, s0*s1), (1, 2048), 0), view_69, out=buf496)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_69
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf498 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf497, buf498, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf549 = reinterpret_tensor(buf543, (s1, s0, 64), (64*s0, 64, 1), 0); del buf543  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf551 = reinterpret_tensor(buf542, (s1, s0, 64), (64*s0, 64, 1), 0); del buf542  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf558 = reinterpret_tensor(buf541, (s1, s0, 64), (64*s0, 64, 1), 0); del buf541  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf563 = reinterpret_tensor(buf536, (s1, s0, 64), (64*s0, 64, 1), 0); del buf536  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [x_9, output], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_layer_norm, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20.run(mul_536, primals_38, primals_39, getitem_25, rsqrt_6, buf380, buf448, buf516, primals_40, div_30, gt_8, buf549, buf551, buf558, buf563, triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_native_layer_norm_backward_20_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_30
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_25
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_38
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_39
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_40
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del rsqrt_6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf565 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf563, (64, s0*s1), (1, 64), 0), view_43, out=buf565)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_43
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf552 = buf531; del buf531  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf554 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21.run(buf380, buf448, buf516, buf549, buf552, buf554, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_21_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf380
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf448
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf516
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf549
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf559 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf561 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_native_layer_norm_backward_5.run(buf551, mul_536, buf559, buf561, s0, s1, 192, triton_red_fused_native_layer_norm_backward_5_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_536
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf553 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf552, buf553, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf555 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf554, buf555, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf560 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf559, buf560, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf562 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf561, buf562, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf566 = reinterpret_tensor(buf561, (1, 64, 3), (192, 1, 64), 0); del buf561  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf563, buf566, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf567 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf566, buf567, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf564 = reinterpret_tensor(buf494, (s0*s1, 2048), (2048, 1), 0); del buf494  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf563, (s0*s1, 64), (64, 1), 0), permute_449, out=buf564)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_449
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf568 = reinterpret_tensor(buf564, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf564  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf568, le_10, gt_7, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf569 = reinterpret_tensor(buf563, (s0*s1, 64), (64, 1), 0); del buf563  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf568, (s0*s1, 2048), (2048, 1), 0), permute_453, out=buf569)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_453
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf576 = reinterpret_tensor(buf566, (64, 3), (1, 64), 0); del buf566  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf578 = buf559; del buf559  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf558, buf569, mul_480, buf576, buf578, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf575 = buf558; del buf558  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf580 = buf551; del buf551  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf575, buf569, primals_32, mul_480, div_31, gt_6, buf580, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_31
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_480
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_32
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf582 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf580, (64, s0*s1), (1, 64), 0), view_39, out=buf582)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_39
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf577 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf576, buf577, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf579 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf578, buf579, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf583 = reinterpret_tensor(buf578, (1, 64, 3), (192, 1, 64), 0); del buf578  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf580, buf583, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf581 = buf569; del buf569  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf580, (s0*s1, 64), (64, 1), 0), permute_457, out=buf581)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf580
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_457
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf585 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf581, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_36, view_37, view_38, None, getitem_16, getitem_17, getitem_18, getitem_19, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf581
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_16
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_17
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_18
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_19
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_36
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_37
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_38
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf584 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf583, buf584, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf586 = buf585[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf587 = buf585[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf588 = buf585[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf585
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf589 = buf546; del buf546  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf588, buf587, buf586, buf589, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf586
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf591 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf589, (192, s0*s1), (1, 192), 0), view_30, out=buf591)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_30
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf592 = reinterpret_tensor(buf544, (1, 192, 3), (576, 1, 192), 0); del buf544  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf589, buf592, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf590 = reinterpret_tensor(buf588, (s0*s1, 64), (64, 1), 0); del buf588  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf589, (s0*s1, 192), (192, 1), 0), permute_466, out=buf590)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_466
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf593 = reinterpret_tensor(buf583, (1, 192), (192, 1), 0); del buf583  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf592, buf593, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf597 = buf576; del buf576  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf599 = buf554; del buf554  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf575, buf590, mul_363, buf597, buf599, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf596 = buf575; del buf575  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf601 = reinterpret_tensor(buf587, (s1, s0, 64), (64*s0, 64, 1), 0); del buf587  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf596, buf590, primals_26, mul_363, div_32, gt_5, buf601, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_32
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_5
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_363
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf603 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf601, (64, s0*s1), (1, 64), 0), view_28, out=buf603)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_28
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf598 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf597, buf598, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf600 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf599, buf600, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf604 = reinterpret_tensor(buf599, (1, 64, 3), (192, 1, 64), 0); del buf599  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf601, buf604, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf605 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf604, buf605, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf571 = buf497; del buf497  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf568, buf571, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf570 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf568, (2048, s0*s1), (1, 2048), 0), view_41, out=buf570)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_41
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf572 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf571, buf572, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf602 = reinterpret_tensor(buf568, (s0*s1, 2048), (2048, 1), 0); del buf568  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf601, (s0*s1, 64), (64, 1), 0), permute_470, out=buf602)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_470
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf606 = reinterpret_tensor(buf602, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf602  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf606, le_11, gt_4, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_4
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf607 = reinterpret_tensor(buf601, (s0*s1, 64), (64, 1), 0); del buf601  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf606, (s0*s1, 2048), (2048, 1), 0), permute_474, out=buf607)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_474
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf614 = reinterpret_tensor(buf604, (64, 3), (1, 64), 0); del buf604  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf616 = buf597; del buf597  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf596, buf607, mul_307, buf614, buf616, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf613 = buf596; del buf596  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf618 = reinterpret_tensor(buf590, (s1, s0, 64), (64*s0, 64, 1), 0); del buf590  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf613, buf607, primals_20, mul_307, div_33, gt_3, buf618, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_33
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_307
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_20
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf620 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf618, (64, s0*s1), (1, 64), 0), view_24, out=buf620)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_24
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf615 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf614, buf615, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf617 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf616, buf617, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf621 = reinterpret_tensor(buf616, (1, 64, 3), (192, 1, 64), 0); del buf616  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf618, buf621, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf619 = buf607; del buf607  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf618, (s0*s1, 64), (64, 1), 0), permute_478, out=buf619)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf618
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_478
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf623 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf619, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_21, view_22, view_23, None, getitem_8, getitem_9, getitem_10, getitem_11, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf619
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_21
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_22
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_23
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf622 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf621, buf622, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf624 = buf623[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf625 = buf623[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf626 = buf623[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf623
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf627 = buf589; del buf589  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf626, buf625, buf624, buf627, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf624
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf629 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf627, (192, s0*s1), (1, 192), 0), view_15, out=buf629)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_15
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf630 = buf592; del buf592  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_16.run(buf627, buf630, s0, s1, 576, triton_red_fused_sum_16_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf628 = reinterpret_tensor(buf626, (s0*s1, 64), (64, 1), 0); del buf626  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf627, (s0*s1, 192), (192, 1), 0), permute_487, out=buf628)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_487
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf631 = reinterpret_tensor(buf621, (1, 192), (192, 1), 0); del buf621  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf630, buf631, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf635 = buf614; del buf614  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf637 = buf552; del buf552  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_8.run(buf613, buf628, mul_190, buf635, buf637, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_8_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf634 = buf613; del buf613  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf639 = reinterpret_tensor(buf625, (s1, s0, 64), (64*s0, 64, 1), 0); del buf625  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9.run(buf634, buf628, primals_14, mul_190, div_34, gt_2, buf639, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_9_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf628
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_34
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_190
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_14
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf641 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf639, (64, s0*s1), (1, 64), 0), view_13, out=buf641)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_13
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf636 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf635, buf636, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf638 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf637, buf638, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf642 = reinterpret_tensor(buf637, (1, 64, 3), (192, 1, 64), 0); del buf637  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf639, buf642, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf643 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf642, buf643, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf609 = buf571; del buf571  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf606, buf609, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf608 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf606, (2048, s0*s1), (1, 2048), 0), view_26, out=buf608)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_26
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf610 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf609, buf610, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf640 = reinterpret_tensor(buf606, (s0*s1, 2048), (2048, 1), 0); del buf606  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf639, (s0*s1, 64), (64, 1), 0), permute_491, out=buf640)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_491
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf644 = reinterpret_tensor(buf640, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf640  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel = 2048*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_native_dropout_backward_threshold_backward_7.run(buf644, le_12, gt_1, triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_threshold_backward_7_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt_1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del le_12
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf645 = reinterpret_tensor(buf639, (s0*s1, 64), (64, 1), 0); del buf639  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf644, (s0*s1, 2048), (2048, 1), 0), permute_495, out=buf645)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_495
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf651 = reinterpret_tensor(buf642, (64, 3), (1, 64), 0); del buf642  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf653 = buf635; del buf635  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_23_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_23.run(buf634, buf645, mul_3232, buf651, buf653, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_23_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf655 = buf634; del buf634  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel = s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24.run(buf655, buf645, primals_8, mul_3232, div_35, gt, s0, s1, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_24_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del div_35
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del gt
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del mul_3232
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del primals_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf657 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf655, (64, s0*s1), (1, 64), 0), view_9, out=buf657)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_9
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf652 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf651, buf652, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf651
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf654 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf653, buf654, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf658 = reinterpret_tensor(buf653, (1, 64, 3), (192, 1, 64), 0); del buf653  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_6.run(buf655, buf658, s0, s1, 192, triton_red_fused_sum_6_r0_numel, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf656 = buf645; del buf645  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf655, (s0*s1, 64), (64, 1), 0), permute_499, out=buf656)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf655
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del permute_499
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf660 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf656, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_6, view_7, view_8, None, getitem, getitem_1, getitem_2, getitem_3, 0.1, [True, True, True, False])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf656
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_2
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del getitem_3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_6
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_7
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_8
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf659 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_native_layer_norm_backward_3.run(buf658, buf659, 64, 3, grid=grid(64), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf661 = buf660[0]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf662 = buf660[1]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf663 = buf660[2]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf660
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf664 = reinterpret_tensor(buf630, (1, 1, 192, 3), (576, 576, 1, 192), 0); del buf630  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_25_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_25.run(buf663, buf662, buf661, buf664, s0, s1, 576, triton_red_fused_sum_25_r0_numel, grid=grid(576), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf665 = reinterpret_tensor(buf658, (1, 1, 192), (192, 192, 1), 0); del buf658  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_17.run(buf664, buf665, 192, 3, grid=grid(192), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf664
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf666 = buf627; del buf627  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15_xnumel = 192*s0*s1
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_poi_fused_clone_15.run(buf663, buf662, buf661, buf666, s1, ps2, s0, triton_poi_fused_clone_15_xnumel, grid=grid(triton_poi_fused_clone_15_xnumel), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf661
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf662
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf663
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf667 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf666, (192, s0*s1), (1, 192), 0), view, out=buf667)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf666
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf647 = buf609; del buf609  # reuse
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18_r0_numel = (2 + s0*s1) // 3
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_red_fused_sum_18.run(buf644, buf647, s0, s1, 6144, triton_red_fused_sum_18_r0_numel, grid=grid(6144), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf646 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf644, (2048, s0*s1), (1, 2048), 0), view_11, out=buf646)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf644
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del view_11
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         buf648 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         triton_per_fused_sum_19.run(buf647, buf648, 2048, 3, grid=grid(2048), stream=stream0)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]         del buf647
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     return (None, None, None, reinterpret_tensor(buf665, (192, ), (1, ), 0), buf667, buf657, reinterpret_tensor(buf659, (64, ), (1, ), 0), buf652, buf654, buf646, reinterpret_tensor(buf648, (2048, ), (1, ), 0), buf641, reinterpret_tensor(buf643, (64, ), (1, ), 0), buf636, buf638, reinterpret_tensor(buf631, (192, ), (1, ), 0), buf629, buf620, reinterpret_tensor(buf622, (64, ), (1, ), 0), buf615, buf617, buf608, reinterpret_tensor(buf610, (2048, ), (1, ), 0), buf603, reinterpret_tensor(buf605, (64, ), (1, ), 0), buf598, buf600, reinterpret_tensor(buf593, (192, ), (1, ), 0), buf591, buf582, reinterpret_tensor(buf584, (64, ), (1, ), 0), buf577, buf579, buf570, reinterpret_tensor(buf572, (2048, ), (1, ), 0), buf565, reinterpret_tensor(buf567, (64, ), (1, ), 0), buf560, buf562, buf553, buf555, reinterpret_tensor(buf545, (192, ), (1, ), 0), buf547, buf537, reinterpret_tensor(buf539, (64, ), (1, ), 0), buf532, buf534, buf528, buf527, buf508, reinterpret_tensor(buf510, (64, ), (1, ), 0), buf503, buf505, buf496, reinterpret_tensor(buf498, (2048, ), (1, ), 0), buf491, reinterpret_tensor(buf493, (64, ), (1, ), 0), buf486, buf488, reinterpret_tensor(buf481, (192, ), (1, ), 0), buf479, buf470, reinterpret_tensor(buf472, (64, ), (1, ), 0), buf465, buf467, buf460, buf459, buf440, reinterpret_tensor(buf442, (64, ), (1, ), 0), buf435, buf437, buf428, reinterpret_tensor(buf430, (2048, ), (1, ), 0), buf423, reinterpret_tensor(buf425, (64, ), (1, ), 0), buf418, buf420, reinterpret_tensor(buf413, (192, ), (1, ), 0), buf411, buf402, reinterpret_tensor(buf404, (64, ), (1, ), 0), buf397, buf399, buf392, buf391, buf372, reinterpret_tensor(buf374, (64, ), (1, ), 0), buf367, buf369, buf360, reinterpret_tensor(buf362, (2048, ), (1, ), 0), buf355, reinterpret_tensor(buf357, (64, ), (1, ), 0), buf350, buf352, buf343, buf345, reinterpret_tensor(buf336, (192, ), (1, ), 0), buf334, buf325, reinterpret_tensor(buf327, (64, ), (1, ), 0), buf320, buf322, buf313, reinterpret_tensor(buf315, (2048, ), (1, ), 0), buf308, reinterpret_tensor(buf310, (64, ), (1, ), 0), buf303, buf305, reinterpret_tensor(buf298, (192, ), (1, ), 0), buf296, buf287, reinterpret_tensor(buf289, (64, ), (1, ), 0), buf282, buf284, buf275, reinterpret_tensor(buf277, (2048, ), (1, ), 0), buf270, reinterpret_tensor(buf272, (64, ), (1, ), 0), buf265, buf267, reinterpret_tensor(buf260, (192, ), (1, ), 0), buf258, buf249, reinterpret_tensor(buf251, (64, ), (1, ), 0), buf244, buf246, buf237, reinterpret_tensor(buf239, (2048, ), (1, ), 0), buf232, reinterpret_tensor(buf234, (64, ), (1, ), 0), buf227, buf229, buf220, buf222, reinterpret_tensor(buf214, (192, ), (1, ), 0), buf212, buf203, reinterpret_tensor(buf205, (64, ), (1, ), 0), buf198, buf200, buf193, buf192, buf173, reinterpret_tensor(buf175, (64, ), (1, ), 0), buf168, buf170, buf161, reinterpret_tensor(buf163, (2048, ), (1, ), 0), buf156, reinterpret_tensor(buf158, (64, ), (1, ), 0), buf151, buf153, reinterpret_tensor(buf146, (192, ), (1, ), 0), buf144, buf135, reinterpret_tensor(buf137, (64, ), (1, ), 0), buf130, buf132, buf125, buf124, buf105, reinterpret_tensor(buf107, (64, ), (1, ), 0), buf100, buf102, buf93, reinterpret_tensor(buf95, (2048, ), (1, ), 0), buf88, reinterpret_tensor(buf90, (64, ), (1, ), 0), buf83, buf85, reinterpret_tensor(buf78, (192, ), (1, ), 0), buf76, buf67, reinterpret_tensor(buf69, (64, ), (1, ), 0), buf62, buf64, buf57, buf56, buf37, reinterpret_tensor(buf39, (64, ), (1, ), 0), buf32, buf34, buf25, reinterpret_tensor(buf27, (2048, ), (1, ), 0), buf20, reinterpret_tensor(buf22, (64, ), (1, ), 0), buf15, buf17, buf8, buf10, )
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_1 = 10
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_2 = 32
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_5 = 320
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_68 = 80
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_26 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_32 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_38 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_39 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_40 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_46 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_52 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_58 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_64 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_70 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_76 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_82 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_88 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_94 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_95 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_96 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_97 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_102 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_108 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_114 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_120 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_126 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_132 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_133 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_134 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_140 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_146 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_152 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_158 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_164 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     primals_190 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_6 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_7 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_8 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_1 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_2 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_3 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_9 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_11 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_1 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_13 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_2 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_190 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_15 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_21 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_22 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_23 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_8 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_9 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_10 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_11 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_24 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_3 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_307 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_26 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_4 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_28 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_5 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_363 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_30 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_36 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_37 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_38 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_16 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_17 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_18 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_19 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_39 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_6 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_480 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_41 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_7 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_43 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_8 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_536 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_25 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rsqrt_6 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_51 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_52 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_53 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_26 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_27 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_28 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_29 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_54 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_9 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_56 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_58 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_64 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_65 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_66 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_36 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_37 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_38 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_39 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_67 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_10 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_808 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_69 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_11 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_71 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_12 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_864 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_73 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_79 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_80 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_81 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_44 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_45 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_46 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_47 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_82 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_13 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_981 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_84 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_92 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_93 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_94 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_54 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_55 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_56 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_57 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_95 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_14 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1102 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_97 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_15 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_99 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_16 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1158 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_101 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_107 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_108 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_109 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_62 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_63 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_64 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_65 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_110 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_17 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1275 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_112 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_120 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_121 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_122 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_72 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_73 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_74 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_75 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_123 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_18 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1396 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_125 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_19 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_127 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_20 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1452 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_81 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rsqrt_16 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_129 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_135 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_136 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_137 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_82 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_83 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_84 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_85 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_138 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_21 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1582 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_140 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_22 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_142 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_23 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1638 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_144 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_150 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_151 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_152 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_90 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_91 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_92 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_93 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_153 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_24 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1755 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_155 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_25 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_157 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_26 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1811 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_159 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_165 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_166 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_167 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_98 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_99 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_100 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_101 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_168 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_27 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1928 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_170 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_28 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_172 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_29 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_1984 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_107 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rsqrt_23 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_180 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_181 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_182 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_108 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_109 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_110 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_111 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_183 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_30 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2106 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_185 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_187 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_193 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_194 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_195 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_118 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_119 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_120 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_121 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_196 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_31 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2231 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_198 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_32 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_200 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_33 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2287 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_202 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_208 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_209 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_210 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_126 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_127 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_128 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_129 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_211 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_34 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2404 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_213 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_221 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_222 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_223 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_136 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_137 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_138 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_139 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_224 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_35 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2525 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_226 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_36 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_228 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_37 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2581 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_230 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_236 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_237 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_238 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_144 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_145 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_146 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_147 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_239 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_38 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2698 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_241 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_249 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_250 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_251 = rand_strided((10, 8, 32, 8), (64, 8, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_154 = rand_strided((10, 8, 32, 8), (2048, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_155 = rand_strided((10, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_156 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_157 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_252 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_39 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2819 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_254 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_40 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     view_256 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     gt_41 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_2875 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     getitem_163 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     rsqrt_33 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     unsqueeze_19 = rand_strided((10, 1, 1, 32, 64), (64, 20480, 20480, 640, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_2 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_159 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_163 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_3 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_167 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_176 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_180 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_4 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_184 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_193 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_5 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_197 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_1 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_201 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_6 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_205 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_214 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_218 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_7 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_222 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_231 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_8 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_235 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_2 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_239 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_9 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_243 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_252 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_256 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_10 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_260 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_269 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_12 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_273 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_3 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_277 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_13 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_281 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_290 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_14 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_294 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_4 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_298 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_15 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_302 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_311 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_16 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_315 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_5 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_319 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_17 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_323 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_332 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_20 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_336 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_7 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_340 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_21 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_344 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_353 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_357 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_22 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_361 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_370 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_23 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_374 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_8 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_378 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_24 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_382 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_391 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_395 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_25 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_399 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_408 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_26 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_412 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_9 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_416 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_27 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_420 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_429 = rand_strided((128, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_433 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_3165 = rand_strided((32, 10, 64), (64, 2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_28 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_437 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_30 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_449 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_10 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_453 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_31 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_457 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_466 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_32 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_470 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_11 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_474 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_33 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_478 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_487 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_34 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_491 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     le_12 = rand_strided((32, 10, 2048), (20480, 2048, 1), device='cuda:0', dtype=torch.bool)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_495 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     mul_3232 = rand_strided((32, 10, 64), (64, 2048, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     div_35 = rand_strided((32, 10, 1), (10, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     permute_499 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     tangents_1 = rand_strided((10, 3, 34, 66), (6732, 2244, 66, 1), device='cuda:0', dtype=torch.float32)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     fn = lambda: call([primals_1, primals_2, mul_5, mul_68, primals_8, primals_14, primals_20, primals_26, primals_32, primals_38, primals_39, primals_40, primals_46, primals_52, primals_58, primals_64, primals_70, primals_76, primals_82, primals_88, primals_94, primals_95, primals_96, primals_97, primals_102, primals_108, primals_114, primals_120, primals_126, primals_132, primals_133, primals_134, primals_140, primals_146, primals_152, primals_158, primals_164, primals_170, primals_176, primals_182, primals_188, primals_189, primals_190, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, gt_1, view_13, gt_2, mul_190, view_15, view_21, view_22, view_23, getitem_8, getitem_9, getitem_10, getitem_11, view_24, gt_3, mul_307, view_26, gt_4, view_28, gt_5, mul_363, view_30, view_36, view_37, view_38, getitem_16, getitem_17, getitem_18, getitem_19, view_39, gt_6, mul_480, view_41, gt_7, view_43, gt_8, mul_536, getitem_25, rsqrt_6, view_51, view_52, view_53, getitem_26, getitem_27, getitem_28, getitem_29, view_54, gt_9, view_56, view_58, view_64, view_65, view_66, getitem_36, getitem_37, getitem_38, getitem_39, view_67, gt_10, mul_808, view_69, gt_11, view_71, gt_12, mul_864, view_73, view_79, view_80, view_81, getitem_44, getitem_45, getitem_46, getitem_47, view_82, gt_13, mul_981, view_84, view_92, view_93, view_94, getitem_54, getitem_55, getitem_56, getitem_57, view_95, gt_14, mul_1102, view_97, gt_15, view_99, gt_16, mul_1158, view_101, view_107, view_108, view_109, getitem_62, getitem_63, getitem_64, getitem_65, view_110, gt_17, mul_1275, view_112, view_120, view_121, view_122, getitem_72, getitem_73, getitem_74, getitem_75, view_123, gt_18, mul_1396, view_125, gt_19, view_127, gt_20, mul_1452, getitem_81, rsqrt_16, view_129, view_135, view_136, view_137, getitem_82, getitem_83, getitem_84, getitem_85, view_138, gt_21, mul_1582, view_140, gt_22, view_142, gt_23, mul_1638, view_144, view_150, view_151, view_152, getitem_90, getitem_91, getitem_92, getitem_93, view_153, gt_24, mul_1755, view_155, gt_25, view_157, gt_26, mul_1811, view_159, view_165, view_166, view_167, getitem_98, getitem_99, getitem_100, getitem_101, view_168, gt_27, mul_1928, view_170, gt_28, view_172, gt_29, mul_1984, getitem_107, rsqrt_23, view_180, view_181, view_182, getitem_108, getitem_109, getitem_110, getitem_111, view_183, gt_30, mul_2106, view_185, view_187, view_193, view_194, view_195, getitem_118, getitem_119, getitem_120, getitem_121, view_196, gt_31, mul_2231, view_198, gt_32, view_200, gt_33, mul_2287, view_202, view_208, view_209, view_210, getitem_126, getitem_127, getitem_128, getitem_129, view_211, gt_34, mul_2404, view_213, view_221, view_222, view_223, getitem_136, getitem_137, getitem_138, getitem_139, view_224, gt_35, mul_2525, view_226, gt_36, view_228, gt_37, mul_2581, view_230, view_236, view_237, view_238, getitem_144, getitem_145, getitem_146, getitem_147, view_239, gt_38, mul_2698, view_241, view_249, view_250, view_251, getitem_154, getitem_155, getitem_156, getitem_157, view_252, gt_39, mul_2819, view_254, gt_40, view_256, gt_41, mul_2875, getitem_163, rsqrt_33, unsqueeze_19, div_2, permute_159, le, permute_163, div_3, permute_167, permute_176, permute_180, div_4, permute_184, permute_193, div_5, permute_197, le_1, permute_201, div_6, permute_205, permute_214, permute_218, div_7, permute_222, permute_231, div_8, permute_235, le_2, permute_239, div_9, permute_243, permute_252, permute_256, div_10, permute_260, permute_269, div_12, permute_273, le_3, permute_277, div_13, permute_281, permute_290, div_14, permute_294, le_4, permute_298, div_15, permute_302, permute_311, div_16, permute_315, le_5, permute_319, div_17, permute_323, permute_332, div_20, permute_336, le_7, permute_340, div_21, permute_344, permute_353, permute_357, div_22, permute_361, permute_370, div_23, permute_374, le_8, permute_378, div_24, permute_382, permute_391, permute_395, div_25, permute_399, permute_408, div_26, permute_412, le_9, permute_416, div_27, permute_420, permute_429, permute_433, mul_3165, div_28, permute_437, div_30, permute_449, le_10, permute_453, div_31, permute_457, permute_466, div_32, permute_470, le_11, permute_474, div_33, permute_478, permute_487, div_34, permute_491, le_12, permute_495, mul_3232, div_35, permute_499, tangents_1])
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] if __name__ == "__main__":
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:54:08.127000 2742634 site-packages/torch/_inductor/graph.py:2014] [213/0] [__output_code] 
V0204 20:54:08.227000 2742634 site-packages/torch/_inductor/graph.py:2022] [213/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/tu/ctupqsqhq67mmy6cfdrccjlddhwftstfopasbfuvhzmc7j5ybebk.py
I0204 20:54:08.975000 2742634 site-packages/torch/_inductor/graph.py:2056] [213/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/tu/ctupqsqhq67mmy6cfdrccjlddhwftstfopasbfuvhzmc7j5ybebk.py
