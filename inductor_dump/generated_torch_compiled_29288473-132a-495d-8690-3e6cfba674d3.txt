W0127 11:21:41.173000 703210 site-packages/torch/_inductor/utils.py:1611] [14/0] DeviceCopy in input program
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] Output code: 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # AOT ID: ['4_forward']
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import torch
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import random
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import os
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import tempfile
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from math import inf, nan
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from cmath import nanj
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch import device, empty_strided
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     grid,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     split_scan_grid,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     grid_combo_kernels,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     start_graph,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     end_graph,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     cooperative_reduction_grid,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] aten = torch.ops.aten
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] _quantized = torch.ops._quantized
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] async_compile = AsyncCompile()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vd/cvdhk2pc7lxkdatu72i5wpslrufudmeqsmwy5zqprl4gucq4i7pe.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [x], Original ATen: [aten.constant_pad_nd]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   x => constant_pad_nd
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %constant_pad_nd : [num_users=2] = call_function[target=torch.ops.aten.constant_pad_nd.default](args = (%primals_1, [2, 2], 0.0), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_constant_pad_nd_0 = async_compile.triton('triton_poi_fused_constant_pad_nd_0', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 256}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_constant_pad_nd_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_constant_pad_nd_0(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 162
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = (xindex % 54)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x1 = xindex // 54
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x2 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = (-2) + x0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp3 = tl.full([1], 50, tl.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp4 = tmp0 < tmp3
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp5 = tmp2 & tmp4
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp6 = tl.load(in_ptr0 + ((-2) + x0 + 50*x1), tmp5 & xmask, other=0.0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rq/crqayxt6ncpbadd7jvnb673rz7rbbd4t5mthcg4nihz7coyzhpwq.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [hx], Original ATen: [aten._to_copy]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   hx => full_default
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([1, 32], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused__to_copy_1 = async_compile.triton('triton_poi_fused__to_copy_1', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 32}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused__to_copy_1(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 32
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = 0.0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/v4/cv4tmx57xidoa3zgc2k5sgd4mkszkb2jpjpxln2rd7gebjmwhyon.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.convolution]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   x_1 => convolution
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%constant_pad_nd, %primals_2, %primals_3, [1], [0], [1], False, [0], 1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_convolution_2 = async_compile.triton('triton_poi_fused_convolution_2', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 1024}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_2', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_convolution_2(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 832
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x2 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x1 = xindex // 52
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uh/cuhhhrqojzfxtqd44dsnijh4kprrzhxl4gwesxo4xmqfs6umvf5b.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret => mm_default_103
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_103 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_3 = async_compile.triton('triton_poi_fused_addmm_3', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_3(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cm/ccmaufbxwonbejn67lpn4wfqoounqq3ia6wmp7agvbq4njtl4pdf.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret => add, add_tensor_103, add_tensor_104, tanh
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_tensor_104 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_104, %primals_7), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_tensor_103 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_103, %primals_6), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_104, %add_tensor_103), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %tanh : [num_users=2] = call_function[target=torch.ops.aten.tanh.default](args = (%add,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_add_addmm_tanh_4 = async_compile.triton('triton_poi_fused_add_addmm_tanh_4', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 32}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_addmm_tanh_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_add_addmm_tanh_4(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 32
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp5 = tmp3 + tmp4
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp6 = tmp2 + tmp5
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp7 = libdevice.tanh(tmp6)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp7, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jg/cjgtdw7t6c3hb47tj3dkejxlhjzes6hl5t35vypxw3ibftwkha3o.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_1 => mm_default_101
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_101 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_1, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_5 = async_compile.triton('triton_poi_fused_addmm_5', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_5(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (1 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rf/crfffyka2we372qswkcqb43z5f2vpnptn5l7zx632p4tt5ym6pyy.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_2 => mm_default_99
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_99 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_2, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_6 = async_compile.triton('triton_poi_fused_addmm_6', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_6(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cw/ccwtpufbicj2ljc3jwlqvaz23jzosnfobruz4asqvrtnf6dcrve2.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_3 => mm_default_97
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_97 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_3, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_7 = async_compile.triton('triton_poi_fused_addmm_7', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_7(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (3 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tt/cttm2zn5rk2zruqf72wh6hebu7xgmkq65d6fm3mgs5cgu5eucw3w.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_4 => mm_default_95
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_95 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_4, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_8 = async_compile.triton('triton_poi_fused_addmm_8', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_8(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cd/ccdqt3fs3bpk2dev3znc4iwv3ru547gm7hsyj7o2h4274wdxd3za.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_5 => mm_default_93
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_93 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_5, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_9 = async_compile.triton('triton_poi_fused_addmm_9', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_9(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (5 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/eg/ceguhzqmacoqdopu55cqwokkb6idqkikehbcn2wicr6fvucjldet.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_6 => mm_default_91
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_91 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_6, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_10 = async_compile.triton('triton_poi_fused_addmm_10', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_10(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (6 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zi/czikgbtuyyolwgnris4gcbgx6g7kshlrheptwbuebick4re3vovy.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_7 => mm_default_89
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_89 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_7, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_11 = async_compile.triton('triton_poi_fused_addmm_11', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_11(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (7 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zk/czklydjvrfmg5g2wqg6cgghbdk54akz7mmi2w4fdqmdxhtlw26dv.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_8 => mm_default_87
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_87 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_8, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_12 = async_compile.triton('triton_poi_fused_addmm_12', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_12(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qx/cqxh4igbecbbinq6b2vxxncxwghjm2cccjuxwzo4mssyij4zwwqn.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_9 => mm_default_85
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_85 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_9, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_13 = async_compile.triton('triton_poi_fused_addmm_13', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_13(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (9 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dm/cdmxlpxjz7rezjnf5fk7kxmbutjfw3v6uaxadmf444zydvtyeopo.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_10 => mm_default_83
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_83 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_10, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_14 = async_compile.triton('triton_poi_fused_addmm_14', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_14(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (10 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gz/cgzw2swoibmuteita2dyhc7mxe5ogdvzvsfx5gm6wmhwfmvjbbju.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_11 => mm_default_81
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_81 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_11, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_15 = async_compile.triton('triton_poi_fused_addmm_15', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_15(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (11 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/im/cimvfejqfmxqywhrfbfn7qaxqcjcwgsd36y5hahgbfxq52iyclmo.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_12 => mm_default_79
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_79 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_12, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_16 = async_compile.triton('triton_poi_fused_addmm_16', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_16(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (12 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ib/cibkpabru6hkmshg2dpwb2bhnj2klo4epxrcw5qgofxpvd3ctb5x.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_13 => mm_default_77
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_77 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_13, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_17 = async_compile.triton('triton_poi_fused_addmm_17', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_17(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (13 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rf/crfllorjpxb6qeyoepcopsg6bdolca2n2rgmbfg5hx6qry4isas7.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_14 => mm_default_75
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_75 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_14, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_18 = async_compile.triton('triton_poi_fused_addmm_18', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_18(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (14 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xz/cxzif3msmr6h76v5zn2co26wnpkn3bf6jidayeu3fps5mp7aezi3.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_15 => mm_default_73
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_73 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_15, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_19 = async_compile.triton('triton_poi_fused_addmm_19', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_19(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (15 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7z/c7zcaekdvzi2hjpsucdsduds7zlrv5tydkscgxoixukiozxvqnsh.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_16 => mm_default_71
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_71 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_16, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_20 = async_compile.triton('triton_poi_fused_addmm_20', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_20(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (16 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/77/c77ppvhxamgqaey7jcbsjay2eb7zxkrn7elldhc47kd33kjhogia.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_17 => mm_default_69
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_69 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_17, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_21 = async_compile.triton('triton_poi_fused_addmm_21', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_21(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (17 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ui/cuioexov3it2jrhjdkcegfr4hmpm56m3hkbiuge4kst52a5z25tc.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_18 => mm_default_67
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_67 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_18, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_22 = async_compile.triton('triton_poi_fused_addmm_22', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_22(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (18 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7x/c7xqjmedvnssfzwrh4gxrfyrjrfcxswcmojczwql5fvqbus43fi6.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_19 => mm_default_65
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_65 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_19, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_23 = async_compile.triton('triton_poi_fused_addmm_23', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_23(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (19 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e2/ce2clfojtmkzflbvtmtp7lyqpq2fc6cj64vzsgbasduthsh2lc36.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_20 => mm_default_63
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_63 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_20, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_24 = async_compile.triton('triton_poi_fused_addmm_24', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_24(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (20 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/n2/cn2hw3bwkgufxbz2pe5hktz5ccgfsmflg5l3nfgsod3ukkc4s3ko.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_21 => mm_default_61
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_61 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_21, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_25 = async_compile.triton('triton_poi_fused_addmm_25', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_25(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (21 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uu/cuuz636j2jbxddlnicu5dartkqybikgn36mqak7fnccuhl7gtkjt.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_22 => mm_default_59
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_59 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_22, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_26 = async_compile.triton('triton_poi_fused_addmm_26', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_26(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (22 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hq/chqr7heof74qnwumjstckrij56xqobe7axzyap2q5opaixa2dcka.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_23 => mm_default_57
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_57 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_23, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_27 = async_compile.triton('triton_poi_fused_addmm_27', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_27(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (23 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zh/czhhctyy6smgv5kh7hv7ad5fywdipcuzpj7erqawnfnoooy4zg2j.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_24 => mm_default_55
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_55 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_24, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_28 = async_compile.triton('triton_poi_fused_addmm_28', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_28(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (24 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/og/cogpqcqtpfg3v2kq5nqvacrnnkqatkx5mpkqg7dmfltuifbknpr4.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_25 => mm_default_53
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_53 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_25, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_29 = async_compile.triton('triton_poi_fused_addmm_29', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_29', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_29(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (25 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qr/cqrhfq7ltl4244bhdrfqebi4c44hnqc2si5c4bimftvfhte3rjhl.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_26 => mm_default_51
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_51 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_26, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_30 = async_compile.triton('triton_poi_fused_addmm_30', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_30(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (26 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vj/cvj7lnbnlpm6mbfe5uumwtzxost6ff4ohfxo4ja45cnknreuekpp.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_27 => mm_default_49
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_49 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_27, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_31 = async_compile.triton('triton_poi_fused_addmm_31', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_31(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (27 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6o/c6om7nbmpmfuk7hdx73xrgu345shtjdhnw2uwb6ipmqpycwx7zrd.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_28 => mm_default_47
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_47 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_28, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_32 = async_compile.triton('triton_poi_fused_addmm_32', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_32(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (28 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ds/cdssrbc5lm6flvof5yf6jhvngeag4bajpjokhh7aumhf3fmcjm2v.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_29 => mm_default_45
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_45 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_29, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_33 = async_compile.triton('triton_poi_fused_addmm_33', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_33(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (29 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fj/cfjkdu3aso3sd53fqvivq622ybivbljkgn6okjnxxcerosszb4zb.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_30 => mm_default_43
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_43 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_30, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_34 = async_compile.triton('triton_poi_fused_addmm_34', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_34', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_34(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (30 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/32/c32c5xruygjs3fcylezsv5hvx4yhzttmtymifhb2woxihi747z7o.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_31 => mm_default_41
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_41 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_31, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_35 = async_compile.triton('triton_poi_fused_addmm_35', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_35(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (31 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6g/c6gopi4u5yhltsj4w4tvlvflsb6e45xwshum2kzbgr4scmiaf2av.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_32 => mm_default_39
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_39 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_32, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_36 = async_compile.triton('triton_poi_fused_addmm_36', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_36(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (32 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hw/chw66cv66brqbcbmi5od2e2znv62ako7jrsxnfwcgwr6xpapjwmt.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_33 => mm_default_37
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_37 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_33, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_37 = async_compile.triton('triton_poi_fused_addmm_37', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_37', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_37(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (33 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sq/csqod4hnwqffe2viuticav5vaq326iveqfnyjuadqd2sr55ywm3o.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_34 => mm_default_35
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_35 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_34, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_38 = async_compile.triton('triton_poi_fused_addmm_38', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_38(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (34 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pr/cprb7q6kignsofmqqy2aekkxq5k2mjucx6kb6ce7mbx3q5ub5qb6.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_35 => mm_default_33
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_33 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_35, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_39 = async_compile.triton('triton_poi_fused_addmm_39', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_39(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (35 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ib/cib5qvbueh42blygoi55j45uyvnnrihif7svvuwxsj2e5apvymin.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_36 => mm_default_31
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_31 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_36, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_40 = async_compile.triton('triton_poi_fused_addmm_40', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_40', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_40(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (36 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zk/czk7mw4mwgvxxox6bx3vctbyp5weff6ztspxozbiax3bg522d3ru.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_37 => mm_default_29
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_29 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_37, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_41 = async_compile.triton('triton_poi_fused_addmm_41', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_41', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_41(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (37 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rw/crwa6v2zbg76djil37ccnbyc6isn3xf6siv3klhdy4vugra6pq7r.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_38 => mm_default_27
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_27 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_38, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_42 = async_compile.triton('triton_poi_fused_addmm_42', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_42', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_42(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (38 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/t3/ct3au4ld3h54rhjm7d56no4su2dtlwe6rso4yomibwiuzgirin6t.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_39 => mm_default_25
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_25 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_39, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_43 = async_compile.triton('triton_poi_fused_addmm_43', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_43', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_43(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (39 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4l/c4ldyfpd3mt4k4xacnubkvbvpvpnvgqunsnlwcxmyrtrtsanlzwh.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_40 => mm_default_23
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_23 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_40, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_44 = async_compile.triton('triton_poi_fused_addmm_44', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_44', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_44(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (40 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lq/clql3n5zeofm2fws3e7gq3mig2b7wrimlszzrgpiox3woxb6zbm7.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_41 => mm_default_21
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_21 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_41, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_45 = async_compile.triton('triton_poi_fused_addmm_45', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_45', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_45(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (41 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ln/cln5hcejwtyezmtvdtrimq6shxzhuw4zet3ukd353tongxvhxoj4.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_42 => mm_default_19
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_19 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_42, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_46 = async_compile.triton('triton_poi_fused_addmm_46', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_46', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_46(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (42 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rc/crc4vdvvswnx54pbpwvkplfta34bko75hh5x666zvo76zex67i4j.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_43 => mm_default_17
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_17 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_43, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_47 = async_compile.triton('triton_poi_fused_addmm_47', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_47', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_47(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (43 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/us/cusy2e7fsncx3pjzpaj6vjya3mnglzdhplmrjzdmloncshjnjjxt.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_44 => mm_default_15
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_15 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_44, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_48 = async_compile.triton('triton_poi_fused_addmm_48', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_48', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_48(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (44 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tb/ctbxmqpxmot3zq24wk6xm37khm5e2bczot5rwm3yjd6lftm6c6fv.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_45 => mm_default_13
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_13 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_45, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_49 = async_compile.triton('triton_poi_fused_addmm_49', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_49', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_49(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (45 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/x7/cx7ydz7xmudmnrjenh4bdszrzy7qhapfod3n6wzl7gwbpayez4yx.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_46 => mm_default_11
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_11 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_46, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_50 = async_compile.triton('triton_poi_fused_addmm_50', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_50', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_50(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (46 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rj/crjxupoyvtsrqikg4h36eikppwmxdaoxjp6qctll4qqdx2ia7sn5.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_47 => mm_default_9
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_9 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_47, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_51 = async_compile.triton('triton_poi_fused_addmm_51', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_51', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_51(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (47 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/iq/ciq3clxxw33wpl5n652e4jvbvzkqvwcc4iukvjaq7xx7kim7l6ea.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_48 => mm_default_7
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_7 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_48, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_52 = async_compile.triton('triton_poi_fused_addmm_52', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_52', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_52(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (48 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lv/clvacoj4yihzeog6vcvd5cuc7m3ga6kcjopthbp77h5dc2uonj4g.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_49 => mm_default_5
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_5 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_49, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_53 = async_compile.triton('triton_poi_fused_addmm_53', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_53', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_53(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (49 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qm/cqmxvdit4obanmxvqfbz5edkudlhz2n2xgjufigaha6q4qpmh5l6.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_50 => mm_default_3
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_3 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_50, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_54 = async_compile.triton('triton_poi_fused_addmm_54', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_54', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_54(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (50 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/62/c62o6kf2wps6wuy4ji6kr5vviiocyjqpkfbhyahqhfnapnxmibv5.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_51 => mm_default_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mm_default_1 : [num_users=1] = call_function[target=torch.ops.aten.mm.default](args = (%select_51, %permute_2), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_55 = async_compile.triton('triton_poi_fused_addmm_55', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_55', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_55(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (51 + 52*x0), xmask, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3m/c3mn5ewzv5co6ckbkrftkgl6kzi3nsogcw3ydswwkc3m4utmennz.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ret_51, x_3, x_5], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.neg, aten._softmax, aten.bernoulli, aten._to_copy, aten.div, aten.mul]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ret_51 => add_51, add_tensor_1, add_tensor_2, tanh_51
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   x_3 => amax, exp, neg, sub, sum_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   x_5 => convert_element_type_1, div_1, inductor_lookup_seed_default, inductor_random_default_1, lt, mul
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_tensor_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_2, %primals_7), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default_1, %primals_6), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_51 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_tensor_2, %add_tensor_1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %tanh_51 : [num_users=2] = call_function[target=torch.ops.aten.tanh.default](args = (%add_51,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %neg : [num_users=2] = call_function[target=torch.ops.aten.neg.default](args = (%tanh_51,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %amax : [num_users=2] = call_function[target=torch.ops.aten.amax.default](args = (%neg, [1], True), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%neg, %amax), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %exp : [num_users=2] = call_function[target=torch.ops.aten.exp.default](args = (%sub,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sum_1 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp, [1], True), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %inductor_random_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, 1, 1], %inductor_lookup_seed_default, rand), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %lt : [num_users=2] = call_function[target=torch.ops.aten.lt.Scalar](args = (%inductor_random_default_1, 0.5), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %convert_element_type_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%lt, torch.float32), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Scalar](args = (%convert_element_type_1, 0.5), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%unsqueeze, %div_1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_per_fused__softmax__to_copy_add_addmm_bernoulli_div_mul_neg_tanh_56 = async_compile.triton('triton_per_fused__softmax__to_copy_add_addmm_bernoulli_div_mul_neg_tanh_56', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 1, 'r0_': 32},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'out_ptr4': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': (10,)}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__softmax__to_copy_add_addmm_bernoulli_div_mul_neg_tanh_56', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_per_fused__softmax__to_copy_add_addmm_bernoulli_div_mul_neg_tanh_56(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr1, out_ptr2, out_ptr3, out_ptr4, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_numel = 32
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     R0_BLOCK: tl.constexpr = 32
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     rnumel = r0_numel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_offset = 0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     roffset = r0_offset
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     rindex = r0_index
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_0 = r0_index
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp5 = tl.load(in_out_ptr0 + (r0_0), None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (r0_0), None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_0), None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (r0_0), None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = tl.full([1, 1], 0, tl.int32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp3 = 0.5
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp4 = tmp2 < tmp3
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp7 = tmp5 + tmp6
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp10 = tmp8 + tmp9
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp11 = tmp7 + tmp10
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp12 = libdevice.tanh(tmp11)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp13 = -tmp12
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp16 = triton_helpers.max2(tmp14, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp17 = tmp13 - tmp16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp18 = tl_math.exp(tmp17)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp19 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp21 = tl.sum(tmp19, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp22 = tmp18 / tmp21
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp23 = tmp4.to(tl.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp24 = 2.0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp25 = tmp23 * tmp24
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp26 = tmp22 * tmp25
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr1 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp4, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr0 + (tl.broadcast_to(r0_0, [XBLOCK, R0_BLOCK])), tmp12, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr4 + (tl.broadcast_to(r0_0, [XBLOCK, R0_BLOCK])), tmp26, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr2 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp16, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr3 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp21, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jv/cjv5q7nuc4bxwj3sthhqwgyr23aocfqr2urfueq4gywkmx2g3prx.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [input_1, input_2], Original ATen: [aten.addmm, aten.relu]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   input_1 => add_tensor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   input_2 => relu
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %add_tensor : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mm_default, %primals_9), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_tensor,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_addmm_relu_57 = async_compile.triton('triton_poi_fused_addmm_relu_57', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 64}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_addmm_relu_57', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_addmm_relu_57(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 64
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp4, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] cpp_fused_randint_58 = async_compile.cpp_pybinding(['int64_t*'], '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #include "/tmp/torchinductor_sahanp/3b/c3bi5gk6mslf6u4iaqafhxm64z6u65e3eain4xlary5blqnvv6xx.h"
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] extern "C"  void kernel(int64_t* in_out_ptr0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] {
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     {
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         {
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]             {
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 auto tmp0 = in_out_ptr0[static_cast<int64_t>(0L)];
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 auto tmp1 = static_cast<int32_t>(0);
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 auto tmp2 = static_cast<int64_t>(0);
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 auto tmp3 = static_cast<int64_t>(10);
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 auto tmp4 = randint64_cpu(tmp0, tmp1, tmp2, tmp3);
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]                 in_out_ptr0[static_cast<int64_t>(0L)] = tmp4;
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]             }
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         }
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     }
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] }
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ac/cac6rzmlhgqno4o27jtsulip2pfodpvy5xz4laa2h7kkleyynpep.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [ones_like, target_poisson], Original ATen: [aten.ones_like, aten.poisson]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ones_like => full_default_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   target_poisson => poisson
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %full_default_1 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1, 10], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %poisson : [num_users=2] = call_function[target=torch.ops.aten.poisson.default](args = (%full_default_1,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_poi_fused_ones_like_poisson_59 = async_compile.triton('triton_poi_fused_ones_like_poisson_59', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.pointwise(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 16}, 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_like_poisson_59', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     min_elem_per_thread=0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_poi_fused_ones_like_poisson_59(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 10
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = xindex < xnumel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     x0 = xindex
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = 1.0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/q2/cq2qinfdgrkelllethylawcdgglfbao5i7nvimmoaitrvgdzpjuu.py
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Topologically Sorted Source Nodes: [target_l1, l1_loss, ce_loss, poisson_loss], Original ATen: [aten.randn_like, aten.sub, aten.abs, aten.mean, aten._log_softmax, aten.nll_loss_forward, aten.mul, aten.exp]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Source node to ATen node mapping:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   ce_loss => amax_1, convert_element_type_3, div_2, exp_1, full_default_3, log, ne, neg_1, sub_2, sum_2, sum_3, sum_4, where_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   l1_loss => abs_1, mean, sub_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   poisson_loss => exp_2, mean_1, mul_1, sub_4
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   target_l1 => inductor_lookup_seed_default_1, inductor_random_default
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] # Graph fragment:
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %inductor_random_default : [num_users=2] = call_function[target=torch.ops.prims.inductor_random.default](args = ([1, 10], %inductor_lookup_seed_default_1, randn), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%addmm_105, %inductor_random_default), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %amax_1 : [num_users=2] = call_function[target=torch.ops.aten.amax.default](args = (%addmm_105, [1], True), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%addmm_105, %amax_1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%sub_2,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp_1, [1], True), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %log : [num_users=2] = call_function[target=torch.ops.aten.log.default](args = (%sum_2,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %ne : [num_users=4] = call_function[target=torch.ops.aten.ne.Scalar](args = (%device_put_1, -100), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %neg_1 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%squeeze_1,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %full_default_3 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %where_1 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%ne, %neg_1, %full_default_3), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.default](args = (%ne,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%sum_3, torch.float32), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.default](args = (%where_1,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sum_4, %convert_element_type_3), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%poisson, %addmm_105), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %exp_2 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%addmm_105,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%exp_2, %mul_1), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%sub_4,), kwargs = {})
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_per_fused__log_softmax_abs_exp_mean_mul_nll_loss_forward_randn_like_sub_60 = async_compile.triton('triton_per_fused__log_softmax_abs_exp_mean_mul_nll_loss_forward_randn_like_sub_60', '''
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] import triton.language as tl
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     size_hints={'x': 1, 'r0_': 16},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     filename=__file__,
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_out_ptr2': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*i1', 'out_ptr3': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1, 'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 'tt.equal_to': (11, 12)}, 'cls': 'AttrsDescriptor'})]},
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__log_softmax_abs_exp_mean_mul_nll_loss_forward_randn_like_sub_60', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1', 'in_out_ptr2'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] @triton.jit
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def triton_per_fused__log_softmax_abs_exp_mean_mul_nll_loss_forward_randn_like_sub_60(in_out_ptr0, in_out_ptr1, in_out_ptr2, in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xnumel = 1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_numel = 10
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     R0_BLOCK: tl.constexpr = 16
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     rnumel = r0_numel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_offset = 0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     roffset = r0_offset
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     rindex = r0_index
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     r0_0 = r0_index
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_0), r0_mask, other=0.0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp21 = tl.load(in_ptr2 + (r0_0), r0_mask, other=0.0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp29 = tl.load(in_ptr3 + (0))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp30 = tl.broadcast_to(tmp29, [XBLOCK, 1])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp1 = r0_0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp2 = tl.randn(tmp0, (tmp1).to(tl.uint32))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp4 = tmp3 - tmp2
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp5 = tl_math.abs(tmp4)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp8 = tl.where(r0_mask, tmp6, 0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp10 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp12 = tl.where(r0_mask, tmp10, float("-inf"))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp13 = triton_helpers.max2(tmp12, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp14 = tmp3 - tmp13
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp15 = tl_math.exp(tmp14)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp16 = tl.broadcast_to(tmp15, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp18 = tl.where(r0_mask, tmp16, 0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp19 = tl.sum(tmp18, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp20 = tl_math.exp(tmp3)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp22 = tmp21 * tmp3
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp23 = tmp20 - tmp22
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp24 = tl.broadcast_to(tmp23, [XBLOCK, R0_BLOCK])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp26 = tl.where(r0_mask, tmp24, 0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp27 = tl.sum(tmp26, 1)[:, None]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp28 = tl_math.log(tmp19)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp31 = tl.full([1, 1], -100, tl.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp32 = tmp30 != tmp31
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp33 = tl.full([1, 1], 0, tl.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp34 = tl.where(tmp32, tmp30, tmp33)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp35 = tl.full([XBLOCK, 1], 10, tl.int32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp36 = tmp34 + tmp35
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp37 = tmp34 < 0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp38 = tl.where(tmp37, tmp36, tmp34)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.device_assert((0 <= tmp38) & (tmp38 < 10), "index out of bounds: 0 <= tmp38 < 10")
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp40 = tl.load(in_ptr1 + (tmp38), None, eviction_policy='evict_last')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp41 = tmp40 - tmp13
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp42 = tmp41 - tmp28
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp43 = -tmp42
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp44 = 0.0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp45 = tl.where(tmp32, tmp43, tmp44)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp46 = tmp32.to(tl.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp47 = tmp46.to(tl.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp48 = tmp45 / tmp47
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp49 = 10.0
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp50 = tmp27 / tmp49
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tmp51 = tmp9 / tmp49
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(r0_0, [XBLOCK, R0_BLOCK])), tmp2, r0_mask)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.debug_barrier()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp28, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr2 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp32, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr3 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp48, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.debug_barrier()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr1 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp50, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.debug_barrier()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(in_out_ptr2 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp51, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     tl.store(out_ptr1 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp13, None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] ''', device_str='cuda')
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] async_compile.wait(globals())
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] del async_compile
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def call(args):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11 = args
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     args.clear()
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_1, (1, 3, 50), (150, 50, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_2, (16, 3, 3), (9, 3, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_3, (16, ), (1, ))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_4, (32, 16), (16, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_5, (32, 32), (32, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_6, (32, ), (1, ))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_7, (32, ), (1, ))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_8, (64, 32), (32, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_10, (10, 64), (64, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     assert_size_stride(primals_11, (10, ), (1, ))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf0 = empty_strided_cuda((1, 3, 54), (162, 54, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.constant_pad_nd]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_constant_pad_nd_0.run(primals_1, buf0, 162, grid=grid(162), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_1
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.convolution]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf1 = extern_kernels.convolution(buf0, primals_2, stride=(1,), padding=(0,), dilation=(1,), transposed=False, output_padding=(0,), groups=1, bias=None)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         assert_size_stride(buf1, (1, 16, 52), (832, 52, 1))
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf2 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [hx], Original ATen: [aten._to_copy]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused__to_copy_1.run(buf2, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf3 = buf1; del buf1  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.convolution]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_convolution_2.run(buf3, primals_3, 832, grid=grid(832), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_3
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf4 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf2, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf4)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf5 = empty_strided_cuda((1, 16), (16, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_3.run(buf3, buf5, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf6 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf5, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf6)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf7 = buf4; del buf4  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf7, primals_7, buf6, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf8 = buf6; del buf6  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf7, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf8)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf9 = buf5; del buf5  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_5.run(buf3, buf9, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf10 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf9, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf10)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf11 = buf8; del buf8  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_1], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf11, primals_7, buf10, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf12 = buf10; del buf10  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf11, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf12)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf13 = buf9; del buf9  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_6.run(buf3, buf13, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf14 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf13, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf14)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf15 = buf12; del buf12  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_2], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf15, primals_7, buf14, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf16 = buf14; del buf14  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf15, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf16)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf17 = buf13; del buf13  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_7.run(buf3, buf17, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf18 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf17, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf18)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf19 = buf16; del buf16  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_3], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf19, primals_7, buf18, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf20 = buf18; del buf18  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf19, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf20)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf21 = buf17; del buf17  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_8.run(buf3, buf21, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf22 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf21, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf22)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf23 = buf20; del buf20  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_4], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf23, primals_7, buf22, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf24 = buf22; del buf22  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf23, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf24)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf25 = buf21; del buf21  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_9.run(buf3, buf25, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf26 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf25, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf26)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf27 = buf24; del buf24  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_5], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf27, primals_7, buf26, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf28 = buf26; del buf26  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf27, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf28)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf29 = buf25; del buf25  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_10.run(buf3, buf29, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf30 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf29, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf30)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf31 = buf28; del buf28  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_6], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf31, primals_7, buf30, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf32 = buf30; del buf30  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf31, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf33 = buf29; del buf29  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_11.run(buf3, buf33, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf34 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf33, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf34)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf35 = buf32; del buf32  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_7], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf35, primals_7, buf34, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf36 = buf34; del buf34  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf35, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf36)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf37 = buf33; del buf33  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_12.run(buf3, buf37, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf38 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf37, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf38)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf39 = buf36; del buf36  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_8], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf39, primals_7, buf38, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf40 = buf38; del buf38  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf39, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf40)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf41 = buf37; del buf37  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_13.run(buf3, buf41, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf42 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf41, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf42)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf43 = buf40; del buf40  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_9], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf43, primals_7, buf42, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf44 = buf42; del buf42  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf43, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf44)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf45 = buf41; del buf41  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_14.run(buf3, buf45, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf46 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf45, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf46)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf47 = buf44; del buf44  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_10], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf47, primals_7, buf46, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf48 = buf46; del buf46  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf47, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf48)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf49 = buf45; del buf45  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_15.run(buf3, buf49, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf50 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf49, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf50)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf51 = buf48; del buf48  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_11], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf51, primals_7, buf50, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf52 = buf50; del buf50  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf51, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf52)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf53 = buf49; del buf49  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_16.run(buf3, buf53, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf54 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf53, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf54)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf55 = buf52; del buf52  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_12], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf55, primals_7, buf54, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf56 = buf54; del buf54  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf55, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf56)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf57 = buf53; del buf53  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_17.run(buf3, buf57, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf58 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf57, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf58)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf59 = buf56; del buf56  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_13], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf59, primals_7, buf58, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf60 = buf58; del buf58  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf59, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf60)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf61 = buf57; del buf57  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_18.run(buf3, buf61, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf62 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf61, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf62)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf63 = buf60; del buf60  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_14], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf63, primals_7, buf62, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf64 = buf62; del buf62  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf63, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf65 = buf61; del buf61  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_19.run(buf3, buf65, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf66 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf65, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf66)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf67 = buf64; del buf64  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_15], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf67, primals_7, buf66, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf68 = buf66; del buf66  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf67, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf68)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf69 = buf65; del buf65  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_20.run(buf3, buf69, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf70 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf69, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf70)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf71 = buf68; del buf68  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_16], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf71, primals_7, buf70, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf72 = buf70; del buf70  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf71, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf72)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf73 = buf69; del buf69  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_21.run(buf3, buf73, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf74 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf73, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf74)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf75 = buf72; del buf72  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_17], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf75, primals_7, buf74, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf76 = buf74; del buf74  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf75, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf76)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf77 = buf73; del buf73  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_22.run(buf3, buf77, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf78 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf77, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf78)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf79 = buf76; del buf76  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_18], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf79, primals_7, buf78, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf80 = buf78; del buf78  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf79, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf80)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf81 = buf77; del buf77  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_23.run(buf3, buf81, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf82 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf81, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf82)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf83 = buf80; del buf80  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_19], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf83, primals_7, buf82, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf84 = buf82; del buf82  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf83, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf84)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf85 = buf81; del buf81  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_24.run(buf3, buf85, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf86 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf85, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf86)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf87 = buf84; del buf84  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_20], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf87, primals_7, buf86, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf88 = buf86; del buf86  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf87, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf88)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf89 = buf85; del buf85  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_25.run(buf3, buf89, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf90 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf89, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf90)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf91 = buf88; del buf88  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_21], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf91, primals_7, buf90, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf92 = buf90; del buf90  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf91, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf92)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf93 = buf89; del buf89  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_26.run(buf3, buf93, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf94 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf93, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf94)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf95 = buf92; del buf92  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_22], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf95, primals_7, buf94, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf96 = buf94; del buf94  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf95, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf96)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf97 = buf93; del buf93  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_27.run(buf3, buf97, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf98 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf97, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf98)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf99 = buf96; del buf96  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_23], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf99, primals_7, buf98, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf100 = buf98; del buf98  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf99, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf100)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf101 = buf97; del buf97  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_28.run(buf3, buf101, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf102 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf101, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf102)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf103 = buf100; del buf100  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_24], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf103, primals_7, buf102, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf104 = buf102; del buf102  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf103, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf104)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf105 = buf101; del buf101  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_29.run(buf3, buf105, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf106 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf105, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf106)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf107 = buf104; del buf104  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_25], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf107, primals_7, buf106, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf108 = buf106; del buf106  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf107, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf108)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf109 = buf105; del buf105  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_30.run(buf3, buf109, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf110 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf109, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf110)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf111 = buf108; del buf108  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_26], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf111, primals_7, buf110, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf112 = buf110; del buf110  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf111, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf112)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf113 = buf109; del buf109  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_31.run(buf3, buf113, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf114 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf113, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf114)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf115 = buf112; del buf112  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_27], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf115, primals_7, buf114, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf116 = buf114; del buf114  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf115, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf116)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf117 = buf113; del buf113  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_32.run(buf3, buf117, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf118 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf117, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf118)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf119 = buf116; del buf116  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_28], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf119, primals_7, buf118, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf120 = buf118; del buf118  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf119, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf120)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf121 = buf117; del buf117  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_33.run(buf3, buf121, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf122 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf121, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf122)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf123 = buf120; del buf120  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_29], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf123, primals_7, buf122, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf124 = buf122; del buf122  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf123, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf124)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf125 = buf121; del buf121  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_34.run(buf3, buf125, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf126 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf125, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf126)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf127 = buf124; del buf124  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_30], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf127, primals_7, buf126, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf128 = buf126; del buf126  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf127, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf128)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf129 = buf125; del buf125  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_35.run(buf3, buf129, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf130 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf129, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf130)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf131 = buf128; del buf128  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_31], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf131, primals_7, buf130, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf132 = buf130; del buf130  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf131, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf132)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf133 = buf129; del buf129  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_36.run(buf3, buf133, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf134 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf133, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf134)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf135 = buf132; del buf132  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_32], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf135, primals_7, buf134, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf136 = buf134; del buf134  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf135, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf136)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf137 = buf133; del buf133  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_37.run(buf3, buf137, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf138 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf137, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf138)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf139 = buf136; del buf136  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_33], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf139, primals_7, buf138, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf140 = buf138; del buf138  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf139, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf140)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf141 = buf137; del buf137  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_38.run(buf3, buf141, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf142 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf141, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf142)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf143 = buf140; del buf140  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_34], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf143, primals_7, buf142, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf144 = buf142; del buf142  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf143, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf144)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf145 = buf141; del buf141  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_39.run(buf3, buf145, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf146 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf145, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf146)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf147 = buf144; del buf144  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_35], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf147, primals_7, buf146, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf148 = buf146; del buf146  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf147, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf148)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf149 = buf145; del buf145  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_40.run(buf3, buf149, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf150 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf149, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf150)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf151 = buf148; del buf148  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_36], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf151, primals_7, buf150, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf152 = buf150; del buf150  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf151, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf152)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf153 = buf149; del buf149  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_41.run(buf3, buf153, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf154 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf153, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf154)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf155 = buf152; del buf152  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_37], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf155, primals_7, buf154, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf156 = buf154; del buf154  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf155, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf156)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf157 = buf153; del buf153  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_42.run(buf3, buf157, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf158 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf157, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf158)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf159 = buf156; del buf156  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_38], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf159, primals_7, buf158, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf160 = buf158; del buf158  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf159, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf160)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf161 = buf157; del buf157  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_43.run(buf3, buf161, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf162 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf161, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf162)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf163 = buf160; del buf160  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_39], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf163, primals_7, buf162, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf164 = buf162; del buf162  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf163, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf164)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf165 = buf161; del buf161  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_44.run(buf3, buf165, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf166 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf165, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf166)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf167 = buf164; del buf164  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_40], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf167, primals_7, buf166, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf168 = buf166; del buf166  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf167, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf168)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf169 = buf165; del buf165  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_45.run(buf3, buf169, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf170 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf169, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf170)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf171 = buf168; del buf168  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_41], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf171, primals_7, buf170, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf172 = buf170; del buf170  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf171, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf172)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf173 = buf169; del buf169  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_46.run(buf3, buf173, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf174 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf173, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf174)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf175 = buf172; del buf172  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_42], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf175, primals_7, buf174, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf176 = buf174; del buf174  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf175, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf176)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf177 = buf173; del buf173  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_47.run(buf3, buf177, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf178 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf177, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf178)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf179 = buf176; del buf176  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_43], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf179, primals_7, buf178, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf180 = buf178; del buf178  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf179, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf180)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf181 = buf177; del buf177  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_48.run(buf3, buf181, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf182 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf181, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf182)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf183 = buf180; del buf180  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_44], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf183, primals_7, buf182, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf184 = buf182; del buf182  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf183, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf184)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf185 = buf181; del buf181  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_49.run(buf3, buf185, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf186 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf185, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf186)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf187 = buf184; del buf184  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_45], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf187, primals_7, buf186, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf188 = buf186; del buf186  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf187, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf188)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf189 = buf185; del buf185  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_50.run(buf3, buf189, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf190 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf189, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf190)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf191 = buf188; del buf188  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_46], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf191, primals_7, buf190, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf192 = buf190; del buf190  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf191, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf192)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf193 = buf189; del buf189  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_51.run(buf3, buf193, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf194 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf193, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf194)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf195 = buf192; del buf192  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_47], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf195, primals_7, buf194, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf196 = buf194; del buf194  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf195, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf196)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf197 = buf193; del buf193  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_52.run(buf3, buf197, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf198 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf197, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf198)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf199 = buf196; del buf196  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_48], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf199, primals_7, buf198, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf200 = buf198; del buf198  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf199, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf200)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf201 = buf197; del buf197  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_53.run(buf3, buf201, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf202 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf201, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf202)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf203 = buf200; del buf200  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_49], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf203, primals_7, buf202, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf204 = buf202; del buf202  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf203, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf204)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf205 = buf201; del buf201  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_54.run(buf3, buf205, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf206 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf205, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf206)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf207 = buf204; del buf204  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_50], Original ATen: [aten.addmm, aten.add, aten.tanh]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_add_addmm_tanh_4.run(buf207, primals_7, buf206, primals_6, 32, grid=grid(32), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf208 = buf206; del buf206  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf207, reinterpret_tensor(primals_5, (32, 32), (1, 32), 0), out=buf208)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf209 = buf205; del buf205  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_55.run(buf3, buf209, 16, grid=grid(16), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf210 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_51], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(buf209, reinterpret_tensor(primals_4, (16, 32), (1, 16), 0), out=buf210)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del buf209
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf214 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [2], out=buf214)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf216 = empty_strided_cuda((1, 1, 1), (1, 1, 1), torch.bool)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf211 = buf208; del buf208  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf212 = empty_strided_cuda((1, 1), (1, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf213 = empty_strided_cuda((1, 1), (1, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf217 = empty_strided_cuda((1, 1, 32), (32, 32, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ret_51, x_3, x_5], Original ATen: [aten.addmm, aten.add, aten.tanh, aten.neg, aten._softmax, aten.bernoulli, aten._to_copy, aten.div, aten.mul]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_per_fused__softmax__to_copy_add_addmm_bernoulli_div_mul_neg_tanh_56.run(buf211, buf214, primals_7, buf210, primals_6, buf216, buf212, buf213, buf217, 0, 1, 32, grid=grid(1), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del buf210
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_6
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_7
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf218 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [input_1], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf217, (1, 32), (0, 1), 0), reinterpret_tensor(primals_8, (32, 64), (1, 32), 0), out=buf218)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf219 = buf218; del buf218  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [input_1, input_2], Original ATen: [aten.addmm, aten.relu]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_addmm_relu_57.run(buf219, primals_9, 64, grid=grid(64), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_9
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf220 = empty_strided_cuda((1, 10), (10, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [input_3], Original ATen: [aten.addmm]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         extern_kernels.addmm(primals_11, buf219, reinterpret_tensor(primals_10, (64, 10), (1, 64), 0), alpha=1, beta=1, out=buf220)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del primals_11
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     buf222 = empty_strided_cpu((1, ), (1, ), torch.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     aten.randint.low_out(-9223372036854775808, 9223372036854775807, [1], out=buf222)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     buf223 = buf222; del buf222  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     cpp_fused_randint_58(buf223)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         torch.cuda.set_device(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf224 = empty_strided_cuda((1, ), (1, ), torch.int64)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf224.copy_(buf223, False)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del buf223
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf225 = empty_strided_cuda((1, 10), (10, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_like, target_poisson], Original ATen: [aten.ones_like, aten.poisson]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_poi_fused_ones_like_poisson_59.run(buf225, 10, grid=grid(10), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_like, target_poisson], Original ATen: [aten.ones_like, aten.poisson]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf226 = torch.ops.aten.poisson.default(buf225)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf227 = buf226
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del buf226
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf221 = buf225; del buf225  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf228 = empty_strided_cuda((), (), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf229 = empty_strided_cuda((1, 1), (1, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf230 = empty_strided_cuda((1, 1), (1, 1), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf233 = empty_strided_cuda((), (), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf231 = buf230; del buf230  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf232 = empty_strided_cuda((1, ), (1, ), torch.bool)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf235 = empty_strided_cuda((), (), torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf236 = buf233; del buf233  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         buf234 = buf228; del buf228  # reuse
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         # Topologically Sorted Source Nodes: [target_l1, l1_loss, ce_loss, poisson_loss], Original ATen: [aten.randn_like, aten.sub, aten.abs, aten.mean, aten._log_softmax, aten.nll_loss_forward, aten.mul, aten.exp]
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         triton_per_fused__log_softmax_abs_exp_mean_mul_nll_loss_forward_randn_like_sub_60.run(buf231, buf236, buf234, buf214, buf220, buf227, buf224, buf221, buf229, buf232, buf235, 1, 1, 10, grid=grid(1), stream=stream0)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]         del buf214
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     return (buf220, buf234, buf235, buf236, primals_2, buf0, buf2, reinterpret_tensor(buf3, (1, 16), (832, 52), 0), buf7, reinterpret_tensor(buf3, (1, 16), (832, 52), 1), buf11, reinterpret_tensor(buf3, (1, 16), (832, 52), 2), buf15, reinterpret_tensor(buf3, (1, 16), (832, 52), 3), buf19, reinterpret_tensor(buf3, (1, 16), (832, 52), 4), buf23, reinterpret_tensor(buf3, (1, 16), (832, 52), 5), buf27, reinterpret_tensor(buf3, (1, 16), (832, 52), 6), buf31, reinterpret_tensor(buf3, (1, 16), (832, 52), 7), buf35, reinterpret_tensor(buf3, (1, 16), (832, 52), 8), buf39, reinterpret_tensor(buf3, (1, 16), (832, 52), 9), buf43, reinterpret_tensor(buf3, (1, 16), (832, 52), 10), buf47, reinterpret_tensor(buf3, (1, 16), (832, 52), 11), buf51, reinterpret_tensor(buf3, (1, 16), (832, 52), 12), buf55, reinterpret_tensor(buf3, (1, 16), (832, 52), 13), buf59, reinterpret_tensor(buf3, (1, 16), (832, 52), 14), buf63, reinterpret_tensor(buf3, (1, 16), (832, 52), 15), buf67, reinterpret_tensor(buf3, (1, 16), (832, 52), 16), buf71, reinterpret_tensor(buf3, (1, 16), (832, 52), 17), buf75, reinterpret_tensor(buf3, (1, 16), (832, 52), 18), buf79, reinterpret_tensor(buf3, (1, 16), (832, 52), 19), buf83, reinterpret_tensor(buf3, (1, 16), (832, 52), 20), buf87, reinterpret_tensor(buf3, (1, 16), (832, 52), 21), buf91, reinterpret_tensor(buf3, (1, 16), (832, 52), 22), buf95, reinterpret_tensor(buf3, (1, 16), (832, 52), 23), buf99, reinterpret_tensor(buf3, (1, 16), (832, 52), 24), buf103, reinterpret_tensor(buf3, (1, 16), (832, 52), 25), buf107, reinterpret_tensor(buf3, (1, 16), (832, 52), 26), buf111, reinterpret_tensor(buf3, (1, 16), (832, 52), 27), buf115, reinterpret_tensor(buf3, (1, 16), (832, 52), 28), buf119, reinterpret_tensor(buf3, (1, 16), (832, 52), 29), buf123, reinterpret_tensor(buf3, (1, 16), (832, 52), 30), buf127, reinterpret_tensor(buf3, (1, 16), (832, 52), 31), buf131, reinterpret_tensor(buf3, (1, 16), (832, 52), 32), buf135, reinterpret_tensor(buf3, (1, 16), (832, 52), 33), buf139, reinterpret_tensor(buf3, (1, 16), (832, 52), 34), buf143, reinterpret_tensor(buf3, (1, 16), (832, 52), 35), buf147, reinterpret_tensor(buf3, (1, 16), (832, 52), 36), buf151, reinterpret_tensor(buf3, (1, 16), (832, 52), 37), buf155, reinterpret_tensor(buf3, (1, 16), (832, 52), 38), buf159, reinterpret_tensor(buf3, (1, 16), (832, 52), 39), buf163, reinterpret_tensor(buf3, (1, 16), (832, 52), 40), buf167, reinterpret_tensor(buf3, (1, 16), (832, 52), 41), buf171, reinterpret_tensor(buf3, (1, 16), (832, 52), 42), buf175, reinterpret_tensor(buf3, (1, 16), (832, 52), 43), buf179, reinterpret_tensor(buf3, (1, 16), (832, 52), 44), buf183, reinterpret_tensor(buf3, (1, 16), (832, 52), 45), buf187, reinterpret_tensor(buf3, (1, 16), (832, 52), 46), buf191, reinterpret_tensor(buf3, (1, 16), (832, 52), 47), buf195, reinterpret_tensor(buf3, (1, 16), (832, 52), 48), buf199, reinterpret_tensor(buf3, (1, 16), (832, 52), 49), buf203, reinterpret_tensor(buf3, (1, 16), (832, 52), 50), buf207, reinterpret_tensor(buf3, (1, 16), (832, 52), 51), buf211, buf212, buf213, buf216, reinterpret_tensor(buf217, (1, 32), (32, 1), 0), buf219, buf220, buf221, buf224, buf227, buf229, buf231, buf232, primals_10, primals_8, primals_4, primals_5, )
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_1 = rand_strided((1, 3, 50), (150, 50, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_2 = rand_strided((16, 3, 3), (9, 3, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_3 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_4 = rand_strided((32, 16), (16, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_5 = rand_strided((32, 32), (32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_6 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_7 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_8 = rand_strided((64, 32), (32, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_10 = rand_strided((10, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     primals_11 = rand_strided((10, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11])
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] if __name__ == "__main__":
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 11:21:42.521000 703210 site-packages/torch/_inductor/graph.py:2014] [14/0] [__output_code] 
V0127 11:21:42.577000 703210 site-packages/torch/_inductor/graph.py:2022] [14/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/z6/cz6hh6m26nuqw3tomeunrvlplr6aszy5poep5z4pbhpx7pa2wcu3.py
I0127 11:21:43.215000 703210 site-packages/torch/_inductor/graph.py:2056] [14/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/z6/cz6hh6m26nuqw3tomeunrvlplr6aszy5poep5z4pbhpx7pa2wcu3.py
