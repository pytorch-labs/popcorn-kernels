V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] Output code: 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # AOT ID: ['90_forward']
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import torch
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import random
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import os
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import tempfile
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from math import inf, nan
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from cmath import nanj
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch import device, empty_strided
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     grid,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     split_scan_grid,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     grid_combo_kernels,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     start_graph,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     end_graph,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     cooperative_reduction_grid,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] aten = torch.ops.aten
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] _quantized = torch.ops._quantized
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] async_compile = AsyncCompile()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cd/ccdmgtw44kymkyqx7agpirycwh5ql2wd23ltbjle5fivquhrwkiv.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.reflection_pad1d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_2 => _unsafe_index
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_unsafe_index : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%permute, [None, None, %sub_7]), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_reflection_pad1d_0 = async_compile.triton('triton_poi_fused_reflection_pad1d_0', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 8192}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_reflection_pad1d_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_reflection_pad1d_0(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (tl.where((-1) + ks1 + ((-1)*tl_math.abs(1 + ((-1)*ks1) + tl_math.abs((-2) + x0))) < 0, (-1) + ((-1)*tl_math.abs(1 + ((-1)*ks1) + tl_math.abs((-2) + x0))) + 2*ks1, (-1) + ks1 + ((-1)*tl_math.abs(1 + ((-1)*ks1) + tl_math.abs((-2) + x0))))), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1000, tl.int32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tmp0 < 0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp4) & (tmp4 < 1000)) | ~(xmask), "index out of bounds: 0 <= tmp4 < 1000")
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1 + 128*tmp4), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/o6/co6jtsouyigxwffmeqsuykqjkndfnyathzrndpoulpudxkxilkuo.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [max_pool1d], Original ATen: [aten.max_pool2d_with_indices]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   max_pool1d => _low_memory_max_pool2d_offsets_to_indices, _low_memory_max_pool2d_with_offsets
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=2] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%unsqueeze, [1, 2], [1, 2], [0, 0], [1, 1], False), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_low_memory_max_pool2d_offsets_to_indices : [num_users=2] = call_function[target=torch.ops.prims._low_memory_max_pool2d_offsets_to_indices.default](args = (%getitem_1, 2, %sub_2, [1, 2], [0, 0]), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_1 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_1', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 4096}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*i64', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_1(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 4*x1 + ks1*x1), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 4*x1 + ks1*x1), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp1 > tmp0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tl.full([1], 1, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full([1], 0, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp1, tmp0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tl.full([1], 2, tl.int32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.where((tmp5 < 0) != (tmp7 < 0), tl.where(tmp5 % tmp7 != 0, tmp5 // tmp7 - 1, tmp5 // tmp7), tmp5 // tmp7)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tmp8 * tmp7
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tmp5 - tmp9
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tmp11 + tmp8
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = 2*x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tmp13 + tmp10
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = ks2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tmp12 * tmp15
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tmp16 + tmp14
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp17, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pq/cpqfrwqbybnsejlklkplxvmg3rnvn3u33nrmxzhqual7qanhpxgm.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_3 => full
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1, 128, %sub_15, 1], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_unpool2d_2 = async_compile.triton('triton_poi_fused_max_unpool2d_2', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 8192}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_unpool2d_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_unpool2d_2(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = 0.0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rv/crvprqyxrronig5y4hpcyc6d73cqpaswgvbwcqkep6zjtebkzwhs.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_3 => index_put
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %index_put : [num_users=1] = call_function[target=torch.ops.aten.index_put_.default](args = (%view_2, [%view_1], %view_3), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_unpool2d_3 = async_compile.triton('triton_poi_fused_max_unpool2d_3', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 4096}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_unpool2d_3', 'mutated_arg_names': ['out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_unpool2d_3(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*(x0 // ks0) + (ks1 // 2)*(x0 // ks0) + ((x0 % ks0))), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (2*((x0 % ks0)) + 4*(x0 // ks0) + ks1*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.load(in_ptr1 + (1 + 2*((x0 % ks0)) + 4*(x0 // ks0) + ks1*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = 4*(x0 // ks0) + 2*(ks1 // 2)*(x0 // ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 512 + 256*(ks1 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp2 < 0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.where(tmp5, tmp4, tmp2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp6) & (tmp6 < 512 + 256*(ks1 // 2))) | ~(xmask), "index out of bounds: 0 <= tmp6 < 512 + 256*(ks1 // 2)")
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(4*(((tmp6 // (4 + 2*(ks1 // 2))) % 128)) + 2*(ks1 // 2)*(((tmp6 // (4 + 2*(ks1 // 2))) % 128)) + ((tmp6 % (4 + 2*(ks1 // 2)))), [XBLOCK])), tmp10, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/in/cin4x27eo2qzn76t7iualasou53unhyonajizi2t6vdkmzmicnlf.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.unsqueeze]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_4 => unsqueeze_3
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %unsqueeze_3 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_2, 1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_unsqueeze_4 = async_compile.triton('triton_poi_fused_unsqueeze_4', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 8192}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_unsqueeze_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_unsqueeze_4(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 4*((((x0 + 4*x1 + 2*x1*(ks1 // 2)) // (4 + 2*(ks1 // 2))) % 128)) + 2*(ks1 // 2)*((((x0 + 4*x1 + 2*x1*(ks1 // 2)) // (4 + 2*(ks1 // 2))) % 128))), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6u/c6unity3nk2kiydakckk7vd7e5o4cys52v3tgbjqvg3jefme6j4s.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [max_pool2d], Original ATen: [aten.max_pool2d_with_indices]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   max_pool2d => _low_memory_max_pool2d_offsets_to_indices_1, _low_memory_max_pool2d_with_offsets_1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=2] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%unsqueeze_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_low_memory_max_pool2d_offsets_to_indices_1 : [num_users=2] = call_function[target=torch.ops.prims._low_memory_max_pool2d_offsets_to_indices.default](args = (%getitem_3, 2, %sym_size_int_2, [2, 2], [0, 0]), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_5 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_5', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 2048}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*i64', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_5(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1 + 4*x1*(ks1 // 2)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1 + 4*x1*(ks1 // 2)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (4 + 2*x0 + 2*(ks1 // 2) + 8*x1 + 4*x1*(ks1 // 2)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.load(in_ptr0 + (5 + 2*x0 + 2*(ks1 // 2) + 8*x1 + 4*x1*(ks1 // 2)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp1 > tmp0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tl.full([1], 1, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full([1], 0, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp1, tmp0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tmp7 > tmp6
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.full([1], 2, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tl.where(tmp8, tmp9, tmp5)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp7, tmp6)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp12 > tmp11
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.full([1], 3, tl.int8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tl.where(tmp13, tmp14, tmp10)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = triton_helpers.maximum(tmp12, tmp11)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.full([1], 2, tl.int32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tl.where((tmp15 < 0) != (tmp17 < 0), tl.where(tmp15 % tmp17 != 0, tmp15 // tmp17 - 1, tmp15 // tmp17), tmp15 // tmp17)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tmp18 * tmp17
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tmp15 - tmp19
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = 2*x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tmp21 + tmp18
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = 2*x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tmp23 + tmp20
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = ks2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = tmp22 * tmp25
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tmp26 + tmp24
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp27, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ms/cmszz3qrsgk7nmqqmldvtm2qodhg6qxnswesrxpb5du3kgzj3x3q.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_5 => index_put_1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %index_put_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put_.default](args = (%view_7, [%view_6], %view_8), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_unpool2d_6 = async_compile.triton('triton_poi_fused_max_unpool2d_6', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 2048}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_unpool2d_6', 'mutated_arg_names': ['out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_unpool2d_6(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*(x0 // ks0) + (ks1 // 2)*(x0 // ks0) + ((x0 % ks0))), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (2*((x0 % ks0)) + 8*(x0 // ks0) + 4*(ks1 // 2)*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.load(in_ptr1 + (1 + 2*((x0 % ks0)) + 8*(x0 // ks0) + 4*(ks1 // 2)*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.load(in_ptr1 + (4 + 2*(ks1 // 2) + 2*((x0 % ks0)) + 8*(x0 // ks0) + 4*(ks1 // 2)*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tl.load(in_ptr1 + (5 + 2*(ks1 // 2) + 2*((x0 % ks0)) + 8*(x0 // ks0) + 4*(ks1 // 2)*(x0 // ks0)), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 512 + 256*(ks1 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp2 < 0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.where(tmp5, tmp4, tmp2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp6) & (tmp6 < 512 + 256*(ks1 // 2))) | ~(xmask), "index out of bounds: 0 <= tmp6 < 512 + 256*(ks1 // 2)")
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp10)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = triton_helpers.maximum(tmp13, tmp12)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(4*(((tmp6 // ks2) % 128)) + 2*(ks1 // 2)*(((tmp6 // ks2) % 128)) + ((tmp6 % ks2)), [XBLOCK])), tmp14, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ku/ckulhy33jepodzajraroaons6u2cgja7b7z77j7xcyy3zfnhdi6h.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.copy]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_7 => copy
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_5, %slice_6), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_tensor_1, %copy, 2, 1, 2), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_tensor, %slice_scatter_default, 3, 1, 129), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%empty, %slice_scatter_default_1, 4, 1, %sub_28), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_2, %slice_18, 4, 0, 1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_copy_7 = async_compile.triton('triton_poi_fused_copy_7', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_copy_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_copy_7(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = ((xindex // ks0) % 130)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex // ks2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x4 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 4 + x0 + 2*(ks1 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp3 >= tmp4
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.broadcast_to(5 + 2*(ks1 // 2), [XBLOCK])
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tmp3 < tmp6
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tmp5 & tmp7
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tmp8 & tmp2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tmp10 >= tmp11
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tl.full([1], 129, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tmp10 < tmp13
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tmp12 & tmp14
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tmp15 & tmp9
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = x2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tmp17 >= tmp18
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tl.full([1], 2, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tmp17 < tmp20
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tmp19 & tmp21
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tmp22 & tmp16
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tl.load(in_ptr0 + (4*(((((-1) + x0 + 4*x1 + 2*x1*(ks1 // 2)) // ks3) % 128)) + 2*(ks1 // 2)*(((((-1) + x0 + 4*x1 + 2*x1*(ks1 // 2)) // ks3) % 128)) + (((3 + x0 + 2*(ks1 // 2)) % ks3))), tmp23 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tl.load(in_ptr1 + (4 + x4 + 2*(ks1 // 2)), tmp16 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = tl.where(tmp22, tmp24, tmp25)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tl.full(tmp26.shape, 0.0, tmp26.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = tl.where(tmp16, tmp26, tmp27)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tl.load(in_ptr1 + (4 + x4 + 2*(ks1 // 2)), tmp9 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = tl.where(tmp15, tmp28, tmp29)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tl.full(tmp30.shape, 0.0, tmp30.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = tl.where(tmp9, tmp30, tmp31)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = float("nan")
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = tl.where(tmp8, tmp32, tmp33)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tl.full(tmp34.shape, 0.0, tmp34.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = tl.where(tmp2, tmp34, tmp35)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = tmp0 >= tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = 5 + 2*(ks1 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tmp0 < tmp38
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tmp37 & tmp39
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp43 = tmp41 >= tmp42
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp44 = tl.full([1], 129, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp45 = tmp41 < tmp44
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp46 = tmp43 & tmp45
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp47 = tmp46 & tmp40
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp48 = x2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp49 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp50 = tmp48 >= tmp49
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp51 = tl.full([1], 2, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp52 = tmp48 < tmp51
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp53 = tmp50 & tmp52
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp54 = tmp53 & tmp47
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp55 = tl.load(in_ptr0 + (4*(((((-5) + x0 + ((-2)*(ks1 // 2)) + 4*x1 + 2*x1*(ks1 // 2)) // ks3) % 128)) + 2*(ks1 // 2)*(((((-5) + x0 + ((-2)*(ks1 // 2)) + 4*x1 + 2*x1*(ks1 // 2)) // ks3) % 128)) + ((((-5) + x0 + ((-2)*(ks1 // 2)) + 4*x1 + 2*x1*(ks1 // 2)) % ks3))), tmp54 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp56 = tl.load(in_ptr1 + (x4), tmp47 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp57 = tl.where(tmp53, tmp55, tmp56)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp58 = tl.full(tmp57.shape, 0.0, tmp57.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp59 = tl.where(tmp47, tmp57, tmp58)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp60 = tl.load(in_ptr1 + (x4), tmp40 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp61 = tl.where(tmp46, tmp59, tmp60)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp62 = tl.full(tmp61.shape, 0.0, tmp61.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp63 = tl.where(tmp40, tmp61, tmp62)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp64 = float("nan")
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp65 = tl.where(tmp40, tmp63, tmp64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp66 = tl.where(tmp2, tmp36, tmp65)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp66, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2c/c2ciagl5d2zmeudgi7hvlbd5rlpswaptns6pchk365rsubt3wxw4.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_4 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_3, %slice_24, 4, %sub_28, %add_63), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_5 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_4, %slice_30, 3, 0, 1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_6 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_5, %slice_36, 3, 129, 130), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_8 = async_compile.triton('triton_poi_fused_8', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_8(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = ((xindex // ks0) % 130)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x4 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x3 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 129, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = (-128) + x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp3 < tmp4
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tmp5 & tmp2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.broadcast_to(5 + 2*(ks1 // 2), [XBLOCK])
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tmp7 >= tmp8
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tmp9 & tmp6
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (1 + 6*x4 + 2*x4*(ks1 // 2)), tmp10 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.load(in_ptr0 + (x3), tmp6 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tl.where(tmp9, tmp11, tmp12)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tl.where(tmp6, tmp13, tmp14)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.broadcast_to(5 + 2*(ks1 // 2), [XBLOCK])
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tmp16 >= tmp17
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tmp18 & tmp2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tl.load(in_ptr0 + ((-767) + ((-256)*(ks1 // 2)) + 6*x4 + 2*x4*(ks1 // 2)), tmp19 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tl.load(in_ptr0 + ((-768) + x3 + ((-256)*(ks1 // 2))), tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tl.where(tmp18, tmp20, tmp21)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tl.where(tmp5, tmp15, tmp22)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tl.full(tmp23.shape, 0.0, tmp23.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tl.where(tmp2, tmp23, tmp24)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tmp0 < tmp26
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tl.broadcast_to(5 + 2*(ks1 // 2), [XBLOCK])
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = tmp28 >= tmp29
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tmp30 & tmp27
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = tl.load(in_ptr0 + (769 + 6*x4 + 256*(ks1 // 2) + 2*x4*(ks1 // 2)), tmp31 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = tl.load(in_ptr0 + (768 + x3 + 256*(ks1 // 2)), tmp27 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = tl.where(tmp30, tmp32, tmp33)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tl.full(tmp34.shape, 0.0, tmp34.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = tl.where(tmp27, tmp34, tmp35)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = 5 + 2*(ks1 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tmp37 >= tmp38
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tl.load(in_ptr0 + (1 + 6*x4 + 2*x4*(ks1 // 2)), tmp39 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = tl.where(tmp39, tmp40, tmp41)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp43 = tl.where(tmp27, tmp36, tmp42)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp44 = tl.where(tmp2, tmp25, tmp43)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp44, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pb/cpbc5hprtpdyvcji547rsotfsqomb6dhgvczk6lodg3hcrntf2hb.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_7 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_6, %slice_42, 2, 0, 1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_scatter_default_7, %slice_48, 2, 2, 3), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_9 = async_compile.triton('triton_poi_fused_9', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_9(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = (-1) + x1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp3 < tmp4
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tmp5 & tmp2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (780 + x0 + 260*(ks1 // 2)), tmp6 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.load(in_ptr0 + ((-780) + x2 + ((-260)*(ks1 // 2))), tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.where(tmp5, tmp7, tmp8)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tl.full(tmp9.shape, 0.0, tmp9.dtype)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.where(tmp2, tmp9, tmp10)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp0 < tmp12
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.load(in_ptr0 + (780 + x0 + 260*(ks1 // 2)), tmp13 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tl.where(tmp13, tmp14, tmp15)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.where(tmp2, tmp11, tmp16)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp17, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/st/cstcaphjegnniiihclfbp73owvabimemkxgegqi6hied2n3j77zc.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10, x_11], Original ATen: [aten.convolution, aten.hardswish, aten.celu]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_10 => add_248, clamp_max, clamp_min, div, mul_334
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_11 => expm1, gt_5, where
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_9 => convolution
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %convolution : [num_users=3] = call_function[target=torch.ops.aten.convolution.default](args = (%squeeze_4, %primals_4, %primals_5, [2, 2], [0, 0], [1, 1], True, [0, 0], 1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_248 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convolution, 3), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clamp_min : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%add_248, 0), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clamp_max : [num_users=1] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min, 6), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_334 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution, %clamp_max), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %div : [num_users=3] = call_function[target=torch.ops.aten.div.Tensor](args = (%mul_334, 6), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %expm1 : [num_users=1] = call_function[target=torch.ops.aten.expm1.default](args = (%div,), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %gt_5 : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%div, 0), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %where : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%gt_5, %div, %expm1), kwargs = {})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_celu_convolution_hardswish_10 = async_compile.triton('triton_poi_fused_celu_convolution_hardswish_10', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 2097152}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_celu_convolution_hardswish_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_celu_convolution_hardswish_10(in_out_ptr0, in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 3.0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = 0.0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp4, tmp5)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = 6.0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = triton_helpers.minimum(tmp6, tmp7)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tmp2 * tmp8
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = 0.16666666666666666
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tmp9 * tmp10
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tmp11 > tmp5
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = libdevice.expm1(tmp11)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.where(tmp12, tmp11, tmp13)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6n/c6n7rsvjqrqw3g77ts74qgiiuddc655bahpmpgwaew573lxqhlo6.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_5 => iota_2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %iota_2 : [num_users=2] = call_function[target=torch.ops.prims.iota.default](args = (1,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_unpool2d_11 = async_compile.triton('triton_poi_fused_max_unpool2d_11', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 1}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': (1,)}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_unpool2d_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_unpool2d_11(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xnumel = 1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.full([1], 0, tl.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp0, None)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ql/cqlqhk22byyc3jvs5dznpoi6uv7x33w4ogc4jkd4m72vdbms7xwf.py
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_3 => iota_1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %iota_1 : [num_users=2] = call_function[target=torch.ops.prims.iota.default](args = (128,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_max_unpool2d_12 = async_compile.triton('triton_poi_fused_max_unpool2d_12', '''
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 128}, 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_unpool2d_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_max_unpool2d_12(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xnumel = 128
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] async_compile.wait(globals())
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] del async_compile
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def call(args):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5 = args
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     args.clear()
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     s0 = primals_2
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_1, (1000, 128), (128, 1))
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_3, (1, s0), (s0, 1))
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_4, (3, 64, 4, 4), (1024, 16, 4, 1))
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_5, (64, ), (1, ))
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         torch.cuda.set_device(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps0 = 4 + s0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf0 = empty_strided_cuda((1, 128, 4 + s0), (512 + 128*s0, 4 + s0, 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.reflection_pad1d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_reflection_pad1d_0_xnumel = 512 + 128*s0
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_reflection_pad1d_0.run(primals_3, primals_1, buf0, ps0, s0, triton_poi_fused_reflection_pad1d_0_xnumel, grid=grid(triton_poi_fused_reflection_pad1d_0_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del primals_1
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps1 = 2 + (s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf1 = empty_strided_cuda((1, 128, 1, 2 + (s0 // 2)), (256 + 128*(s0 // 2), 2 + (s0 // 2), 2 + (s0 // 2), 1), torch.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [max_pool1d], Original ATen: [aten.max_pool2d_with_indices]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_1_xnumel = 256 + 128*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_1.run(buf0, buf1, ps1, s0, ps0, triton_poi_fused_max_pool2d_with_indices_1_xnumel, grid=grid(triton_poi_fused_max_pool2d_with_indices_1_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf2 = empty_strided_cuda((1, 128, 4 + 2*(s0 // 2), 1), (512 + 256*(s0 // 2), 4 + 2*(s0 // 2), 1, 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_2_xnumel = 512 + 256*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_2.run(buf2, triton_poi_fused_max_unpool2d_2_xnumel, grid=grid(triton_poi_fused_max_unpool2d_2_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_3_xnumel = 256 + 128*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_3.run(buf1, buf0, buf2, ps1, s0, triton_poi_fused_max_unpool2d_3_xnumel, grid=grid(triton_poi_fused_max_unpool2d_3_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps2 = 4 + 2*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf4 = empty_strided_cuda((1, 1, 128, 4 + 2*(s0 // 2)), (512 + 256*(s0 // 2), 512 + 256*(s0 // 2), 4 + 2*(s0 // 2), 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.unsqueeze]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_unsqueeze_4_xnumel = 512 + 256*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_unsqueeze_4.run(buf2, buf4, ps2, s0, triton_poi_fused_unsqueeze_4_xnumel, grid=grid(triton_poi_fused_unsqueeze_4_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf5 = empty_strided_cuda((1, 1, 64, 2 + (s0 // 2)), (128 + 64*(s0 // 2), 128 + 64*(s0 // 2), 2 + (s0 // 2), 1), torch.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [max_pool2d], Original ATen: [aten.max_pool2d_with_indices]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5_xnumel = 128 + 64*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf4, buf5, ps1, s0, ps2, triton_poi_fused_max_pool2d_with_indices_5_xnumel, grid=grid(triton_poi_fused_max_pool2d_with_indices_5_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf6 = reinterpret_tensor(buf2, (1, 1, 128, 4 + 2*(s0 // 2)), (512 + 256*(s0 // 2), 512 + 256*(s0 // 2), 4 + 2*(s0 // 2), 1), 0); del buf2  # reuse
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_2_xnumel = 512 + 256*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_2.run(buf6, triton_poi_fused_max_unpool2d_2_xnumel, grid=grid(triton_poi_fused_max_unpool2d_2_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_6_xnumel = 128 + 64*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_6.run(buf5, buf4, buf6, ps1, s0, ps2, triton_poi_fused_max_unpool2d_6_xnumel, grid=grid(triton_poi_fused_max_unpool2d_6_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf8 = empty_strided_cuda((1, 1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps3 = 6 + 2*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps4 = 780 + 260*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf9 = empty_strided_cuda((1, 1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.copy]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_copy_7_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_copy_7.run(buf6, buf8, buf9, ps3, s0, ps4, ps2, triton_poi_fused_copy_7_xnumel, grid=grid(triton_poi_fused_copy_7_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf6
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf10 = buf8; del buf8  # reuse
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_8_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_8.run(buf9, buf10, ps3, s0, triton_poi_fused_8_xnumel, grid=grid(triton_poi_fused_8_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf11 = reinterpret_tensor(buf9, (1, 1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 1, 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), 0); del buf9  # reuse
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_9_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_9.run(buf10, buf11, ps4, s0, triton_poi_fused_9_xnumel, grid=grid(triton_poi_fused_9_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf10
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_9], Original ATen: [aten.convolution]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf12 = extern_kernels.convolution(reinterpret_tensor(buf11, (1, 3, 130, 6 + 2*(s0 // 2)), (0, 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), 0), primals_4, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=True, output_padding=(0, 0), groups=1, bias=None)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         assert_size_stride(buf12, (1, 64, 262, 14 + 4*(s0 // 2)), (234752 + 67072*(s0 // 2), 3668 + 1048*(s0 // 2), 14 + 4*(s0 // 2), 1))
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps5 = 3668 + 1048*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf13 = buf12; del buf12  # reuse
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf14 = empty_strided_cuda((1, 64, 262, 14 + 4*(s0 // 2)), (234752 + 67072*(s0 // 2), 3668 + 1048*(s0 // 2), 14 + 4*(s0 // 2), 1), torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10, x_11], Original ATen: [aten.convolution, aten.hardswish, aten.celu]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_celu_convolution_hardswish_10_xnumel = 234752 + 67072*(s0 // 2)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_celu_convolution_hardswish_10.run(buf13, primals_5, buf14, ps5, triton_poi_fused_celu_convolution_hardswish_10_xnumel, grid=grid(triton_poi_fused_celu_convolution_hardswish_10_xnumel), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del primals_5
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf15 = empty_strided_cuda((1, ), (1, ), torch.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_5], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_11.run(buf15, 1, grid=grid(1), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf16 = empty_strided_cuda((128, ), (1, ), torch.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.max_unpool2d]
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_max_unpool2d_12.run(buf16, 128, grid=grid(128), stream=stream0)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     return (buf14, primals_3, primals_4, reinterpret_tensor(buf0, (1, 128, 1, 4 + s0), (512 + 128*s0, 4 + s0, 4 + s0, 1), 0), buf1, buf4, buf5, reinterpret_tensor(buf11, (1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), 0), buf13, reinterpret_tensor(buf15, (1, 1, 1), (1, 1, 1), 0), reinterpret_tensor(buf16, (1, 128, 1), (128, 1, 1), 0), s0, 2 + (s0 // 2), 2 + (s0 // 2), 4 + 2*(s0 // 2), 6 + 2*(s0 // 2), 5 + 2*(s0 // 2), 4 + 2*(s0 // 2), 4 + 2*(s0 // 2), 4 + 2*(s0 // 2), )
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_1 = rand_strided((1000, 128), (128, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_2 = 32
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_3 = rand_strided((1, 32), (32, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_4 = rand_strided((3, 64, 4, 4), (1024, 16, 4, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5])
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] if __name__ == "__main__":
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 09:56:48.248000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:48.264000 3192161 site-packages/torch/_inductor/graph.py:2022] [379/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/rd/crd2nz6yqebtzpcw6ogdbrj46a4feplm6rkg6kqyaaqpf2fmdgvs.py
I0127 09:56:48.648000 3192161 site-packages/torch/_inductor/graph.py:2056] [379/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/rd/crd2nz6yqebtzpcw6ogdbrj46a4feplm6rkg6kqyaaqpf2fmdgvs.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] Output code: 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # AOT ID: ['90_backward']
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import torch
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import random
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import os
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import tempfile
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from math import inf, nan
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from cmath import nanj
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch import device, empty_strided
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     grid,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     split_scan_grid,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     grid_combo_kernels,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     start_graph,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     end_graph,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     cooperative_reduction_grid,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] aten = torch.ops.aten
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] _quantized = torch.ops._quantized
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] async_compile = AsyncCompile()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/d6/cd6z73t6r3tsetof4pich4gtgblquangm5mrwg5lo64xrp7d7g6g.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.elu_backward, aten.hardswish, aten.hardswish_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   x_10 => add_248, clamp_max, clamp_min, div, mul_334
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_343 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, 1.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_344 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_343, 1.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_248 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convolution, 3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clamp_min : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%add_248, 0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clamp_max : [num_users=1] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min, 6), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_334 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution, %clamp_max), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %div : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%mul_334, 6), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_345 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, 1.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%mul_345,), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_346 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_344, %exp), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_347 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%tangents_1, 1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %le_2 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%div, 0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %where_1 : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%le_2, %mul_346, %mul_347), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %lt_11 : [num_users=1] = call_function[target=torch.ops.aten.lt.Scalar](args = (%convolution, -3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %le_3 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%convolution, 3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%convolution, 3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_257 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%div_1, 0.5), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %mul_348 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where_1, %add_257), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %where_2 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_3, %mul_348, %where_1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %where_3 : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%lt_11, %full_default, %where_2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_elu_backward_hardswish_hardswish_backward_0 = async_compile.triton('triton_poi_fused_elu_backward_hardswish_hardswish_backward_0', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 2097152}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_elu_backward_hardswish_hardswish_backward_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_elu_backward_hardswish_hardswish_backward_0(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.load(in_ptr0 + (x0), xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = -3.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 3.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tmp0 <= tmp3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp0 + tmp3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = 6.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = triton_helpers.minimum(tmp7, tmp8)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tmp0 * tmp9
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = 0.16666666666666666
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp12 <= tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = 1.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tmp14 * tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tmp16 * tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tmp12 * tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tl_math.exp(tmp18)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tmp17 * tmp19
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tl.where(tmp13, tmp20, tmp16)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = 0.3333333333333333
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tmp0 * tmp22
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = 0.5
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tmp23 + tmp24
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = tmp21 * tmp25
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tl.where(tmp4, tmp26, tmp21)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = tl.where(tmp2, tmp6, tmp27)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp28, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gr/cgrfale2iwmjsaw3gs2zytd4gzhff7gozhlxnjhaexdjdsrrbuxd.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where_3, [0, 2, 3]), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_red_fused_convolution_backward_1 = async_compile.triton('triton_red_fused_convolution_backward_1', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.reduction(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 256, 'r0_': 8192},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_red_fused_convolution_backward_1(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xnumel = 192
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     rnumel = r0_numel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     rbase = r0_base
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % 3)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // 3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x3 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         roffset = r0_offset
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         rindex = r0_index
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         r0_2 = r0_index
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp0 = r0_2 + x0*(triton_helpers.div_floor_integer(3670 + 1048*(ks0 // 2),  3))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp1 = 3668 + 1048*(ks0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (14*((((r0_2 + x0*(triton_helpers.div_floor_integer(3670 + 1048*(ks0 // 2),  3))) // (14 + 4*(ks0 // 2))) % 262)) + 3668*x1 + 4*(ks0 // 2)*((((r0_2 + x0*(triton_helpers.div_floor_integer(3670 + 1048*(ks0 // 2),  3))) // (14 + 4*(ks0 // 2))) % 262)) + 1048*x1*(ks0 // 2) + (((r0_2 + x0*(triton_helpers.div_floor_integer(3670 + 1048*(ks0 // 2),  3))) % (14 + 4*(ks0 // 2))))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zo/czon5g23g3tfhpe57ozp2yp5dykxo3ve2jhpwjcmbvyyqk6fldth.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where_3, [0, 2, 3]), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_per_fused_convolution_backward_2 = async_compile.triton('triton_per_fused_convolution_backward_2', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 64, 'r0_': 4},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_per_fused_convolution_backward_2(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xnumel = 64
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_numel = 3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     rnumel = r0_numel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_offset = 0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     roffset = r0_offset
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     rindex = r0_index
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     r0_1 = r0_index
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 3*x0), r0_mask & xmask, other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/go/cgo3qwx3zy6vybhsnvzssrlvj25gjy4tbb7my5nvybvdsbzx3j6d.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone, aten.zeros_like, aten.copy, aten.slice_backward, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_52,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_2 : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 1, 130, %add_63], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_8 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_52, %full_2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_5, %copy_8, 2, 2, 3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_3 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 3, 130, %add_63], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone, 2, 1, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_258 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default, %slice_scatter_default_1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_55,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_10 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_55, %full_2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%add_258, %copy_10, 2, 0, 1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone_1, 2, 1, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_259 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default_2, %slice_scatter_default_3), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3 = async_compile.triton('triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full(tmp3.shape, 0.0, tmp3.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tmp0 >= tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.full(tmp8.shape, 0.0, tmp8.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.where(tmp7, tmp10, tmp11)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp0 >= tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tmp0 < tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tmp13 & tmp14
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tl.load(in_ptr0 + (1560 + x0 + 520*(ks1 // 2)), tmp15 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tl.where(tmp15, tmp16, tmp17)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tmp12 + tmp18
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tl.where(tmp2, tmp5, tmp19)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = (-1) + x1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tmp21 >= tmp22
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tmp23 & tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = tl.full(tmp25.shape, 0.0, tmp25.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tl.where(tmp24, tmp25, tmp26)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = tl.load(in_ptr0 + ((-780) + x2 + ((-260)*(ks1 // 2))), tmp15 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tl.where(tmp23, tmp27, tmp28)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tmp21 >= tmp30
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = tmp21 < tmp22
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = tmp31 & tmp32
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = tmp33 & tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tl.load(in_ptr0 + (1560 + x0 + 520*(ks1 // 2)), tmp34 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = tl.where(tmp33, tmp35, tmp36)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = tmp29 + tmp37
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tl.full(tmp38.shape, 0.0, tmp38.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tl.where(tmp15, tmp38, tmp39)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = tl.where(tmp15, tmp40, tmp17)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = tmp20 + tmp41
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp42, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yw/cywrwtorlfnnrlrlcsgnw3q33gnekpe5dhr4wl3grvvsu7yldxou.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.slice_backward, aten.clone, aten.zeros_like, aten.copy, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_3 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 3, 130, %add_63], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_58,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_6 : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 3, 1, %add_63], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_12 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_58, %full_6), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%add_259, %copy_12, 3, 129, 130), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone_2, 3, 1, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_260 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default_4, %slice_scatter_default_5), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_61,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_14 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_61, %full_6), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_6 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%add_260, %copy_14, 3, 0, 1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone_3, 3, 128, 129), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_261 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default_6, %slice_scatter_default_7), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4 = async_compile.triton('triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = ((xindex // ks0) % 130)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x3 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex // ks1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full(tmp3.shape, 0.0, tmp3.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.full([1], 129, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tmp0 >= tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.full(tmp8.shape, 0.0, tmp8.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.where(tmp7, tmp10, tmp11)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp0 >= tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tmp0 < tmp14
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tmp13 & tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.load(in_ptr0 + (774 + x0 + 258*(ks2 // 2) + 780*x2 + 260*x2*(ks2 // 2)), tmp16 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tl.where(tmp16, tmp17, tmp18)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tmp12 + tmp19
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tl.where(tmp2, tmp5, tmp20)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tl.full([1], 128, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tmp0 >= tmp22
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tmp0 < tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tmp23 & tmp24
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = (-128) + x1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tl.full([1], 129, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = tmp26 >= tmp27
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tmp28 & tmp25
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tl.full(tmp30.shape, 0.0, tmp30.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = tl.where(tmp29, tmp30, tmp31)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = tl.load(in_ptr0 + ((-768) + x3 + ((-256)*(ks2 // 2))), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = tl.where(tmp28, tmp32, tmp33)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = tmp26 >= tmp35
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = tmp26 < tmp37
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tmp36 & tmp38
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tmp39 & tmp25
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = tl.load(in_ptr0 + (774 + x0 + 258*(ks2 // 2) + 780*x2 + 260*x2*(ks2 // 2)), tmp40 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp43 = tl.where(tmp39, tmp41, tmp42)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp44 = tmp34 + tmp43
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp45 = tl.full(tmp44.shape, 0.0, tmp44.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp46 = tl.where(tmp25, tmp44, tmp45)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp47 = tl.where(tmp25, tmp46, tmp18)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp48 = tmp21 + tmp47
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp48, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6v/c6vcahhbv2feueenbp3un5cds54tyq35eg33s47axz23jn3ovkst.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.slice_backward, aten.clone, aten.zeros_like, aten.copy, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_3 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 3, 130, %add_63], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_64,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_default_1 : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([1, 1, 3, 130, 1], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_16 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_64, %full_default_1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%add_261, %copy_16, 4, %sub_28, %add_63), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone_4, 4, 1, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_262 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default_8, %slice_scatter_default_9), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%slice_67,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %copy_18 : [num_users=1] = call_function[target=torch.ops.aten.copy.default](args = (%slice_67, %full_default_1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_10 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%add_262, %copy_18, 4, 0, 1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %slice_scatter_default_11 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%full_3, %clone_5, 4, %sub_44, %sub_28), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_263 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_scatter_default_10, %slice_scatter_default_11), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5 = async_compile.triton('triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 16384}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = x0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 < tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.full(tmp3.shape, 0.0, tmp3.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = 5 + 2*(ks1 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tmp0 >= tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.full(tmp8.shape, 0.0, tmp8.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.where(tmp7, tmp10, tmp11)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tmp0 >= tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tmp0 < tmp14
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = tmp13 & tmp15
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.load(in_ptr0 + (5 + 2*(ks1 // 2) + 6*x1 + 2*x1*(ks1 // 2)), tmp16 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tl.where(tmp16, tmp17, tmp18)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tmp12 + tmp19
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tl.where(tmp2, tmp5, tmp20)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = 4 + 2*(ks1 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tmp0 >= tmp22
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tmp0 < tmp6
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tmp23 & tmp24
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = (-4) + x0 + ((-2)*(ks1 // 2))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tl.broadcast_to(5 + 2*(ks1 // 2), [XBLOCK])
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = tmp26 >= tmp27
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tmp28 & tmp25
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tl.full(tmp30.shape, 0.0, tmp30.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = tl.where(tmp29, tmp30, tmp31)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = tl.load(in_ptr0 + ((-4) + x2 + ((-2)*(ks1 // 2))), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = tl.where(tmp28, tmp32, tmp33)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = tmp26 >= tmp35
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = tmp26 < tmp37
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tmp36 & tmp38
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tmp39 & tmp25
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = tl.load(in_ptr0 + (5 + 2*(ks1 // 2) + 6*x1 + 2*x1*(ks1 // 2)), tmp40 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp43 = tl.where(tmp39, tmp41, tmp42)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp44 = tmp34 + tmp43
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp45 = tl.full(tmp44.shape, 0.0, tmp44.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp46 = tl.where(tmp25, tmp44, tmp45)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp47 = tl.where(tmp25, tmp46, tmp18)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp48 = tmp21 + tmp47
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp48, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3l/c3l3qfivuknx5tckd4zvjvlba74yrldqaob2o3hoc6d5lltyzqal.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.gather]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %gather : [num_users=1] = call_function[target=torch.ops.aten.gather.default](args = (%view_11, -1, %view_10), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_gather_6 = async_compile.triton('triton_poi_fused_gather_6', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 2048}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_gather_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_gather_6(in_ptr0, in_ptr1, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = 512 + 256*(ks0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tmp0 < 0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp4) & (tmp4 < 512 + 256*(ks0 // 2))) | ~(xmask), "index out of bounds: 0 <= tmp4 < 512 + 256*(ks0 // 2)")
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (787 + 6*(((tmp4 // (4 + 2*(ks0 // 2))) % 128)) + 262*(ks0 // 2) + 2*(ks0 // 2)*(((tmp4 // (4 + 2*(ks0 // 2))) % 128)) + ((tmp4 % (4 + 2*(ks0 // 2))))), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g3/cg3gooud62s3aoqzzl4b37dhs3ufmx7ao2c6gxmsyq54dhqr5zje.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.gather]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %gather_1 : [num_users=1] = call_function[target=torch.ops.aten.gather.default](args = (%view_14, -1, %view_13), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_gather_7 = async_compile.triton('triton_poi_fused_gather_7', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 4096}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_gather_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_gather_7(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = 4 + 2*(ks0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = tmp0 < 0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp4) & (tmp4 < 4 + 2*(ks0 // 2))) | ~(xmask), "index out of bounds: 0 <= tmp4 < 4 + 2*(ks0 // 2)")
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (2*((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) * ((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) <= ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64))))) + ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) * (((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) < (((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))))) + (ks0 // 2)*((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) * ((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) <= ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64))))) + ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) * (((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) < (((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))))) + ((((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0)))) * ((((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0)))) <= ((-1) + ((2 + (ks0 // 2)) * ((2 + (ks0 // 2)) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (2 + (ks0 // 2)))))) + ((-1) + ((2 + (ks0 // 2)) * ((2 + (ks0 // 2)) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (2 + (ks0 // 2))))) * (((-1) + ((2 + (ks0 // 2)) * ((2 + (ks0 // 2)) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (2 + (ks0 // 2))))) < (((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0))))))), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (2*((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) * ((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) <= ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64))))) + ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) * (((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) < (((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))))) + (ks0 // 2)*((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) * ((((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))) <= ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64))))) + ((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) * (((-1) + ((64) * ((64) <= (1 + (x1 // 2))) + (1 + (x1 // 2)) * ((1 + (x1 // 2)) < (64)))) < (((0) * ((0) >= (x1 // 2)) + (x1 // 2) * ((x1 // 2) > (0)))))) + ((((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0)))) * ((((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + (tmp4 // 2))) + (1 + (tmp4 // 2)) * ((1 + (tmp4 // 2)) < (ks1)))) < (((0) * ((0) >= (tmp4 // 2)) + (tmp4 // 2) * ((tmp4 // 2) > (0))))))), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tmp4 + 4*x1 + 2*x1*(ks0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = tmp6 == tmp9
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = tl.where(tmp10, tmp7, tmp11)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp12, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zr/czr3kl36jkmcav2l6lqnazjkpwtfb76rlc5qcfdzso7pctlefyh5.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.embedding_dense_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_default_4 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1000, 128], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_embedding_dense_backward_8 = async_compile.triton('triton_poi_fused_embedding_dense_backward_8', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 131072}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_embedding_dense_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_embedding_dense_backward_8(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xnumel = 128000
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ki/ckicjh4rosvatswydwinykugzj3zcklqnmmujpy6cldk4vuv377b.py
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.hardswish_backward, aten.reflection_pad1d_backward, aten.embedding_dense_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Source node to ATen node mapping:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] # Graph fragment:
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %add_265 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_18, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %ge_27 : [num_users=1] = call_function[target=torch.ops.aten.ge.Scalar](args = (%add_265, 0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %le_4 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%add_265, %add_268), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %logical_and : [num_users=1] = call_function[target=torch.ops.aten.logical_and.default](args = (%ge_27, %le_4), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_unsafe_masked_index : [num_users=1] = call_function[target=torch.ops.aten._unsafe_masked_index.default](args = (%squeeze_8, %logical_and, [%view_16, %view_17, %add_265], 0.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %ge_28 : [num_users=1] = call_function[target=torch.ops.aten.ge.Scalar](args = (%view_18, 1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %le_5 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%view_18, 2), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %logical_and_1 : [num_users=1] = call_function[target=torch.ops.aten.logical_and.default](args = (%ge_28, %le_5), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_unsafe_masked_index_1 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_masked_index.default](args = (%squeeze_8, %logical_and_1, [%view_16, %view_17, %sub_76], 0.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %ge_29 : [num_users=1] = call_function[target=torch.ops.aten.ge.Scalar](args = (%view_18, %sub_79), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %le_6 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%view_18, %sub_80), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %logical_and_2 : [num_users=1] = call_function[target=torch.ops.aten.logical_and.default](args = (%ge_29, %le_6), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %_unsafe_masked_index_2 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_masked_index.default](args = (%squeeze_8, %logical_and_2, [%view_16, %view_17, %sub_78], 0.0), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %where_4 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%unsqueeze_8, %full_default, %permute_1), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %clone_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%where_4,), kwargs = {memory_format: torch.contiguous_format})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %full_default_4 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([1000, 128], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] #   %index_put_2 : [num_users=1] = call_function[target=torch.ops.aten.index_put_.default](args = (%full_default_4, [%primals_3], %clone_7, True), kwargs = {})
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9 = async_compile.triton('triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9', '''
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] import triton.language as tl
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton_heuristics.pointwise(
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     size_hints={'x': 4096}, 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     filename=__file__,
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'out_ptr3': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9', 'mutated_arg_names': ['out_ptr3'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     min_elem_per_thread=0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] @triton.jit
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr3, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     xmask = xindex < xnumel
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x0 = (xindex % ks0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x1 = xindex // ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     x2 = xindex
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp47 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp0 = 2 + x0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp3 = 3 + ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp4 = tmp0 <= tmp3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp5 = tmp2 & tmp4
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp6 = tl.load(in_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp5, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp7 = tl.load(in_ptr1 + (x1), tmp5 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (2*tmp7 + tmp7*(ks0 // 2) + ((((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0)))) * ((((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1)))) < (((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0))))))), tmp5 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp9 = tl.load(in_ptr3 + (2*tmp7 + tmp7*(ks0 // 2) + ((((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0)))) * ((((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (x0 // 2))) + (2 + (x0 // 2)) * ((2 + (x0 // 2)) < (ks1)))) < (((0) * ((0) >= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) > (0))))))), tmp5 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp10 = 2 + x0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp11 = tmp8 == tmp10
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp12 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp13 = tl.where(tmp11, tmp9, tmp12)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp15 = tl.where(tmp5, tmp13, tmp14)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp16 = x0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp17 = tl.full([1], 1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp18 = tmp16 >= tmp17
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp19 = tl.full([1], 2, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp20 = tmp16 <= tmp19
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp21 = tmp18 & tmp20
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp22 = tl.load(in_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp21, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp23 = tl.load(in_ptr1 + (x1), tmp21 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp24 = tl.load(in_ptr2 + (2*tmp23 + tmp23*(ks0 // 2) + (tl.where(((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))) < 0, 2 + (ks0 // 2) + ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))), ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0))))))))), tmp21 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp25 = tl.load(in_ptr3 + (2*tmp23 + tmp23*(ks0 // 2) + (tl.where(((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))) < 0, 2 + (ks0 // 2) + ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))), ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (2 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((2 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (1 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0))))))))), tmp21 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp26 = 2 + ((-1)*x0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp27 = tmp24 == tmp26
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp28 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp29 = tl.where(tmp27, tmp25, tmp28)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp30 = tl.full(tmp29.shape, 0.0, tmp29.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp31 = tl.where(tmp21, tmp29, tmp30)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp32 = (-3) + ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp33 = tmp16 >= tmp32
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp34 = (-2) + ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp35 = tmp16 <= tmp34
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp36 = tmp33 & tmp35
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp37 = tl.load(in_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp36, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp38 = tl.load(in_ptr1 + (x1), tmp36 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp39 = tl.load(in_ptr2 + (2*tmp38 + tmp38*(ks0 // 2) + (tl.where(((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))) < 0, 2 + (ks0 // 2) + ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))), ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0))))))))), tmp36 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp40 = tl.load(in_ptr3 + (2*tmp38 + tmp38*(ks0 // 2) + (tl.where(((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))) < 0, 2 + (ks0 // 2) + ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))))), ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) * ((((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((1 + ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) < (ks1)))) < (((0) * ((0) >= (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2)))) + (ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) * ((ks0 + (triton_helpers.div_floor_integer((-1)*x0,  2))) > (0))))))))), tmp36 & xmask, eviction_policy='evict_last', other=0.0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp41 = ((-1)*x0) + 2*ks0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp42 = tmp39 == tmp41
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp43 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp44 = tl.where(tmp42, tmp40, tmp43)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp45 = tl.full(tmp44.shape, 0.0, tmp44.dtype)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp46 = tl.where(tmp36, tmp44, tmp45)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp48 = tl.full([XBLOCK], 1000, tl.int32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp49 = tmp47 + tmp48
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp50 = tmp47 < 0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp51 = tl.where(tmp50, tmp49, tmp47)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.device_assert(((0 <= tmp51) & (tmp51 < 1000)) | ~(xmask), "index out of bounds: 0 <= tmp51 < 1000")
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp53 = tl.full([1], -1, tl.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp54 = tmp47 == tmp53
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp55 = tmp15 + tmp31
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp56 = tmp55 + tmp46
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp57 = 0.0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tmp58 = tl.where(tmp54, tmp57, tmp56)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tl.atomic_add(out_ptr3 + (x1 + 128*tmp51), tmp58, xmask, sem='relaxed')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] ''', device_str='cuda')
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] async_compile.wait(globals())
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] del async_compile
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def call(args):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_2, sym_size_int_1, sym_size_int_3, sym_size_int_4, add_63, sub_28, sub_30, sym_size_int_6, sub_44, primals_3, primals_4, unsqueeze, _low_memory_max_pool2d_offsets_to_indices, unsqueeze_3, _low_memory_max_pool2d_offsets_to_indices_1, squeeze_4, convolution, view_16, view_17, tangents_1 = args
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     args.clear()
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     s0 = primals_2
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_3, (1, s0), (s0, 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(primals_4, (3, 64, 4, 4), (1024, 16, 4, 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(unsqueeze, (1, 128, 1, 4 + s0), (512 + 128*s0, 4 + s0, 4 + s0, 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(_low_memory_max_pool2d_offsets_to_indices, (1, 128, 1, 2 + (s0 // 2)), (256 + 128*(s0 // 2), 2 + (s0 // 2), 2 + (s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(unsqueeze_3, (1, 1, 128, 4 + 2*(s0 // 2)), (512 + 256*(s0 // 2), 512 + 256*(s0 // 2), 4 + 2*(s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(_low_memory_max_pool2d_offsets_to_indices_1, (1, 1, 64, 2 + (s0 // 2)), (128 + 64*(s0 // 2), 128 + 64*(s0 // 2), 2 + (s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(squeeze_4, (1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(convolution, (1, 64, 262, 14 + 4*(s0 // 2)), (234752 + 67072*(s0 // 2), 3668 + 1048*(s0 // 2), 14 + 4*(s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(view_16, (1, 1, 1), (1, 1, 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(view_17, (1, 128, 1), (128, 1, 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     assert_size_stride(tangents_1, (1, 64, 262, 14 + 4*(s0 // 2)), (234752 + 67072*(s0 // 2), 3668 + 1048*(s0 // 2), 14 + 4*(s0 // 2), 1))
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         torch.cuda.set_device(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf0 = convolution; del convolution  # reuse
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.elu_backward, aten.hardswish, aten.hardswish_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_elu_backward_hardswish_hardswish_backward_0_xnumel = 234752 + 67072*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_elu_backward_hardswish_hardswish_backward_0.run(buf0, tangents_1, triton_poi_fused_elu_backward_hardswish_hardswish_backward_0_xnumel, grid=grid(triton_poi_fused_elu_backward_hardswish_hardswish_backward_0_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del tangents_1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf1 = empty_strided_cuda((64, 3), (3, 1), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_red_fused_convolution_backward_1_r0_numel = (3670 + 1048*(s0 // 2)) // 3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_red_fused_convolution_backward_1.run(buf0, buf1, s0, 192, triton_red_fused_convolution_backward_1_r0_numel, grid=grid(192), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf2 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_per_fused_convolution_backward_2.run(buf1, buf2, 64, 3, grid=grid(64), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf3 = torch.ops.aten.convolution_backward.default(buf0, squeeze_4, primals_4, [64], [2, 2], [0, 0], [1, 1], True, [0, 0], 1, [True, True, False])
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del primals_4
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del squeeze_4
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf4 = buf3[0]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf5 = buf3[1]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps0 = 780 + 260*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf6 = empty_strided_cuda((1, 1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone, aten.zeros_like, aten.copy, aten.slice_backward, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3.run(buf4, buf6, ps0, s0, triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3_xnumel, grid=grid(triton_poi_fused_add_clone_copy_slice_backward_zeros_like_3_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps1 = 6 + 2*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf7 = reinterpret_tensor(buf4, (1, 1, 3, 130, 6 + 2*(s0 // 2)), (2340 + 780*(s0 // 2), 2340 + 780*(s0 // 2), 780 + 260*(s0 // 2), 6 + 2*(s0 // 2), 1), 0); del buf4  # reuse
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.slice_backward, aten.clone, aten.zeros_like, aten.copy, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4.run(buf6, buf7, ps1, ps0, s0, triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4_xnumel, grid=grid(triton_poi_fused_add_clone_copy_slice_backward_zeros_like_4_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf8 = buf6; del buf6  # reuse
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.slice_backward, aten.clone, aten.zeros_like, aten.copy, aten.add]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5_xnumel = 2340 + 780*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5.run(buf7, buf8, ps1, s0, triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5_xnumel, grid=grid(triton_poi_fused_add_clone_copy_slice_backward_zeros_like_5_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf7
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf9 = empty_strided_cuda((1, 1, 128 + 64*(s0 // 2)), (128 + 64*(s0 // 2), 128 + 64*(s0 // 2), 1), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.gather]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_gather_6_xnumel = 128 + 64*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_gather_6.run(_low_memory_max_pool2d_offsets_to_indices_1, buf8, buf9, s0, triton_poi_fused_gather_6_xnumel, grid=grid(triton_poi_fused_gather_6_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf8
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         ps2 = 2 + (s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf10 = empty_strided_cuda((1, 128, 2 + (s0 // 2)), (256 + 128*(s0 // 2), 2 + (s0 // 2), 1), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.gather]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_gather_7_xnumel = 256 + 128*(s0 // 2)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_gather_7.run(_low_memory_max_pool2d_offsets_to_indices, _low_memory_max_pool2d_offsets_to_indices_1, buf9, buf10, s0, ps2, triton_poi_fused_gather_7_xnumel, grid=grid(triton_poi_fused_gather_7_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del _low_memory_max_pool2d_offsets_to_indices_1
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf9
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         buf14 = empty_strided_cuda((1000, 128), (128, 1), torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.embedding_dense_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_embedding_dense_backward_8.run(buf14, 128000, grid=grid(128000), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.hardswish_backward, aten.reflection_pad1d_backward, aten.embedding_dense_backward]
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9_xnumel = 128*s0
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9.run(view_16, view_17, _low_memory_max_pool2d_offsets_to_indices, buf10, primals_3, buf14, s0, ps2, triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9_xnumel, grid=grid(triton_poi_fused_embedding_dense_backward_hardswish_backward_reflection_pad1d_backward_9_xnumel), stream=stream0)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del _low_memory_max_pool2d_offsets_to_indices
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del buf10
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del primals_3
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del view_16
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]         del view_17
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     return (buf14, None, None, buf5, buf2, )
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_2 = 32
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sym_size_int_1 = 18
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sym_size_int_3 = 18
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sym_size_int_4 = 36
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     add_63 = 38
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sub_28 = 37
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sub_30 = 36
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sym_size_int_6 = 36
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     sub_44 = 36
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_3 = rand_strided((1, 32), (32, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     primals_4 = rand_strided((3, 64, 4, 4), (1024, 16, 4, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     unsqueeze = rand_strided((1, 128, 1, 36), (4608, 36, 36, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     _low_memory_max_pool2d_offsets_to_indices = rand_strided((1, 128, 1, 18), (2304, 18, 18, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     unsqueeze_3 = rand_strided((1, 1, 128, 36), (4608, 4608, 36, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     _low_memory_max_pool2d_offsets_to_indices_1 = rand_strided((1, 1, 64, 18), (1152, 1152, 18, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     squeeze_4 = rand_strided((1, 3, 130, 38), (14820, 4940, 38, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     convolution = rand_strided((1, 64, 262, 78), (1307904, 20436, 78, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     view_16 = rand_strided((1, 1, 1), (1, 1, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     view_17 = rand_strided((1, 128, 1), (128, 1, 1), device='cuda:0', dtype=torch.int64)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     tangents_1 = rand_strided((1, 64, 262, 78), (1307904, 20436, 78, 1), device='cuda:0', dtype=torch.float32)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     fn = lambda: call([primals_2, sym_size_int_1, sym_size_int_3, sym_size_int_4, add_63, sub_28, sub_30, sym_size_int_6, sub_44, primals_3, primals_4, unsqueeze, _low_memory_max_pool2d_offsets_to_indices, unsqueeze_3, _low_memory_max_pool2d_offsets_to_indices_1, squeeze_4, convolution, view_16, view_17, tangents_1])
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] if __name__ == "__main__":
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 09:56:51.065000 3192161 site-packages/torch/_inductor/graph.py:2014] [379/0] [__output_code] 
V0127 09:56:51.084000 3192161 site-packages/torch/_inductor/graph.py:2022] [379/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/qn/cqnjir6thmwkut6ectekwawvqs5fdxe5qtz4edgchz2mxtfjvlbe.py
I0127 09:56:51.635000 3192161 site-packages/torch/_inductor/graph.py:2056] [379/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/qn/cqnjir6thmwkut6ectekwawvqs5fdxe5qtz4edgchz2mxtfjvlbe.py
