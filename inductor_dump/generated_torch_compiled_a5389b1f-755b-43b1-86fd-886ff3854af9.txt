V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] Output code: 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # AOT ID: ['35_forward']
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import torch
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import random
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import os
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import tempfile
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from math import inf, nan
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from cmath import nanj
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch import device, empty_strided
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     grid,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     split_scan_grid,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     grid_combo_kernels,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     start_graph,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     end_graph,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     cooperative_reduction_grid,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] aten = torch.ops.aten
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] _quantized = torch.ops._quantized
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] async_compile = AsyncCompile()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dy/cdydpbyb2eu3o56dmr75xvkx3b2k7klrfzm2ei7ztizq2vlhwfqo.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward => clone
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clone_0 = async_compile.triton('triton_poi_fused_clone_0', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clone_0(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 64*ks2*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp0, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lo/cloifxmrr35fbfqwi7rkcn66vxzj37y33qkgwwjysazal6yifbhk.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward => clone_1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_1 : [num_users=3] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clone_1 = async_compile.triton('triton_poi_fused_clone_1', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 65536}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clone_1(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 192*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + 64*x2), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6j/c6jxgax4simhuumtrxxq5txqh5fqp6sri37fnajde2drjeko7pfq.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward => view_6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_6 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_3, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_view_2 = async_compile.triton('triton_poi_fused_view_2', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_view_2(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xn/cxnpwfobm2wvcwqlpuspk5sceruh36pefbrf6jtt5lmn33gjd4vc.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward => view_7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_7 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_4, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_view_3 = async_compile.triton('triton_poi_fused_view_3', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_view_3(in_ptr0, out_ptr0, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (ks2 + x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks3))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3e/c3emcvt4ftwyksvluh4zhn4zeco477fzymgetbmp3xtxuqasy3hi.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward => view_8
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_8 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%permute_5, [%primals_1, 8, %primals_2, 8]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_view_4 = async_compile.triton('triton_poi_fused_view_4', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_view_4(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 8*x1 + 64*((((x0 + 8*x1 + 64*x2) // 64) % ks0)) + 64*ks0*((((x0 + 8*x1 + 64*x2 + 64*ks0*x3) // ks1) % ks2)) + 128*ks0*ks2), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp0, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4l/c4lc2mtvqxjhxrfjbb5e5fua7xz5dipus3n4746k3h4pzd7jy2wh.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [dropout, add, x_1], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   add => add_144
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dropout => gt, inductor_lookup_seed_default, inductor_random_default_4, mul_127, mul_128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_1 => add_149, add_150, clone_3, mul_137, mul_138, rsqrt, sub_66, var_mean
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_lookup_seed_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_random_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default, rand), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %gt : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_4, 0.1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_127 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt, %view_10), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_128 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_127, 1.1111111111111112), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_144 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%permute, %mul_128), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_3 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%add_144,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_3, [2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_149 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_4, 1e-05), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %rsqrt : [num_users=3] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_149,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_66 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_3, %getitem_5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_137 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_66, %rsqrt), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_138 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_137, %primals_8), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_150 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_138, %primals_9), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_319 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_144, %getitem_5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_598 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_319, %rsqrt), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_9 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt, 64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'out_ptr6': '*fp32', 'load_seed_offset': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr1, out_ptr4, out_ptr5, out_ptr6, load_seed_offset, ks1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = (xindex % ks1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x3 + 64*ks2*x2), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp39 = tl.load(in_ptr5 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 0.1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = 64.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tmp36 * tmp37
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp40 = tmp38 + tmp39
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp41 = 0.015625
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp42 = tmp35 * tmp41
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 64*x0), tmp40, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr5 + (r0_1 + 64*x3 + 64*ks2*x2), tmp36, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr6 + (x0), tmp42, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7x/c7xiwpcllx6grv7seskyi2tmfwzhufdnp6juo3kcrsogddnsiaza.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward_1 => full_default
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([%mul_8, 64], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_view_6 = async_compile.triton('triton_poi_fused_view_6', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_view_6(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yz/cyzwdgu5elljzfcnkkfdvncxmcnjxrgkrf7sxllmjm4mrgytduqf.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   multi_head_attention_forward_1 => clone_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_4 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_1,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clone_7 = async_compile.triton('triton_poi_fused_clone_7', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 65536}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clone_7(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 64) % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*x2 + 128*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (64 + x0 + 64*x2), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ay/caykh7arksrkm5gmsep3nzkbzkwfnw2q7zono232imoqcxvcfosw.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_1, add_1, x_2], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   add_1 => add_296
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dropout_1 => gt_1, inductor_lookup_seed_default_1, inductor_random_default_3, mul_252, mul_253
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_2 => add_301, add_302, mul_262, mul_263, rsqrt_1, sub_133, var_mean_1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_lookup_seed_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_random_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_1, rand), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %gt_1 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_3, 0.1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_252 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_1, %view_23), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_253 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_252, 1.1111111111111112), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_296 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_150, %mul_253), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_1 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_296, [2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_301 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 1e-05), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %rsqrt_1 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_301,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_133 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_296, %getitem_15), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_262 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_133, %rsqrt_1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_263 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_262, %primals_14), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_302 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_263, %primals_15), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_8 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_1, 64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'load_seed_offset': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': (9,)}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr1, out_ptr4, out_ptr5, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = tl.load(in_ptr3 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp39 = tl.load(in_ptr4 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 0.1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = 64.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tmp36 * tmp37
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp40 = tmp38 + tmp39
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp41 = 0.015625
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp42 = tmp35 * tmp41
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr4 + (r0_1 + 64*x0), tmp40, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr5 + (x0), tmp42, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/26/c26qdh6wbqb4cgwbdmfmdaml4x3z43asbhqv7o4naocrp4zd4tic.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dropout_2 => gt_2, inductor_lookup_seed_default_2, inductor_random_default_2, mul_289, mul_290
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   relu => relu
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%view_25,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_lookup_seed_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_random_default_2 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 2048], %inductor_lookup_seed_default_2, rand), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %gt_2 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_2, 0.1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_289 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_2, %relu), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_290 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_289, 1.1111111111111112), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %le_1 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_dropout_relu_threshold_backward_9 = async_compile.triton('triton_poi_fused_native_dropout_relu_threshold_backward_9', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 1048576}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr2': '*fp32', 'out_ptr3': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_relu_threshold_backward_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_dropout_relu_threshold_backward_9(in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr2, out_ptr3, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = (xindex % 2048)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 0.1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp9, tmp8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp5 * tmp10
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = 1.1111111111111112
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp10 <= tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp13, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr3 + (x0), tmp15, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cj/ccjcclk525bnff55zrgew77a7lhwu3esv2lodmidryltaw3mmu5d.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [dropout_3, add_2, x_4], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   add_2 => add_359
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dropout_3 => gt_3, inductor_lookup_seed_default_3, inductor_random_default_1, mul_308, mul_309
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_4 => add_364, mul_318, rsqrt_2, sub_162, var_mean_2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_lookup_seed_default_3 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 3), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_random_default_1 : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_2, %primals_1, 64], %inductor_lookup_seed_default_3, rand), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %gt_3 : [num_users=2] = call_function[target=torch.ops.aten.gt.Scalar](args = (%inductor_random_default_1, 0.1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_308 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%gt_3, %view_27), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_309 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_308, 1.1111111111111112), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_359 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_302, %mul_309), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_2 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%add_359, [2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_364 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_16, 1e-05), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %rsqrt_2 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_364,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_162 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_359, %getitem_17), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_318 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_162, %rsqrt_2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_7 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_2, 64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10 = async_compile.triton('triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*i1', 'out_ptr4': '*fp32', 'load_seed_offset': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, out_ptr1, out_ptr4, load_seed_offset, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = r0_1 + 64*x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 0.1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 > tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp7 + tmp8
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp6 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 1.1111111111111112
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp5 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.where(xmask, tmp14, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.where(xmask, tmp17, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tl.sum(tmp19, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tmp21.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp20 / tmp22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp14 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp24 * tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.broadcast_to(tmp25, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tl.where(xmask, tmp26, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tl.sum(tmp28, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tmp13 - tmp23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = 64.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp32 + tmp33
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = libdevice.rsqrt(tmp34)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp30 * tmp35
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = 0.015625
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tmp35 * tmp37
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (r0_1 + 64*x0), tmp4, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp36, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr4 + (x0), tmp38, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jd/cjd22czrgwaurlglv3pzqadxv5xwxsokykkvmoa2vpy25yo4wwyk.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.pow, aten.unsqueeze]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_7 => pow_1, unsqueeze_2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%permute_19, 2.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %unsqueeze_2 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%pow_1, -2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_pow_unsqueeze_11 = async_compile.triton('triton_poi_fused_pow_unsqueeze_11', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_pow_unsqueeze_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_pow_unsqueeze_11(in_ptr0, in_ptr1, in_ptr2, out_ptr1, ks0, ks1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     ymask = yindex < ynumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y3 = yindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y0 = (yindex % 64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y3 + 64*ks0*x2), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 * tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4 * tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (y3 + 64*ks0*x2), tmp5, xmask & ymask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ur/curzbmhspsknpnpgbn6w2gbq4lnxuxmzsxyajccrnzvrinacmive.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.avg_pool2d]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_7 => avg_pool2d
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %avg_pool2d : [num_users=3] = call_function[target=torch.ops.aten.avg_pool2d.default](args = (%unsqueeze_2, [1, 3], [1, 2]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_avg_pool2d_12 = async_compile.triton('triton_poi_fused_avg_pool2d_12', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_avg_pool2d_12(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*ks1*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (ks0 + x0 + 128*ks1*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0 + 128*ks1 + 128*ks1*x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1 + tmp0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp3 + tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = 0.3333333333333333
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4 * tmp5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0 + x1 + x0*(triton_helpers.div_floor_integer((-3) + ks2,  2))), tmp6, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ku/ckuczu5xxwvw5xizspqrc37bgwgh3yyzh6yswlxpxuid4n372tr6.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten._native_batch_norm_legit]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_8 => var_mean_3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_3 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_28, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused__native_batch_norm_legit_13 = async_compile.triton('triton_red_fused__native_batch_norm_legit_13', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 2048, 'r0_': 4},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused__native_batch_norm_legit_13(in_ptr0, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_mean = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_m2 = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_weight = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + x0 + x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.full([1, 1], 0, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp1 < tmp0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tmp2.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tmp0 < tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp4.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tmp3 - tmp5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tmp6.to(tmp0.dtype)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tl_math.abs(tmp0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = triton_helpers.maximum(tmp1, tmp8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tmp7 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp11 = 3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = libdevice.sqrt(tmp12)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_reduce(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]             tmp14, tmp15_mean, tmp15_m2, tmp15_weight, roffset == 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_mean = tl.where(r0_mask & xmask, tmp15_mean_next, tmp15_mean)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_m2 = tl.where(r0_mask & xmask, tmp15_m2_next, tmp15_m2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_weight = tl.where(r0_mask & xmask, tmp15_weight_next, tmp15_weight)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18, tmp19, tmp20 = triton_helpers.welford(tmp15_mean, tmp15_m2, tmp15_weight, 1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp18[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp19[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp20[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp15, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5f/c5fj25tuc2vixlld7f2wi2vhxk6otbow7mbrypj3nkrozy7hhb75.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.native_layer_norm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_10 => clone_6, var_mean_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_6 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%permute_20,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_4 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_6, [2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_native_layer_norm_14 = async_compile.triton('triton_per_fused_native_layer_norm_14', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128, 'r0_': 64},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 4, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_native_layer_norm_14(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_2 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_2 + x0 + 64*x1 + r0_2*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 64*x1*(triton_helpers.div_floor_integer((-3) + ks1,  2))), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.load(in_ptr1 + (r0_2 + 64*x1), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr2 + (r0_2 + 64*x1), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([1, 1], 0, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1 < tmp0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp0 < tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp3 - tmp5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp6.to(tmp0.dtype)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl_math.abs(tmp0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = triton_helpers.maximum(tmp1, tmp8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp7 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp13 - tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp16 / tmp18
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp19 + tmp20
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = libdevice.rsqrt(tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp15 * tmp22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tl.broadcast_to(tmp23, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.where(xmask, tmp24, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = tl.broadcast_to(tmp24, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tl.where(xmask, tmp27, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tl.sum(tmp29, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = tl.full([XBLOCK, 1], 64, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp31.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = tmp30 / tmp32
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp24 - tmp33
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = tmp34 * tmp34
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tl.broadcast_to(tmp35, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tl.where(xmask, tmp36, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp39 = tl.sum(tmp38, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp33, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp39, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rl/crljd7amc4e5icsb5rgpvnzjcoelktyiliizorto4v67met373yj.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.native_layer_norm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_10 => add_451, clone_6, rsqrt_4, var_mean_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_6 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%permute_20,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_4 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%clone_6, [2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_451 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_20, 1e-05), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %rsqrt_4 : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_451,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_layer_norm_15 = async_compile.triton('triton_poi_fused_native_layer_norm_15', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_15', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_layer_norm_15(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = 64.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 / tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = libdevice.rsqrt(tmp4)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp5, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pv/cpvafxb4oq5w33wdq7jt5cipef74b3nhbuxkdhdl7ipx4upe3sec.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.bernoulli]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_12 => inductor_lookup_seed_default_4, inductor_random_default, lt_6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_lookup_seed_default_4 : [num_users=1] = call_function[target=torch.ops.prims.inductor_lookup_seed.default](args = (%inductor_seeds_default, 4), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %inductor_random_default : [num_users=1] = call_function[target=torch.ops.prims.inductor_random.default](args = ([%primals_1, 64, 1], %inductor_lookup_seed_default_4, rand), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %lt_6 : [num_users=2] = call_function[target=torch.ops.aten.lt.Scalar](args = (%inductor_random_default, 0.5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_bernoulli_16 = async_compile.triton('triton_poi_fused_bernoulli_16', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 2048}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'out_ptr1': '*i1', 'load_seed_offset': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_bernoulli_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_bernoulli_16(in_ptr0, out_ptr1, load_seed_offset, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + load_seed_offset)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.rand(tmp0, (tmp1).to(tl.uint32))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 0.5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 < tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4w/c4wxk6ahymgfxuajq7wy5ml6kn6ei4wplczjoaagkq2qht2g2dog.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten._to_copy, aten.div, aten.mul]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_12 => convert_element_type, div, mul_417
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%lt_6, torch.float32), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Scalar](args = (%convert_element_type, 0.5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_417 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_21, %div), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__to_copy_div_mul_17 = async_compile.triton('triton_poi_fused__to_copy_div_mul_17', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*i1', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_div_mul_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__to_copy_div_mul_17(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = xindex // ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // ks0) % 64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.load(in_ptr1 + (x4), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr2 + (x4), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tl.load(in_ptr3 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.load(in_ptr4 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tl.load(in_ptr7 + (x4), xmask, eviction_policy='evict_last').to(tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1 < tmp0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp0 < tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4.to(tl.int8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp3 - tmp5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp6.to(tmp0.dtype)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl_math.abs(tmp0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = triton_helpers.maximum(tmp1, tmp8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp7 * tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp13 - tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp16 / tmp18
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = 1e-05
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp19 + tmp20
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = libdevice.rsqrt(tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp15 * tmp22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp23 - tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = tmp25 * tmp26
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tmp27 * tmp28
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = tmp29 + tmp30
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = tmp32.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = 2.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = tmp33 * tmp34
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp31 * tmp35
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp36, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2t/c2tt76qwzrwgsci5vudn66tsxfdr73qg2fdue2jfimbzkr42uh6x.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten._to_copy]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => convert_element_type_2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_2 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_30, torch.int64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__to_copy_18 = async_compile.triton('triton_poi_fused__to_copy_18', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__to_copy_18(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = 0.49606299212598426
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = triton_helpers.maximum(tmp3, tmp4)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b4/cb45uq7vvlu22hcsco2qu2gw26pivhw23kcqqfpvypuexm5acn4e.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.add, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => add_498, clamp_max
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_498 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_2, 1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_max : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_498, 63), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_add_clamp_19 = async_compile.triton('triton_poi_fused_add_clamp_19', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_add_clamp_19(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = 0.49606299212598426
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = triton_helpers.maximum(tmp3, tmp4)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.full([1], 1, tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp6 + tmp7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.full([1], 63, tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = triton_helpers.minimum(tmp8, tmp9)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp10, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6e/c6ejxn25kghbgvkxsreynyl7bsrqxeghnk4mvhnxduufuz2thm6m.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.arange, aten._to_copy, aten.clamp, aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => clamp_min_1, convert_element_type_3, convert_element_type_4, iota_1, view_31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %iota_1 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (%floordiv,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_1, torch.float32), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_1 : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], -1.0), kwargs = {dtype: torch.float64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_2 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 1), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_3 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], -3), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %scalar_tensor_default_3 : [num_users=1] = call_function[target=torch.ops.aten.scalar_tensor.default](args = (%primals_2,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_3, %scalar_tensor_default_3), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_4 : [num_users=3] = call_function[target=torch.ops.aten.full.default](args = ([], 2), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_tensor_mode : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor_mode](args = (%add_tensor, %full_default_4), kwargs = {rounding_mode: floor})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_2, %div_tensor_mode), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_tensor_1, torch.float64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_1, %convert_element_type_default), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_tensor : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_4, %div_tensor_mode), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_4, %mul_tensor), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_tensor_3, torch.float64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_1, %convert_element_type_default_1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %true_divide_tensor : [num_users=1] = call_function[target=torch.ops.aten.true_divide.Tensor](args = (%add_tensor_2, %add_tensor_4), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%true_divide_tensor, torch.float32), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, %convert_element_type_default_2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_min_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%mul_tensor_1, 0.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_31 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%clamp_min_1, [%floordiv]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_4 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_31, torch.int64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__to_copy_arange_clamp_view_20 = async_compile.triton('triton_poi_fused__to_copy_arange_clamp_view_20', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_arange_clamp_view_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__to_copy_arange_clamp_view_20(out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = -3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp0 + tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 2.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 / tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = libdevice.floor(tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 1.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7 + tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp8.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.full([1], -1.0, tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp10 + tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp4 * tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp4 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp13.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp11 / tmp15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp18.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp19 * tmp17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp20, tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp23, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sv/csvsrjbx2ierbjjgrnqzlbn74ulrfqvbyqj7t5554febzd7yheol.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.add, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => add_512, clamp_max_1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_512 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_4, 1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_max_1 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_512, %sub_235), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_add_clamp_21 = async_compile.triton('triton_poi_fused_add_clamp_21', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_add_clamp_21(out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = -3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp0 + tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 2.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 / tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = libdevice.floor(tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 1.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7 + tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp8.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.full([1], -1.0, tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp10 + tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp4 * tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp4 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp13.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp11 / tmp15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp18.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp19 * tmp17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp20, tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tl.full([1], 1, tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp23 + tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = triton_helpers.div_floor_integer((-3) + ks0,  2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = triton_helpers.minimum(tmp25, tmp26)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp27, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rh/crhxim5sixvupf2htxf4anx3qt53fajpwwhyegyk2w4zi2i44tjb.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.arange, aten._to_copy, aten.clamp, aten.view, aten.sub]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => clamp_max_2, clamp_min_1, clamp_min_2, convert_element_type_3, iota_1, sub_245, view_31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %iota_1 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (%floordiv,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_3 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_1, torch.float32), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_1 : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], -1.0), kwargs = {dtype: torch.float64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_2 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 1), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_3 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], -3), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %scalar_tensor_default_3 : [num_users=1] = call_function[target=torch.ops.aten.scalar_tensor.default](args = (%primals_2,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_3, %scalar_tensor_default_3), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_4 : [num_users=3] = call_function[target=torch.ops.aten.full.default](args = ([], 2), kwargs = {dtype: torch.int64, layout: torch.strided, device: cpu, pin_memory: False})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_tensor_mode : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor_mode](args = (%add_tensor, %full_default_4), kwargs = {rounding_mode: floor})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_2, %div_tensor_mode), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_tensor_1, torch.float64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_1, %convert_element_type_default), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_tensor : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_4, %div_tensor_mode), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_4, %mul_tensor), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_tensor_3, torch.float64), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_tensor_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%full_default_1, %convert_element_type_default_1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %true_divide_tensor : [num_users=1] = call_function[target=torch.ops.aten.true_divide.Tensor](args = (%add_tensor_2, %add_tensor_4), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_default_2 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%true_divide_tensor, torch.float32), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_3, %convert_element_type_default_2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_min_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%mul_tensor_1, 0.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_31 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%clamp_min_1, [%floordiv]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_245 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_31, %convert_element_type_4), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_min_2 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_245, 0.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_max_2 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_2, 1.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__to_copy_arange_clamp_sub_view_22 = async_compile.triton('triton_poi_fused__to_copy_arange_clamp_sub_view_22', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_arange_clamp_sub_view_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__to_copy_arange_clamp_sub_view_22(out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = -3.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp0 + tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 2.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 / tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = libdevice.floor(tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 1.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7 + tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp8.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.full([1], -1.0, tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp10 + tmp9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp4 * tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp4 + tmp12
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp13.to(tl.float64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp11 / tmp15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp18.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp19 * tmp17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp20, tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp23.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp22 - tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = triton_helpers.maximum(tmp25, tmp21)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = triton_helpers.minimum(tmp26, tmp7)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp27, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6e/c6eou3j7voynlno2hslakcf7pgeq2qqndpbxyg3gzfxjrftwxowa.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.sub, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => clamp_max_3, clamp_min_3, sub_262
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_262 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_30, %convert_element_type_2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_min_3 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_262, 0.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_max_3 : [num_users=2] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_3, 1.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clamp_sub_23 = async_compile.triton('triton_poi_fused_clamp_sub_23', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clamp_sub_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clamp_sub_23(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = x0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = 0.49606299212598426
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = triton_helpers.maximum(tmp3, tmp4)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp6.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp5 - tmp7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = triton_helpers.maximum(tmp8, tmp4)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = 1.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = triton_helpers.minimum(tmp9, tmp10)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp11, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7a/c7alvdok4v6qk4k2ersnbrsge5khul6ww5n3l6qh4sf37wdi3axj.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_14, x_17], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.neg, aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_14 => _unsafe_index, _unsafe_index_1, add_551, mul_457, sub_248
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_17 => clone_7, neg
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %_unsafe_index : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%unsqueeze_3, [None, None, %convert_element_type_2, %convert_element_type_4]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %_unsafe_index_1 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%unsqueeze_3, [None, None, %convert_element_type_2, %clamp_max_1]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_248 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_1, %_unsafe_index), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_457 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_248, %clamp_max_2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_551 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index, %mul_457), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%permute_22,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_7 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%neg,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24 = async_compile.triton('triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'in_ptr5': '*i64', 'in_ptr6': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 10, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // ks0) % 128)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([XBLOCK], 64, tl.int32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp0 < 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = ks1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp5 + tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp5 < 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.where(tmp8, tmp7, tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (tmp4 + tmp9 + 64*x2 + tmp4*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp11 + tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp11 < 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr2 + (tmp14 + tmp4 + 64*x2 + tmp4*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp15 - tmp10
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp16 * tmp17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp10 + tmp18
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp20 + tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tmp20 < 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tl.where(tmp22, tmp21, tmp20)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tl.load(in_ptr2 + (tmp23 + tmp9 + 64*x2 + tmp23*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tl.load(in_ptr2 + (tmp14 + tmp23 + 64*x2 + tmp23*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp25 - tmp24
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = tmp26 * tmp17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tmp24 + tmp27
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tmp28 - tmp19
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = tmp29 * tmp30
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp19 + tmp31
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = -tmp32
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp33, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mv/cmvmr7t5a3luwkkm7ou7dgrxlppvdwuyvk2usx26pfazergpkswe.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_17], Original ATen: [aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_17 => amax, exp, sub_276, sum_1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %amax : [num_users=1] = call_function[target=torch.ops.aten.amax.default](args = (%clone_7, [1], True), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_276 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_7, %amax), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %exp : [num_users=2] = call_function[target=torch.ops.aten.exp.default](args = (%sub_276,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%exp, [1], True), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused__softmax_25 = async_compile.triton('triton_red_fused__softmax_25', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 4096, 'r0_': 8},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__softmax_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused__softmax_25(in_ptr0, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], float("-inf"), tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + 2*x0 + 2*x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = triton_helpers.maximum(_tmp2, tmp1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = triton_helpers.max2(_tmp2, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp8 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.load(in_ptr0 + (r0_1 + 2*x0 + 2*x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp4 - tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tl_math.exp(tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tl.broadcast_to(tmp6, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = _tmp8 + tmp7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp8 = tl.where(r0_mask & xmask, tmp9, _tmp8)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.sum(_tmp8, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp8, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2f/c2fgbnnbzzh5vps4qpw5s4kbirx356b2keonkavbt57mropy2xd4.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_17], Original ATen: [aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_17 => div_1, exp, sub_276
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_276 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clone_7, %amax), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %exp : [num_users=2] = call_function[target=torch.ops.aten.exp.default](args = (%sub_276,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_1 : [num_users=4] = call_function[target=torch.ops.aten.div.Tensor](args = (%exp, %sum_1), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__softmax_26 = async_compile.triton('triton_poi_fused__softmax_26', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'y': 256, 'x': 128}, tile_hint=TileHint.DEFAULT,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__softmax_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__softmax_26(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     ymask = yindex < ynumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y0 = (yindex % ks0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y1 = yindex // ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y3 = yindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 2*x2 + 256*y1 + 2*x2*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 256*y1*(triton_helpers.div_floor_integer((-3) + ks1,  2))), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x2 + 128*y1), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.load(in_ptr2 + (x2 + 128*y1), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 - tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl_math.exp(tmp2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 / tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x2 + 128*y3), tmp5, xmask & ymask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yt/cytycke47la6ukg66ln6rb4ioypggo2h27xxk2vydernveefv6aa.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [pairwise_distance, mse_loss], Original ATen: [aten.sub, aten.add, aten.norm, aten.mse_loss_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   mse_loss => pow_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   pairwise_distance => add_642, pow_3, sub_293, sum_2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_293 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_6), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_642 : [num_users=1] = call_function[target=torch.ops.aten.add.Scalar](args = (%sub_293, 1e-06), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_3 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%add_642, 2.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%pow_3, [1]), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_4 : [num_users=2] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sum_2, 0.5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_mse_loss_backward_norm_sub_27 = async_compile.triton('triton_per_fused_add_mse_loss_backward_norm_sub_27', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32, 'r0_': 128},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mse_loss_backward_norm_sub_27', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_mse_loss_backward_norm_sub_27(in_out_ptr0, in_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 256*x0 + 256*x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (128 + r0_1 + 256*x0 + 256*x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), xmask, other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 - tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = 1e-06
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4 * tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = libdevice.sqrt(tmp9)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.debug_barrier()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp10, xmask)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jz/cjz65yirzwpjcxofz6j25kj4lfvc74lheoiihuuaqpgg5vb7ibde.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [pairwise_distance, dist_pos, sub_1, dist_neg, add_3, sub_2, loss, loss_1], Original ATen: [aten.sub, aten.linalg_vector_norm, aten.add, aten.clamp_min, aten.mean]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   add_3 => add_656
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dist_neg => pow_7, pow_8, sum_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   dist_pos => pow_5, pow_6, sum_3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   loss => clamp_min_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   loss_1 => mean
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   pairwise_distance => sub_293
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   sub_1 => sub_300
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   sub_2 => sub_302
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_293 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_6), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_5 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sub_293, 2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%pow_5, None), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_6 : [num_users=2] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sum_3, 0.5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_300 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_7), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_7 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sub_300, 2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%pow_7, None), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_8 : [num_users=2] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%sum_4, 0.5), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_656 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%pow_6, 1.0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_302 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_656, %pow_8), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clamp_min_4 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_302, 0), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%clamp_min_4,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28 = async_compile.triton('triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 1, 'r0_': 4096},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': (5,)}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_0 = (r0_index % 128)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index // 128
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_0 + 256*r0_1 + 256*r0_1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.load(in_ptr0 + (128 + r0_0 + 256*r0_1 + 256*r0_1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask, eviction_policy='evict_last', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tl.load(in_ptr0 + (256 + r0_0 + 256*r0_1 + 256*r0_1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask, eviction_policy='evict_first', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 - tmp1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tmp2 * tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp5 = tl.where(r0_mask, tmp6, _tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tmp0 - tmp7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = tmp8 * tmp8
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp11 = tl.where(r0_mask, tmp12, _tmp11)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = libdevice.sqrt(tmp5)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = libdevice.sqrt(tmp11)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = 1.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp13 + tmp15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp16 - tmp14
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = 0.0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp17, tmp18)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp19 / tmp15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.debug_barrier()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp13, None)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.debug_barrier()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr1 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp14, None)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp20, None)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gg/cggf5swst7boovexaqn37r2g6tlbskahdzgsfoi6n6xp77jkdaex.py
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [mse_loss], Original ATen: [aten.mse_loss]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   mse_loss => mean_1, pow_9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_9 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%pow_4, 2), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%pow_9,), kwargs = {})
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_mse_loss_29 = async_compile.triton('triton_red_fused_mse_loss_29', '''
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 1, 'r0_': 32},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': (3,)}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_mse_loss_29', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_mse_loss_29(in_out_ptr0, in_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp3 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_0 = r0_index
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_0), r0_mask, eviction_policy='evict_first', other=0.0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tmp0 * tmp0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tl.broadcast_to(tmp1, [XBLOCK, R0_BLOCK])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = _tmp3 + tmp2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp3 = tl.where(r0_mask, tmp4, _tmp3)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.sum(_tmp3, 1)[:, None]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = ks0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp3 / tmp6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.debug_barrier()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp7, None)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] async_compile.wait(globals())
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] del async_compile
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def call(args):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23 = args
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     args.clear()
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     s0 = primals_1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     s1 = primals_2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_3, (s0, s1, 64), (64*s1, 64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_4, (192, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_5, (192, 64), (64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_6, (64, 64), (64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_7, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_10, (192, 64), (64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_11, (192, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_12, (64, 64), (64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_13, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_16, (2048, 64), (64, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_17, (2048, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_18, (64, 2048), (2048, 1))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_19, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_21, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_22, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_23, (64, ), (1, ))
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         torch.cuda.set_device(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps0 = 64*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf0 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0.run(primals_3, buf0, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf1 = empty_strided_cuda((s0*s1, 192), (192, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.mm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf0, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_5, (64, 192), (1, 64), 0), out=buf1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_5
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps1 = s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps2 = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf2 = empty_strided_cuda((3, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_1_xnumel = 192*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_1.run(buf1, primals_4, buf2, ps1, ps2, triton_poi_fused_clone_1_xnumel, grid=grid(triton_poi_fused_clone_1_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_4
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf3 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_2.run(buf2, buf3, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf4 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_3.run(buf2, buf4, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf5 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_4_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_4.run(buf2, buf5, s0, ps0, s1, triton_poi_fused_view_4_xnumel, grid=grid(triton_poi_fused_view_4_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf2
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf6 = torch.ops.aten._scaled_dot_product_efficient_attention.default(buf3, buf4, buf5, None, True, 0.1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf7 = buf6[0]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf8 = buf6[1]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf9 = buf6[2]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf10 = buf6[3]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf6
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf11 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0.run(buf7, buf11, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf12 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf11, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_6, (64, 64), (1, 64), 0), out=buf12)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf13 = empty_strided_cuda((5, ), (1, ), torch.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: []
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         aten.randint.low_out(-9223372036854775808, 9223372036854775807, [5], out=buf13)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf15 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf19 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf85 = empty_strided_cuda((s1, s0, 64), (64, 64*s1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf86 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout, add, x_1], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel = s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5.run(buf13, primals_3, buf12, primals_7, primals_8, primals_9, buf15, buf19, buf85, buf86, 0, s0, s1, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_5_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_3
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_7
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_9
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf20 = buf12; del buf12  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.addmm(reinterpret_tensor(primals_11, (64, ), (1, ), 0), reinterpret_tensor(buf19, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_10, (64, 64), (1, 64), 0), alpha=1, beta=1, out=buf20)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf21 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_6_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_6.run(buf21, triton_poi_fused_view_6_xnumel, grid=grid(triton_poi_fused_view_6_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf22 = empty_strided_cuda((s0*s1, 128), (128, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(buf21, reinterpret_tensor(primals_10, (64, 128), (1, 64), 4096), out=buf22)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf23 = empty_strided_cuda((2, s1, s0, 64), (64*s0*s1, 64*s0, 64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_7_xnumel = 128*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_7.run(buf22, primals_11, buf23, ps1, ps2, triton_poi_fused_clone_7_xnumel, grid=grid(triton_poi_fused_clone_7_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf22
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_11
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf24 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_2_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_2.run(buf23, buf24, s0, ps0, s1, triton_poi_fused_view_2_xnumel, grid=grid(triton_poi_fused_view_2_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf25 = empty_strided_cuda((s0, 8, s1, 8), (64, 8, 64*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_3_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_3.run(buf23, buf25, s0, ps0, ps2, s1, triton_poi_fused_view_3_xnumel, grid=grid(triton_poi_fused_view_3_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten._scaled_dot_product_efficient_attention]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf26 = torch.ops.aten._scaled_dot_product_efficient_attention.default(reinterpret_tensor(buf20, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf24, buf25, None, True, 0.1)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf27 = buf26[0]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf28 = buf26[1]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf29 = buf26[2]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf30 = buf26[3]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf26
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf31 = empty_strided_cuda((s1, s0, 8, 8), (64*s0, 64, 8, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.clone]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0_xnumel = 64*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_0.run(buf27, buf31, s0, ps0, s1, triton_poi_fused_clone_0_xnumel, grid=grid(triton_poi_fused_clone_0_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf32 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [multi_head_attention_forward_1], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf31, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_12, (64, 64), (1, 64), 0), out=buf32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf34 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf38 = reinterpret_tensor(buf32, (s1, s0, 64), (64*s0, 64, 1), 0); del buf32  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf39 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf84 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_1, add_1, x_2], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel = s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8.run(buf38, buf13, buf19, primals_13, primals_14, primals_15, buf34, buf39, buf84, 1, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_8_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_13
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_15
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf40 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf39, (s0*s1, 64), (64, 1), 0), reinterpret_tensor(primals_16, (64, 2048), (1, 64), 0), out=buf40)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf42 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf43 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf83 = empty_strided_cuda((s1, s0, 2048), (2048*s0, 2048, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [relu, dropout_2], Original ATen: [aten.relu, aten.native_dropout, aten.threshold_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_9_xnumel = 2048*s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_relu_threshold_backward_9.run(buf13, buf40, primals_17, buf42, buf43, buf83, 2, triton_poi_fused_native_dropout_relu_threshold_backward_9_xnumel, grid=grid(triton_poi_fused_native_dropout_relu_threshold_backward_9_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf40
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_17
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf44 = empty_strided_cuda((s0*s1, 64), (64, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.addmm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf43, (s0*s1, 2048), (2048, 1), 0), reinterpret_tensor(primals_18, (2048, 64), (1, 2048), 0), out=buf44)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf46 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf50 = reinterpret_tensor(buf44, (s1, s0, 64), (64*s0, 64, 1), 0); del buf44  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf82 = empty_strided_cuda((s1, s0, 1), (s0, 1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [dropout_3, add_2, x_4], Original ATen: [aten.native_dropout, aten.add, aten.native_layer_norm, aten.native_layer_norm_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel = s0*s1
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10.run(buf50, buf13, buf39, primals_19, buf46, buf82, 3, triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_native_layer_norm_native_layer_norm_backward_10_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_19
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf52 = empty_strided_cuda((s0, 64, 1, s1), (64, 1, 64*s0*s1, 64*s0), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.pow, aten.unsqueeze]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_pow_unsqueeze_11_ynumel = 64*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_pow_unsqueeze_11.run(buf50, primals_20, primals_21, buf52, s0, s1, triton_poi_fused_pow_unsqueeze_11_ynumel, s1, grid=grid(triton_poi_fused_pow_unsqueeze_11_ynumel, s1), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf53 = empty_strided_cuda((s0, 64, 1, ((-1) + s1) // 2), (64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.avg_pool2d]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_avg_pool2d_12_xnumel = 64*s0*(((-1) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_avg_pool2d_12.run(buf52, buf53, ps0, s0, s1, triton_poi_fused_avg_pool2d_12_xnumel, grid=grid(triton_poi_fused_avg_pool2d_12_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf54 = empty_strided_cuda((1, 64*s0, 1), (64*s0, 1, 64*s0), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf55 = empty_strided_cuda((1, 64*s0, 1), (64*s0, 1, 64*s0), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten._native_batch_norm_legit]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_13_xnumel = 64*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_13_r0_numel = 1 + (((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_13.run(buf53, buf54, buf55, s1, triton_red_fused__native_batch_norm_legit_13_xnumel, triton_red_fused__native_batch_norm_legit_13_r0_numel, grid=grid(triton_red_fused__native_batch_norm_legit_13_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps3 = 1 + (((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf57 = empty_strided_cuda((s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf58 = empty_strided_cuda((s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, s0 + s0*(((-3) + s1) // 2)), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.native_layer_norm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_14_xnumel = s0 + s0*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_14.run(buf53, buf54, buf55, buf57, buf58, ps3, s1, triton_per_fused_native_layer_norm_14_xnumel, 64, grid=grid(triton_per_fused_native_layer_norm_14_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf60 = reinterpret_tensor(buf58, (s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, 1), 0); del buf58  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_10], Original ATen: [aten.native_layer_norm]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_15_xnumel = s0 + s0*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_15.run(buf60, triton_poi_fused_native_layer_norm_15_xnumel, grid=grid(triton_poi_fused_native_layer_norm_15_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf62 = empty_strided_cuda((s0, 64, 1), (64, 1, 1), torch.bool)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.bernoulli]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_bernoulli_16_xnumel = 64*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_bernoulli_16.run(buf13, buf62, 4, triton_poi_fused_bernoulli_16_xnumel, grid=grid(triton_poi_fused_bernoulli_16_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf13
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps4 = 64 + 64*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf63 = empty_strided_cuda((s0, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten._to_copy, aten.div, aten.mul]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_div_mul_17_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_div_mul_17.run(buf53, buf54, buf55, buf57, buf60, primals_22, primals_23, buf62, buf63, ps3, ps4, s1, triton_poi_fused__to_copy_div_mul_17_xnumel, grid=grid(triton_poi_fused__to_copy_div_mul_17_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf54
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf55
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_23
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf64 = empty_strided_cuda((128, 1), (1, 1), torch.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten._to_copy]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_18.run(buf64, 128, grid=grid(128), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf65 = empty_strided_cuda((128, 1), (1, 1), torch.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.add, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_clamp_19.run(buf65, 128, grid=grid(128), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf66 = empty_strided_cuda((2 + 2*(((-3) + s1) // 2), ), (1, ), torch.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.arange, aten._to_copy, aten.clamp, aten.view]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_arange_clamp_view_20_xnumel = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_arange_clamp_view_20.run(buf66, s1, triton_poi_fused__to_copy_arange_clamp_view_20_xnumel, grid=grid(triton_poi_fused__to_copy_arange_clamp_view_20_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf67 = empty_strided_cuda((2 + 2*(((-3) + s1) // 2), ), (1, ), torch.int64)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.add, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_clamp_21_xnumel = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_clamp_21.run(buf67, s1, triton_poi_fused_add_clamp_21_xnumel, grid=grid(triton_poi_fused_add_clamp_21_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf68 = empty_strided_cuda((2 + 2*(((-3) + s1) // 2), ), (1, ), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.arange, aten._to_copy, aten.clamp, aten.view, aten.sub]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_arange_clamp_sub_view_22_xnumel = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_arange_clamp_sub_view_22.run(buf68, s1, triton_poi_fused__to_copy_arange_clamp_sub_view_22_xnumel, grid=grid(triton_poi_fused__to_copy_arange_clamp_sub_view_22_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf70 = empty_strided_cuda((128, 1), (1, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14], Original ATen: [aten.sub, aten.clamp]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clamp_sub_23.run(buf70, 128, grid=grid(128), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps5 = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps6 = 256 + 256*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf69 = empty_strided_cuda((s0, 1, 128, 2 + 2*(((-3) + s1) // 2)), (256 + 256*(((-3) + s1) // 2), 256*s0 + 256*s0*(((-3) + s1) // 2), 2 + 2*(((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf71 = reinterpret_tensor(buf69, (s0, 2 + 2*(((-3) + s1) // 2), 128), (256 + 256*(((-3) + s1) // 2), 1, 2 + 2*(((-3) + s1) // 2)), 0); del buf69  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_14, x_17], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.neg, aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24_xnumel = 256*s0 + 256*s0*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24.run(buf71, buf64, buf66, buf63, buf67, buf68, buf65, buf70, ps5, ps3, ps6, s1, triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24_xnumel, grid=grid(triton_poi_fused__softmax__unsafe_index_add_mul_neg_sub_24_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf63
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf72 = empty_strided_cuda((s0, 1, 128), (128, 128*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf73 = empty_strided_cuda((s0, 1, 128), (128, 128*s0, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_17], Original ATen: [aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_25_xnumel = 128*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_25_r0_numel = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_25.run(buf71, buf72, buf73, s1, triton_red_fused__softmax_25_xnumel, triton_red_fused__softmax_25_r0_numel, grid=grid(triton_red_fused__softmax_25_xnumel), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf74 = empty_strided_cuda((s0, 2 + 2*(((-3) + s1) // 2), 128), (256 + 256*(((-3) + s1) // 2), 128, 1), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_17], Original ATen: [aten._softmax]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax_26_ynumel = 2*s0 + 2*s0*(((-3) + s1) // 2)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax_26.run(buf71, buf72, buf73, buf74, ps5, s1, triton_poi_fused__softmax_26_ynumel, 128, grid=grid(triton_poi_fused__softmax_26_ynumel, 128), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf71
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf72
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf73
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf75 = empty_strided_cuda((s0, ), (1, ), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf76 = buf75; del buf75  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [pairwise_distance, mse_loss], Original ATen: [aten.sub, aten.add, aten.norm, aten.mse_loss_backward]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_mse_loss_backward_norm_sub_27.run(buf76, buf74, s1, s0, 128, grid=grid(s0), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf77 = empty_strided_cuda((), (), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf79 = empty_strided_cuda((), (), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf78 = buf77; del buf77  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf80 = buf79; del buf79  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf87 = empty_strided_cuda((), (), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [pairwise_distance, dist_pos, sub_1, dist_neg, add_3, sub_2, loss, loss_1], Original ATen: [aten.sub, aten.linalg_vector_norm, aten.add, aten.clamp_min, aten.mean]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28_r0_numel = 128*s0
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28.run(buf78, buf80, buf74, buf87, s1, 1, triton_red_fused_add_clamp_min_linalg_vector_norm_mean_sub_28_r0_numel, grid=grid(1), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf81 = empty_strided_cuda((), (), torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf88 = buf81; del buf81  # reuse
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [mse_loss], Original ATen: [aten.mse_loss]
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_mse_loss_29.run(buf88, buf76, s0, 1, s0, grid=grid(1), stream=stream0)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     return (buf74, buf87, buf88, primals_8, primals_14, primals_20, primals_21, primals_22, reinterpret_tensor(buf0, (s0*s1, 64), (64, 1), 0), buf3, buf4, buf5, buf7, buf8, buf9, buf10, reinterpret_tensor(buf11, (s0*s1, 64), (64, 1), 0), buf15, reinterpret_tensor(buf19, (s0*s1, 64), (64, 1), 0), buf21, reinterpret_tensor(buf20, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), buf24, buf25, buf27, buf28, buf29, buf30, reinterpret_tensor(buf31, (s0*s1, 64), (64, 1), 0), buf34, buf38, reinterpret_tensor(buf39, (s0*s1, 64), (64, 1), 0), buf42, reinterpret_tensor(buf43, (s0*s1, 2048), (2048, 1), 0), buf46, buf50, buf52, buf53, buf57, buf60, buf62, buf64, buf65, buf66, buf67, buf68, buf70, buf74, buf76, buf78, buf80, buf82, primals_18, buf83, primals_16, buf84, primals_12, reinterpret_tensor(primals_10, (64, 64), (64, 1), 0), buf85, buf86, primals_6, s0, s1, s0*s1, 8*s0, 1 + (((-3) + s1) // 2), )
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_1 = 32
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_2 = 10
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_3 = rand_strided((32, 10, 64), (640, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_4 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_5 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_6 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_10 = rand_strided((192, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_11 = rand_strided((192, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_12 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_13 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_16 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_17 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_18 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_19 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_22 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_23 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23])
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] if __name__ == "__main__":
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 12:26:29.881000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:29.928000 1940816 site-packages/torch/_inductor/graph.py:2022] [110/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/ky/ckyv7fy4yawsct4dvmkbok5vt47gumfldsgjiwied7nzvitct54v.py
I0127 12:26:30.619000 1940816 site-packages/torch/_inductor/graph.py:2056] [110/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/ky/ckyv7fy4yawsct4dvmkbok5vt47gumfldsgjiwied7nzvitct54v.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] Output code: 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # AOT ID: ['35_backward']
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import torch
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import random
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import os
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import tempfile
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from math import inf, nan
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from cmath import nanj
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.utils import maybe_profile
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch import device, empty_strided
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     grid,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     split_scan_grid,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     grid_combo_kernels,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     start_graph,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     end_graph,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     cooperative_reduction_grid,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] aten = torch.ops.aten
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] inductor_ops = torch.ops.inductor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] _quantized = torch.ops._quantized
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] async_compile = AsyncCompile()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jr/cjrwncrru6ywnnwbijfgup2jewa2p6vl75kcxjwowwliwmpaodss.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten._native_batch_norm_legit]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_8 => var_mean_3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %var_mean_3 : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_28, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused__native_batch_norm_legit_0 = async_compile.triton('triton_red_fused__native_batch_norm_legit_0', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 2048, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused__native_batch_norm_legit_0(in_ptr0, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_mean = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_m2 = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15_weight = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + x0 + x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.full([1, 1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp1 < tmp0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tmp2.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp4.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tmp3 - tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tmp6.to(tmp0.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tl_math.abs(tmp0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = triton_helpers.maximum(tmp1, tmp8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tmp7 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp11 = 3.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = tmp10 * tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = libdevice.sqrt(tmp12)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_mean_next, tmp15_m2_next, tmp15_weight_next = triton_helpers.welford_reduce(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]             tmp14, tmp15_mean, tmp15_m2, tmp15_weight, roffset == 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_mean = tl.where(r0_mask & xmask, tmp15_mean_next, tmp15_mean)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_m2 = tl.where(r0_mask & xmask, tmp15_m2_next, tmp15_m2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15_weight = tl.where(r0_mask & xmask, tmp15_weight_next, tmp15_weight)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18, tmp19, tmp20 = triton_helpers.welford(tmp15_mean, tmp15_m2, tmp15_weight, 1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp18[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp19[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp20[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp15, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/y4/cy45dbibcuuynbtfsbxlfu4nakaw4y5a7clog57xn2awwau74xfs.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_306 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%permute_20, %getitem_21), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_554 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_306, %rsqrt_4), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_layer_norm_backward_1 = async_compile.triton('triton_poi_fused_native_layer_norm_backward_1', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_backward_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_layer_norm_backward_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.load(in_ptr1 + (x4), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr2 + (x4), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tl.load(in_ptr3 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tl.load(in_ptr4 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp1 < tmp0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp4.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp3 - tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp6.to(tmp0.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl_math.abs(tmp0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = triton_helpers.maximum(tmp1, tmp8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp7 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 3.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp13 - tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp16 / tmp18
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = 1e-05
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp19 + tmp20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = libdevice.rsqrt(tmp21)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp15 * tmp22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp23 - tmp24
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = tmp25 * tmp26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp27, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/v2/cv2jnduysxoeyinzb4zhetackmrvciz4nd33msdcm5m2gseiykrs.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.neg, aten.add, aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_550 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%unsqueeze_6, %clamp_max_3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_8 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_551,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_666 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_550, %neg_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_11 : [num_users=4] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 1, 64, %sym_size_int_18], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %index_put_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%full_11, [None, None, %clamp_max, %convert_element_type_4], %add_666, True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2 = async_compile.triton('triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qj/cqjs5cddogoduevizw2wvica2taafwxjzbdwft272rfphyry6kds.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [add_3, sub_2, sub_1, pairwise_distance], Original ATen: [aten.div, aten.scalar_tensor, aten.add, aten.sub, aten.ge, aten.where, aten.neg, aten.eq, aten.masked_fill, aten.mul]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   add_3 => add_656
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   pairwise_distance => add_642, sub_293
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   sub_1 => sub_300
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   sub_2 => sub_302
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Scalar](args = (%expand, 1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_656 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%pow_6, 1.0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_302 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_656, %pow_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %ge_19 : [num_users=1] = call_function[target=torch.ops.aten.ge.Scalar](args = (%sub_302, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%ge_19, %div_2, %full_default_10), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_1 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%where,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_300 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_7), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_300, %pow_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %eq_344 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%pow_8, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_1 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%eq_344, %full_default_10, %div_3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_546 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%neg_1, %where_1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_293 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_6), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_4 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_293, %pow_6), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %eq_345 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%pow_6, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_2 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%eq_345, %full_default_10, %div_4), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_547 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where, %where_2), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_3 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_547,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_659 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_546, %mul_547), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_642 : [num_users=1] = call_function[target=torch.ops.aten.add.Scalar](args = (%sub_293, 1e-06), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_5 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_642, %unsqueeze_5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %eq_346 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%unsqueeze_5, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_3 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%eq_346, %full_default_10, %div_5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_548 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%unsqueeze_4, %where_3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_4 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_548,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_660 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_659, %mul_548), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_661 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%neg_3, %neg_4), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3 = async_compile.triton('triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 4096}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'out_ptr2': '*fp32', 'out_ptr3': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 11), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr2, out_ptr3, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 128
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (0))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.load(in_ptr1 + (0))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (0))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.broadcast_to(tmp9, [XBLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0 + 256*x1 + 256*x1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr3 + (256 + x0 + 256*x1 + 256*x1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tl.load(in_ptr3 + (128 + x0 + 256*x1 + 256*x1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = tl.load(in_ptr5 + (0))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = 1.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 + tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp3 - tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp6 >= tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp10 * tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tl.where(tmp8, tmp11, tmp7)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = -tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp5 == tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp15 - tmp16
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17 / tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.where(tmp14, tmp7, tmp18)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp13 * tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp1 == tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp15 - tmp22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp23 / tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tl.where(tmp21, tmp7, tmp24)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp12 * tmp25
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = -tmp26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tl.full([1], 2.0, tl.float64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = tmp30.to(tl.float64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tmp29 / tmp31
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = tmp32.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp28 * tmp33
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = tmp34 * tmp36
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tmp28 == tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp39 = 1e-06
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp40 = tmp23 + tmp39
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp41 = tmp40 / tmp28
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp42 = tl.where(tmp38, tmp7, tmp41)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp43 = tmp37 * tmp42
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp44 = -tmp43
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp45 = tmp27 + tmp44
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp46 = tmp20 + tmp26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp47 = tmp46 + tmp43
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp20, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr2 + (x2), tmp45, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr3 + (x2), tmp47, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/se/csevcfkahmzxdzqx4umk2n4nk533vleztby44yj4ks2jb2pto4w2.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [pairwise_distance], Original ATen: [aten.scalar_tensor, aten.neg, aten.sub, aten.add, aten.div, aten.eq, aten.masked_fill, aten.mul, aten.select_backward, aten._softmax_backward_data]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   pairwise_distance => add_642, sub_293
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_2 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_546,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_293 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_5, %select_6), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_3 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_547,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_659 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_546, %mul_547), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_642 : [num_users=1] = call_function[target=torch.ops.aten.add.Scalar](args = (%sub_293, 1e-06), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_5 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%add_642, %unsqueeze_5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %eq_346 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%unsqueeze_5, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_3 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%eq_346, %full_default_10, %div_5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_548 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%unsqueeze_4, %where_3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_4 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_548,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_660 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_659, %mul_548), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_661 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%neg_3, %neg_4), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_3 : [num_users=3] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, %floordiv, 128], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %select_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_3, %neg_2, 1, 2), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_662 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%tangents_1, %select_scatter_default), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %select_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_3, %add_661, 1, 1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_663 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_662, %select_scatter_default_1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %select_scatter_default_2 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%full_3, %add_660, 1, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_664 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_663, %select_scatter_default_2), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_549 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_664, %div_1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4 = async_compile.triton('triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 128) % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.load(in_ptr1 + (x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr3 + (x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = x1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.full([1], 2, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 == tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = -tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.where(tmp3, tmp5, tmp6)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp0 + tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp1 == tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tl.where(tmp10, tmp11, tmp6)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp8 + tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp1 == tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.where(tmp15, tmp16, tmp6)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp13 + tmp17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp18 * tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp20, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/26/c26a4wcqe6ip6n6fleng2fbqth37x4s3cunna2l2k4vfzxysdvtk.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten._softmax_backward_data]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_549, [1], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused__softmax_backward_data_5 = async_compile.triton('triton_red_fused__softmax_backward_data_5', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 4096, 'r0_': 8},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.DEFAULT,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__softmax_backward_data_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused__softmax_backward_data_5(in_ptr0, out_ptr0, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 128
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_2 + 256*x1 + 256*x1*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fq/cfqcyxwwwip4oacnu3zk2m2jc7yf56kecbvvsyf74qdrfj3zwja4.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.neg, aten.add, aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_550 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%unsqueeze_6, %clamp_max_3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_7 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_550,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_665 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%unsqueeze_6, %neg_7), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_551 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_550, %clamp_max_2), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_8 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_551,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_666 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_550, %neg_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_552 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_665, %clamp_max_2), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %neg_9 : [num_users=1] = call_function[target=torch.ops.aten.neg.default](args = (%mul_552,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_667 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_665, %neg_9), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_11 : [num_users=4] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 1, 64, %sym_size_int_18], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %index_put : [num_users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%full_11, [None, None, %clamp_max, %clamp_max_1], %mul_551, True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %index_put_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%full_11, [None, None, %clamp_max, %convert_element_type_4], %add_666, True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %index_put_2 : [num_users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%full_11, [None, None, %convert_element_type_2, %clamp_max_1], %mul_552, True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %index_put_3 : [num_users=1] = call_function[target=torch.ops.aten.index_put_.default](args = (%full_11, [None, None, %convert_element_type_2, %convert_element_type_4], %add_667, True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6 = async_compile.triton('triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*i64', 'in_ptr6': '*i64', 'in_ptr7': '*i64', 'in_ptr8': '*i64', 'out_ptr1': '*fp32', 'out_ptr3': '*fp32', 'out_ptr4': '*fp32', 'out_ptr5': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'ks3': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6', 'mutated_arg_names': ['out_ptr1', 'out_ptr3', 'out_ptr4', 'out_ptr5'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 9, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, out_ptr1, out_ptr3, out_ptr4, out_ptr5, ks0, ks1, ks2, ks3, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 128) % ks1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0 + 128*x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.load(in_ptr5 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.load(in_ptr6 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = tl.load(in_ptr7 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tl.load(in_ptr8 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = -tmp0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = libdevice.fma(tmp1, tmp2, tmp3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = -tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp5 * tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp7 * tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.full([XBLOCK], 64, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 + tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp10 < 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp10)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.device_assert(((0 <= tmp14) & (tmp14 < 64)) | ~(xmask), "index out of bounds: 0 <= tmp14 < 64")
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = ks2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp16 + tmp17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp16 < 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tl.where(tmp19, tmp18, tmp16)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.device_assert(((0 <= tmp20) & (tmp20 < 1 + (triton_helpers.div_floor_integer((-3) + ks3,  2)))) | ~(xmask), "index out of bounds: 0 <= tmp20 < 1 + (triton_helpers.div_floor_integer((-3) + ks3,  2))")
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = -tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp7 + tmp22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = -tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp5 + tmp24
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp25 * tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tmp27 + tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tmp27 < 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tl.where(tmp29, tmp28, tmp27)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.device_assert(((0 <= tmp30) & (tmp30 < 64)) | ~(xmask), "index out of bounds: 0 <= tmp30 < 64")
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = -tmp26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = tmp25 + tmp32
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = tmp34 + tmp17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp34 < 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = tl.where(tmp36, tmp35, tmp34)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.device_assert(((0 <= tmp37) & (tmp37 < 1 + (triton_helpers.div_floor_integer((-3) + ks3,  2)))) | ~(xmask), "index out of bounds: 0 <= tmp37 < 1 + (triton_helpers.div_floor_integer((-3) + ks3,  2))")
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.atomic_add(out_ptr1 + (tmp14 + tmp20 + 64*x2 + tmp14*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), tmp23, xmask, sem='relaxed')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.atomic_add(out_ptr3 + (tmp20 + tmp30 + 64*x2 + tmp30*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), tmp33, xmask, sem='relaxed')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.atomic_add(out_ptr4 + (tmp14 + tmp37 + 64*x2 + tmp14*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), tmp9, xmask, sem='relaxed')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.atomic_add(out_ptr5 + (tmp30 + tmp37 + 64*x2 + tmp30*(triton_helpers.div_floor_integer((-3) + ks3,  2)) + 64*x2*(triton_helpers.div_floor_integer((-3) + ks3,  2))), tmp26, xmask, sem='relaxed')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6a/c6aln5eeqdv74rm2rgwwdpq3hdukmaur7hcca3ewmtxwdhrs74xm.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten._to_copy, aten.div, aten.mul]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_12 => convert_element_type, div
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%lt_6, torch.float32), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Scalar](args = (%convert_element_type, 0.5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_553 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_6, %div), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused__to_copy_div_mul_7 = async_compile.triton('triton_poi_fused__to_copy_div_mul_7', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_div_mul_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused__to_copy_div_mul_7(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last').to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 + tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4 + tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = 2.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp8 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp6 * tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp11, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bf/cbfjw4jwelylvz5csb4bqmx6birhsq3ywwudqzoyte3r5cjnyp47.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_560 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_24, %mul_554), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_560, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%permute_24, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_native_layer_norm_backward_8 = async_compile.triton('triton_red_fused_native_layer_norm_backward_8', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 64, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_native_layer_norm_backward_8(in_ptr0, in_ptr1, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp4 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp7 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = (r0_index % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + x0 + 64*r0_2 + x0*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 64*r0_2*(triton_helpers.div_floor_integer((-3) + ks1,  2))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r0_1 + x0 + 64*r0_2 + x0*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 64*r0_2*(triton_helpers.div_floor_integer((-3) + ks1,  2))), r0_mask & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 * tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = _tmp4 + tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp4 = tl.where(r0_mask & xmask, tmp5, _tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = _tmp7 + tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp7 = tl.where(r0_mask & xmask, tmp8, _tmp7)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(_tmp4, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.sum(_tmp7, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp7, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jz/cjzpv64ntdsgxknoa6ppwshmz7ef6p5jbumzvihuj7cxrpzmskwd.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_555 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_24, %primals_22), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_555, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_557 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_555, %mul_554), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_557, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_native_layer_norm_backward_9 = async_compile.triton('triton_per_fused_native_layer_norm_backward_9', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128, 'r0_': 64},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_9', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_native_layer_norm_backward_9(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_2 + x0 + 64*x1 + r0_2*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 64*x1*(triton_helpers.div_floor_integer((-3) + ks1,  2))), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_2), None, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.load(in_ptr2 + (r0_2 + x0 + 64*x1 + r0_2*(triton_helpers.div_floor_integer((-3) + ks1,  2)) + 64*x1*(triton_helpers.div_floor_integer((-3) + ks1,  2))), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 * tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.where(xmask, tmp3, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.sum(tmp5, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp2 * tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.broadcast_to(tmp8, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.where(xmask, tmp9, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tl.sum(tmp11, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp12, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vs/cvs4lzijrlo7bsk2zic6im52lknk3qmqo4q6y7wyrkxb6svzyvji.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_555 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_24, %primals_22), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_556 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_555, 64), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_558 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_554, %sum_7), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_307 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_556, %sum_6), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_308 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_307, %mul_558), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %div_6 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%rsqrt_4, 64), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_559 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_6, %sub_308), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_layer_norm_backward_10 = async_compile.triton('triton_poi_fused_native_layer_norm_backward_10', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 7, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_layer_norm_backward_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_layer_norm_backward_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // ks0) % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_out_ptr0 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x3), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.load(in_ptr4 + (x0 + x2 + x2*(triton_helpers.div_floor_integer((-3) + ks2,  2))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = 0.015625
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 * tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = 64.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp5 * tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp7 - tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp9 - tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp2 * tmp13
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp14, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/n7/cn7ettsbfqsna37q3gsxyw4tmehrihdsmfgfhwnpct4wlj6vwvt6.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_32, [0, 2]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_309 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_28, %unsqueeze_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_561 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_32, %sub_309), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_561, [0, 2]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_native_batch_norm_backward_11 = async_compile.triton('triton_red_fused_native_batch_norm_backward_11', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 2048, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_batch_norm_backward_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_native_batch_norm_backward_11(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp2 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r0_1 + x0 + x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (r0_1 + x0 + x0*(triton_helpers.div_floor_integer((-3) + ks0,  2))), r0_mask & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = _tmp2 + tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp2 = tl.where(r0_mask & xmask, tmp3, _tmp2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tl.full([1, 1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tmp5 < tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tmp6.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tmp4 < tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = tmp8.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tmp7 - tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp11 = tmp10.to(tmp4.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = tl_math.abs(tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = triton_helpers.maximum(tmp5, tmp12)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tmp11 * tmp13
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15 = 3.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp16 = tmp14 * tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp17 = libdevice.sqrt(tmp16)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp19 = tmp17 - tmp18
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp20 = tmp0 * tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.sum(_tmp2, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp2, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp22, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kl/cklvpamg3nhkrvqnqic2g5kuos5igixhjggac2gdfladedtrfdmg.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.scalar_tensor, aten.sign, aten.abs, aten.relu, aten.mul, aten.native_batch_norm_backward, aten.pow, aten.threshold_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_7 => abs_1, mul_361, mul_365, relu_1, sign
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sign : [num_users=3] = call_function[target=torch.ops.aten.sign.default](args = (%squeeze_2,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%squeeze_2,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%abs_1,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_361 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sign, %relu_1), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_365 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_361, 3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_309 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_28, %unsqueeze_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_568 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_309, %unsqueeze_12), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_311 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_32, %mul_568), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_312 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_311, %unsqueeze_10), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %pow_10 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%mul_365, -0.5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_570 : [num_users=1] = call_function[target=torch.ops.aten.mul.Scalar](args = (%pow_10, 0.5), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_571 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_33, %mul_570), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_572 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_571, 3), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_573 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_572, %sign), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_1, 0), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_4 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default_10, %mul_573), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12 = async_compile.triton('triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp32 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp3.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp1 < tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp4 - tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7.to(tmp1.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl_math.abs(tmp1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = triton_helpers.maximum(tmp2, tmp9)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp8 * tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = 3.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tmp11 * tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = libdevice.sqrt(tmp13)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp14 - tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = (tl.full([], 1.00000000000000, tl.float64) / ((64*ks1 + 64*ks1*(triton_helpers.div_floor_integer((-3) + ks2,  2))) / (64*ks1)))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp18.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp17 * tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = tmp21 / tmp23
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = 1e-05
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp24 + tmp25
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp27 = libdevice.rsqrt(tmp26)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp28 = tmp27 * tmp27
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp29 = tmp20 * tmp28
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp30 = tmp16 * tmp29
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp31 = tmp0 - tmp30
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp33 = tmp32 * tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp34 = tmp31 - tmp33
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp35 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp36 = tmp10 <= tmp35
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp37 = 1.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp38 = tmp27 * tmp37
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp39 = tmp34 * tmp38
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp40 = -0.5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp41 = libdevice.pow(tmp13, tmp40)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp42 = 0.5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp43 = tmp41 * tmp42
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp44 = tmp39 * tmp43
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp45 = tmp44 * tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp46 = tmp45 * tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp47 = tl.where(tmp36, tmp35, tmp46)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp47, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ze/czeybstsj5x4crawyk5slylv5ochbwhsyfv3g642cytld5tuarh3.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.sign, aten.mul, aten.zeros_like, aten.add]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   x_7 => sign
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sign : [num_users=3] = call_function[target=torch.ops.aten.sign.default](args = (%squeeze_2,), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_575 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%where_4, %sign), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_15 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%primals_1, 64, %sym_size_int_18], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_671 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_575, %full_15), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_add_mul_sign_zeros_like_13 = async_compile.triton('triton_poi_fused_add_mul_sign_zeros_like_13', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_mul_sign_zeros_like_13', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_add_mul_sign_zeros_like_13(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp3.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp1 < tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp5.to(tl.int8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp4 - tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp7.to(tmp1.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp0 * tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tmp9 + tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp11, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gm/cgmymvoml6ofvrqvrrejsgtvf3nwswzcsloktwrs6b5x2bm6p32l.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.avg_pool2d_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %avg_pool2d_backward : [num_users=1] = call_function[target=torch.ops.aten.avg_pool2d_backward.default](args = (%unsqueeze_15, %unsqueeze_2, [1, 3], [1, 2], [0, 0], False, True, None), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_avg_pool2d_backward_14 = async_compile.triton('triton_poi_fused_avg_pool2d_backward_14', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_avg_pool2d_backward_14', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_avg_pool2d_backward_14(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1 + x1*(triton_helpers.div_floor_integer((-3) + ks0,  2)) + ((((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))) * ((((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1)))) < (((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0))))))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.load(in_ptr0 + (x1 + x1*(triton_helpers.div_floor_integer((-3) + ks0,  2)) + ((1 + ((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))) * ((1 + ((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))) <= ((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1))))) + ((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1)))) * (((-1) + ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1)))) < (1 + ((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0))))))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tmp0 / 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.full([1], 1, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 < tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = ((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = ((ks1) * ((ks1) <= (1 + (x0 // 2))) + (1 + (x0 // 2)) * ((1 + (x0 // 2)) < (ks1)))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp5 < tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp4 & tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.where(tmp8, tmp1, tmp9)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp11 / 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = 1 + ((0) * ((0) >= (triton_helpers.div_floor_integer((-1) + x0,  2))) + (triton_helpers.div_floor_integer((-1) + x0,  2)) * ((triton_helpers.div_floor_integer((-1) + x0,  2)) > (0)))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp13 < tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp4 & tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp10 + tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.where(tmp15, tmp16, tmp10)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp17, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/de/cdevqy2txeq47vvpgs4mespoystzweuqa63di32g4sims3rmrjv6.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_584 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_27, %mul_318), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_584, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_15 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%permute_27, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_native_layer_norm_backward_15 = async_compile.triton('triton_red_fused_native_layer_norm_backward_15', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_native_layer_norm_backward_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_native_layer_norm_backward_15(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp16 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp21 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (ks1*x0 + 64*ks1*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (tl.broadcast_to(x0, [XBLOCK, R0_BLOCK])), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tmp4 * tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tl.load(in_ptr3 + (tl.broadcast_to(x0, [XBLOCK, R0_BLOCK])), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tmp6 + tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = 2.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tmp8 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp11 = tmp3 * tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = tmp11 * tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = tl.full(tmp12.shape, 0, tmp12.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.where(tmp2, tmp12, tmp13)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp17 = _tmp16 + tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp16 = tl.where(r0_mask & xmask, tmp17, _tmp16)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp18 = tl.full(tmp11.shape, 0, tmp11.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp19 = tl.where(tmp2, tmp11, tmp18)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp20 = tl.broadcast_to(tmp19, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp22 = _tmp21 + tmp20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp21 = tl.where(r0_mask & xmask, tmp22, _tmp21)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.sum(_tmp16, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tl.sum(_tmp21, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp16, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp21, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mf/cmfezigcjubhwdogriuej2fibgri6oimllqurl5f2vamoij4o4ov.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_584 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_27, %mul_318), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_14 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_584, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_native_layer_norm_backward_16 = async_compile.triton('triton_per_fused_native_layer_norm_backward_16', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 64, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_native_layer_norm_backward_16(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ne/cne74dnrbntv6wi7zko3htdsiu4g4gmehkwxt322yq3qnghuuruf.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_579 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_27, %primals_20), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_579, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_581 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_579, %mul_318), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_13 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_581, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_native_layer_norm_backward_17 = async_compile.triton('triton_per_fused_native_layer_norm_backward_17', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_layer_norm_backward_17', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_native_layer_norm_backward_17(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1 + ks1*r0_2 + 64*ks1*x0), xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_2 + 64*x3), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.load(in_ptr2 + (r0_2), None, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.load(in_ptr3 + (r0_2), None, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp1 * tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = 2.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp5 * tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp0 * tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp8 * tmp2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tl.where(xmask, tmp10, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tl.sum(tmp12, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp9 * tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tl.where(xmask, tmp15, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tl.sum(tmp17, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp13, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp18, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gi/cgienyelgywc2xlow4ookhblezjpbrb4jk4cramxlyrcmsebtvnn.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_579 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%permute_27, %primals_20), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_580 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_579, 64), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_582 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_318, %sum_13), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_314 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_580, %sum_12), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_315 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_314, %mul_582), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_583 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_7, %sub_315), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_5 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_3, torch.float32), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_585 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_5, 1.1111111111111112), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_586 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_583, %mul_585), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18 = async_compile.triton('triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'y': 16, 'x': 2048}, tile_hint=TileHint.DEFAULT,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*i1', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, ks0, ks1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     ymask = yindex < ynumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     y0 = yindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0 + ks1*x3), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.load(in_out_ptr0 + (x3 + 64*ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr5 + (x2 + ks0*y0), xmask & ymask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tl.load(in_ptr6 + (x3 + 64*ks0*y0), xmask & ymask, eviction_policy='evict_last').to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp4 + tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 2.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tmp6 * tmp7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tmp1 * tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp9 * tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = 64.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp10 * tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tmp12 - tmp13
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tmp2 * tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp14 - tmp16
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp0 * tmp17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp19.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = 1.1111111111111112
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tmp20 * tmp21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp18 * tmp22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.debug_barrier()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x3 + 64*ks0*y0), tmp18, xmask & ymask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3 + 64*ks0*y0), tmp23, xmask & ymask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tv/ctvbgzb4ath5j2u45d7fqqgdpz7xysc5jhb5vee3wmvhodqngxe2.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_16 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_34, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_sum_19 = async_compile.triton('triton_red_fused_sum_19', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_sum_19(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*r0_2 + 64*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xq/cxqkn2mfr4ys5rrymcrazmhxdsl6kdparqby77ra2cogzzyyzxoi.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_6 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_2, torch.float32), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_587 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_6, 1.1111111111111112), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_588 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_36, %mul_587), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %where_5 : [num_users=1] = call_function[target=torch.ops.aten.where.self](args = (%le_1, %full_default_10, %mul_588), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20 = async_compile.triton('triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 1048576}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i1', 'in_ptr1': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask).to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x0), xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), xmask).to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 1.1111111111111112
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tmp3 * tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tmp1 * tmp5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.where(tmp0, tmp7, tmp6)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp8, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/42/c42snkbsgwrl3vfcbgqvfvbh7c3o5sg47nimhrpo74vuos3pqshh.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_672 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_583, %view_39), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_595 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_672, %mul_262), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_20 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_595, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_21 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_672, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_21 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_21', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_21(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp16 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp3 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tmp5 * tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = tl.where(tmp2, tmp7, tmp8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.where(tmp2, tmp5, tmp13)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp17 = _tmp16 + tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp16 = tl.where(r0_mask & xmask, tmp17, _tmp16)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.sum(_tmp16, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp11, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/na/cnagk7rjnd7j2ecfw4ealasqscnvnvtnnmfolvfx2bvefjmyqkbh.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_672 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_583, %view_39), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_590 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_672, %primals_14), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_591 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_590, 64), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_18 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_590, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_592 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_590, %mul_262), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_19 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_592, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_593 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_262, %sum_19), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_317 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_591, %sum_18), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_318 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_317, %mul_593), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_594 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_8, %sub_318), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_7 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt_1, torch.float32), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_596 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_7, 1.1111111111111112), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_597 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_594, %mul_596), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp4 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = 64.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp4 * tmp16
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17 - tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp9 * tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp18 - tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp15 * tmp20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = 1.1111111111111112
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp23 * tmp24
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp21 * tmp25
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp21, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr2 + (r0_1 + 64*x0), tmp26, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kf/ckfqh2wmosafaadiwdhg6vxts3xprygdt3uhm37q5iw66dz6truc.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_8,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clone_23 = async_compile.triton('triton_poi_fused_clone_23', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 65536}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 4, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clone_23(in_ptr0, in_ptr1, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 64) % 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = ((xindex // 128) % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = x1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([1], 1, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x4 + 128*x3 + 128*ks2*x2), tmp10, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gy/cgy2oimzi7hrayd56y3bxevh7cula2edog4hksmtb7bxyn6zi6dn.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_50, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_sum_24 = async_compile.triton('triton_red_fused_sum_24', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_24', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_sum_24(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 384
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 128
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 128)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 128*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/es/cesd4vcwlixxmiovkghwbp4zdyuhklf55mct5pkiwxyzfjcche7k.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_23 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_50, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_53, %view_51],), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_cat_sum_25 = async_compile.triton('triton_per_fused_cat_sum_25', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 128, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_25', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_cat_sum_25(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 128
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*r0_1), r0_mask & xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e2/ce2zpr46pccgflunhs3cq4ze7a3wbzrmde7to5rts25b7vdp4o7u.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %view_52 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%view_48, [%mul_8, 64]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_view_26 = async_compile.triton('triton_poi_fused_view_26', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 32768}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_view_26', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_view_26(in_ptr0, out_ptr0, ks0, ks1, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) % 8)) + 64*((((x0 + 64*((x1 % ks0)) + 64*ks0*(x1 // ks0)) // (64*ks0)) % ks1)) + 64*ks1*(((((((x0 + 64*((x1 % ks0))) // 8) % (8*ks0))) // 8) % ks0)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ok/cokdwyu7g6bwsloemvyxmlrwnnzlyuupd3iprvhehd2nfgnny7fq.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_24 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_52, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_53, %view_51],), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_cat_sum_27 = async_compile.triton('triton_per_fused_cat_sum_27', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 64, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_cat_sum_27', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_cat_sum_27(in_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r0_1), r0_mask & xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oa/coaj725xafkmkij3pgqy2hfxrqzc22gkdi7awkabdylbmimukqpd.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_674 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_594, %view_54), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_604 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_674, %mul_598), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_27 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_604, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_28 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%add_674, [0, 1]), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_add_native_layer_norm_backward_28 = async_compile.triton('triton_red_fused_add_native_layer_norm_backward_28', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 256, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_native_layer_norm_backward_28', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_add_native_layer_norm_backward_28(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp11 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp16 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.load(in_ptr1 + (x0 + 64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % (ks0*ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp3 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tl.load(in_ptr2 + (x0 + 64*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + 64*ks1*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0))), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = tmp5 * tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tl.full(tmp7.shape, 0, tmp7.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = tl.where(tmp2, tmp7, tmp8)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tl.broadcast_to(tmp9, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = _tmp11 + tmp10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp11 = tl.where(r0_mask & xmask, tmp12, _tmp11)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = tl.full(tmp5.shape, 0, tmp5.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.where(tmp2, tmp5, tmp13)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15 = tl.broadcast_to(tmp14, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp17 = _tmp16 + tmp15
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp16 = tl.where(r0_mask & xmask, tmp17, _tmp16)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.sum(_tmp11, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = tl.sum(_tmp16, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp11, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ro/crocryqfeg2nrwne5f5kx2b4gnqvjyucnujcvkpvvs7hcjoioo3o.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %add_674 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_594, %view_54), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_599 : [num_users=3] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_674, %primals_8), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_600 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_599, 64), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_25 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_599, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_601 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_599, %mul_598), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_26 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_601, [2], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_602 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_598, %sum_26), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_320 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_600, %sum_25), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sub_321 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_320, %mul_602), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_603 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_9, %sub_321), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %convert_element_type_8 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt, torch.float32), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_605 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_8, 1.1111111111111112), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %mul_606 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_603, %mul_605), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29 = async_compile.triton('triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 512, 'r0_': 64},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i1', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 64
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = tl.full([XBLOCK, R0_BLOCK], True, tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = (xindex % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r0_1 + 64*x0), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (r0_1 + 64*x3 + 64*ks1*x2), xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tl.load(in_ptr4 + (r0_1 + 64*x0), xmask, other=0.0).to(tl.int1)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 + tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tmp2 * tmp3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tl.where(xmask, tmp5, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.sum(tmp7, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp4 * tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp16 = 64.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp17 = tmp4 * tmp16
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp18 = tmp17 - tmp8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp19 = tmp9 * tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp20 = tmp18 - tmp19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp21 = tmp15 * tmp20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp24 = 1.1111111111111112
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp25 = tmp23 * tmp24
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp26 = tmp21 * tmp25
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(in_out_ptr0 + (r0_1 + 64*x0), tmp26, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oy/coytxnpaevt5stm52kk53xxnf6tknconaiqsiss6gf2betcb5b2v.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_30 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_64, [0, 1], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_sum_30 = async_compile.triton('triton_red_fused_sum_30', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 1024, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_30', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_sum_30(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 576
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 192)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.broadcast_to(x0 // 64, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.full([1, 1], 2, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp5 = tmp3 == tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = tl.load(in_ptr0 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp7 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp8 = tl.where(tmp5, tmp6, tmp7)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp9 = tl.full([1, 1], 1, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp10 = tmp3 == tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp11 = tl.load(in_ptr1 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp12 = tl.where(tmp10, tmp11, tmp7)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp13 = tmp8 + tmp12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp14 = tl.full([1, 1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp15 = tmp3 == tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp16 = tl.load(in_ptr2 + (8*((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) % 8)) + 64*((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + 64*ks0*((((r0_2 + x1*((2 + ks0*ks1) // 3)) // ks0) % ks1)) + ((x0 % 64))) // (64*ks0)) % ks1)) + 64*ks1*(((((((64*(((r0_2 + x1*((2 + ks0*ks1) // 3)) % ks0)) + ((x0 % 64))) // 8) % (8*ks0))) // 8) % ks0)) + ((((x0 % 64)) % 8))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp17 = tl.where(tmp15, tmp16, tmp7)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp18 = tmp13 + tmp17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp19 = tl.full(tmp18.shape, 0, tmp18.dtype)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp20 = tl.where(tmp2, tmp18, tmp19)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp23 = _tmp22 + tmp21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp22, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3n/c3nngipqifa6tdsejuwxly6jwvshw7fu2piulukt5z2uocqpemem.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_30 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_64, [0, 1], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_sum_31 = async_compile.triton('triton_per_fused_sum_31', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 256, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER_TINY,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_31', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_sum_31(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 192
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 192*r0_1), r0_mask & xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jv/cjvghknftdsrqy3ygrynrq4e5rf3rfh5lukozrkod6uyt3o3z4qi.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %clone_25 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%squeeze_9,), kwargs = {memory_format: torch.contiguous_format})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_poi_fused_clone_32 = async_compile.triton('triton_poi_fused_clone_32', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.pointwise(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 65536}, 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_32', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     min_elem_per_thread=0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_poi_fused_clone_32(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = ((xindex // 64) % 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x2 = ((xindex // 192) % ks0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex // ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x4 = (xindex % 192)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp8 = tl.load(in_ptr1 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp13 = tl.load(in_ptr2 + (8*((((((x0 + 64*x3) // 8) % (8*ks2))) % 8)) + 64*((((x0 + 64*x3 + 64*ks2*x2) // (64*ks2)) % ks0)) + 64*ks0*(((((((x0 + 64*x3) // 8) % (8*ks2))) // 8) % ks2)) + ((x0 % 8))), xmask, eviction_policy='evict_last')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = x1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.full([1], 2, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp2 = tmp0 == tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = 0.0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.where(tmp2, tmp3, tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp6 = tl.full([1], 1, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp7 = tmp0 == tmp6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp9 = tl.where(tmp7, tmp8, tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp10 = tmp5 + tmp9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp12 = tmp0 == tmp11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp14 = tl.where(tmp12, tmp13, tmp4)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp15 = tmp10 + tmp14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x4 + 192*x3 + 192*ks2*x2), tmp15, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dq/cdqy3moejgkulrcjvhex5tdc5vgpnscoxsufzegviexehijpp44g.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_37, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_red_fused_sum_33 = async_compile.triton('triton_red_fused_sum_33', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 8192, 'r0_': 128},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_sum_33', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_red_fused_sum_33(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 6144
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rbase = r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x1 = xindex // 2048
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = (xindex % 2048)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x3 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_index = r0_offset + r0_base
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         r0_2 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp0 = r0_2 + x1*((2 + ks0*ks1) // 3)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp1 = ks0*ks1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp2 = tmp0 < tmp1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp3 = tl.load(in_ptr0 + (x0 + 2048*r0_2 + 2048*x1*((2 + ks0*ks1) // 3)), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         tmp6 = _tmp5 + tmp4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/t6/ct6dcpylza2pojg72zh5d3nyk36cb4a7j6rxbz5bn3kt6wyoommp.py
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Source node to ATen node mapping:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] # Graph fragment:
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] #   %sum_17 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_37, [0], True), kwargs = {})
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_per_fused_sum_34 = async_compile.triton('triton_per_fused_sum_34', '''
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] import triton.language as tl
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton_heuristics.persistent_reduction(
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     size_hints={'x': 2048, 'r0_': 4},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     reduction_hint=ReductionHint.OUTER,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     filename=__file__,
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_sum_34', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] @triton.jit
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def triton_per_fused_sum_34(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xnumel = 2048
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_numel = 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rnumel = r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     xmask = xindex < xnumel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_offset = 0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_mask = r0_index < r0_numel
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     roffset = r0_offset
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rindex = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     r0_1 = r0_index
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     x0 = xindex
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 2048*r0_1), r0_mask & xmask, other=0.0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] ''', device_str='cuda')
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] async_compile.wait(globals())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] del async_compile
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def call(args):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_1, primals_2, mul_8, mul_71, sym_size_int_18, primals_8, primals_14, primals_20, primals_21, primals_22, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, full_default, view_19, view_20, view_21, getitem_10, getitem_11, getitem_12, getitem_13, view_22, gt_1, mul_262, view_24, gt_2, view_26, gt_3, mul_318, unsqueeze_2, avg_pool2d, getitem_21, rsqrt_4, lt_6, convert_element_type_2, clamp_max, convert_element_type_4, clamp_max_1, clamp_max_2, clamp_max_3, div_1, pow_4, pow_6, pow_8, div_7, permute_28, le_1, permute_32, div_8, permute_36, permute_48, mul_598, div_9, permute_52, tangents_1, tangents_2, tangents_3 = args
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     args.clear()
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     s0 = primals_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     s1 = primals_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_14, (64, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_20, (64, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_21, (64, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(primals_22, (64, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_6, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_7, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_8, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_1, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_2, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_3, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_9, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(gt, (s1, s0, 64), (64*s0, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_11, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(full_default, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_19, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_20, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_21, (s0, 8, s1, 8), (64, 8, 64*s0, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_10, (s0, 8, s1, 8), (64*s1, 8, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_11, (s0, 8, 32*math.ceil(s1 / 32)), (256*math.ceil(s1 / 32), 32*math.ceil(s1 / 32), 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_12, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_13, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_22, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(gt_1, (s1, s0, 64), (64*s0, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(mul_262, (s1, s0, 64), (64*s0, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_24, (s0*s1, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(gt_2, (s1, s0, 2048), (2048*s0, 2048, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(view_26, (s0*s1, 2048), (2048, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(gt_3, (s1, s0, 64), (64*s0, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(mul_318, (s1, s0, 64), (64*s0, 64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(unsqueeze_2, (s0, 64, 1, s1), (64, 1, 64*s0*s1, 64*s0))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(avg_pool2d, (s0, 64, 1, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(getitem_21, (s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(rsqrt_4, (s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(lt_6, (s0, 64, 1), (64, 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(convert_element_type_2, (128, 1), (1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(clamp_max, (128, 1), (1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(convert_element_type_4, (2 + 2*(((-3) + s1) // 2), ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(clamp_max_1, (2 + 2*(((-3) + s1) // 2), ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(clamp_max_2, (2 + 2*(((-3) + s1) // 2), ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(clamp_max_3, (128, 1), (1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(div_1, (s0, 2 + 2*(((-3) + s1) // 2), 128), (256 + 256*(((-3) + s1) // 2), 128, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(pow_4, (s0, ), (1, ))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(pow_6, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(pow_8, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(div_7, (s1, s0, 1), (s0, 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(permute_28, (64, 2048), (2048, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(le_1, (s1, s0, 2048), (2048*s0, 2048, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(permute_32, (2048, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(div_8, (s1, s0, 1), (s0, 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(permute_36, (64, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(permute_48, (64, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(mul_598, (s1, s0, 64), (64, 64*s1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(div_9, (s1, s0, 1), (s0, 1, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(permute_52, (64, 64), (64, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(tangents_1, (s0, 2 + 2*(((-3) + s1) // 2), 128), (256 + 256*(((-3) + s1) // 2), 128, 1))
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(tangents_2, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     assert_size_stride(tangents_3, (), ())
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         torch.cuda.set_device(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf17 = empty_strided_cuda((1, 64*s0, 1), (64*s0, 1, 64*s0), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf18 = empty_strided_cuda((1, 64*s0, 1), (64*s0, 1, 64*s0), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten._native_batch_norm_legit]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_0_xnumel = 64*s0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_0_r0_numel = 1 + (((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__native_batch_norm_legit_0.run(avg_pool2d, buf17, buf18, s1, triton_red_fused__native_batch_norm_legit_0_xnumel, triton_red_fused__native_batch_norm_legit_0_r0_numel, grid=grid(triton_red_fused__native_batch_norm_legit_0_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps0 = 1 + (((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps1 = 64 + 64*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf20 = empty_strided_cuda((s0, 1 + (((-3) + s1) // 2), 64), (64 + 64*(((-3) + s1) // 2), 1, 1 + (((-3) + s1) // 2)), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_1_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_1.run(avg_pool2d, buf17, buf18, getitem_21, rsqrt_4, buf20, ps0, ps1, s1, triton_poi_fused_native_layer_norm_backward_1_xnumel, grid=grid(triton_poi_fused_native_layer_norm_backward_1_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf10 = empty_strided_cuda((s0, 1, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.neg, aten.add, aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2.run(buf10, triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf12 = empty_strided_cuda((s0, 1, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2.run(buf12, triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf14 = empty_strided_cuda((s0, 1, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2.run(buf14, triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf8 = empty_strided_cuda((s0, 1, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2.run(buf8, triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_2_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf0 = empty_strided_cuda((s0, 128), (128, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf2 = empty_strided_cuda((s0, 128), (128, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf3 = empty_strided_cuda((s0, 128), (128, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [add_3, sub_2, sub_1, pairwise_distance], Original ATen: [aten.div, aten.scalar_tensor, aten.add, aten.sub, aten.ge, aten.where, aten.neg, aten.eq, aten.masked_fill, aten.mul]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3_xnumel = 128*s0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3.run(pow_6, pow_8, tangents_2, div_1, pow_4, tangents_3, buf0, buf2, buf3, s1, s0, triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3_xnumel, grid=grid(triton_poi_fused_add_div_eq_ge_masked_fill_mul_neg_scalar_tensor_sub_where_3_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del pow_4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del pow_6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del pow_8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del tangents_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del tangents_3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps2 = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps3 = 256 + 256*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf4 = empty_strided_cuda((s0, 2 + 2*(((-3) + s1) // 2), 128), (256 + 256*(((-3) + s1) // 2), 128, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [pairwise_distance], Original ATen: [aten.scalar_tensor, aten.neg, aten.sub, aten.add, aten.div, aten.eq, aten.masked_fill, aten.mul, aten.select_backward, aten._softmax_backward_data]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4_xnumel = 256*s0 + 256*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4.run(tangents_1, buf0, buf2, buf3, div_1, buf4, ps2, ps3, triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4_xnumel, grid=grid(triton_poi_fused__softmax_backward_data_add_div_eq_masked_fill_mul_neg_scalar_tensor_select_backward_sub_4_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del tangents_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf5 = reinterpret_tensor(buf3, (s0, 1, 128), (128, 128*s0, 1), 0); del buf3  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._softmax_backward_data]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_backward_data_5_xnumel = 128*s0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_backward_data_5_r0_numel = 2 + 2*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused__softmax_backward_data_5.run(buf4, buf5, s1, triton_red_fused__softmax_backward_data_5_xnumel, triton_red_fused__softmax_backward_data_5_r0_numel, grid=grid(triton_red_fused__softmax_backward_data_5_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mul, aten.neg, aten.add, aten.new_zeros, aten._unsafe_index_put]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6_xnumel = 256*s0 + 256*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6.run(div_1, buf5, buf4, clamp_max_3, clamp_max_2, clamp_max, convert_element_type_4, convert_element_type_2, clamp_max_1, buf10, buf14, buf8, buf12, ps3, ps2, ps0, s1, triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6_xnumel, grid=grid(triton_poi_fused__unsafe_index_put_add_mul_neg_new_zeros_6_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf5
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del clamp_max
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del clamp_max_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del clamp_max_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del clamp_max_3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del convert_element_type_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del convert_element_type_4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del div_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf16 = empty_strided_cuda((s0, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten._to_copy, aten.div, aten.mul]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_div_mul_7_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused__to_copy_div_mul_7.run(buf8, buf10, buf12, buf14, lt_6, buf16, ps0, triton_poi_fused__to_copy_div_mul_7_xnumel, grid=grid(triton_poi_fused__to_copy_div_mul_7_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del lt_6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf23 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf24 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8_r0_numel = s0 + s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_layer_norm_backward_8.run(buf16, buf20, buf23, buf24, ps0, s1, 64, triton_red_fused_native_layer_norm_backward_8_r0_numel, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf21 = empty_strided_cuda((s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, s0 + s0*(((-3) + s1) // 2)), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf22 = empty_strided_cuda((s0, 1 + (((-3) + s1) // 2), 1), (1 + (((-3) + s1) // 2), 1, s0 + s0*(((-3) + s1) // 2)), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_9_xnumel = s0 + s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_9.run(buf16, primals_22, buf20, buf21, buf22, ps0, s1, triton_per_fused_native_layer_norm_backward_9_xnumel, 64, grid=grid(triton_per_fused_native_layer_norm_backward_9_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf25 = reinterpret_tensor(buf16, (s0, 1 + (((-3) + s1) // 2), 64), (64 + 64*(((-3) + s1) // 2), 1, 1 + (((-3) + s1) // 2)), 0); del buf16  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_10_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_layer_norm_backward_10.run(buf25, rsqrt_4, primals_22, buf21, buf20, buf22, ps0, ps1, s1, triton_poi_fused_native_layer_norm_backward_10_xnumel, grid=grid(triton_poi_fused_native_layer_norm_backward_10_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del rsqrt_4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf26 = empty_strided_cuda((64*s0, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf27 = empty_strided_cuda((64*s0, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_batch_norm_backward_11_xnumel = 64*s0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_batch_norm_backward_11_r0_numel = 1 + (((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_batch_norm_backward_11.run(buf25, avg_pool2d, buf17, buf26, buf27, s1, triton_red_fused_native_batch_norm_backward_11_xnumel, triton_red_fused_native_batch_norm_backward_11_r0_numel, grid=grid(triton_red_fused_native_batch_norm_backward_11_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf28 = reinterpret_tensor(buf25, (1, 64*s0, 1 + (((-3) + s1) // 2)), (64*s0 + 64*s0*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), 0); del buf25  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf29 = reinterpret_tensor(buf28, (s0, 64, 1 + (((-3) + s1) // 2)), (64 + 64*(((-3) + s1) // 2), 1 + (((-3) + s1) // 2), 1), 0); del buf28  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.scalar_tensor, aten.sign, aten.abs, aten.relu, aten.mul, aten.native_batch_norm_backward, aten.pow, aten.threshold_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12.run(buf29, avg_pool2d, buf17, buf27, buf18, buf26, ps0, s0, s1, triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12_xnumel, grid=grid(triton_poi_fused_abs_mul_native_batch_norm_backward_pow_relu_scalar_tensor_sign_threshold_backward_12_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf17
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf18
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf27
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.sign, aten.mul, aten.zeros_like, aten.add]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_mul_sign_zeros_like_13_xnumel = 64*s0 + 64*s0*(((-3) + s1) // 2)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_add_mul_sign_zeros_like_13.run(buf30, avg_pool2d, triton_poi_fused_add_mul_sign_zeros_like_13_xnumel, grid=grid(triton_poi_fused_add_mul_sign_zeros_like_13_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del avg_pool2d
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf31 = empty_strided_cuda((s0, 64, 1, s1), (64*s1, s1, s1, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.avg_pool2d_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_avg_pool2d_backward_14_xnumel = 64*s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_avg_pool2d_backward_14.run(buf30, buf31, s1, ps0, triton_poi_fused_avg_pool2d_backward_14_xnumel, grid=grid(triton_poi_fused_avg_pool2d_backward_14_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf30
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf35 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf37 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_layer_norm_backward_15_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_native_layer_norm_backward_15.run(buf31, mul_318, primals_20, primals_21, buf35, buf37, s0, s1, 192, triton_red_fused_native_layer_norm_backward_15_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf36 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf35, buf36, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf38 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf37, buf38, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf32 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf33 = empty_strided_cuda((s1, s0, 1), (s0, 1, s0*s1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_17_xnumel = s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_17.run(buf31, mul_318, primals_20, primals_21, buf32, buf33, s0, s1, triton_per_fused_native_layer_norm_backward_17_xnumel, 64, grid=grid(triton_per_fused_native_layer_norm_backward_17_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf34 = mul_318; del mul_318  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf39 = empty_strided_cuda((s1, s0, 64), (64*s0, 64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18_xnumel = 64*s0
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18.run(buf34, div_7, buf31, primals_20, primals_21, buf32, buf33, gt_3, buf39, s0, s1, s1, triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18_xnumel, grid=grid(s1, triton_poi_fused_native_dropout_backward_native_layer_norm_backward_18_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf32
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf33
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del div_7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del gt_3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf41 = empty_strided_cuda((64, 2048), (2048, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf39, (64, s0*s1), (1, 64), 0), view_26, out=buf41)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_26
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf42 = reinterpret_tensor(buf37, (1, 64, 3), (192, 1, 64), 0); del buf37  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19.run(buf39, buf42, s0, s1, 192, triton_red_fused_sum_19_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf43 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf42, buf43, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf40 = empty_strided_cuda((s0*s1, 2048), (2048, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf39, (s0*s1, 64), (64, 1), 0), permute_28, out=buf40)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del permute_28
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf44 = reinterpret_tensor(buf40, (s1, s0, 2048), (2048*s0, 2048, 1), 0); del buf40  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.scalar_tensor, aten.native_dropout_backward, aten.threshold_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20_xnumel = 2048*s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20.run(buf44, le_1, gt_2, triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20_xnumel, grid=grid(triton_poi_fused_native_dropout_backward_scalar_tensor_threshold_backward_20_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del gt_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del le_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf45 = reinterpret_tensor(buf39, (s0*s1, 64), (64, 1), 0); del buf39  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (s0*s1, 2048), (2048, 1), 0), permute_32, out=buf45)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del permute_32
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf52 = reinterpret_tensor(buf42, (64, 3), (1, 64), 0); del buf42  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf54 = buf35; del buf35  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_21.run(buf34, buf45, mul_262, buf52, buf54, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_21_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf51 = buf34; del buf34  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf56 = reinterpret_tensor(buf31, (s1, s0, 64), (64*s0, 64, 1), 0); del buf31  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22_xnumel = s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22.run(buf51, buf45, primals_14, mul_262, div_8, gt_1, buf56, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_22_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del div_8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del gt_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del mul_262
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_14
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf58 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf56, (64, s0*s1), (1, 64), 0), view_22, out=buf58)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_22
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf53 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf52, buf53, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf55 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf54, buf55, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf59 = reinterpret_tensor(buf54, (1, 64, 3), (192, 1, 64), 0); del buf54  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19.run(buf56, buf59, s0, s1, 192, triton_red_fused_sum_19_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf57 = buf45; del buf45  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf56, (s0*s1, 64), (64, 1), 0), permute_36, out=buf57)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf56
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del permute_36
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf61 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf57, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_19, view_20, view_21, None, getitem_10, getitem_11, getitem_12, getitem_13, 0.1, [True, True, True, False])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf57
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_12
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_13
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_19
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_20
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_21
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf60 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf59, buf60, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf62 = buf61[0]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf63 = buf61[1]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf64 = buf61[2]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf61
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps4 = 128*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf65 = empty_strided_cuda((s1, s0, 2, 64), (128*s0, 128, 64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_23_xnumel = 128*s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_23.run(buf64, buf63, buf65, s1, ps4, s0, triton_poi_fused_clone_23_xnumel, grid=grid(triton_poi_fused_clone_23_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf63
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf77 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf66 = reinterpret_tensor(buf77, (128, 64), (64, 1), 4096)  # alias
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf65, (128, s0*s1), (1, 128), 0), full_default, out=buf66)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del full_default
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf67 = empty_strided_cuda((1, 128, 3), (384, 1, 128), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_24_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_24.run(buf65, buf67, s0, s1, 384, triton_red_fused_sum_24_r0_numel, grid=grid(384), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf65
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf76 = reinterpret_tensor(buf59, (192, ), (1, ), 0); del buf59  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf75 = reinterpret_tensor(buf76, (128, ), (1, ), 64)  # alias
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_cat_sum_25.run(buf67, buf75, 128, 3, grid=grid(128), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf67
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf69 = reinterpret_tensor(buf64, (s0*s1, 64), (64, 1), 0); del buf64  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.view]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_26_xnumel = 64*s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_view_26.run(buf62, buf69, s0, s1, triton_poi_fused_view_26_xnumel, grid=grid(triton_poi_fused_view_26_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf71 = reinterpret_tensor(buf77, (64, 64), (64, 1), 0)  # alias
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf69, (64, s0*s1), (1, 64), 0), view_11, out=buf71)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_11
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf72 = reinterpret_tensor(buf52, (1, 64, 3), (192, 1, 64), 0); del buf52  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19.run(buf69, buf72, s0, s1, 192, triton_red_fused_sum_19_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf70 = reinterpret_tensor(buf62, (s0*s1, 64), (64, 1), 0); del buf62  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(buf69, permute_48, out=buf70)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf69
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del permute_48
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf74 = reinterpret_tensor(buf76, (64, ), (1, ), 0)  # alias
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum, aten.cat]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_cat_sum_27.run(buf72, buf74, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf80 = reinterpret_tensor(buf72, (64, 3), (1, 64), 0); del buf72  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf82 = empty_strided_cuda((64, 3), (1, 64), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_add_native_layer_norm_backward_28.run(buf51, buf70, mul_598, buf80, buf82, s0, s1, 192, triton_red_fused_add_native_layer_norm_backward_28_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf84 = buf51; del buf51  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward, aten.native_dropout_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel = s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29.run(buf84, buf70, primals_8, mul_598, div_9, gt, s0, s1, triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel, 64, grid=grid(triton_per_fused_add_native_dropout_backward_native_layer_norm_backward_29_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del div_9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del gt
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del mul_598
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del primals_8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf86 = empty_strided_cuda((64, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf84, (64, s0*s1), (1, 64), 0), view_9, out=buf86)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_9
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf81 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf80, buf81, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf80
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf83 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.add, aten.native_layer_norm_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf82, buf83, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf87 = reinterpret_tensor(buf82, (1, 64, 3), (192, 1, 64), 0); del buf82  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_19.run(buf84, buf87, s0, s1, 192, triton_red_fused_sum_19_r0_numel, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf85 = buf70; del buf70  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf84, (s0*s1, 64), (64, 1), 0), permute_52, out=buf85)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf84
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del permute_52
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten._scaled_dot_product_efficient_attention_backward]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf89 = torch.ops.aten._scaled_dot_product_efficient_attention_backward.default(reinterpret_tensor(buf85, (s0, 8, s1, 8), (64, 8, 64*s0, 1), 0), view_6, view_7, view_8, None, getitem, getitem_1, getitem_2, getitem_3, 0.1, [True, True, True, False])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf85
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_2
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del getitem_3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_6
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_7
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_8
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf88 = empty_strided_cuda((1, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_native_layer_norm_backward_16.run(buf87, buf88, 64, 3, grid=grid(64), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf90 = buf89[0]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf91 = buf89[1]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf92 = buf89[2]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf89
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf93 = empty_strided_cuda((1, 1, 192, 3), (576, 576, 1, 192), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_30_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_30.run(buf92, buf91, buf90, buf93, s0, s1, 576, triton_red_fused_sum_30_r0_numel, grid=grid(576), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf94 = reinterpret_tensor(buf87, (1, 1, 192), (192, 192, 1), 0); del buf87  # reuse
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_sum_31.run(buf93, buf94, 192, 3, grid=grid(192), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf93
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         ps5 = 192*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf95 = empty_strided_cuda((s1, s0, 3, 64), (192*s0, 192, 64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.clone]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_32_xnumel = 192*s0*s1
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_poi_fused_clone_32.run(buf92, buf91, buf90, buf95, s1, ps5, s0, triton_poi_fused_clone_32_xnumel, grid=grid(triton_poi_fused_clone_32_xnumel), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf90
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf91
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf92
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf96 = empty_strided_cuda((192, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf95, (192, s0*s1), (1, 192), 0), view, out=buf96)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf95
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf47 = empty_strided_cuda((1, 2048, 3), (6144, 1, 2048), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_33_r0_numel = (2 + s0*s1) // 3
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_red_fused_sum_33.run(buf44, buf47, s0, s1, 6144, triton_red_fused_sum_33_r0_numel, grid=grid(6144), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf46 = empty_strided_cuda((2048, 64), (64, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf44, (2048, s0*s1), (1, 2048), 0), view_24, out=buf46)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf44
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del view_24
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         buf48 = empty_strided_cuda((1, 2048), (2048, 1), torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.sum]
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         stream0 = get_raw_stream(0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         triton_per_fused_sum_34.run(buf47, buf48, 2048, 3, grid=grid(2048), stream=stream0)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]         del buf47
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     return (None, None, None, reinterpret_tensor(buf94, (192, ), (1, ), 0), buf96, buf86, reinterpret_tensor(buf88, (64, ), (1, ), 0), buf81, buf83, buf77, buf76, buf58, reinterpret_tensor(buf60, (64, ), (1, ), 0), buf53, buf55, buf46, reinterpret_tensor(buf48, (2048, ), (1, ), 0), buf41, reinterpret_tensor(buf43, (64, ), (1, ), 0), buf36, buf38, buf23, buf24, )
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._inductor.utils import print_performance
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_1 = 32
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_2 = 10
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     mul_8 = 320
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     mul_71 = 256
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     sym_size_int_18 = 4
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     primals_22 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_6 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_7 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_8 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem = rand_strided((32, 8, 10, 8), (640, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_1 = rand_strided((32, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_2 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_3 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_9 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     gt = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_11 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     full_default = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_19 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_20 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_21 = rand_strided((32, 8, 10, 8), (64, 8, 2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_10 = rand_strided((32, 8, 10, 8), (640, 8, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_11 = rand_strided((32, 8, 32), (256, 32, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_12 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_13 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_22 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     gt_1 = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     mul_262 = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_24 = rand_strided((320, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     gt_2 = rand_strided((10, 32, 2048), (65536, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     view_26 = rand_strided((320, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     gt_3 = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     mul_318 = rand_strided((10, 32, 64), (2048, 64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     unsqueeze_2 = rand_strided((32, 64, 1, 10), (64, 1, 20480, 2048), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     avg_pool2d = rand_strided((32, 64, 1, 4), (256, 4, 4, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     getitem_21 = rand_strided((32, 4, 1), (4, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     rsqrt_4 = rand_strided((32, 4, 1), (4, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     lt_6 = rand_strided((32, 64, 1), (64, 1, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     convert_element_type_2 = rand_strided((128, 1), (1, 1), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     clamp_max = rand_strided((128, 1), (1, 1), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     convert_element_type_4 = rand_strided((8, ), (1, ), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     clamp_max_1 = rand_strided((8, ), (1, ), device='cuda:0', dtype=torch.int64)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     clamp_max_2 = rand_strided((8, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     clamp_max_3 = rand_strided((128, 1), (1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     div_1 = rand_strided((32, 8, 128), (1024, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     pow_4 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     pow_6 = rand_strided((), (), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     pow_8 = rand_strided((), (), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     div_7 = rand_strided((10, 32, 1), (32, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     permute_28 = rand_strided((64, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     le_1 = rand_strided((10, 32, 2048), (65536, 2048, 1), device='cuda:0', dtype=torch.bool)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     permute_32 = rand_strided((2048, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     div_8 = rand_strided((10, 32, 1), (32, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     permute_36 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     permute_48 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     mul_598 = rand_strided((10, 32, 64), (64, 640, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     div_9 = rand_strided((10, 32, 1), (32, 1, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     permute_52 = rand_strided((64, 64), (64, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tangents_1 = rand_strided((32, 8, 128), (1024, 128, 1), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tangents_2 = rand_strided((), (), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     tangents_3 = rand_strided((), (), device='cuda:0', dtype=torch.float32)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     fn = lambda: call([primals_1, primals_2, mul_8, mul_71, sym_size_int_18, primals_8, primals_14, primals_20, primals_21, primals_22, view, view_6, view_7, view_8, getitem, getitem_1, getitem_2, getitem_3, view_9, gt, view_11, full_default, view_19, view_20, view_21, getitem_10, getitem_11, getitem_12, getitem_13, view_22, gt_1, mul_262, view_24, gt_2, view_26, gt_3, mul_318, unsqueeze_2, avg_pool2d, getitem_21, rsqrt_4, lt_6, convert_element_type_2, clamp_max, convert_element_type_4, clamp_max_1, clamp_max_2, clamp_max_3, div_1, pow_4, pow_6, pow_8, div_7, permute_28, le_1, permute_32, div_8, permute_36, permute_48, mul_598, div_9, permute_52, tangents_1, tangents_2, tangents_3])
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] if __name__ == "__main__":
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0127 12:26:35.540000 1940816 site-packages/torch/_inductor/graph.py:2014] [110/0] [__output_code] 
V0127 12:26:35.592000 1940816 site-packages/torch/_inductor/graph.py:2022] [110/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/3t/c3tdyamfidzex2uu6zdlrya4cqftuhmrxlxw7rrrvexryrrig6cf.py
I0127 12:26:36.287000 1940816 site-packages/torch/_inductor/graph.py:2056] [110/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/3t/c3tdyamfidzex2uu6zdlrya4cqftuhmrxlxw7rrrvexryrrig6cf.py
