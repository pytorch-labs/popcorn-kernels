V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] Output code: 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # AOT ID: ['3_forward']
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import torch
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import random
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import os
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import tempfile
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from math import inf, nan
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from cmath import nanj
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch import device, empty_strided
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     grid,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     split_scan_grid,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     grid_combo_kernels,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     start_graph,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     end_graph,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     cooperative_reduction_grid,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] aten = torch.ops.aten
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] _quantized = torch.ops._quantized
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] async_compile = AsyncCompile()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/p6/cp6hgtvrvc7dxthwgqvnlzqrmjhqp2tqmneozfor3iix4upde6o2.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_1, x_2], Original ATen: [aten.convolution, aten.relu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_1 => convolution
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_2 => relu
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%view, %primals_4, %primals_5, [1, 1, 1], [0, 0, 0], [1, 1, 1], True, [0, 0, 0], 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_convolution_relu_0 = async_compile.triton('triton_poi_fused_convolution_relu_0', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 262144}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_convolution_relu_0(in_out_ptr0, in_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2q/c2qfrbs7322t5hcet2qcoqqggm3ffuvd52q6tt46ww6xmqf4kavl.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_3, x_4], Original ATen: [aten.convolution, aten.gelu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_3 => convolution_1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_4 => add_23, erf, mul_25, mul_26, mul_27
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %convolution_1 : [num_users=3] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_6, %primals_7, [1, 1, 1], [0, 0, 0], [1, 1, 1], True, [0, 0, 0], 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_25 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, 0.5), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, 0.7071067811865476), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_26,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_23 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_25, %add_23), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_convolution_gelu_1 = async_compile.triton('triton_poi_fused_convolution_gelu_1', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_gelu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_convolution_gelu_1(in_out_ptr0, in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = 0.5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tmp2 * tmp3
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = 0.7071067811865476
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp6 = tmp2 * tmp5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp7 = libdevice.erf(tmp6)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp8 = 1.0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp9 = tmp7 + tmp8
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp10 = tmp4 * tmp9
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x2), tmp10, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/r6/cr6bqtvorvm364a7pktm4dtshjqd2vufqq63mpnd3b3cj7xlsrxb.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_4, x_5], Original ATen: [aten.gelu, aten.view]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_4 => add_23, erf, mul_25, mul_26, mul_27
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_5 => view_1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_25 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, 0.5), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, 0.7071067811865476), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_26,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_23 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_25, %add_23), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_1 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_27, [1, 20, -1]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_gelu_view_2 = async_compile.triton('triton_poi_fused_gelu_view_2', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_gelu_view_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_gelu_view_2(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % ks0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*(((x0 // (8 + ks2)) % (8 + ks1))) + 64*(x0 // (64 + 8*ks1 + 8*ks2 + ks1*ks2)) + 576*x1 + ks2*(((x0 // (8 + ks2)) % (8 + ks1))) + 8*ks1*(x0 // (64 + 8*ks1 + 8*ks2 + ks1*ks2)) + 8*ks2*(x0 // (64 + 8*ks1 + 8*ks2 + ks1*ks2)) + 72*ks1*x1 + 72*ks2*x1 + ks1*ks2*(x0 // (64 + 8*ks1 + 8*ks2 + ks1*ks2)) + 9*ks1*ks2*x1 + ((x0 % (8 + ks2)))), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x2), tmp0, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yp/cypv75rdbtb6tl63kkyoa2c4zcqmfwukabmbmrrvauzx4fphyw2p.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_6, x_7], Original ATen: [aten.convolution, aten.relu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_6 => convolution_2
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_7 => relu_1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%view_1, %primals_8, %primals_9, [1], [0], [1], True, [0], 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_convolution_relu_3 = async_compile.triton('triton_poi_fused_convolution_relu_3', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 524288}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_3', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_convolution_relu_3(in_out_ptr0, in_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nz/cnztlaiboahi5wc7qmqtgcnl5cbqbqeae6glojllzwh7k7q7d2kz.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_8 => convolution_3
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %convolution_3 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %primals_10, %primals_11, [1], [0], [1], True, [0], 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_convolution_4 = async_compile.triton('triton_poi_fused_convolution_4', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 262144}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_convolution_4(in_out_ptr0, in_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 + tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hv/chvnyecghujsbigfsrm4cn6v7shjdyu4mqa7brmle2tl43age2uc.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => var_mean, view_2
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_2, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused__native_batch_norm_legit_functional_gelu_view_5 = async_compile.triton('triton_red_fused__native_batch_norm_legit_functional_gelu_view_5', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 8192},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_gelu_view_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 3, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused__native_batch_norm_legit_functional_gelu_view_5(in_ptr0, out_ptr0, out_ptr1, out_ptr2, ks0, ks1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 30
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 6)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 6
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22_mean = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22_m2 = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22_weight = tl.zeros([XBLOCK, R0_BLOCK], tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = ks2
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (r0_2 + 584*x1 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0 + 72*ks0*x1 + 72*ks1*x1 + 9*ks0*ks1*x1), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = 0.5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp5 = tmp3 * tmp4
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = 0.7071067811865476
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp7 = tmp3 * tmp6
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp8 = libdevice.erf(tmp7)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp9 = 1.0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp10 = tmp8 + tmp9
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp11 = tmp5 * tmp10
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp12 = tl.full(tmp11.shape, 0, tmp11.dtype)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp13 = tl.where(tmp2, tmp11, tmp12)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp14 = 0.0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp15 = tl.full(tmp14.shape, 0, tmp14.dtype)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp16 = tl.where(tmp2, tmp14, tmp15)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp17 = tl.full(tmp9.shape, 0, tmp9.dtype)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp18 = tl.where(tmp2, tmp9, tmp17)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp19 = tl.broadcast_to(tmp13, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp20 = tl.broadcast_to(tmp16, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp21 = tl.broadcast_to(tmp18, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp22_mean_next, tmp22_m2_next, tmp22_weight_next = triton_helpers.welford_combine(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             tmp22_mean, tmp22_m2, tmp22_weight,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             tmp19, tmp20, tmp21
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp22_mean = tl.where(r0_mask & xmask, tmp22_mean_next, tmp22_mean)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp22_m2 = tl.where(r0_mask & xmask, tmp22_m2_next, tmp22_m2)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp22_weight = tl.where(r0_mask & xmask, tmp22_weight_next, tmp22_weight)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp25, tmp26, tmp27 = triton_helpers.welford(tmp22_mean, tmp22_m2, tmp22_weight, 1)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22 = tmp25[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp23 = tmp26[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp24 = tmp27[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp22, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr1 + (x3), tmp23, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr2 + (x3), tmp24, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/q3/cq35fhw4qntqoehff74gahhdxk74sxihtnmp4nwxad6tbet46mkc.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional, aten.mean]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => add_51, mean, mean_1, rsqrt, var_mean, view_2
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_2, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_51 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %rsqrt : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_51,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_4, [0]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%view_6, [0]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_12, %mean), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%primals_13, %mean_1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused__native_batch_norm_legit_functional_gelu_mean_view_6 = async_compile.triton('triton_per_fused__native_batch_norm_legit_functional_gelu_mean_view_6', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 8, 'r0_': 8},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'out_ptr4': '*fp32', 'out_ptr6': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_gelu_mean_view_6', 'mutated_arg_names': ['in_ptr3', 'in_ptr4', 'out_ptr4', 'out_ptr6'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused__native_batch_norm_legit_functional_gelu_mean_view_6(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr4, out_ptr6, ks0, ks1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 6
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 8
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr1 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tl.load(in_ptr2 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp27 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp34 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, R0_BLOCK])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp7 = tl.where(r0_mask & xmask, tmp3, 0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp8 = tl.where(r0_mask & xmask, tmp4, 0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp9 = tl.where(r0_mask & xmask, tmp5, 0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp13 = tmp10[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp14 = tmp11[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp15 = tmp12[:, None]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp16 = ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp17 = tmp16.to(tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp18 = tmp14 / tmp17
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp19 = 1e-05
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp20 = tmp18 + tmp19
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp21 = libdevice.rsqrt(tmp20)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22 = (((2920 + 360*ks1 + 360*ks2 + 45*ks1*ks2) / 5) / ((tl.full([], -1.00000000000000, tl.float64)) + ((2920 + 360*ks1 + 360*ks2 + 45*ks1*ks2) / 5)))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp23 = tmp22.to(tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp24 = tmp18 * tmp23
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp25 = 0.1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp26 = tmp24 * tmp25
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp28 = 0.9
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp29 = tmp27 * tmp28
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp30 = tmp26 + tmp29
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp31 = 1.0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp32 = tmp30 / tmp31
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp33 = tmp13 * tmp25
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp35 = tmp34 * tmp28
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp36 = tmp33 + tmp35
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp37 = tmp36 / tmp31
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr2 + (x0), tmp21, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr4 + (x0), tmp32, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr6 + (x0), tmp37, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr1 + (x0), tmp14, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/n6/cn6dglumxmwyou3jzv5u7nqbt2xp5gqcxnpk4nmo3xomaoejnlcc.py
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => add_51, add_54, mul_61, mul_67, rsqrt, sub_19, var_mean, view_2, view_7
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=3] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%view_2, [0, 2]), kwargs = {correction: 0, keepdim: True})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_51 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %rsqrt : [num_users=2] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_51,), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_2, %getitem_1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_19, %rsqrt), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_67 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_61, %unsqueeze), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_54 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_67, %unsqueeze_1), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_7 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%add_54, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7', '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 262144}, 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp9 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp11 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp19 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp21 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = 0.5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 * tmp1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = 0.7071067811865476
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tmp0 * tmp3
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = libdevice.erf(tmp4)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp6 = 1.0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp7 = tmp5 + tmp6
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp8 = tmp2 * tmp7
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp10 = tmp8 - tmp9
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp12 = ks0
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp13 = tmp12.to(tl.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp14 = tmp11 / tmp13
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp15 = 1e-05
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp16 = tmp14 + tmp15
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp17 = libdevice.rsqrt(tmp16)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp18 = tmp10 * tmp17
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp20 = tmp18 * tmp19
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22 = tmp20 + tmp21
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x2), tmp22, xmask)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] cpp_fused_full_randint_8 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*', 'int64_t*', 'int64_t*', 'const int64_t', 'const int64_t'], '''
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #include "/tmp/torchinductor_sahanp/3b/c3bi5gk6mslf6u4iaqafhxm64z6u65e3eain4xlary5blqnvv6xx.h"
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] extern "C"  void kernel(const int64_t* in_ptr0,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                        int64_t* out_ptr0,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                        int64_t* out_ptr1,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                        int64_t* out_ptr2,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                        const int64_t ks0,
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                        const int64_t ks1)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         #pragma GCC ivdep
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5L); x0+=static_cast<int64_t>(1L))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp1 = x0;
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp2 = c10::convert<int32_t>(tmp1);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp3 = static_cast<int64_t>(1);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp4 = static_cast<int64_t>(5);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     auto tmp5 = randint64_cpu(tmp0, tmp2, tmp3, tmp4);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                     out_ptr0[static_cast<int64_t>(x0)] = tmp5;
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp0 = 584L + 72L*ks0 + 72L*ks1 + 9L*ks0*ks1;
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp1 = c10::convert<int64_t>(tmp0);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 out_ptr1[static_cast<int64_t>(0L)] = tmp1;
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             {
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp0 = in_ptr0[static_cast<int64_t>(1L)];
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp1 = static_cast<int32_t>(0);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp2 = static_cast<int64_t>(1);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp3 = static_cast<int64_t>(6);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 auto tmp4 = randint64_cpu(tmp0, tmp1, tmp2, tmp3);
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]                 out_ptr2[static_cast<int64_t>(0L)] = tmp4;
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]             }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] }
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''')
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] async_compile.wait(globals())
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] del async_compile
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def call(args):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15 = args
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     args.clear()
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     s0 = primals_1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     s1 = primals_2
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_3, (1, s0, s1), (s0*s1, s1, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_4, (1, 10, 5, 5, 5), (1250, 125, 25, 5, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_5, (10, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_6, (10, 20, 5, 5, 5), (2500, 125, 25, 5, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_7, (20, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_8, (20, 10, 5), (50, 5, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_9, (10, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_10, (10, 5, 5), (25, 5, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_11, (5, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_12, (5, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_13, (5, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_14, (5, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_15, (5, ), (1, ))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         torch.cuda.set_device(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_1], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf0 = extern_kernels.convolution(reinterpret_tensor(primals_3, (1, 1, 1, s0, s1), (s0*s1, s0*s1, s0*s1, s1, 1), 0), primals_4, stride=(1, 1, 1), padding=(0, 0, 0), dilation=(1, 1, 1), transposed=True, output_padding=(0, 0, 0), groups=1, bias=None)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         assert_size_stride(buf0, (1, 10, 5, 4 + s0, 4 + s1), (800 + 200*s0 + 200*s1 + 50*s0*s1, 80 + 20*s0 + 20*s1 + 5*s0*s1, 16 + 4*s0 + 4*s1 + s0*s1, 4 + s1, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps0 = 80 + 20*s0 + 20*s1 + 5*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf1 = buf0; del buf0  # reuse
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_1, x_2], Original ATen: [aten.convolution, aten.relu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_relu_0_xnumel = 800 + 200*s0 + 200*s1 + 50*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_relu_0.run(buf1, primals_5, ps0, triton_poi_fused_convolution_relu_0_xnumel, grid=grid(triton_poi_fused_convolution_relu_0_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_5
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_3], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf2 = extern_kernels.convolution(buf1, primals_6, stride=(1, 1, 1), padding=(0, 0, 0), dilation=(1, 1, 1), transposed=True, output_padding=(0, 0, 0), groups=1, bias=None)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         assert_size_stride(buf2, (1, 20, 9, 8 + s0, 8 + s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 64 + 8*s0 + 8*s1 + s0*s1, 8 + s1, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps1 = 576 + 72*s0 + 72*s1 + 9*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf3 = buf2; del buf2  # reuse
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf4 = empty_strided_cuda((1, 20, 9, 8 + s0, 8 + s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 64 + 8*s0 + 8*s1 + s0*s1, 8 + s1, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_3, x_4], Original ATen: [aten.convolution, aten.gelu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_gelu_1_xnumel = 11520 + 1440*s0 + 1440*s1 + 180*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_gelu_1.run(buf3, primals_7, buf4, ps1, triton_poi_fused_convolution_gelu_1_xnumel, grid=grid(triton_poi_fused_convolution_gelu_1_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_7
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps2 = 576 + 72*s0 + 72*s1 + 9*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf5 = empty_strided_cuda((1, 20, 576 + 72*s0 + 72*s1 + 9*s0*s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_4, x_5], Original ATen: [aten.gelu, aten.view]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_view_2_xnumel = 11520 + 1440*s0 + 1440*s1 + 180*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_view_2.run(buf4, buf5, ps2, s0, s1, triton_poi_fused_gelu_view_2_xnumel, grid=grid(triton_poi_fused_gelu_view_2_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf4
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_6], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf6 = extern_kernels.convolution(buf5, primals_8, stride=(1,), padding=(0,), dilation=(1,), transposed=True, output_padding=(0,), groups=1, bias=None)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         assert_size_stride(buf6, (1, 10, 580 + 72*s0 + 72*s1 + 9*s0*s1), (5800 + 720*s0 + 720*s1 + 90*s0*s1, 580 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps3 = 580 + 72*s0 + 72*s1 + 9*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf7 = reinterpret_tensor(buf6, (1, 10, 580 + 72*s0 + 72*s1 + 9*s0*s1), (5800 + 720*s0 + 720*s1 + 90*s0*s1, 580 + 72*s0 + 72*s1 + 9*s0*s1, 1), 0); del buf6  # reuse
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_6, x_7], Original ATen: [aten.convolution, aten.relu]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_relu_3_xnumel = 5800 + 720*s0 + 720*s1 + 90*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_relu_3.run(buf7, primals_9, ps3, triton_poi_fused_convolution_relu_3_xnumel, grid=grid(triton_poi_fused_convolution_relu_3_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_9
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf8 = extern_kernels.convolution(buf7, primals_10, stride=(1,), padding=(0,), dilation=(1,), transposed=True, output_padding=(0,), groups=1, bias=None)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         assert_size_stride(buf8, (1, 5, 584 + 72*s0 + 72*s1 + 9*s0*s1), (2920 + 360*s0 + 360*s1 + 45*s0*s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps4 = 584 + 72*s0 + 72*s1 + 9*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf9 = reinterpret_tensor(buf8, (1, 5, 584 + 72*s0 + 72*s1 + 9*s0*s1), (2920 + 360*s0 + 360*s1 + 45*s0*s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, 1), 0); del buf8  # reuse
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_8], Original ATen: [aten.convolution]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_4_xnumel = 2920 + 360*s0 + 360*s1 + 45*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_convolution_4.run(buf9, primals_11, ps4, triton_poi_fused_convolution_4_xnumel, grid=grid(triton_poi_fused_convolution_4_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_11
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf10 = empty_strided_cuda((1, 5, 1, 6), (30, 6, 30, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf11 = empty_strided_cuda((1, 5, 1, 6), (30, 6, 30, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf12 = empty_strided_cuda((1, 5, 1, 6), (30, 6, 30, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused__native_batch_norm_legit_functional_gelu_view_5_r0_numel = 12*s0 + 12*s1 + ((589 + 9*s0*s1) // 6)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused__native_batch_norm_legit_functional_gelu_view_5.run(buf9, buf10, buf11, buf12, s0, s1, ps4, 30, triton_red_fused__native_batch_norm_legit_functional_gelu_view_5_r0_numel, grid=grid(30), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf13 = empty_strided_cuda((1, 5, 1), (5, 1, 5), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf14 = empty_strided_cuda((1, 5, 1), (5, 1, 5), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf16 = empty_strided_cuda((1, 5, 1), (5, 1, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional, aten.mean]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused__native_batch_norm_legit_functional_gelu_mean_view_6.run(buf10, buf11, buf12, primals_13, primals_12, buf13, buf14, buf16, primals_13, primals_12, ps4, s0, s1, 5, 6, grid=grid(5), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf10
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf11
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf12
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_12
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_13
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf17 = empty_strided_cuda((1, 5, 584 + 72*s0 + 72*s1 + 9*s0*s1), (2920 + 360*s0 + 360*s1 + 45*s0*s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, 1), torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten._native_batch_norm_legit_functional]
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7_xnumel = 2920 + 360*s0 + 360*s1 + 45*s0*s1
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7.run(buf9, buf13, buf14, primals_14, primals_15, buf17, ps4, triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7_xnumel, grid=grid(triton_poi_fused__native_batch_norm_legit_functional_gelu_view_7_xnumel), stream=stream0)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf14
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_15
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     buf18 = empty_strided_cpu((2, ), (1, ), torch.int64)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     # Topologically Sorted Source Nodes: [], Original ATen: []
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     aten.randint.low_out(-9223372036854775808, 9223372036854775807, [2], out=buf18)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     buf19 = empty_strided_cpu((1, 5), (5, 1), torch.int64)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     buf28 = empty_strided_cpu((1, ), (1, ), torch.int64)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     buf29 = empty_strided_cpu((1, ), (1, ), torch.int64)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     cpp_fused_full_randint_8(buf18, buf19, buf28, buf29, s0, s1)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     return (buf17, buf19, buf28, buf29, primals_4, primals_6, primals_8, primals_10, primals_14, reinterpret_tensor(primals_3, (1, 1, 1, s0, s1), (s0*s1, s0*s1, s0*s1, s1, 1), 0), buf1, buf3, buf5, buf7, buf9, reinterpret_tensor(buf16, (5, ), (1, ), 0), reinterpret_tensor(buf13, (1, 5, 1), (5, 1, 1), 0), s0, s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, )
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_1 = 64
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_2 = 64
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_3 = rand_strided((1, 64, 64), (4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_4 = rand_strided((1, 10, 5, 5, 5), (1250, 125, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_5 = rand_strided((10, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_6 = rand_strided((10, 20, 5, 5, 5), (2500, 125, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_7 = rand_strided((20, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_8 = rand_strided((20, 10, 5), (50, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_9 = rand_strided((10, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_10 = rand_strided((10, 5, 5), (25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_11 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_12 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_13 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_14 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_15 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15])
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] if __name__ == "__main__":
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:42:37.853000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:37.874000 2742634 site-packages/torch/_inductor/graph.py:2022] [10/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/q7/cq7ttryfvfltbmaxkb2isqrjae4dgcbeeyee7ae2lwt6w47swu6f.py
I0204 20:42:38.877000 2742634 site-packages/torch/_inductor/graph.py:2056] [10/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/q7/cq7ttryfvfltbmaxkb2isqrjae4dgcbeeyee7ae2lwt6w47swu6f.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] Output code: 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # AOT ID: ['3_backward']
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import torch
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import random
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import os
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import tempfile
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from math import inf, nan
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from cmath import nanj
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.utils import maybe_profile
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch import device, empty_strided
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     grid,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     split_scan_grid,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     grid_combo_kernels,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     start_graph,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     end_graph,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     cooperative_reduction_grid,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] aten = torch.ops.aten
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] inductor_ops = torch.ops.inductor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] _quantized = torch.ops._quantized
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] async_compile = AsyncCompile()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hu/chunjp3ykosx4njv6p47r6gok7svmucljcbwdgsx5njsbi2im2s7.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.native_batch_norm_backward, aten.gelu, aten.view]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => view_2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_1 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_8, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_23 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_2, %unsqueeze_3), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_76 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_8, %sub_23), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_2 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_76, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused_gelu_native_batch_norm_backward_view_0 = async_compile.triton('triton_red_fused_gelu_native_batch_norm_backward_view_0', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 8192},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_gelu_native_batch_norm_backward_view_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 2, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused_gelu_native_batch_norm_backward_view_0(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 30
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp22 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = 584 + 72*ks0 + 72*ks1 + 9*ks0*ks1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (r0_2 + 584*x1 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0 + 72*ks0*x1 + 72*ks1*x1 + 9*ks0*ks1*x1), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp7 = tl.load(in_ptr1 + (r0_2 + 584*x1 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0 + 72*ks0*x1 + 72*ks1*x1 + 9*ks0*ks1*x1), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp8 = 0.5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp9 = tmp7 * tmp8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp10 = 0.7071067811865476
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp11 = tmp7 * tmp10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp12 = libdevice.erf(tmp11)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp13 = 1.0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp14 = tmp12 + tmp13
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp15 = tmp9 * tmp14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp16 = tl.load(in_ptr2 + (tl.broadcast_to(x1, [XBLOCK, R0_BLOCK])), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp17 = tmp15 - tmp16
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp18 = tmp3 * tmp17
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp19 = tl.full(tmp18.shape, 0, tmp18.dtype)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp20 = tl.where(tmp2, tmp18, tmp19)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp21 = tl.broadcast_to(tmp20, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp23 = _tmp22 + tmp21
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp22 = tl.where(r0_mask & xmask, tmp23, _tmp22)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22 = tl.sum(_tmp22, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr1 + (x3), tmp22, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/l3/cl3xeidv7vael4iljg634kszwtz7k2zbfnyxvq5ux3lg5vypsso6.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_1 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%view_8, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused_native_batch_norm_backward_1 = async_compile.triton('triton_per_fused_native_batch_norm_backward_1', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 8, 'r0_': 8},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_native_batch_norm_backward_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused_native_batch_norm_backward_1(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/if/cifd66tlxs2vn6c7hyubex5zuloruzkg6n4xiiapxxp5fn72brt2.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten.native_batch_norm_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => view_2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_23 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_2, %unsqueeze_3), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_76 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_8, %sub_23), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_2 : [num_users=2] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_76, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_85 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sum_2, %squeeze_1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused_gelu_native_batch_norm_backward_view_2 = async_compile.triton('triton_per_fused_gelu_native_batch_norm_backward_view_2', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 8, 'r0_': 8},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_gelu_native_batch_norm_backward_view_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused_gelu_native_batch_norm_backward_view_2(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp6 = tmp4 * tmp5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr1 + (x0), tmp6, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ji/cjiqjnq3b2veqcgplztxz4dpgtdlte52skmj7qxvucn2ikym65lr.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten.native_batch_norm_backward, aten.gelu_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_10 => view_2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_9 => add_44, erf_1, mul_48, mul_49, mul_50
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, 0.7071067811865476), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf_1 : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_49,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_44 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf_1, 1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_48, %add_44), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_50, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_23 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_2, %unsqueeze_3), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_83 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_23, %unsqueeze_7), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%view_8, %mul_83), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sub_26 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_25, %unsqueeze_5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_84 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_26, %unsqueeze_9), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %view_9 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%mul_84, [1, 5, %sym_size_int_8]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_87 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_44, 0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_88 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, %convolution_3), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_89 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_88, -0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%mul_89,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_90 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, 0.3989422804014327), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_91 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_3, %mul_90), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_62 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_87, %mul_91), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_92 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_9, %add_62), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3 = async_compile.triton('triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 262144}, 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, ks0, ks1, ks2, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x2 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // ks0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_out_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp10 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp12 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp16 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp21 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp24 = tl.load(in_ptr5 + (x1), xmask, eviction_policy='evict_last')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = 0.5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tmp1 * tmp2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = 0.7071067811865476
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tmp1 * tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp6 = libdevice.erf(tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp7 = 1.0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp8 = tmp6 + tmp7
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp9 = tmp3 * tmp8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp11 = tmp9 - tmp10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp13 = (tl.full([], 1.00000000000000, tl.float64) / ((2920 + 360*ks1 + 360*ks2 + 45*ks1*ks2) / 5))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp14 = tmp13.to(tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp15 = tmp12 * tmp14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp17 = tmp16 * tmp16
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp18 = tmp15 * tmp17
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp19 = tmp11 * tmp18
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp20 = tmp0 - tmp19
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp22 = tmp21 * tmp14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp23 = tmp20 - tmp22
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp25 = tmp16 * tmp24
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp26 = tmp23 * tmp25
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp27 = tmp8 * tmp2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp28 = tmp1 * tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp29 = -0.5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp30 = tmp28 * tmp29
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp31 = tl_math.exp(tmp30)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp32 = 0.3989422804014327
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp33 = tmp31 * tmp32
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp34 = tmp1 * tmp33
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp35 = tmp27 + tmp34
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp36 = tmp26 * tmp35
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp36, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vh/cvhbx5b2cawueiv4ysvlszcyrfnfcijabwcduuqjmxgv4b7m4abo.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_92, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused_convolution_backward_4 = async_compile.triton('triton_red_fused_convolution_backward_4', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 8192},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'ks2': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused_convolution_backward_4(in_ptr0, out_ptr0, ks0, ks1, ks2, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 30
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = ks2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (r0_2 + 584*x1 + x0*((589 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0 + 72*ks0*x1 + 72*ks1*x1 + 9*ks0*ks1*x1), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jg/cjgdsmcsplemmno5xefsalo6qp3jsozpigew5b64gxjfwao3yhxc.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_1, 0), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %where : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%le, %full_default, %getitem_2), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_threshold_backward_5 = async_compile.triton('triton_poi_fused_threshold_backward_5', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 524288}, 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_threshold_backward_5', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_threshold_backward_5(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = 0.0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 <= tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.where(tmp2, tmp1, tmp3)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/an/can6fiot5r3unbzfw2xjm4tfdczhvbskrvtur7u4vhvtarnaim2n.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused_convolution_backward_6 = async_compile.triton('triton_red_fused_convolution_backward_6', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 64, 'r0_': 8192},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_6', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused_convolution_backward_6(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 60
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((195 + 3*ks0*ks1) // 2) + 12*ks0*x0 + 12*ks1*x0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = 580 + 72*ks0 + 72*ks1 + 9*ks0*ks1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (r0_2 + 580*x1 + x0*((195 + 3*ks0*ks1) // 2) + 12*ks0*x0 + 12*ks1*x0 + 72*ks0*x1 + 72*ks1*x1 + 9*ks0*ks1*x1), r0_mask & tmp2 & xmask, eviction_policy='evict_first', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jl/cjlgwxhmxeun42jlyvgmrjwbp5jvn5nxiwljjic43f627p5rkl5l.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where, [0, 2]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused_convolution_backward_7 = async_compile.triton('triton_per_fused_convolution_backward_7', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 16, 'r0_': 8},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused_convolution_backward_7(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rt/crtfhirp4lho5zvppocuqmyvstj4vo3sxdo6ujtytrc4hmpef7mo.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.gelu, aten.gelu_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   x_4 => add_23, erf, mul_26
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, 0.7071067811865476), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %erf : [num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_26,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_23 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_94 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_23, 0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_95 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, %convolution_1), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_96 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_95, -0.5), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%mul_96,), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_97 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, 0.3989422804014327), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_98 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution_1, %mul_97), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %add_64 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_94, %mul_98), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %mul_99 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_10, %add_64), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_gelu_gelu_backward_8 = async_compile.triton('triton_poi_fused_gelu_gelu_backward_8', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 1048576}, 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_gelu_gelu_backward_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_gelu_gelu_backward_8(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = 0.7071067811865476
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tmp1 * tmp2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = libdevice.erf(tmp3)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = 1.0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp6 = tmp4 + tmp5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp7 = 0.5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp8 = tmp6 * tmp7
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp9 = tmp1 * tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp10 = -0.5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp11 = tmp9 * tmp10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp12 = tl_math.exp(tmp11)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp13 = 0.3989422804014327
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp14 = tmp12 * tmp13
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp15 = tmp1 * tmp14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp16 = tmp8 + tmp15
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp17 = tmp0 * tmp16
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp17, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6a/c6ajbgmomcvkwhkqiaesq23ct3j3gdno7g5pm46jtwbkwsiuwjft.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_99, [0, 2, 3, 4]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused_convolution_backward_9 = async_compile.triton('triton_red_fused_convolution_backward_9', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 128, 'r0_': 8192},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_9', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused_convolution_backward_9(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 120
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = 576 + 72*ks0 + 72*ks1 + 9*ks0*ks1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (8*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (8 + ks1)) % (8 + ks0))) + 64*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (64 + 8*ks0 + 8*ks1 + ks0*ks1)) % 9)) + 576*x1 + ks1*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (8 + ks1)) % (8 + ks0))) + 8*ks0*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (64 + 8*ks0 + 8*ks1 + ks0*ks1)) % 9)) + 8*ks1*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (64 + 8*ks0 + 8*ks1 + ks0*ks1)) % 9)) + 72*ks0*x1 + 72*ks1*x1 + ks0*ks1*((((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) // (64 + 8*ks0 + 8*ks1 + ks0*ks1)) % 9)) + 9*ks0*ks1*x1 + (((r0_2 + x0*((581 + 9*ks0*ks1) // 6) + 12*ks0*x0 + 12*ks1*x0) % (8 + ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s6/cs6yggklfwvknjrphuqxpmr464m5t6z6wr7usgcvtnkoyeoo2q4i.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_99, [0, 2, 3, 4]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused_convolution_backward_10 = async_compile.triton('triton_per_fused_convolution_backward_10', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 8},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused_convolution_backward_10(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 20
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 6*x0), r0_mask & xmask, other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6o/c6osx2mdzpxxkljzqkcfy2vfm554e7hilmcz3za33sqiojn7jk63.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %full_default : [num_users=2] = call_function[target=torch.ops.aten.full.default](args = ([], 0.0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %le_1 : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu, 0), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %where_1 : [num_users=2] = call_function[target=torch.ops.aten.where.self](args = (%le_1, %full_default, %getitem_8), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_poi_fused_threshold_backward_11 = async_compile.triton('triton_poi_fused_threshold_backward_11', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.pointwise(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 262144}, 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_threshold_backward_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     min_elem_per_thread=0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_poi_fused_threshold_backward_11(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.load(in_ptr0 + (x0), xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = 0.0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp2 = tmp0 <= tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.where(tmp2, tmp1, tmp3)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cd/ccdmfwtur4fdvge7dwb3pbxtzc2ep6womna7ln6o7oece3rroifp.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where_1, [0, 2, 3, 4]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_red_fused_convolution_backward_12 = async_compile.triton('triton_red_fused_convolution_backward_12', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 32, 'r0_': 8192},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ks0': 'i32', 'ks1': 'i32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_convolution_backward_12', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_red_fused_convolution_backward_12(in_ptr0, out_ptr0, ks0, ks1, xnumel, r0_numel, XBLOCK : tl.constexpr, R0_BLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 30
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_base = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rbase = r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = (xindex % 3)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x1 = xindex // 3
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     _tmp5 = tl.full([XBLOCK, R0_BLOCK], 0, tl.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x3 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     for r0_offset in range(0, r0_numel, R0_BLOCK):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_index = r0_offset + r0_base
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         r0_2 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp0 = r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp1 = 80 + 20*ks0 + 20*ks1 + 5*ks0*ks1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp2 = tmp0 < tmp1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp3 = tl.load(in_ptr0 + (4*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (4 + ks1)) % (4 + ks0))) + 16*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (16 + 4*ks0 + 4*ks1 + ks0*ks1)) % 5)) + 80*x1 + ks1*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (4 + ks1)) % (4 + ks0))) + 4*ks0*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (16 + 4*ks0 + 4*ks1 + ks0*ks1)) % 5)) + 4*ks1*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (16 + 4*ks0 + 4*ks1 + ks0*ks1)) % 5)) + 20*ks0*x1 + 20*ks1*x1 + ks0*ks1*((((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) // (16 + 4*ks0 + 4*ks1 + ks0*ks1)) % 5)) + 5*ks0*ks1*x1 + (((r0_2 + x0*((82 + 20*ks0 + 20*ks1 + 5*ks0*ks1) // 3)) % (4 + ks1)))), r0_mask & tmp2 & xmask, eviction_policy='evict_last', other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp4 = tl.broadcast_to(tmp3, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         tmp6 = _tmp5 + tmp4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         _tmp5 = tl.where(r0_mask & xmask, tmp6, _tmp5)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp5 = tl.sum(_tmp5, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x3), tmp5, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gw/cgwcrnibt2ymb5fi23d6yqtpolrqndbqivngvi7ia4pptmlildyi.py
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Source node to ATen node mapping:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] # Graph fragment:
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%where_1, [0, 2, 3, 4]), kwargs = {})
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_per_fused_convolution_backward_13 = async_compile.triton('triton_per_fused_convolution_backward_13', '''
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] import triton.language as tl
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton_heuristics.persistent_reduction(
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     size_hints={'x': 16, 'r0_': 4},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     filename=__file__,
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_convolution_backward_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'E1309284F070F92E1AD25A7946F3C18B4B066B8A9F4AE2408BC7FC1EBFE3BEEE', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] @triton.jit
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def triton_per_fused_convolution_backward_13(in_ptr0, out_ptr0, xnumel, r0_numel, XBLOCK : tl.constexpr):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xnumel = 10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_numel = 3
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     R0_BLOCK: tl.constexpr = 4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rnumel = r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     RBLOCK: tl.constexpr = R0_BLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     xmask = xindex < xnumel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_index = tl.arange(0, R0_BLOCK)[None, :]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_offset = 0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_mask = r0_index < r0_numel
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     roffset = r0_offset
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     rindex = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     r0_1 = r0_index
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     x0 = xindex
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0_1 + 3*x0), r0_mask & xmask, other=0.0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, R0_BLOCK])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp3 = tl.where(r0_mask & xmask, tmp1, 0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] ''', device_str='cuda')
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] async_compile.wait(globals())
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] del async_compile
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def call(args):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_1, primals_2, sym_size_int_8, primals_4, primals_6, primals_8, primals_10, primals_14, view, relu, convolution_1, view_1, relu_1, convolution_3, squeeze_1, unsqueeze_3, tangents_1 = args
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     args.clear()
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     s0 = primals_1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     s1 = primals_2
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_4, (1, 10, 5, 5, 5), (1250, 125, 25, 5, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_6, (10, 20, 5, 5, 5), (2500, 125, 25, 5, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_8, (20, 10, 5), (50, 5, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_10, (10, 5, 5), (25, 5, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(primals_14, (5, ), (1, ))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(view, (1, 1, 1, s0, s1), (s0*s1, s0*s1, s0*s1, s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(relu, (1, 10, 5, 4 + s0, 4 + s1), (800 + 200*s0 + 200*s1 + 50*s0*s1, 80 + 20*s0 + 20*s1 + 5*s0*s1, 16 + 4*s0 + 4*s1 + s0*s1, 4 + s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(convolution_1, (1, 20, 9, 8 + s0, 8 + s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 64 + 8*s0 + 8*s1 + s0*s1, 8 + s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(view_1, (1, 20, 576 + 72*s0 + 72*s1 + 9*s0*s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(relu_1, (1, 10, 580 + 72*s0 + 72*s1 + 9*s0*s1), (5800 + 720*s0 + 720*s1 + 90*s0*s1, 580 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(convolution_3, (1, 5, 584 + 72*s0 + 72*s1 + 9*s0*s1), (2920 + 360*s0 + 360*s1 + 45*s0*s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(squeeze_1, (5, ), (1, ))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(unsqueeze_3, (1, 5, 1), (5, 1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     assert_size_stride(tangents_1, (1, 5, 584 + 72*s0 + 72*s1 + 9*s0*s1), (2920 + 360*s0 + 360*s1 + 45*s0*s1, 584 + 72*s0 + 72*s1 + 9*s0*s1, 1))
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         torch.cuda.set_device(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf0 = empty_strided_cuda((5, 6), (6, 1), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf2 = empty_strided_cuda((5, 6), (6, 1), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.native_batch_norm_backward, aten.gelu, aten.view]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_gelu_native_batch_norm_backward_view_0_r0_numel = 12*s0 + 12*s1 + ((589 + 9*s0*s1) // 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_gelu_native_batch_norm_backward_view_0.run(tangents_1, convolution_3, unsqueeze_3, buf0, buf2, s0, s1, 30, triton_red_fused_gelu_native_batch_norm_backward_view_0_r0_numel, grid=grid(30), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf1 = empty_strided_cuda((5, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.native_batch_norm_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_native_batch_norm_backward_1.run(buf0, buf1, 5, 6, grid=grid(5), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf0
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf3 = empty_strided_cuda((5, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf4 = empty_strided_cuda((5, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten.native_batch_norm_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_gelu_native_batch_norm_backward_view_2.run(buf2, squeeze_1, buf3, buf4, 5, 6, grid=grid(5), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         ps0 = 584 + 72*s0 + 72*s1 + 9*s0*s1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf5 = convolution_3; del convolution_3  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_9, x_10], Original ATen: [aten.gelu, aten.view, aten.native_batch_norm_backward, aten.gelu_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3_xnumel = 2920 + 360*s0 + 360*s1 + 45*s0*s1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3.run(buf5, tangents_1, unsqueeze_3, buf3, squeeze_1, buf1, primals_14, ps0, s0, s1, triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3_xnumel, grid=grid(triton_poi_fused_gelu_gelu_backward_native_batch_norm_backward_view_3_xnumel), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del squeeze_1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del tangents_1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del unsqueeze_3
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf6 = buf2; del buf2  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_4_r0_numel = 12*s0 + 12*s1 + ((589 + 9*s0*s1) // 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_4.run(buf5, buf6, s0, s1, ps0, 30, triton_red_fused_convolution_backward_4_r0_numel, grid=grid(30), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf7 = buf3; del buf3  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_native_batch_norm_backward_1.run(buf6, buf7, 5, 6, grid=grid(5), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf8 = torch.ops.aten.convolution_backward.default(buf5, relu_1, primals_10, [5], [1], [0], [1], True, [0], 1, [True, True, False])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf5
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_10
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf9 = buf8[0]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf10 = buf8[1]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf11 = relu_1; del relu_1  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_threshold_backward_5_xnumel = 5800 + 720*s0 + 720*s1 + 90*s0*s1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_threshold_backward_5.run(buf11, buf9, triton_poi_fused_threshold_backward_5_xnumel, grid=grid(triton_poi_fused_threshold_backward_5_xnumel), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf9
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf12 = empty_strided_cuda((10, 6), (6, 1), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_6_r0_numel = 12*s0 + 12*s1 + ((195 + 3*s0*s1) // 2)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_6.run(buf11, buf12, s0, s1, 60, triton_red_fused_convolution_backward_6_r0_numel, grid=grid(60), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf13 = empty_strided_cuda((10, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_convolution_backward_7.run(buf12, buf13, 10, 6, grid=grid(10), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf12
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf14 = torch.ops.aten.convolution_backward.default(buf11, view_1, primals_8, [10], [1], [0], [1], True, [0], 1, [True, True, False])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf11
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_8
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del view_1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf15 = buf14[0]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf16 = buf14[1]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf14
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf17 = reinterpret_tensor(buf15, (1, 20, 9, 8 + s0, 8 + s1), (11520 + 1440*s0 + 1440*s1 + 180*s0*s1, 576 + 72*s0 + 72*s1 + 9*s0*s1, 64 + 8*s0 + 8*s1 + s0*s1, 8 + s1, 1), 0); del buf15  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [x_4], Original ATen: [aten.gelu, aten.gelu_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_gelu_backward_8_xnumel = 11520 + 1440*s0 + 1440*s1 + 180*s0*s1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_gelu_gelu_backward_8.run(buf17, convolution_1, triton_poi_fused_gelu_gelu_backward_8_xnumel, grid=grid(triton_poi_fused_gelu_gelu_backward_8_xnumel), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del convolution_1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf18 = empty_strided_cuda((20, 6), (6, 1), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_9_r0_numel = 12*s0 + 12*s1 + ((581 + 9*s0*s1) // 6)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_9.run(buf17, buf18, s0, s1, 120, triton_red_fused_convolution_backward_9_r0_numel, grid=grid(120), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf19 = empty_strided_cuda((20, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_convolution_backward_10.run(buf18, buf19, 20, 6, grid=grid(20), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf18
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf20 = torch.ops.aten.convolution_backward.default(buf17, relu, primals_6, [20], [1, 1, 1], [0, 0, 0], [1, 1, 1], True, [0, 0, 0], 1, [True, True, False])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf17
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_6
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf21 = buf20[0]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf22 = buf20[1]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf20
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf23 = relu; del relu  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.threshold_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_threshold_backward_11_xnumel = 800 + 200*s0 + 200*s1 + 50*s0*s1
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_poi_fused_threshold_backward_11.run(buf23, buf21, triton_poi_fused_threshold_backward_11_xnumel, grid=grid(triton_poi_fused_threshold_backward_11_xnumel), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf21
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf24 = reinterpret_tensor(buf6, (10, 3), (3, 1), 0); del buf6  # reuse
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_12_r0_numel = (82 + 20*s0 + 20*s1 + 5*s0*s1) // 3
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_red_fused_convolution_backward_12.run(buf23, buf24, s0, s1, 30, triton_red_fused_convolution_backward_12_r0_numel, grid=grid(30), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf25 = empty_strided_cuda((10, ), (1, ), torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         stream0 = get_raw_stream(0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         triton_per_fused_convolution_backward_13.run(buf24, buf25, 10, 3, grid=grid(10), stream=stream0)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf24
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         # Topologically Sorted Source Nodes: [], Original ATen: [aten.convolution_backward]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf26 = torch.ops.aten.convolution_backward.default(buf23, view, primals_4, [10], [1, 1, 1], [0, 0, 0], [1, 1, 1], True, [0, 0, 0], 1, [False, True, False])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf23
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del primals_4
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del view
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         buf27 = buf26[1]
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]         del buf26
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     return (None, None, None, buf27, buf25, buf22, buf19, buf16, buf13, buf10, buf7, None, None, buf4, buf1, )
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._inductor.utils import print_performance
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_1 = 64
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_2 = 64
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     sym_size_int_8 = 46664
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_4 = rand_strided((1, 10, 5, 5, 5), (1250, 125, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_6 = rand_strided((10, 20, 5, 5, 5), (2500, 125, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_8 = rand_strided((20, 10, 5), (50, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_10 = rand_strided((10, 5, 5), (25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     primals_14 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     view = rand_strided((1, 1, 1, 64, 64), (4096, 4096, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     relu = rand_strided((1, 10, 5, 68, 68), (231200, 23120, 4624, 68, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     convolution_1 = rand_strided((1, 20, 9, 72, 72), (933120, 46656, 5184, 72, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     view_1 = rand_strided((1, 20, 46656), (933120, 46656, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     relu_1 = rand_strided((1, 10, 46660), (466600, 46660, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     convolution_3 = rand_strided((1, 5, 46664), (233320, 46664, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     squeeze_1 = rand_strided((5, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     unsqueeze_3 = rand_strided((1, 5, 1), (5, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     tangents_1 = rand_strided((1, 5, 46664), (233320, 46664, 1), device='cuda:0', dtype=torch.float32)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     fn = lambda: call([primals_1, primals_2, sym_size_int_8, primals_4, primals_6, primals_8, primals_10, primals_14, view, relu, convolution_1, view_1, relu_1, convolution_3, squeeze_1, unsqueeze_3, tangents_1])
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] if __name__ == "__main__":
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 20:42:41.252000 2742634 site-packages/torch/_inductor/graph.py:2014] [10/0_1] [__output_code] 
V0204 20:42:41.280000 2742634 site-packages/torch/_inductor/graph.py:2022] [10/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/7e/c7ebvqv2qkgzzepiv6uy4zumjmpfb66jlt6nehwe7h62l4f6rfki.py
I0204 20:42:41.767000 2742634 site-packages/torch/_inductor/graph.py:2056] [10/0_1] [__output_code] Output code written to: /tmp/torchinductor_sahanp/7e/c7ebvqv2qkgzzepiv6uy4zumjmpfb66jlt6nehwe7h62l4f6rfki.py
