
# This is a random torch model generated by the following modules: ['TransformerDecoder', 'TransformerEncoderLayer', 'SiLU', 'Fold', 'BCELoss', 'MultiheadAttention', 'Conv2d', 'Linear', 'MultiMarginLoss', 'MaxUnpool2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.silu = nn.SiLU()
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8)
        self.transformer_decoder = nn.TransformerDecoder(
            nn.TransformerDecoderLayer(d_model=64, nhead=8), num_layers=2
        )
        self.multihead_attention = nn.MultiheadAttention(embed_dim=64, num_heads=8)
        self.fold = nn.Fold(output_size=(32, 32), kernel_size=2, stride=2)
        self.fc1 = nn.Linear(32 * 32 * 16, 128)
        self.fc2 = nn.Linear(128, 10)
        self.bce_loss = nn.BCELoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Conv2d and SiLU
        x = self.silu(self.conv1(x))
        
        # MaxUnpool2d (assuming we have indices from a previous maxpool)
        _, indices = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.max_unpool2d(x, indices)
        
        # Reshape for Transformer
        b, c, h, w = x.shape
        x = x.view(b, c, h * w).permute(2, 0, 1)  # (seq_len, batch, feature)
        
        # TransformerEncoderLayer
        x = self.transformer_encoder_layer(x)
        
        # TransformerDecoder
        memory = torch.zeros_like(x)
        x = self.transformer_decoder(x, memory)
        
        # MultiheadAttention
        x, _ = self.multihead_attention(x, x, x)
        
        # Reshape back for Fold
        x = x.permute(1, 2, 0).view(b, c, h, w)
        
        # Fold
        x = self.fold(x.view(b, c * 4, h // 2 * w // 2))
        
        # Flatten for Linear layers
        x = x.view(b, -1)
        
        # Linear layers
        x = self.silu(self.fc1(x))
        x = self.fc2(x)
        
        # Apply losses (assuming we have targets for demonstration)
        targets = torch.randint(0, 10, (b,)).to(x.device)
        bce_targets = torch.rand_like(x).sigmoid()
        bce_loss = self.bce_loss(x.sigmoid(), bce_targets)
        multi_margin_loss = self.multi_margin_loss(x, targets)
        
        return x, bce_loss, multi_margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
