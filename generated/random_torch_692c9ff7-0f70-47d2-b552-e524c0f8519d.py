
# This is a random torch model generated by the following modules: ['EmbeddingBag', 'LogSigmoid', 'MaxPool1d', 'RNNCell', 'ELU', 'Sequential', 'ConvTranspose2d', 'CELU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 64, mode='mean')
        self.max_pool1d = nn.MaxPool1d(kernel_size=2, stride=2)
        self.rnn_cell = nn.RNNCell(64, 128)
        self.elu = nn.ELU()
        self.sequential = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.CELU(),
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.CELU(),
            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),
            nn.CELU()
        )
        self.log_sigmoid = nn.LogSigmoid()

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        x = x.unsqueeze(1)  # Add a dimension for MaxPool1d
        x = self.max_pool1d(x)
        x = x.squeeze(1)  # Remove the added dimension
        x = self.rnn_cell(x)
        x = self.elu(x)
        x = x.unsqueeze(-1).unsqueeze(-1)  # Reshape for ConvTranspose2d
        x = self.sequential(x)
        x = x.view(x.size(0), -1)  # Flatten for LogSigmoid
        x = self.log_sigmoid(x)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

