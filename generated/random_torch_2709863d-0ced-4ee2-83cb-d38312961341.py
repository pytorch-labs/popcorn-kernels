
# This is a random torch model generated by the following modules: ['SiLU', 'SELU', 'RNNCellBase']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.silu1 = nn.SiLU()
        self.selu1 = nn.SELU()
        self.rnn_cell1 = nn.RNNCellBase(input_size=128, hidden_size=256)
        self.silu2 = nn.SiLU()
        self.selu2 = nn.SELU()
        self.rnn_cell2 = nn.RNNCellBase(input_size=256, hidden_size=128)
        self.silu3 = nn.SiLU()
        self.selu3 = nn.SELU()

    def forward(self, x):
        # Flatten the input to a 2D tensor (batch_size, -1)
        batch_size = x.size(0)
        x = x.view(batch_size, -1)
        
        # Apply SiLU and SELU
        x = self.silu1(x)
        x = self.selu1(x)
        
        # Reshape for RNNCellBase
        x = x.view(batch_size, -1, 128)
        
        # Initialize hidden state for RNNCellBase
        hx1 = torch.zeros(batch_size, 256).to(x.device)
        hx2 = torch.zeros(batch_size, 128).to(x.device)
        
        # Apply RNNCellBase
        for i in range(x.size(1)):
            hx1 = self.rnn_cell1(x[:, i, :], hx1)
        
        # Apply SiLU and SELU
        hx1 = self.silu2(hx1)
        hx1 = self.selu2(hx1)
        
        # Apply second RNNCellBase
        for i in range(x.size(1)):
            hx2 = self.rnn_cell2(hx1, hx2)
        
        # Apply final SiLU and SELU
        hx2 = self.silu3(hx2)
        hx2 = self.selu3(hx2)
        
        # Reshape to output shape (batch_size, -1)
        output = hx2.view(batch_size, -1)
        
        return output


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
