
# This is a random torch model generated by the following modules: ['Linear', 'MultiMarginLoss', 'ReflectionPad3d', 'LazyConv3d', 'AvgPool1d', 'InstanceNorm3d', 'Tanhshrink', 'PixelShuffle', 'BCELoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.reflection_pad = nn.ReflectionPad3d(1)
        self.lazy_conv3d = nn.LazyConv3d(out_channels=16, kernel_size=3)
        self.instance_norm3d = nn.InstanceNorm3d(16)
        self.avg_pool1d = nn.AvgPool1d(kernel_size=2)
        self.linear1 = nn.Linear(16 * 8 * 8 * 8, 128)
        self.linear2 = nn.Linear(128, 64)
        self.tanhshrink = nn.Tanhshrink()
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.multi_margin_loss = nn.MultiMarginLoss()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Apply ReflectionPad3d
        x = self.reflection_pad(x)
        
        # Apply LazyConv3d
        x = self.lazy_conv3d(x)
        
        # Apply InstanceNorm3d
        x = self.instance_norm3d(x)
        
        # Reshape for AvgPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x = self.avg_pool1d(x)
        
        # Reshape for Linear layers
        x = x.view(x.size(0), -1)  # Flatten all dimensions except batch
        x = self.linear1(x)
        x = self.tanhshrink(x)
        x = self.linear2(x)
        
        # Reshape for PixelShuffle
        x = x.view(x.size(0), 16, 8, 8)  # Reshape to 4D tensor
        x = self.pixel_shuffle(x)
        
        # Apply MultiMarginLoss and BCELoss (assuming x is the output and y is the target)
        # Note: These losses are typically used during training, not in the forward pass.
        # For demonstration purposes, we'll compute the losses here.
        y_multi_margin = torch.randint(0, 10, (x.size(0),)).to(x.device)
        y_bce = torch.randint(0, 2, (x.size(0), x.size(1), x.size(2), x.size(3))).float().to(x.device)
        
        multi_margin_loss = self.multi_margin_loss(x.view(x.size(0), -1), y_multi_margin)
        bce_loss = self.bce_loss(torch.sigmoid(x), y_bce)
        
        # Return the output and the computed losses
        return x, multi_margin_loss, bce_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 16, 16, 16).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

