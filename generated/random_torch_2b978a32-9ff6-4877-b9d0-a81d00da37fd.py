
# This is a random torch model generated by the following modules: ['PoissonNLLLoss', 'LogSoftmax', 'CosineEmbeddingLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.log_softmax = nn.LogSoftmax(dim=1)
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()

    def forward(self, x):
        # Apply LogSoftmax to the input
        x = self.log_softmax(x)
        
        # Generate a target tensor for PoissonNLLLoss
        target = torch.randint(0, 10, x.shape).float()
        
        # Compute PoissonNLLLoss
        poisson_loss = self.poisson_nll_loss(x, target)
        
        # Generate a second input tensor for CosineEmbeddingLoss
        x2 = torch.randn_like(x)
        
        # Generate a target tensor for CosineEmbeddingLoss
        target_cosine = torch.ones(x.shape[0])
        
        # Compute CosineEmbeddingLoss
        cosine_loss = self.cosine_embedding_loss(x, x2, target_cosine)
        
        # Return both losses as a tuple
        return poisson_loss, cosine_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10).cuda()  # Example input shape (batch_size, num_classes)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

