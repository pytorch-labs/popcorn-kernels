
# This is a random torch model generated by the following modules: ['LogSoftmax', 'TripletMarginWithDistanceLoss', 'MSELoss', 'LogSigmoid', 'Hardtanh', 'Softplus']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.hardtanh1 = nn.Hardtanh()
        self.hardtanh2 = nn.Hardtanh()
        self.softplus1 = nn.Softplus()
        self.softplus2 = nn.Softplus()
        self.log_sigmoid = nn.LogSigmoid()
        self.log_softmax = nn.LogSoftmax(dim=1)
        self.triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: F.pairwise_distance(x, y, p=2))
        self.mse_loss = nn.MSELoss()

    def forward(self, x):
        # Apply Hardtanh twice
        x = self.hardtanh1(x)
        x = self.hardtanh2(x)
        
        # Apply Softplus twice
        x = self.softplus1(x)
        x = self.softplus2(x)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Reshape for LogSoftmax
        x = x.view(x.size(0), -1)
        x = self.log_softmax(x)
        
        # Generate anchor, positive, and negative samples for TripletMarginWithDistanceLoss
        anchor = x[:x.size(0)//2]
        positive = x[x.size(0)//2:]
        negative = torch.flip(positive, dims=[0])
        
        # Compute TripletMarginWithDistanceLoss
        triplet_loss = self.triplet_loss(anchor, positive, negative)
        
        # Compute MSELoss between anchor and positive
        mse_loss = self.mse_loss(anchor, positive)
        
        # Return the final output and the losses
        return x, triplet_loss, mse_loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(10, 3, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
