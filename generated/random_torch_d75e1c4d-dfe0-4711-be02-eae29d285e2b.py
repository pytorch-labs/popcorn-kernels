
# This is a random torch model generated by the following modules: ['BatchNorm3d', 'CrossMapLRN2d', 'MultiMarginLoss', 'AdaptiveLogSoftmaxWithLoss', 'Sequential', 'GaussianNLLLoss', 'ConstantPad3d', 'Dropout1d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.bn1 = nn.BatchNorm3d(10)
        self.lrn1 = nn.CrossMapLRN2d(size=5, alpha=1e-4, beta=0.75, k=1.0)
        self.pad1 = nn.ConstantPad3d(padding=(1, 1, 1, 1, 1, 1), value=0)
        self.dropout1 = nn.Dropout1d(p=0.5)
        self.sequential = nn.Sequential(
            nn.Conv2d(10, 20, kernel_size=3),
            nn.ReLU(),
            nn.Conv2d(20, 30, kernel_size=3),
            nn.ReLU()
        )
        self.bn2 = nn.BatchNorm3d(30)
        self.lrn2 = nn.CrossMapLRN2d(size=5, alpha=1e-4, beta=0.75, k=1.0)
        self.pad2 = nn.ConstantPad3d(padding=(1, 1, 1, 1, 1, 1), value=0)
        self.dropout2 = nn.Dropout1d(p=0.5)
        self.adaptive_log_softmax = nn.AdaptiveLogSoftmaxWithLoss(30, 10, [5, 5])
        self.gaussian_nll_loss = nn.GaussianNLLLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, depth, height, width)
        x = self.pad1(x)
        x = self.bn1(x)
        x = x.view(x.size(0), x.size(1), x.size(3), x.size(4))  # Reshape to 4D for LRN
        x = self.lrn1(x)
        x = x.view(x.size(0), x.size(1), x.size(2), x.size(3), 1)  # Reshape back to 5D
        x = self.dropout1(x)
        
        x = x.view(x.size(0), x.size(1), x.size(3), x.size(4))  # Reshape to 4D for Sequential
        x = self.sequential(x)
        x = x.view(x.size(0), x.size(1), 1, x.size(2), x.size(3))  # Reshape back to 5D
        
        x = self.pad2(x)
        x = self.bn2(x)
        x = x.view(x.size(0), x.size(1), x.size(3), x.size(4))  # Reshape to 4D for LRN
        x = self.lrn2(x)
        x = x.view(x.size(0), x.size(1), x.size(2), x.size(3), 1)  # Reshape back to 5D
        x = self.dropout2(x)
        
        # Flatten for AdaptiveLogSoftmaxWithLoss
        x = x.view(x.size(0), x.size(1), -1)
        x = x.mean(dim=2)  # Reduce to (batch_size, features)
        
        # Dummy target for loss functions
        target = torch.randint(0, 10, (x.size(0),)).to(x.device)
        output = self.adaptive_log_softmax(x, target)
        
        # Dummy inputs for GaussianNLLLoss and MultiMarginLoss
        mean = x
        var = torch.ones_like(mean)
        gaussian_loss = self.gaussian_nll_loss(mean, target.float(), var)
        margin_loss = self.multi_margin_loss(x, target)
        
        return output, gaussian_loss, margin_loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 5, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
