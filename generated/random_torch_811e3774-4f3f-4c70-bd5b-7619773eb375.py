
# This is a random torch model generated by the following modules: ['KLDivLoss', 'Softmax', 'Hardtanh']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.softmax = nn.Softmax(dim=1)
        self.hardtanh1 = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.hardtanh2 = nn.Hardtanh(min_val=-0.5, max_val=0.5)
        self.hardtanh3 = nn.Hardtanh(min_val=-0.2, max_val=0.2)
        self.kldivloss = nn.KLDivLoss(reduction='batchmean')

    def forward(self, x):
        # Apply Hardtanh layers
        x = self.hardtanh1(x)
        x = self.hardtanh2(x)
        x = self.hardtanh3(x)
        
        # Reshape the input to match the expected shape for Softmax
        x = x.view(x.size(0), -1)  # Flatten the input
        
        # Apply Softmax
        x = self.softmax(x)
        
        # Generate a target distribution for KLDivLoss
        target = torch.ones_like(x) / x.size(1)  # Uniform distribution
        
        # Compute KLDivLoss
        loss = self.kldivloss(x.log(), target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
