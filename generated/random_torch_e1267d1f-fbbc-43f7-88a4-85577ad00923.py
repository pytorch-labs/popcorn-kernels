
# This is a random torch model generated by the following modules: ['LazyConv1d', 'TransformerDecoder', 'PairwiseDistance', 'Hardswish', 'MaxPool1d', 'AdaptiveAvgPool3d', 'KLDivLoss', 'AdaptiveLogSoftmaxWithLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.LazyConv1d(out_channels=32, kernel_size=3)
        self.maxpool1 = nn.MaxPool1d(kernel_size=2)
        self.transformer_decoder = nn.TransformerDecoder(
            nn.TransformerDecoderLayer(d_model=32, nhead=4), num_layers=2
        )
        self.hardswish = nn.Hardswish()
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.pairwise_distance = nn.PairwiseDistance(p=2)
        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')
        self.adaptive_log_softmax = nn.AdaptiveLogSoftmaxWithLoss(in_features=32, n_classes=10, cutoffs=[2, 4])

    def forward(self, x):
        # Reshape input to 1D if necessary
        if x.dim() > 3:
            x = x.view(x.size(0), -1, x.size(-1))  # Flatten to (batch, channels, length)
        
        # Apply LazyConv1d
        x = self.conv1(x)
        
        # Apply MaxPool1d
        x = self.maxpool1(x)
        
        # Reshape for TransformerDecoder
        x = x.permute(2, 0, 1)  # (seq_len, batch, features)
        memory = torch.zeros_like(x)  # Dummy memory for TransformerDecoder
        x = self.transformer_decoder(x, memory)
        x = x.permute(1, 2, 0)  # (batch, features, seq_len)
        
        # Apply Hardswish
        x = self.hardswish(x)
        
        # Reshape for AdaptiveAvgPool3d
        x = x.unsqueeze(1).unsqueeze(1)  # Add dummy dimensions for 3D pooling
        x = self.adaptive_avg_pool3d(x)
        x = x.squeeze()  # Remove dummy dimensions
        
        # Compute PairwiseDistance
        x1 = x[:, :16]  # Split into two halves
        x2 = x[:, 16:]
        x = self.pairwise_distance(x1, x2)
        
        # Reshape for KLDivLoss
        x = x.unsqueeze(1)  # Add batch dimension
        target = torch.zeros_like(x)  # Dummy target for KLDivLoss
        x = self.kl_div_loss(F.log_softmax(x, dim=1), F.softmax(target, dim=1))
        
        # Reshape for AdaptiveLogSoftmaxWithLoss
        x = x.unsqueeze(0)  # Add batch dimension
        target = torch.zeros(1, dtype=torch.long)  # Dummy target for AdaptiveLogSoftmaxWithLoss
        x = self.adaptive_log_softmax(x, target)
        
        return x.output

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
