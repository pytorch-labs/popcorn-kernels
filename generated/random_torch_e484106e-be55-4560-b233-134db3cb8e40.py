
# This is a random torch model generated by the following modules: ['Softshrink', 'SyncBatchNorm', 'Tanh', 'CTCLoss', 'AdaptiveMaxPool2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.softshrink = nn.Softshrink(lambd=0.5)
        self.sync_batchnorm = nn.SyncBatchNorm(10)
        self.tanh = nn.Tanh()
        self.ctc_loss = nn.CTCLoss()
        self.adaptive_max_pool = nn.AdaptiveMaxPool2d((5, 5))
        
        # Additional layers to make the model functional
        self.conv1 = nn.Conv2d(3, 10, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(20 * 5 * 5, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        # Apply convolutional layers
        x = self.conv1(x)
        x = self.sync_batchnorm(x)
        x = self.softshrink(x)
        x = self.adaptive_max_pool(x)
        
        x = self.conv2(x)
        x = self.sync_batchnorm(x)
        x = self.softshrink(x)
        x = self.adaptive_max_pool(x)
        
        # Flatten the tensor
        x = x.view(-1, 20 * 5 * 5)
        
        # Apply fully connected layers
        x = self.fc1(x)
        x = self.tanh(x)
        x = self.fc2(x)
        
        # Apply CTC Loss (assuming input is log probabilities and targets are provided)
        # Note: CTC Loss requires specific input shapes and targets, so this is just a placeholder
        # For actual usage, you would need to provide the correct input and target tensors
        log_probs = F.log_softmax(x, dim=2)
        input_lengths = torch.full((x.size(0),), x.size(1), dtype=torch.long)
        target_lengths = torch.randint(1, x.size(1), (x.size(0),), dtype=torch.long)
        targets = torch.randint(0, 10, (x.size(0), x.size(1)), dtype=torch.long)
        loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

