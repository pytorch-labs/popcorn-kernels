
# This is a random torch model generated by the following modules: ['Conv3d', 'ChannelShuffle', 'PReLU', 'BCELoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv3d_1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)
        self.channel_shuffle_1 = nn.ChannelShuffle(groups=4)
        self.prelu_1 = nn.PReLU()
        self.conv3d_2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)
        self.channel_shuffle_2 = nn.ChannelShuffle(groups=8)
        self.prelu_2 = nn.PReLU()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Apply Conv3d, ChannelShuffle, and PReLU in sequence
        x = self.conv3d_1(x)
        x = self.channel_shuffle_1(x)
        x = self.prelu_1(x)
        
        # Apply Conv3d, ChannelShuffle, and PReLU again
        x = self.conv3d_2(x)
        x = self.channel_shuffle_2(x)
        x = self.prelu_2(x)
        
        # Flatten the output for BCELoss
        x = x.view(x.size(0), -1)  # Flatten all dimensions except batch
        
        # Apply BCELoss (assuming the target is a binary tensor of the same shape)
        # Note: BCELoss is typically used during training, not in the forward pass of a model.
        # Here, we assume a dummy target for demonstration purposes.
        target = torch.zeros_like(x)
        loss = self.bce_loss(torch.sigmoid(x), target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 32, 32, 32).cuda()  # Example input shape for Conv3d
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

