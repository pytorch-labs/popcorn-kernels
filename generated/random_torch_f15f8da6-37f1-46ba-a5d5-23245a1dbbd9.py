
# This is a random torch model generated by the following modules: ['RNN', 'LogSigmoid', 'GaussianNLLLoss', 'Bilinear', 'RNNCellBase', 'ModuleList', 'Unfold']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rnn1 = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)
        self.rnn_cell = nn.RNNCellBase(input_size=20, hidden_size=30)
        self.bilinear = nn.Bilinear(30, 30, 40)
        self.unfold = nn.Unfold(kernel_size=(2, 2), stride=(1, 1))
        self.module_list = nn.ModuleList([nn.Linear(40, 10), nn.Linear(10, 5)])
        self.log_sigmoid = nn.LogSigmoid()
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, input_size)
        batch_size, seq_len, input_size = x.shape
        
        # Pass through RNN
        x, _ = self.rnn1(x)  # Output shape: (batch_size, seq_len, hidden_size=20)
        
        # Pass through RNNCellBase
        hx = torch.zeros(batch_size, 30).to(x.device)  # Initialize hidden state
        for t in range(seq_len):
            hx = self.rnn_cell(x[:, t, :], hx)  # Output shape: (batch_size, hidden_size=30)
        
        # Pass through Bilinear
        x = self.bilinear(hx, hx)  # Output shape: (batch_size, 40)
        
        # Pass through Unfold (reshape to 4D tensor first)
        x = x.view(batch_size, 1, 8, 5)  # Reshape to (batch_size, 1, 8, 5)
        x = self.unfold(x)  # Output shape: (batch_size, 4, 16)
        x = x.view(batch_size, -1)  # Flatten to (batch_size, 64)
        
        # Pass through ModuleList
        for layer in self.module_list:
            x = layer(x)  # Output shape: (batch_size, 5)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)  # Output shape: (batch_size, 5)
        
        # GaussianNLLLoss requires target and variance, so we return x for now
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 10).cuda()  # (batch_size=1, sequence_length=10, input_size=10)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

