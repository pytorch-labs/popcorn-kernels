
# This is a random torch model generated by the following modules: ['Conv3d', 'CELU', 'Identity', 'LazyLinear', 'HingeEmbeddingLoss', 'SmoothL1Loss', 'RNNCellBase', 'GRU', 'Linear']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv3d = nn.Conv3d(1, 10, kernel_size=3)
        self.celu = nn.CELU()
        self.identity = nn.Identity()
        self.lazy_linear = nn.LazyLinear(128)
        self.rnn_cell = nn.RNNCellBase(128, 64)
        self.gru = nn.GRU(64, 32, num_layers=2)
        self.linear = nn.Linear(32, 10)
        self.hinge_embedding_loss = nn.HingeEmbeddingLoss()
        self.smooth_l1_loss = nn.SmoothL1Loss()

    def forward(self, x):
        # Apply Conv3d
        x = self.conv3d(x)
        
        # Apply CELU activation
        x = self.celu(x)
        
        # Apply Identity (no change)
        x = self.identity(x)
        
        # Reshape for LazyLinear
        x = x.view(x.size(0), -1)
        
        # Apply LazyLinear
        x = self.lazy_linear(x)
        
        # Apply RNNCellBase
        hx = torch.zeros(x.size(0), 64).to(x.device)
        x = self.rnn_cell(x, hx)
        
        # Reshape for GRU
        x = x.unsqueeze(0)
        
        # Apply GRU
        _, x = self.gru(x)
        x = x[-1]  # Take the last layer's hidden state
        
        # Apply Linear
        x = self.linear(x)
        
        # Compute losses (dummy targets for demonstration)
        target = torch.randint(0, 10, (x.size(0),)).to(x.device)
        hinge_loss = self.hinge_embedding_loss(x, target.float())
        smooth_l1_loss = self.smooth_l1_loss(x, target.float())
        
        # Return the output and losses
        return x, hinge_loss, smooth_l1_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 16, 16, 16).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

