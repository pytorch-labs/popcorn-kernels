
# This is a random torch model generated by the following modules: ['ReplicationPad1d', 'Tanhshrink', 'EmbeddingBag', 'RMSNorm', 'ZeroPad1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(num_embeddings=1000, embedding_dim=64, mode='mean')
        self.replication_pad1d = nn.ReplicationPad1d(padding=2)
        self.zero_pad1d = nn.ZeroPad1d(padding=2)
        self.rms_norm = RMSNorm(dim=64)
        self.tanhshrink = nn.Tanhshrink()

    def forward(self, x):
        # Assuming input x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Reshape to add a dummy dimension for 1D padding
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, embedding_dim)
        
        # Apply padding layers
        x = self.replication_pad1d(x)
        x = self.zero_pad1d(x)
        
        # Remove the dummy dimension
        x = x.squeeze(1)  # Shape: (batch_size, embedding_dim + padding_total)
        
        # Apply RMSNorm
        x = self.rms_norm(x)
        
        # Apply Tanhshrink
        x = self.tanhshrink(x)
        
        return x


class RMSNorm(nn.Module):
    def __init__(self, dim, eps=1e-8):
        super().__init__()
        self.scale = dim ** -0.5
        self.eps = eps
        self.g = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale
        return x / norm.clamp(min=self.eps) * self.g


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

