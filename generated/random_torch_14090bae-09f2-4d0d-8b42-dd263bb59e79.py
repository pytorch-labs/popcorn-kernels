
# This is a random torch model generated by the following modules: ['PairwiseDistance', 'Sequential', 'Linear', 'RMSNorm', 'BCELoss', 'BatchNorm3d', 'Module', 'LayerNorm', 'CELU', 'Hardsigmoid']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.sequential = nn.Sequential(
            nn.Linear(128, 64),
            nn.CELU(),
            nn.Linear(64, 32),
            nn.Hardsigmoid()
        )
        self.batch_norm3d = nn.BatchNorm3d(16)
        self.layer_norm = nn.LayerNorm(32)
        self.rms_norm = RMSNorm(32)
        self.linear = nn.Linear(32, 1)
        self.pairwise_distance = nn.PairwiseDistance()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.batch_norm3d(x)
        x = x.view(x.size(0), -1)  # Flatten the input for Linear layers
        x = self.sequential(x)
        x = self.layer_norm(x)
        x = self.rms_norm(x)
        x = self.linear(x)
        x = torch.sigmoid(x)  # To ensure the output is between 0 and 1 for BCELoss
        
        # Create a dummy target for PairwiseDistance and BCELoss
        dummy_target = torch.ones_like(x)
        pairwise_loss = self.pairwise_distance(x, dummy_target)
        bce_loss = self.bce_loss(x, dummy_target)
        
        return x, pairwise_loss, bce_loss

class RMSNorm(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.scale = dim ** 0.5
        self.gamma = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        return F.normalize(x, dim=-1) * self.scale * self.gamma

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 16, 8, 8, 8).cuda()  # Example input for BatchNorm3d
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
