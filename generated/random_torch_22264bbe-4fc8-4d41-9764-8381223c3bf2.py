
# This is a random torch model generated by the following modules: ['ReplicationPad2d', 'RNNCell', 'FractionalMaxPool3d', 'Softshrink', 'Softmax', 'ModuleList', 'ZeroPad1d', 'Fold']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.replication_pad = nn.ReplicationPad2d(2)
        self.rnn_cell = nn.RNNCell(input_size=64, hidden_size=128)
        self.fractional_max_pool = nn.FractionalMaxPool3d(kernel_size=2, output_size=(16, 16, 16))
        self.softshrink = nn.Softshrink(lambd=0.5)
        self.softmax = nn.Softmax(dim=1)
        self.module_list = nn.ModuleList([nn.ZeroPad1d(2) for _ in range(3)])
        self.fold = nn.Fold(output_size=(32, 32), kernel_size=(4, 4))

    def forward(self, x):
        # Apply ReplicationPad2d
        x = self.replication_pad(x)
        
        # Reshape for RNNCell
        batch_size, channels, height, width = x.shape
        x = x.view(batch_size, -1)  # Flatten spatial dimensions
        x = self.rnn_cell(x)
        
        # Reshape for FractionalMaxPool3d
        x = x.view(batch_size, 1, 128, 16, 16)  # Add dummy dimensions for 3D pooling
        x = self.fractional_max_pool(x)
        
        # Apply Softshrink
        x = self.softshrink(x)
        
        # Reshape for ModuleList (ZeroPad1d)
        x = x.view(batch_size, -1)  # Flatten again
        for pad in self.module_list:
            x = pad(x)
        
        # Reshape for Fold
        x = x.view(batch_size, 1, 32, 32)  # Reshape to match Fold input
        x = self.fold(x)
        
        # Apply Softmax
        x = self.softmax(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

