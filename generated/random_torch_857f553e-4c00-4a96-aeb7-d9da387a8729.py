
# This is a random torch model generated by the following modules: ['AdaptiveMaxPool2d', 'CosineEmbeddingLoss', 'MaxPool1d', 'AvgPool2d', 'TransformerDecoder', 'Upsample', 'MultiLabelMarginLoss', 'LazyConvTranspose2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.adaptive_max_pool = nn.AdaptiveMaxPool2d((16, 16))
        self.max_pool1d = nn.MaxPool1d(kernel_size=2)
        self.avg_pool2d = nn.AvgPool2d(kernel_size=2)
        self.transformer_decoder = nn.TransformerDecoder(
            nn.TransformerDecoderLayer(d_model=64, nhead=8), num_layers=3
        )
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.lazy_conv_transpose2d = nn.LazyConvTranspose2d(out_channels=32, kernel_size=3, stride=2)
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()
        self.multi_label_margin_loss = nn.MultiLabelMarginLoss()

    def forward(self, x):
        # Apply AdaptiveMaxPool2d
        x = self.adaptive_max_pool(x)
        
        # Reshape for MaxPool1d
        x = x.view(x.size(0), -1, x.size(3))  # Reshape to (batch_size, channels * height, width)
        x = self.max_pool1d(x)
        
        # Reshape back to 4D for AvgPool2d
        x = x.view(x.size(0), -1, 16, 16)  # Reshape to (batch_size, channels, height, width)
        x = self.avg_pool2d(x)
        
        # Reshape for TransformerDecoder
        x = x.view(x.size(0), -1, 64)  # Reshape to (batch_size, sequence_length, d_model)
        x = x.permute(1, 0, 2)  # Transformer expects (sequence_length, batch_size, d_model)
        x = self.transformer_decoder(x, x)
        x = x.permute(1, 0, 2)  # Reshape back to (batch_size, sequence_length, d_model)
        
        # Reshape for Upsample
        x = x.view(x.size(0), -1, 8, 8)  # Reshape to (batch_size, channels, height, width)
        x = self.upsample(x)
        
        # Apply LazyConvTranspose2d
        x = self.lazy_conv_transpose2d(x)
        
        # Dummy labels for loss functions (not used in forward pass)
        target = torch.randint(0, 2, (x.size(0), x.size(1))).float()
        target2 = torch.randint(0, 2, (x.size(0), x.size(1))).long()
        
        # Apply CosineEmbeddingLoss (dummy)
        loss1 = self.cosine_embedding_loss(x.view(x.size(0), -1), target.view(target.size(0), -1), torch.ones(x.size(0)))
        
        # Apply MultiLabelMarginLoss (dummy)
        loss2 = self.multi_label_margin_loss(x.view(x.size(0), -1), target2)
        
        # Return the final output and losses (for demonstration purposes)
        return x, loss1, loss2


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
