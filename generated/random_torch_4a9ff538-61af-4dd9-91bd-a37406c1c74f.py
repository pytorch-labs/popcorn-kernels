
# This is a random torch model generated by the following modules: ['AvgPool1d', 'Dropout2d', 'MSELoss', 'Tanh', 'Module', 'MaxPool3d', 'SoftMarginLoss', 'BCELoss', 'Hardswish', 'ParameterDict']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.avg_pool1d = nn.AvgPool1d(kernel_size=2)
        self.dropout2d = nn.Dropout2d(p=0.5)
        self.tanh = nn.Tanh()
        self.max_pool3d = nn.MaxPool3d(kernel_size=2)
        self.hardswish = nn.Hardswish()
        self.parameter_dict = nn.ParameterDict({
            'param1': nn.Parameter(torch.randn(10)),
            'param2': nn.Parameter(torch.randn(10))
        })
        self.mse_loss = nn.MSELoss()
        self.soft_margin_loss = nn.SoftMarginLoss()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width, depth)
        # Reshape to fit AvgPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten height, width, depth
        x = self.avg_pool1d(x)
        
        # Reshape back to fit Dropout2d
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))
        x = self.dropout2d(x)
        
        # Apply Tanh activation
        x = self.tanh(x)
        
        # Reshape to fit MaxPool3d
        x = x.unsqueeze(2)  # Add depth dimension
        x = self.max_pool3d(x)
        
        # Apply Hardswish activation
        x = self.hardswish(x)
        
        # Use ParameterDict
        param1 = self.parameter_dict['param1']
        param2 = self.parameter_dict['param2']
        x = x * param1.view(1, -1, 1, 1, 1) + param2.view(1, -1, 1, 1, 1)
        
        # Compute losses (just for demonstration, not typical in forward pass)
        target = torch.randn_like(x)
        mse_loss = self.mse_loss(x, target)
        soft_margin_loss = self.soft_margin_loss(x.view(-1), target.view(-1))
        bce_loss = self.bce_loss(torch.sigmoid(x), torch.sigmoid(target))
        
        # Return the output and losses
        return x, mse_loss, soft_margin_loss, bce_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32, 32).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

