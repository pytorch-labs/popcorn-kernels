
# This is a random torch model generated by the following modules: ['Container', 'Flatten', 'GRU', 'AvgPool1d', 'Softmax2d', 'GaussianNLLLoss', 'RMSNorm', 'ConvTranspose3d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.container = nn.Sequential(
            nn.ConvTranspose3d(1, 10, kernel_size=3, stride=2, padding=1),
            nn.AvgPool1d(kernel_size=2),
            nn.Flatten(),
            nn.RMSNorm(1280),
            nn.GRU(1280, 256, batch_first=True),
            nn.Softmax2d(),
            nn.GaussianNLLLoss()
        )
        self.gru = nn.GRU(256, 128, batch_first=True)
        self.rms_norm = nn.RMSNorm(128)
        self.conv_transpose = nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1)
        self.softmax = nn.Softmax2d()
        self.flatten = nn.Flatten()
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.container(x)
        x = x.view(x.size(0), -1, 256)  # Reshape for GRU
        x, _ = self.gru(x)
        x = self.rms_norm(x)
        x = x.unsqueeze(1).unsqueeze(1)  # Reshape for ConvTranspose3d
        x = self.conv_transpose(x)
        x = self.softmax(x)
        x = self.flatten(x)
        x = self.gaussian_nll_loss(x, torch.randn_like(x), torch.ones_like(x))  # Dummy target and variance
        return x

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 32, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
