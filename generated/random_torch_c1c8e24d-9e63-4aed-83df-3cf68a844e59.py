
# This is a random torch model generated by the following modules: ['Sequential', 'SyncBatchNorm', 'CTCLoss', 'Dropout', 'CircularPad1d', 'BatchNorm3d', 'LazyConv2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.sequential = nn.Sequential(
            nn.LazyConv2d(out_channels=16, kernel_size=3),
            nn.SyncBatchNorm(16),
            nn.Dropout(0.5),
            nn.CircularPad1d(1),
            nn.LazyConv2d(out_channels=32, kernel_size=3),
            nn.BatchNorm3d(32),
            nn.Dropout(0.5),
        )
        self.fc = nn.Linear(32 * 28 * 28, 10)  # Assuming input shape is (batch_size, channels, height, width)
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Assuming input is 4D (batch_size, channels, height, width)
        x = self.sequential(x)
        x = x.view(x.size(0), -1)  # Flatten the tensor
        x = self.fc(x)
        return x

    def compute_loss(self, log_probs, targets, input_lengths, target_lengths):
        return self.ctc_loss(log_probs, targets, input_lengths, target_lengths)


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input shape (batch_size, channels, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
