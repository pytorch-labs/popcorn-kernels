
# This is a random torch model generated by the following modules: ['MaxPool2d', 'MaxUnpool3d', 'AdaptiveAvgPool2d', 'RMSNorm', 'CTCLoss', 'Hardshrink', 'Dropout2d', 'PoissonNLLLoss', 'AdaptiveAvgPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)
        self.maxunpool3d = nn.MaxUnpool3d(kernel_size=2, stride=2)
        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d((5, 5))
        self.rmsnorm = RMSNorm(25)  # Assuming RMSNorm is a custom layer
        self.hardshrink = nn.Hardshrink()
        self.dropout2d = nn.Dropout2d(p=0.5)
        self.adaptiveavgpool1d = nn.AdaptiveAvgPool1d(10)
        self.ctcloss = nn.CTCLoss()
        self.poissonnllloss = nn.PoissonNLLLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        x = self.maxpool2d(x)
        x = x.unsqueeze(1)  # Add a dimension to make it 5D for MaxUnpool3d
        x, indices = F.max_pool3d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.maxunpool3d(x, indices)
        x = x.squeeze(1)  # Remove the added dimension
        x = self.adaptiveavgpool2d(x)
        x = x.view(x.size(0), -1)  # Flatten for RMSNorm
        x = self.rmsnorm(x)
        x = x.view(x.size(0), 5, 5)  # Reshape back to 2D
        x = self.hardshrink(x)
        x = self.dropout2d(x)
        x = x.view(x.size(0), -1)  # Flatten for AdaptiveAvgPool1d
        x = x.unsqueeze(1)  # Add a dimension for AdaptiveAvgPool1d
        x = self.adaptiveavgpool1d(x)
        x = x.squeeze(1)  # Remove the added dimension
        # Assuming we have some target for CTCLoss and PoissonNLLLoss
        target = torch.randint(0, 10, (x.size(0), 10), dtype=torch.long)
        input_lengths = torch.full((x.size(0),), 10, dtype=torch.long)
        target_lengths = torch.randint(1, 10, (x.size(0),), dtype=torch.long)
        ctc_loss = self.ctcloss(x, target, input_lengths, target_lengths)
        poisson_loss = self.poissonnllloss(x, target.float())
        return ctc_loss + poisson_loss

# Assuming RMSNorm is a custom layer
class RMSNorm(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.scale = dim ** 0.5
        self.gamma = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        return F.normalize(x, dim=-1) * self.scale * self.gamma

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
