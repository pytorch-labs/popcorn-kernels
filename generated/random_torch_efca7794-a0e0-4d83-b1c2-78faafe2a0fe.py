
# This is a random torch model generated by the following modules: ['GroupNorm', 'ZeroPad1d', 'MultiMarginLoss', 'LazyLinear', 'EmbeddingBag', 'CELU', 'SyncBatchNorm', 'MaxPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.group_norm = nn.GroupNorm(2, 4)  # GroupNorm with 2 groups and 4 channels
        self.zero_pad1d = nn.ZeroPad1d(2)  # ZeroPad1d with padding of 2
        self.lazy_linear1 = nn.LazyLinear(128)  # LazyLinear with output size 128
        self.lazy_linear2 = nn.LazyLinear(64)  # LazyLinear with output size 64
        self.embedding_bag = nn.EmbeddingBag(100, 32, mode='mean')  # EmbeddingBag with 100 embeddings, 32 dimensions
        self.celu = nn.CELU()  # CELU activation
        self.sync_batch_norm = nn.SyncBatchNorm(32)  # SyncBatchNorm with 32 features
        self.max_pool1d = nn.MaxPool1d(kernel_size=2)  # MaxPool1d with kernel size 2
        self.multi_margin_loss = nn.MultiMarginLoss()  # MultiMarginLoss for loss calculation

    def forward(self, x):
        # Assuming x is of shape (batch_size, channels, sequence_length)
        x = self.group_norm(x)
        x = self.zero_pad1d(x)
        x = self.max_pool1d(x)
        
        # Reshape for LazyLinear
        x = x.view(x.size(0), -1)  # Flatten the tensor
        x = self.lazy_linear1(x)
        x = self.celu(x)
        x = self.lazy_linear2(x)
        
        # Reshape for EmbeddingBag (assuming x is now of shape (batch_size, 64))
        x = x.view(x.size(0), -1, 32)  # Reshape to (batch_size, 2, 32) for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Apply SyncBatchNorm
        x = self.sync_batch_norm(x)
        
        # Return the output (assuming no loss calculation in forward)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 4, 64).cuda()  # Example input shape (batch_size=1, channels=4, sequence_length=64)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

