
# This is a random torch model generated by the following modules: ['PoissonNLLLoss', 'TransformerDecoderLayer', 'TransformerEncoder', 'Module', 'Fold', 'MultiMarginLoss', 'CosineEmbeddingLoss', 'Softsign']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=64, nhead=8), num_layers=3)
        self.transformer_decoder_layer = nn.TransformerDecoderLayer(d_model=64, nhead=8)
        self.transformer_decoder = nn.TransformerDecoder(self.transformer_decoder_layer, num_layers=2)
        self.fold = nn.Fold(output_size=(8, 8), kernel_size=(2, 2))
        self.softsign = nn.Softsign()
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, feature_dim)
        batch_size, seq_len, feature_dim = x.shape
        
        # Reshape for TransformerEncoder
        x = x.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, feature_dim)
        x = self.transformer_encoder(x)
        
        # Reshape for TransformerDecoder
        memory = x  # Use encoder output as memory for decoder
        tgt = torch.zeros_like(x)  # Create a dummy target sequence
        x = self.transformer_decoder(tgt, memory)
        
        # Reshape for Fold
        x = x.permute(1, 2, 0)  # Reshape to (batch_size, feature_dim, seq_len)
        x = x.view(batch_size, -1, 8, 8)  # Reshape to (batch_size, channels, height, width)
        x = self.fold(x)
        
        # Apply Softsign
        x = self.softsign(x)
        
        # Compute losses (dummy targets for demonstration)
        target_poisson = torch.randint(0, 10, (batch_size,)).float()
        loss_poisson = self.poisson_nll_loss(x.mean(dim=(1, 2, 3)), target_poisson)
        
        target_multi_margin = torch.randint(0, 10, (batch_size,))
        loss_multi_margin = self.multi_margin_loss(x.view(batch_size, -1), target_multi_margin)
        
        target_cosine = torch.ones(batch_size)
        loss_cosine = self.cosine_embedding_loss(x.view(batch_size, -1), x.view(batch_size, -1), target_cosine)
        
        # Return the final output and the computed losses
        return x, loss_poisson, loss_multi_margin, loss_cosine

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(2, 16, 64).cuda()  # (batch_size, sequence_length, feature_dim)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
