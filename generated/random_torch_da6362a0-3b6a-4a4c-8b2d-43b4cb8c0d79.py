
# This is a random torch model generated by the following modules: ['UpsamplingBilinear2d', 'Identity', 'PReLU', 'LazyConvTranspose1d', 'GLU', 'RNNBase', 'RNN']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)
        self.identity = nn.Identity()
        self.prelu = nn.PReLU()
        self.conv_transpose1d = nn.LazyConvTranspose1d(out_channels=64, kernel_size=3, stride=2)
        self.glu = nn.GLU(dim=1)
        self.rnn_base = nn.RNNBase(input_size=64, hidden_size=128, num_layers=2, nonlinearity='tanh')
        self.rnn = nn.RNN(input_size=64, hidden_size=128, num_layers=2, nonlinearity='tanh')

    def forward(self, x):
        # Assuming input is 4D (batch, channels, height, width)
        x = self.upsample(x)  # Upsample the input
        x = self.identity(x)  # Pass through identity layer
        x = self.prelu(x)  # Apply PReLU activation
        
        # Reshape for 1D convolution
        x = x.view(x.size(0), x.size(1), -1)  # Flatten height and width dimensions
        x = self.conv_transpose1d(x)  # Apply 1D transposed convolution
        
        # Apply GLU
        x = self.glu(x)
        
        # Reshape for RNN
        x = x.permute(2, 0, 1)  # RNN expects (seq_len, batch, input_size)
        x, _ = self.rnn_base(x)  # Pass through RNNBase
        x, _ = self.rnn(x)  # Pass through RNN
        
        # Reshape back to original dimensions (batch, channels, height, width)
        x = x.permute(1, 2, 0)  # Swap dimensions back
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape to 4D
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input: batch of 1, 3 channels, 32x32 image
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

