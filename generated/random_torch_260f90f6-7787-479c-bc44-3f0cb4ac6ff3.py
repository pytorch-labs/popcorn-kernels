
# This is a random torch model generated by the following modules: ['LazyBatchNorm2d', 'ConstantPad2d', 'Module', 'Hardtanh', 'Flatten', 'GaussianNLLLoss', 'Softshrink', 'LazyConvTranspose2d', 'Conv3d', 'ParameterDict']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pad = nn.ConstantPad2d(2, 3.5)
        self.bn1 = nn.LazyBatchNorm2d()
        self.conv_transpose = nn.LazyConvTranspose2d(out_channels=32, kernel_size=3)
        self.conv3d = nn.Conv3d(1, 10, kernel_size=3)
        self.hardtanh = nn.Hardtanh(min_val=-2, max_val=2)
        self.softshrink = nn.Softshrink(lambd=0.5)
        self.flatten = nn.Flatten()
        self.param_dict = nn.ParameterDict({
            'param1': nn.Parameter(torch.randn(10)),
            'param2': nn.Parameter(torch.randn(10))
        })
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        x = self.pad(x)
        x = self.bn1(x)
        x = self.conv_transpose(x)
        x = x.unsqueeze(1)  # Add a channel dimension for Conv3d
        x = self.conv3d(x)
        x = x.squeeze(2)  # Remove the extra dimension after Conv3d
        x = self.hardtanh(x)
        x = self.softshrink(x)
        x = self.flatten(x)
        # Use the parameters from ParameterDict
        param1 = self.param_dict['param1']
        param2 = self.param_dict['param2']
        x = x * param1 + param2  # Example usage of parameters
        # GaussianNLLLoss requires a target, so it's not used in the forward pass
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
