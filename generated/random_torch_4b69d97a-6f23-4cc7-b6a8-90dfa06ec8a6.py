
# This is a random torch model generated by the following modules: ['AdaptiveAvgPool1d', 'RNNBase', 'NLLLoss', 'AdaptiveMaxPool2d', 'RNN', 'CELU', 'AdaptiveMaxPool3d', 'ConstantPad3d', 'RNNCell']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.adaptive_avg_pool1d = nn.AdaptiveAvgPool1d(output_size=10)
        self.rnn_base = nn.RNNBase(input_size=10, hidden_size=20, num_layers=2)
        self.adaptive_max_pool2d = nn.AdaptiveMaxPool2d(output_size=(5, 5))
        self.rnn = nn.RNN(input_size=20, hidden_size=30, num_layers=2)
        self.celu = nn.CELU()
        self.adaptive_max_pool3d = nn.AdaptiveMaxPool3d(output_size=(3, 3, 3))
        self.constant_pad3d = nn.ConstantPad3d(padding=1, value=0)
        self.rnn_cell = nn.RNNCell(input_size=30, hidden_size=40)
        self.nll_loss = nn.NLLLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, length)
        x = self.adaptive_avg_pool1d(x)  # Output shape: (batch_size, channels, 10)
        x = x.permute(2, 0, 1)  # Shape: (10, batch_size, channels)
        x, _ = self.rnn_base(x)  # Output shape: (10, batch_size, 20)
        x = x.permute(1, 2, 0)  # Shape: (batch_size, 20, 10)
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 20, 10)
        x = self.adaptive_max_pool2d(x)  # Output shape: (batch_size, 1, 5, 5)
        x = x.squeeze(1)  # Shape: (batch_size, 5, 5)
        x = x.permute(2, 0, 1)  # Shape: (5, batch_size, 5)
        x, _ = self.rnn(x)  # Output shape: (5, batch_size, 30)
        x = self.celu(x)  # Output shape: (5, batch_size, 30)
        x = x.permute(1, 2, 0)  # Shape: (batch_size, 30, 5)
        x = x.unsqueeze(1).unsqueeze(1)  # Shape: (batch_size, 1, 1, 30, 5)
        x = self.adaptive_max_pool3d(x)  # Output shape: (batch_size, 1, 1, 3, 3)
        x = self.constant_pad3d(x)  # Output shape: (batch_size, 1, 1, 5, 5)
        x = x.squeeze(1).squeeze(1)  # Shape: (batch_size, 5, 5)
        x = x.permute(2, 0, 1)  # Shape: (5, batch_size, 5)
        x = self.rnn_cell(x[0])  # Output shape: (batch_size, 40)
        x = F.log_softmax(x, dim=1)  # Output shape: (batch_size, 40)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 100).cuda()  # Example input shape: (batch_size=1, channels=3, length=100)
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
