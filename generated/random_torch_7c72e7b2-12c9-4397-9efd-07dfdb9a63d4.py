
# This is a random torch model generated by the following modules: ['Softmax', 'InstanceNorm1d', 'EmbeddingBag', 'L1Loss', 'LocalResponseNorm', 'CosineEmbeddingLoss', 'Linear']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 64, mode='mean')
        self.linear1 = nn.Linear(64, 128)
        self.linear2 = nn.Linear(128, 64)
        self.linear3 = nn.Linear(64, 32)
        self.instance_norm = nn.InstanceNorm1d(32)
        self.local_response_norm = nn.LocalResponseNorm(2)
        self.softmax = nn.Softmax(dim=1)
        self.l1_loss = nn.L1Loss()
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Pass through linear layers
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = self.linear3(x)
        
        # Reshape for InstanceNorm1d
        x = x.unsqueeze(0)  # Add batch dimension
        x = self.instance_norm(x)
        x = x.squeeze(0)  # Remove batch dimension
        
        # Apply LocalResponseNorm
        x = self.local_response_norm(x)
        
        # Apply Softmax
        x = self.softmax(x)
        
        # Compute L1Loss with a dummy target
        dummy_target = torch.zeros_like(x)
        l1_loss = self.l1_loss(x, dummy_target)
        
        # Compute CosineEmbeddingLoss with dummy inputs
        dummy_input1 = torch.randn_like(x)
        dummy_input2 = torch.randn_like(x)
        cosine_loss = self.cosine_embedding_loss(dummy_input1, dummy_input2, torch.tensor(1.0))
        
        # Return the final output and the losses
        return x, l1_loss, cosine_loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

