
# This is a random torch model generated by the following modules: ['EmbeddingBag', 'ReLU6', 'MSELoss', 'ZeroPad1d', 'MultiMarginLoss', 'MaxUnpool1d', 'UpsamplingBilinear2d', 'LSTMCell', 'ReplicationPad3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 64, mode='mean')
        self.relu6 = nn.ReLU6()
        self.zero_pad1d = nn.ZeroPad1d(2)
        self.max_unpool1d = nn.MaxUnpool1d(kernel_size=2, stride=2)
        self.upsampling_bilinear2d = nn.UpsamplingBilinear2d(scale_factor=2)
        self.lstm_cell = nn.LSTMCell(64, 128)
        self.replication_pad3d = nn.ReplicationPad3d(1)
        self.mse_loss = nn.MSELoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Assuming x is a 1D tensor for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Apply ReLU6
        x = self.relu6(x)
        
        # Reshape for ZeroPad1d
        x = x.unsqueeze(1)  # Add a dummy dimension
        x = self.zero_pad1d(x)
        
        # Reshape for MaxUnpool1d
        x = x.squeeze(1)  # Remove the dummy dimension
        x = x.unsqueeze(1)  # Add a channel dimension
        x, indices = F.max_pool1d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.max_unpool1d(x, indices)
        
        # Reshape for UpsamplingBilinear2d
        x = x.unsqueeze(1)  # Add a dummy dimension
        x = x.unsqueeze(1)  # Add another dummy dimension
        x = self.upsampling_bilinear2d(x)
        
        # Reshape for LSTMCell
        x = x.view(x.size(0), -1)  # Flatten
        hx = torch.zeros(x.size(0), 128).to(x.device)
        cx = torch.zeros(x.size(0), 128).to(x.device)
        x = self.lstm_cell(x, (hx, cx))[0]
        
        # Reshape for ReplicationPad3d
        x = x.unsqueeze(1)  # Add a dummy dimension
        x = x.unsqueeze(1)  # Add another dummy dimension
        x = self.replication_pad3d(x)
        
        # Compute losses (assuming we have a target tensor)
        target = torch.randn_like(x)
        mse_loss = self.mse_loss(x, target)
        multi_margin_loss = self.multi_margin_loss(x, torch.randint(0, 10, (x.size(0),)).to(x.device))
        
        return x, mse_loss, multi_margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

