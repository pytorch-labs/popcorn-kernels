
# This is a random torch model generated by the following modules: ['HuberLoss', 'MultiLabelSoftMarginLoss', 'SELU', 'ReplicationPad1d', 'CELU', 'Mish', 'ModuleDict', 'LazyConv3d', 'Flatten']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lazy_conv3d = nn.LazyConv3d(out_channels=16, kernel_size=3)
        self.replication_pad1d = nn.ReplicationPad1d(padding=2)
        self.selu = nn.SELU()
        self.celu = nn.CELU()
        self.mish = nn.Mish()
        self.flatten = nn.Flatten()
        self.module_dict = nn.ModuleDict({
            'huber_loss': nn.HuberLoss(),
            'multi_label_soft_margin_loss': nn.MultiLabelSoftMarginLoss()
        })
        
    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, depth, height, width)
        x = self.lazy_conv3d(x)  # Shape: (batch_size, 16, depth-2, height-2, width-2)
        x = x.mean(dim=[2, 3, 4])  # Reduce spatial dimensions to 1D
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 16)
        x = self.replication_pad1d(x)  # Shape: (batch_size, 1, 20)
        x = self.selu(x)
        x = self.celu(x)
        x = self.mish(x)
        x = self.flatten(x)  # Shape: (batch_size, 20)
        
        # Dummy target for loss computation
        target = torch.randint(0, 2, (x.shape[0], x.shape[1])).float()
        
        # Compute losses using ModuleDict
        huber_loss = self.module_dict['huber_loss'](x, target)
        multi_label_loss = self.module_dict['multi_label_soft_margin_loss'](x, target)
        
        # Return the average of the two losses
        return (huber_loss + multi_label_loss) / 2


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32, 32).cuda()  # Example input shape: (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
