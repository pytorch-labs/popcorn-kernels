
# This is a random torch model generated by the following modules: ['Linear', 'GaussianNLLLoss', 'InstanceNorm3d', 'ConstantPad1d', 'ZeroPad1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.linear1 = nn.Linear(128, 64)
        self.linear2 = nn.Linear(64, 32)
        self.linear3 = nn.Linear(32, 16)
        self.instance_norm = nn.InstanceNorm3d(16)
        self.constant_pad = nn.ConstantPad1d(2, 1.0)
        self.zero_pad = nn.ZeroPad1d(2)
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Reshape input to have a fixed number of features
        x = x.view(x.size(0), -1)  # Flatten the input
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = F.relu(self.linear3(x))
        
        # Reshape for InstanceNorm3d
        x = x.view(x.size(0), 16, 1, 1, 1)  # Reshape to 5D tensor
        x = self.instance_norm(x)
        
        # Reshape for 1D padding
        x = x.view(x.size(0), -1)  # Flatten again
        x = x.unsqueeze(1)  # Add a dimension for 1D padding
        x = self.constant_pad(x)
        x = self.zero_pad(x)
        
        # Reshape for GaussianNLLLoss
        x = x.squeeze(1)  # Remove the extra dimension
        target = torch.randn_like(x)  # Dummy target for GaussianNLLLoss
        var = torch.ones_like(x)  # Dummy variance for GaussianNLLLoss
        loss = self.gaussian_nll_loss(x, target, var)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 128).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

