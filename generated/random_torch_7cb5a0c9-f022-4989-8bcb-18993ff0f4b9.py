
# This is a random torch model generated by the following modules: ['LazyInstanceNorm1d', 'Hardshrink', 'AdaptiveAvgPool2d', 'LazyInstanceNorm3d', 'LazyConv3d', 'MaxUnpool1d', 'Softsign', 'SiLU', 'LazyConvTranspose1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lazy_instance_norm1d = nn.LazyInstanceNorm1d()
        self.hardshrink = nn.Hardshrink()
        self.adaptive_avg_pool2d = nn.AdaptiveAvgPool2d((5, 5))
        self.lazy_instance_norm3d = nn.LazyInstanceNorm3d()
        self.lazy_conv3d = nn.LazyConv3d(out_channels=16, kernel_size=3)
        self.max_unpool1d = nn.MaxUnpool1d(kernel_size=2, stride=2)
        self.softsign = nn.Softsign()
        self.silu = nn.SiLU()
        self.lazy_conv_transpose1d = nn.LazyConvTranspose1d(out_channels=32, kernel_size=3, stride=2)

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, height, width)
        x = x.unsqueeze(1)  # Add a dimension to make it 3D for LazyInstanceNorm1d
        x = self.lazy_instance_norm1d(x)
        x = self.hardshrink(x)
        
        # Reshape for AdaptiveAvgPool2d
        x = x.view(x.size(0), x.size(1), x.size(2), -1)  # Reshape to 4D
        x = self.adaptive_avg_pool2d(x)
        
        # Reshape for LazyInstanceNorm3d
        x = x.unsqueeze(1)  # Add a dimension to make it 5D for LazyInstanceNorm3d
        x = self.lazy_instance_norm3d(x)
        
        # Apply LazyConv3d
        x = self.lazy_conv3d(x)
        
        # Reshape for MaxUnpool1d
        x = x.view(x.size(0), x.size(1), -1)  # Reshape to 3D
        indices = torch.arange(0, x.size(2), 2).repeat(x.size(0), x.size(1), 1).to(x.device)
        x = self.max_unpool1d(x, indices)
        
        # Apply Softsign
        x = self.softsign(x)
        
        # Apply SiLU
        x = self.silu(x)
        
        # Apply LazyConvTranspose1d
        x = self.lazy_conv_transpose1d(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

