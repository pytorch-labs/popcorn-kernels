
# This is a random torch model generated by the following modules: ['Hardtanh', 'PixelShuffle', 'Unflatten', 'ParameterList', 'Dropout2d', 'LSTM', 'Tanh', 'ModuleDict', 'MaxPool2d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.unflatten = nn.Unflatten(1, (16, 8))
        self.parameter_list = nn.ParameterList([nn.Parameter(torch.randn(10)) for _ in range(5)])
        self.dropout2d = nn.Dropout2d(p=0.5)
        self.lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)
        self.tanh = nn.Tanh()
        self.module_dict = nn.ModuleDict({
            'conv1': nn.Conv2d(1, 10, kernel_size=5),
            'conv2': nn.Conv2d(10, 20, kernel_size=5)
        })
        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        # Apply Hardtanh
        x = self.hardtanh(x)
        
        # Apply PixelShuffle
        x = self.pixel_shuffle(x)
        
        # Apply Unflatten
        x = self.unflatten(x)
        
        # Apply ParameterList (not directly used in forward, but can be used in computations)
        param = self.parameter_list[0]
        x = x + param.view(1, -1, 1, 1)
        
        # Apply Dropout2d
        x = self.dropout2d(x)
        
        # Reshape for LSTM
        batch_size, channels, height, width = x.size()
        x = x.view(batch_size, channels * height, width)
        x = x.permute(0, 2, 1)  # (batch_size, width, channels * height)
        
        # Apply LSTM
        x, _ = self.lstm(x)
        
        # Apply Tanh
        x = self.tanh(x)
        
        # Reshape back for Conv2d
        x = x.permute(0, 2, 1)
        x = x.view(batch_size, -1, height, width)
        
        # Apply ModuleDict (Conv2d layers)
        x = self.module_dict['conv1'](x)
        x = F.relu(x)
        x = self.module_dict['conv2'](x)
        x = F.relu(x)
        
        # Apply MaxPool2d
        x = self.max_pool2d(x)
        
        return x

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
