
# This is a random torch model generated by the following modules: ['Softsign', 'CosineEmbeddingLoss', 'CTCLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.softsign = nn.Softsign()
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Apply Softsign activation
        x = self.softsign(x)
        
        # Reshape x to fit the expected input shape for CosineEmbeddingLoss
        x_reshaped = x.view(-1, x.size(-1))
        
        # Generate random target tensor for CosineEmbeddingLoss
        target = torch.randint(0, 2, (x_reshaped.size(0),), dtype=torch.float32).to(x.device)
        
        # Compute CosineEmbeddingLoss
        cosine_loss = self.cosine_embedding_loss(x_reshaped, x_reshaped, target)
        
        # Reshape x to fit the expected input shape for CTCLoss
        x_reshaped_ctc = x.view(x.size(0), x.size(1), -1)
        
        # Generate random target tensor for CTCLoss
        target_lengths = torch.randint(1, x_reshaped_ctc.size(1), (x_reshaped_ctc.size(0),)).to(x.device)
        input_lengths = torch.full((x_reshaped_ctc.size(0),), x_reshaped_ctc.size(1)).to(x.device)
        target_labels = torch.randint(0, x_reshaped_ctc.size(2), (target_lengths.sum().item(),)).to(x.device)
        
        # Compute CTCLoss
        ctc_loss = self.ctc_loss(x_reshaped_ctc, target_labels, input_lengths, target_lengths)
        
        # Return the sum of the losses as the output
        return cosine_loss + ctc_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 20).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

