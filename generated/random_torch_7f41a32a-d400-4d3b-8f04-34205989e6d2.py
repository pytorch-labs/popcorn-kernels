
# This is a random torch model generated by the following modules: ['Embedding', 'Softsign', 'RNNCellBase', 'LSTM', 'GLU', 'MultiMarginLoss', 'CrossEntropyLoss', 'MaxPool3d', 'AvgPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Assuming vocabulary size of 1000
        self.softsign = nn.Softsign()
        self.rnn_cell = nn.RNNCellBase(input_size=128, hidden_size=64)
        self.lstm = nn.LSTM(input_size=64, hidden_size=32, num_layers=2)
        self.glu = nn.GLU(dim=1)
        self.maxpool3d = nn.MaxPool3d(kernel_size=(2, 2, 2))
        self.avgpool1d = nn.AvgPool1d(kernel_size=2)
        self.cross_entropy_loss = nn.CrossEntropyLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Assuming x is a tensor of integers (indices for embedding)
        x = self.embedding(x)
        x = self.softsign(x)
        
        # Reshape for RNNCellBase
        x = x.view(-1, 128)
        x = self.rnn_cell(x)
        
        # Reshape for LSTM
        x = x.view(-1, 1, 64)
        x, _ = self.lstm(x)
        
        # Reshape for GLU
        x = x.view(-1, 64)
        x = self.glu(x)
        
        # Reshape for MaxPool3d
        x = x.view(-1, 32, 2, 2, 2)
        x = self.maxpool3d(x)
        
        # Reshape for AvgPool1d
        x = x.view(-1, 32, 4)
        x = self.avgpool1d(x)
        
        # Flatten for loss computation
        x = x.view(-1, 32)
        
        # Dummy target for loss computation
        target = torch.randint(0, 32, (x.size(0),), device=x.device)
        
        # Compute losses (just for demonstration, not used in final output)
        loss1 = self.cross_entropy_loss(x, target)
        loss2 = self.multi_margin_loss(x, target)
        
        return x, loss1, loss2


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10, 20)).cuda()  # Example input shape: (batch_size, sequence_length)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

