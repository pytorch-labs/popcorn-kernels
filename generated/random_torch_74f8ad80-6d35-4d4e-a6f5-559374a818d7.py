
# This is a random torch model generated by the following modules: ['RNNCell', 'MaxUnpool1d', 'Conv1d', 'Module', 'LSTMCell', 'MaxUnpool2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rnn_cell1 = nn.RNNCell(input_size=128, hidden_size=64)
        self.rnn_cell2 = nn.RNNCell(input_size=64, hidden_size=32)
        self.lstm_cell1 = nn.LSTMCell(input_size=32, hidden_size=16)
        self.lstm_cell2 = nn.LSTMCell(input_size=16, hidden_size=8)
        self.conv1d = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.max_unpool1d = nn.MaxUnpool1d(kernel_size=2, stride=2, padding=0)
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, input_size)
        batch_size, sequence_length, input_size = x.size()
        
        # Initialize hidden states for RNN and LSTM cells
        h_rnn1 = torch.zeros(batch_size, 64).to(x.device)
        h_rnn2 = torch.zeros(batch_size, 32).to(x.device)
        h_lstm1 = (torch.zeros(batch_size, 16).to(x.device), torch.zeros(batch_size, 16).to(x.device))
        h_lstm2 = (torch.zeros(batch_size, 8).to(x.device), torch.zeros(batch_size, 8).to(x.device))
        
        # Process through RNN cells
        for t in range(sequence_length):
            h_rnn1 = self.rnn_cell1(x[:, t, :], h_rnn1)
            h_rnn2 = self.rnn_cell2(h_rnn1, h_rnn2)
        
        # Process through LSTM cells
        for t in range(sequence_length):
            h_lstm1 = self.lstm_cell1(h_rnn2, h_lstm1)
            h_lstm2 = self.lstm_cell2(h_lstm1[0], h_lstm2)
        
        # Reshape for Conv1d
        x = h_lstm2[0].unsqueeze(1)  # Shape: (batch_size, 1, 8)
        x = x.transpose(1, 2)  # Shape: (batch_size, 8, 1)
        
        # Apply Conv1d
        x = self.conv1d(x)  # Shape: (batch_size, 16, 1)
        
        # Apply MaxUnpool1d
        x = x.unsqueeze(3)  # Shape: (batch_size, 16, 1, 1)
        x = self.max_unpool1d(x, torch.tensor([0]))  # Shape: (batch_size, 16, 2, 1)
        
        # Apply MaxUnpool2d
        x = x.transpose(1, 2)  # Shape: (batch_size, 2, 16, 1)
        x = self.max_unpool2d(x, torch.tensor([0]))  # Shape: (batch_size, 2, 32, 2)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 128).cuda()  # Example input: (batch_size=1, sequence_length=10, input_size=128)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

