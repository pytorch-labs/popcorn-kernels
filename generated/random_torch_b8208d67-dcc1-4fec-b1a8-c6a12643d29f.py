
# This is a random torch model generated by the following modules: ['ReflectionPad1d', 'Unflatten', 'SELU', 'UpsamplingNearest2d', 'Softmin', 'Embedding', 'AdaptiveAvgPool3d', 'ConvTranspose3d', 'LayerNorm']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)
        self.reflection_pad = nn.ReflectionPad1d(2)
        self.conv_transpose3d = nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1)
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d((16, 16, 16))
        self.layer_norm = nn.LayerNorm([64, 16, 16, 16])
        self.upsampling_nearest2d = nn.UpsamplingNearest2d(scale_factor=2)
        self.unflatten = nn.Unflatten(1, (64, 16, 16))
        self.selu = nn.SELU()
        self.softmin = nn.Softmin(dim=1)

    def forward(self, x):
        # Assume input is a 1D tensor of indices for embedding
        x = self.embedding(x)
        
        # Reshape and pad for ReflectionPad1d
        x = x.unsqueeze(1)  # Add a channel dimension
        x = self.reflection_pad(x)
        
        # Reshape for ConvTranspose3d
        x = x.unsqueeze(-1).unsqueeze(-1)  # Add spatial dimensions
        x = x.permute(0, 2, 1, 3, 4)  # Rearrange dimensions for ConvTranspose3d
        x = self.conv_transpose3d(x)
        
        # Apply AdaptiveAvgPool3d
        x = self.adaptive_avg_pool3d(x)
        
        # Apply LayerNorm
        x = self.layer_norm(x)
        
        # Reshape for UpsamplingNearest2d
        x = x.permute(0, 2, 1, 3, 4)  # Rearrange dimensions
        x = x.reshape(x.size(0), x.size(1), -1, x.size(-1))  # Flatten some dimensions
        x = self.upsampling_nearest2d(x)
        
        # Apply Unflatten
        x = self.unflatten(x)
        
        # Apply SELU activation
        x = self.selu(x)
        
        # Apply Softmin
        x = self.softmin(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (1, 128)).cuda()  # Input for embedding
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

