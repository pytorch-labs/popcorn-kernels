
# This is a random torch model generated by the following modules: ['CosineEmbeddingLoss', 'MultiMarginLoss', 'Hardtanh']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.hardtanh1 = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.hardtanh2 = nn.Hardtanh(min_val=-0.5, max_val=0.5)
        self.hardtanh3 = nn.Hardtanh(min_val=-2.0, max_val=2.0)
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Apply Hardtanh layers
        x = self.hardtanh1(x)
        x = self.hardtanh2(x)
        x = self.hardtanh3(x)
        
        # Reshape the input to match the expected shape for loss functions
        x = x.view(-1)  # Flatten the input
        
        # Create dummy targets for the loss functions
        target_cosine = torch.ones(x.shape[0], dtype=torch.float32)
        target_margin = torch.randint(0, 2, (x.shape[0],), dtype=torch.int64)
        
        # Compute the losses
        cosine_loss = self.cosine_embedding_loss(x, x, target_cosine)
        margin_loss = self.multi_margin_loss(x.unsqueeze(0), target_margin.unsqueeze(0))
        
        # Return the sum of the losses
        return cosine_loss + margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 10).cuda()  # Arbitrary shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

