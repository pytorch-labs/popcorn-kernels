
# This is a random torch model generated by the following modules: ['MaxPool1d', 'ConvTranspose3d', 'ConvTranspose2d', 'PixelShuffle', 'RNNCellBase', 'BatchNorm2d', 'UpsamplingNearest2d', 'ReplicationPad3d', 'RNNBase']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.maxpool1d = nn.MaxPool1d(kernel_size=2, stride=2)
        self.convtranspose3d = nn.ConvTranspose3d(1, 10, kernel_size=3, stride=2)
        self.convtranspose2d = nn.ConvTranspose2d(10, 20, kernel_size=3, stride=2)
        self.pixelshuffle = nn.PixelShuffle(2)
        self.rnncellbase = nn.RNNCell(20, 30)
        self.batchnorm2d = nn.BatchNorm2d(30)
        self.upsamplingnearest2d = nn.UpsamplingNearest2d(scale_factor=2)
        self.replicationpad3d = nn.ReplicationPad3d(1)
        self.rnnbase = nn.RNN(30, 40, num_layers=2, batch_first=True)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width, depth)
        # Reshape to 1D for MaxPool1d
        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, channels, height * width * depth)
        x = self.maxpool1d(x)
        
        # Reshape back to 3D for ConvTranspose3d
        x = x.view(x.size(0), x.size(1), 8, 8, 8)  # Arbitrary shape for demonstration
        x = self.convtranspose3d(x)
        
        # Reshape to 2D for ConvTranspose2d
        x = x.view(x.size(0), x.size(1), x.size(2), x.size(3) * x.size(4))
        x = self.convtranspose2d(x)
        
        # PixelShuffle
        x = self.pixelshuffle(x)
        
        # Reshape for RNNCellBase
        x = x.view(x.size(0), x.size(1), -1).permute(0, 2, 1)  # (batch_size, seq_len, features)
        hx = torch.zeros(x.size(0), 30).to(x.device)
        x = self.rnncellbase(x[:, 0, :], hx)
        
        # Reshape for BatchNorm2d
        x = x.view(x.size(0), -1, 1, 1)  # (batch_size, channels, 1, 1)
        x = self.batchnorm2d(x)
        
        # UpsamplingNearest2d
        x = self.upsamplingnearest2d(x)
        
        # Reshape for ReplicationPad3d
        x = x.view(x.size(0), x.size(1), 1, 1, 1)  # (batch_size, channels, 1, 1, 1)
        x = self.replicationpad3d(x)
        
        # Reshape for RNNBase
        x = x.view(x.size(0), x.size(1), -1).permute(0, 2, 1)  # (batch_size, seq_len, features)
        h0 = torch.zeros(2, x.size(0), 40).to(x.device)  # 2 layers for RNN
        x, _ = self.rnnbase(x, h0)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 16, 16, 16).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

