
# This is a random torch model generated by the following modules: ['Embedding', 'PoissonNLLLoss', 'LayerNorm', 'InstanceNorm3d', 'Softsign', 'CircularPad2d', 'InstanceNorm1d', 'HingeEmbeddingLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Assuming vocab size of 1000
        self.layer_norm = nn.LayerNorm(128)
        self.instance_norm3d = nn.InstanceNorm3d(128)
        self.instance_norm1d = nn.InstanceNorm1d(128)
        self.softsign = nn.Softsign()
        self.circular_pad2d = nn.CircularPad2d(2)
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.hinge_embedding_loss = nn.HingeEmbeddingLoss()

    def forward(self, x):
        # Assuming x is a tensor of integers (indices for embedding)
        x = self.embedding(x)
        
        # Reshape for InstanceNorm3d
        x = x.unsqueeze(2).unsqueeze(3).unsqueeze(4)  # Shape: (batch, 128, 1, 1, 1)
        x = self.instance_norm3d(x)
        x = x.squeeze(4).squeeze(3).squeeze(2)  # Shape: (batch, 128)
        
        # Apply LayerNorm
        x = self.layer_norm(x)
        
        # Reshape for InstanceNorm1d
        x = x.unsqueeze(2)  # Shape: (batch, 128, 1)
        x = self.instance_norm1d(x)
        x = x.squeeze(2)  # Shape: (batch, 128)
        
        # Apply Softsign
        x = self.softsign(x)
        
        # Reshape for CircularPad2d
        x = x.unsqueeze(1).unsqueeze(2)  # Shape: (batch, 1, 1, 128)
        x = self.circular_pad2d(x)
        x = x.squeeze(2).squeeze(1)  # Shape: (batch, 128)
        
        # Dummy target for PoissonNLLLoss and HingeEmbeddingLoss
        target_poisson = torch.ones_like(x) * 0.5
        target_hinge = torch.ones_like(x) * 1.0
        
        # Apply PoissonNLLLoss
        poisson_loss = self.poisson_nll_loss(x, target_poisson)
        
        # Apply HingeEmbeddingLoss
        hinge_loss = self.hinge_embedding_loss(x, target_hinge)
        
        # Return both losses (for demonstration purposes)
        return poisson_loss, hinge_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input tensor of shape (10,)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

