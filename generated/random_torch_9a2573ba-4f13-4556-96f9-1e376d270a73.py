
# This is a random torch model generated by the following modules: ['ReflectionPad3d', 'GaussianNLLLoss', 'BCEWithLogitsLoss', 'BatchNorm2d', 'Bilinear']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pad = nn.ReflectionPad3d(1)
        self.bn1 = nn.BatchNorm2d(10)
        self.bn2 = nn.BatchNorm2d(20)
        self.bilinear = nn.Bilinear(20, 10, 50)
        self.gaussian_nll_loss = nn.GaussianNLLLoss()
        self.bce_with_logits_loss = nn.BCEWithLogitsLoss()

    def forward(self, x):
        # Apply ReflectionPad3d
        x = self.pad(x)
        
        # Reshape to 4D tensor for BatchNorm2d
        x = x.view(-1, 10, 8, 8)
        
        # Apply BatchNorm2d
        x = self.bn1(x)
        
        # Reshape to 2D tensor for Bilinear
        x = x.view(-1, 20)
        
        # Apply Bilinear
        x = self.bilinear(x, torch.randn_like(x))
        
        # Reshape to 4D tensor for BatchNorm2d
        x = x.view(-1, 20, 5, 5)
        
        # Apply BatchNorm2d
        x = self.bn2(x)
        
        # Reshape to 2D tensor for loss functions
        x = x.view(-1, 50)
        
        # Dummy target for GaussianNLLLoss
        target_gaussian = torch.randn_like(x)
        var = torch.ones_like(x)
        loss_gaussian = self.gaussian_nll_loss(x, target_gaussian, var)
        
        # Dummy target for BCEWithLogitsLoss
        target_bce = torch.randint(0, 2, x.size()).float()
        loss_bce = self.bce_with_logits_loss(x, target_bce)
        
        # Return both losses
        return loss_gaussian, loss_bce


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 8, 8, 8).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

