
# This is a random torch model generated by the following modules: ['ModuleList', 'MaxPool1d', 'AvgPool1d', 'EmbeddingBag', 'ReflectionPad3d', 'MaxUnpool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        # Define a ModuleList to hold multiple layers
        self.layers = nn.ModuleList([
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.AvgPool1d(kernel_size=2, stride=2),
            nn.EmbeddingBag(num_embeddings=1000, embedding_dim=128, mode='mean'),
            nn.ReflectionPad3d(padding=1),
            nn.MaxUnpool1d(kernel_size=2, stride=2),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.AvgPool1d(kernel_size=2, stride=2),
            nn.EmbeddingBag(num_embeddings=1000, embedding_dim=128, mode='mean'),
            nn.ReflectionPad3d(padding=1),
            nn.MaxUnpool1d(kernel_size=2, stride=2)
        ])

    def forward(self, x):
        # Assume input x is of arbitrary shape, reshape it to fit the layers
        # First, flatten the input to 1D for EmbeddingBag
        if len(x.shape) > 2:
            x = x.view(-1, x.shape[-1])
        
        # Apply layers in sequence
        for i, layer in enumerate(self.layers):
            if isinstance(layer, nn.EmbeddingBag):
                # EmbeddingBag expects input to be a 1D tensor of indices
                x = torch.randint(0, 1000, (x.shape[0],)).to(x.device)
                x = layer(x)
            elif isinstance(layer, nn.ReflectionPad3d):
                # Reshape to 5D tensor for ReflectionPad3d
                x = x.view(x.shape[0], 1, 1, 1, -1)
                x = layer(x)
                x = x.view(x.shape[0], -1)
            elif isinstance(layer, nn.MaxUnpool1d):
                # MaxUnpool1d requires indices from a previous MaxPool1d
                if i > 0 and isinstance(self.layers[i-1], nn.MaxPool1d):
                    x, indices = self.layers[i-1](x)
                    x = layer(x, indices)
                else:
                    x = layer(x)
            else:
                x = layer(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 100).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

