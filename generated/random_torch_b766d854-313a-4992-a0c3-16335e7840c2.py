
# This is a random torch model generated by the following modules: ['GRUCell', 'ParameterDict', 'Bilinear', 'ParameterList', 'Mish', 'MaxUnpool3d', 'LogSoftmax']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        # Initialize GRUCell
        self.gru_cell = nn.GRUCell(input_size=128, hidden_size=256)
        
        # Initialize ParameterDict
        self.param_dict = nn.ParameterDict({
            'weight1': nn.Parameter(torch.randn(256, 128)),
            'weight2': nn.Parameter(torch.randn(128, 64))
        })
        
        # Initialize Bilinear
        self.bilinear = nn.Bilinear(in1_features=64, in2_features=64, out_features=32)
        
        # Initialize ParameterList
        self.param_list = nn.ParameterList([
            nn.Parameter(torch.randn(32, 16)),
            nn.Parameter(torch.randn(16, 8))
        ])
        
        # Initialize Mish activation
        self.mish = nn.Mish()
        
        # Initialize MaxUnpool3d
        self.max_unpool3d = nn.MaxUnpool3d(kernel_size=2, stride=2, padding=0)
        
        # Initialize LogSoftmax
        self.log_softmax = nn.LogSoftmax(dim=1)

    def forward(self, x):
        # Assuming x is of shape (batch_size, sequence_length, input_size)
        batch_size, seq_len, input_size = x.size()
        
        # Initialize hidden state for GRUCell
        hx = torch.zeros(batch_size, 256).to(x.device)
        
        # Process sequence with GRUCell
        for t in range(seq_len):
            hx = self.gru_cell(x[:, t, :], hx)
        
        # Apply ParameterDict weights
        x = torch.matmul(hx, self.param_dict['weight1'])
        x = torch.matmul(x, self.param_dict['weight2'])
        
        # Apply Bilinear transformation
        x = self.bilinear(x, x)
        
        # Apply ParameterList weights
        for param in self.param_list:
            x = torch.matmul(x, param)
        
        # Apply Mish activation
        x = self.mish(x)
        
        # Reshape for MaxUnpool3d
        x = x.view(batch_size, 8, 2, 2, 2)
        
        # Apply MaxUnpool3d (assuming indices are available)
        # For simplicity, we assume indices are the same as the input
        _, indices = torch.max(x, dim=2, keepdim=True)
        x = self.max_unpool3d(x, indices)
        
        # Reshape back to 2D
        x = x.view(batch_size, -1)
        
        # Apply LogSoftmax
        x = self.log_softmax(x)
        
        return x

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 128).cuda()  # (batch_size, sequence_length, input_size)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
