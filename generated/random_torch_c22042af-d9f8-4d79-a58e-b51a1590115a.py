
# This is a random torch model generated by the following modules: ['Linear', 'ReLU', 'Conv2d', 'LogSoftmax']
import torch
import torch.nn as nn
import torch.nn.functional as F


class RandomModel(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Conv2d
        self.relu1 = nn.ReLU()  # ReLU
        self.fc1 = nn.Linear(16 * 8 * 8, 128)  # Linear
        self.relu2 = nn.ReLU()  # ReLU
        self.fc2 = nn.Linear(128, 64)  # Linear
        self.log_softmax = nn.LogSoftmax(dim=1)  # LogSoftmax

    def forward(self, x):
        # Assume x has shape (batch_size, channels, height, width)
        x = self.conv(x)  # Apply Conv2d
        x = self.relu1(x)  # Apply ReLU
        x = F.max_pool2d(x, 2)  # Max pooling to reduce spatial dimensions
        
        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer
        x = self.fc1(x)  # Apply Linear
        x = self.relu2(x)  # Apply ReLU
        x = self.fc2(x)  # Apply Linear
        return self.log_softmax(x)  # Apply LogSoftmax


def get_random_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 32, 32)  # Example input tensor of shape (batch_size, channels, height, width)
    return [x]

