
# This is a random torch model generated by the following modules: ['Softmax', 'ConstantPad2d', 'Module', 'InstanceNorm3d', 'ZeroPad2d', 'Softshrink', 'UpsamplingBilinear2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.constant_pad = nn.ConstantPad2d(2, 3.0)
        self.zero_pad = nn.ZeroPad2d(1)
        self.instance_norm = nn.InstanceNorm3d(10)
        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)
        self.softmax = nn.Softmax(dim=1)
        self.softshrink = nn.Softshrink(0.5)

    def forward(self, x):
        # Apply ConstantPad2d
        x = self.constant_pad(x)
        
        # Apply ZeroPad2d
        x = self.zero_pad(x)
        
        # Reshape for InstanceNorm3d
        x = x.unsqueeze(0)  # Add batch dimension
        x = x.unsqueeze(0)  # Add channel dimension
        x = x.expand(1, 10, -1, -1, -1)  # Expand to 10 channels
        x = self.instance_norm(x)
        
        # Reshape back to 2D
        x = x.squeeze(0).squeeze(0)
        
        # Apply UpsamplingBilinear2d
        x = self.upsample(x)
        
        # Apply Softshrink
        x = self.softshrink(x)
        
        # Apply Softmax
        x = self.softmax(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
