
# This is a random torch model generated by the following modules: ['FractionalMaxPool2d', 'RNNBase', 'NLLLoss', 'MultiLabelMarginLoss', 'Conv1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1d = nn.Conv1d(1, 10, kernel_size=5)
        self.fractional_max_pool2d = nn.FractionalMaxPool2d(kernel_size=2, output_size=(10, 10))
        self.rnn = nn.RNNBase(input_size=10, hidden_size=20, num_layers=2)
        self.nll_loss = nn.NLLLoss()
        self.multi_label_margin_loss = nn.MultiLabelMarginLoss()

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, height, width)
        # First, reshape the input to fit Conv1d
        x = x.view(x.size(0), 1, -1)  # Reshape to (batch_size, 1, height * width)
        x = F.relu(self.conv1d(x))  # Apply Conv1d
        
        # Reshape back to 2D for FractionalMaxPool2d
        x = x.view(x.size(0), 10, 10, -1)  # Reshape to (batch_size, 10, 10, some_dim)
        x = self.fractional_max_pool2d(x)  # Apply FractionalMaxPool2d
        
        # Reshape for RNN
        x = x.view(x.size(0), -1, 10)  # Reshape to (batch_size, seq_len, input_size)
        x, _ = self.rnn(x)  # Apply RNN
        
        # Compute loss (assuming some target tensors)
        target_nll = torch.randint(0, 10, (x.size(0),), dtype=torch.long).to(x.device)
        target_multi_label = torch.randint(0, 2, (x.size(0), 10), dtype=torch.long).to(x.device)
        
        # Apply NLLLoss and MultiLabelMarginLoss
        nll_loss = self.nll_loss(x, target_nll)
        multi_label_loss = self.multi_label_margin_loss(x, target_multi_label)
        
        # Return the sum of losses as the output
        return nll_loss + multi_label_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
