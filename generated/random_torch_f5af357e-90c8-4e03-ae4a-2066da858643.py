
# This is a random torch model generated by the following modules: ['CTCLoss', 'RMSNorm', 'Container']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rms_norm1 = RMSNorm(128)
        self.rms_norm2 = RMSNorm(64)
        self.container = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
        )
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, feature_dim)
        batch_size, sequence_length, feature_dim = x.shape
        
        # Apply RMSNorm to the input
        x = self.rms_norm1(x)
        
        # Pass through the container (a sequence of layers)
        x = self.container(x.view(-1, feature_dim)).view(batch_size, sequence_length, -1)
        
        # Apply RMSNorm again
        x = self.rms_norm2(x)
        
        # Compute CTC loss (assuming we have target sequences and input lengths)
        # For demonstration, we'll create dummy targets and input lengths
        log_probs = F.log_softmax(x, dim=-1)
        targets = torch.randint(0, 32, (batch_size, sequence_length), dtype=torch.long)
        input_lengths = torch.full((batch_size,), sequence_length, dtype=torch.long)
        target_lengths = torch.randint(1, sequence_length + 1, (batch_size,), dtype=torch.long)
        
        loss = self.ctc_loss(log_probs, targets, input_lengths, target_lengths)
        
        return loss


class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-8):
        super().__init__()
        self.scale = dim ** -0.5
        self.eps = eps
        self.g = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale
        return x / norm.clamp(min=self.eps) * self.g


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 128).cuda()  # (batch_size, sequence_length, feature_dim)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

