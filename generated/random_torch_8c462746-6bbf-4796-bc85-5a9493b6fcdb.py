
# This is a random torch model generated by the following modules: ['Upsample', 'Embedding', 'MaxPool1d', 'CircularPad3d', 'ReplicationPad3d', 'RReLU', 'SiLU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)
        self.upsample = nn.Upsample(scale_factor=2)
        self.maxpool1d = nn.MaxPool1d(kernel_size=2, stride=2)
        self.circular_pad3d = nn.CircularPad3d(padding=1)
        self.replication_pad3d = nn.ReplicationPad3d(padding=1)
        self.rrelu = nn.RReLU()
        self.silu = nn.SiLU()

    def forward(self, x):
        # Assume input is a 1D tensor of indices for embedding
        x = self.embedding(x)
        
        # Reshape for 1D operations
        x = x.unsqueeze(1)  # Add a channel dimension
        x = self.maxpool1d(x)
        
        # Reshape for 3D operations
        x = x.unsqueeze(1)  # Add a depth dimension
        x = self.circular_pad3d(x)
        x = self.replication_pad3d(x)
        
        # Apply activation functions
        x = self.rrelu(x)
        x = self.silu(x)
        
        # Upsample
        x = x.squeeze(1)  # Remove depth dimension
        x = self.upsample(x)
        
        # Final reshape to match output dimensions
        x = x.squeeze(1)  # Remove channel dimension
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for embedding
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

