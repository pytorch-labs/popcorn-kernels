
# This is a random torch model generated by the following modules: ['InstanceNorm2d', 'GaussianNLLLoss', 'ConstantPad2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pad = nn.ConstantPad2d(2, 3.0)  # Padding with value 3.0
        self.norm1 = nn.InstanceNorm2d(3)    # Instance normalization for 3 channels
        self.norm2 = nn.InstanceNorm2d(3)    # Repeating InstanceNorm2d
        self.loss = nn.GaussianNLLLoss()     # Gaussian NLL Loss

    def forward(self, x):
        # Assume input x is of shape (batch_size, channels, height, width)
        x = self.pad(x)                      # Apply padding
        x = self.norm1(x)                    # Apply first instance normalization
        x = self.norm2(x)                    # Apply second instance normalization
        
        # For GaussianNLLLoss, we need to predict mean and variance
        mean = x.mean(dim=[2, 3], keepdim=True)  # Compute mean over spatial dimensions
        var = x.var(dim=[2, 3], keepdim=True)    # Compute variance over spatial dimensions
        
        # Flatten the output for GaussianNLLLoss
        mean = mean.view(mean.size(0), -1)
        var = var.view(var.size(0), -1)
        
        # Dummy target for GaussianNLLLoss (same shape as mean)
        target = torch.zeros_like(mean)
        
        # Compute GaussianNLLLoss
        loss = self.loss(mean, target, var)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Input with 3 channels, 64x64 spatial dimensions
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

