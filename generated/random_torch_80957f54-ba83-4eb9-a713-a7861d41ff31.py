
# This is a random torch model generated by the following modules: ['Conv2d', 'MaxUnpool2d', 'GroupNorm', 'LazyBatchNorm3d', 'MultiLabelMarginLoss', 'RMSNorm', 'AdaptiveAvgPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.max_unpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.group_norm1 = nn.GroupNorm(4, 16)
        self.lazy_bn3d1 = nn.LazyBatchNorm3d()
        self.rms_norm1 = nn.RMSNorm(16)
        self.adaptive_avg_pool1d = nn.AdaptiveAvgPool1d(output_size=10)
        self.multi_label_margin_loss = nn.MultiLabelMarginLoss()

    def forward(self, x):
        # Conv2d
        x = self.conv1(x)
        
        # MaxUnpool2d (requires indices from a previous max pooling operation)
        # Since we don't have a max pooling layer, we'll simulate the indices
        _, indices = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.max_unpool1(x, indices)
        
        # GroupNorm
        x = self.group_norm1(x)
        
        # Reshape for LazyBatchNorm3d
        x = x.unsqueeze(0)  # Add a batch dimension
        x = x.unsqueeze(0)  # Add a channel dimension
        x = self.lazy_bn3d1(x)
        
        # Reshape back to 2D
        x = x.squeeze(0).squeeze(0)
        
        # RMSNorm
        x = self.rms_norm1(x)
        
        # Reshape for AdaptiveAvgPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x = self.adaptive_avg_pool1d(x)
        
        # MultiLabelMarginLoss (requires target labels)
        # Since this is a loss function, we'll return the output and the loss separately
        output = x.view(x.size(0), -1)  # Flatten for output
        target = torch.randint(0, 2, (output.size(0), output.size(1))).float()  # Random target
        loss = self.multi_label_margin_loss(output, target)
        
        return output, loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

