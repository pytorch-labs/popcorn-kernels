
# This is a random torch model generated by the following modules: ['AdaptiveAvgPool3d', 'LSTM', 'AvgPool3d', 'AdaptiveMaxPool2d', 'InstanceNorm1d', 'ReplicationPad2d', 'Tanh', 'SELU', 'GRU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d((8, 8, 8))
        self.lstm = nn.LSTM(input_size=512, hidden_size=256, num_layers=2, batch_first=True)
        self.avg_pool3d = nn.AvgPool3d(kernel_size=2, stride=2)
        self.adaptive_max_pool2d = nn.AdaptiveMaxPool2d((4, 4))
        self.instance_norm1d = nn.InstanceNorm1d(256)
        self.replication_pad2d = nn.ReplicationPad2d(2)
        self.tanh = nn.Tanh()
        self.selu = nn.SELU()
        self.gru = nn.GRU(input_size=256, hidden_size=128, num_layers=2, batch_first=True)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.adaptive_avg_pool3d(x)  # Output shape: (batch_size, channels, 8, 8, 8)
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions: (batch_size, channels, 8*8*8)
        x = x.permute(0, 2, 1)  # Swap dimensions for LSTM: (batch_size, 8*8*8, channels)
        x, _ = self.lstm(x)  # Output shape: (batch_size, 8*8*8, 256)
        x = x.permute(0, 2, 1)  # Swap back: (batch_size, 256, 8*8*8)
        x = x.view(x.size(0), x.size(1), 8, 8, 8)  # Reshape back to 3D: (batch_size, 256, 8, 8, 8)
        x = self.avg_pool3d(x)  # Output shape: (batch_size, 256, 4, 4, 4)
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions: (batch_size, 256, 4*4*4)
        x = self.instance_norm1d(x)  # Output shape: (batch_size, 256, 4*4*4)
        x = x.view(x.size(0), x.size(1), 4, 4, 4)  # Reshape back to 3D: (batch_size, 256, 4, 4, 4)
        x = x[:, :, :, :, 0]  # Take the first slice along depth: (batch_size, 256, 4, 4)
        x = self.replication_pad2d(x)  # Output shape: (batch_size, 256, 8, 8)
        x = self.adaptive_max_pool2d(x)  # Output shape: (batch_size, 256, 4, 4)
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions: (batch_size, 256, 4*4)
        x = self.tanh(x)  # Output shape: (batch_size, 256, 16)
        x = self.selu(x)  # Output shape: (batch_size, 256, 16)
        x = x.permute(0, 2, 1)  # Swap dimensions for GRU: (batch_size, 16, 256)
        x, _ = self.gru(x)  # Output shape: (batch_size, 16, 128)
        x = x[:, -1, :]  # Take the last hidden state: (batch_size, 128)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 16, 16, 16).cuda()  # Example input shape: (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

