
# This is a random torch model generated by the following modules: ['ConvTranspose2d', 'ConvTranspose3d', 'MaxUnpool1d', 'Bilinear']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose2d_1 = nn.ConvTranspose2d(1, 10, kernel_size=5, stride=2)
        self.conv_transpose2d_2 = nn.ConvTranspose2d(10, 20, kernel_size=5, stride=2)
        self.conv_transpose3d_1 = nn.ConvTranspose3d(20, 30, kernel_size=3, stride=2)
        self.conv_transpose3d_2 = nn.ConvTranspose3d(30, 40, kernel_size=3, stride=2)
        self.max_unpool1d_1 = nn.MaxUnpool1d(kernel_size=2, stride=2)
        self.max_unpool1d_2 = nn.MaxUnpool1d(kernel_size=2, stride=2)
        self.bilinear_1 = nn.Bilinear(40, 40, 50)
        self.bilinear_2 = nn.Bilinear(50, 50, 10)

    def forward(self, x):
        # Assuming input is 4D (batch, channels, height, width)
        x = F.relu(self.conv_transpose2d_1(x))
        x = F.relu(self.conv_transpose2d_2(x))
        
        # Reshape to 5D for ConvTranspose3d
        x = x.unsqueeze(2)  # Add a depth dimension
        x = F.relu(self.conv_transpose3d_1(x))
        x = F.relu(self.conv_transpose3d_2(x))
        
        # Reshape back to 4D for MaxUnpool1d
        x = x.squeeze(2)  # Remove the depth dimension
        x = x.permute(0, 2, 1, 3)  # Swap channels and height for MaxUnpool1d
        x = x.reshape(x.size(0), x.size(1), -1)  # Flatten height and width
        
        # MaxUnpool1d requires indices, so we create dummy indices
        _, indices = F.max_pool1d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.max_unpool1d_1(x, indices)
        x = self.max_unpool1d_2(x, indices)
        
        # Reshape for Bilinear
        x = x.reshape(x.size(0), -1)  # Flatten all dimensions except batch
        x = F.relu(self.bilinear_1(x, x))  # Using the same tensor for both inputs
        x = self.bilinear_2(x, x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 28, 28).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

