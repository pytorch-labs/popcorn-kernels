
# This is a random torch model generated by the following modules: ['AdaptiveAvgPool2d', 'AdaptiveLogSoftmaxWithLoss', 'Hardtanh', 'ReLU6', 'ParameterDict', 'PixelUnshuffle', 'Conv1d', 'MaxUnpool2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pixel_unshuffle = nn.PixelUnshuffle(downscale_factor=2)
        self.conv1d = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1)
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.relu6 = nn.ReLU6()
        self.adaptive_avg_pool2d = nn.AdaptiveAvgPool2d((5, 5))
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.adaptive_log_softmax = nn.AdaptiveLogSoftmaxWithLoss(in_features=32, n_classes=10, cutoffs=[5])
        self.parameter_dict = nn.ParameterDict({
            'param1': nn.Parameter(torch.randn(32, 5, 5)),
            'param2': nn.Parameter(torch.randn(32, 5, 5))
        })

    def forward(self, x):
        # PixelUnshuffle
        x = self.pixel_unshuffle(x)
        
        # Reshape for Conv1d
        batch_size, channels, height, width = x.shape
        x = x.view(batch_size, channels * height, width)
        
        # Conv1d
        x = self.conv1d(x)
        
        # Hardtanh
        x = self.hardtanh(x)
        
        # ReLU6
        x = self.relu6(x)
        
        # Reshape back to 4D for AdaptiveAvgPool2d
        x = x.view(batch_size, 32, height, width)
        
        # AdaptiveAvgPool2d
        x = self.adaptive_avg_pool2d(x)
        
        # MaxUnpool2d (requires indices from a previous max pooling, which we don't have, so we'll just pass the input as is)
        # Since we don't have indices, we'll skip this step in practice, but we include it for demonstration
        # x = self.max_unpool2d(x, indices)
        
        # AdaptiveLogSoftmaxWithLoss
        # Reshape for AdaptiveLogSoftmaxWithLoss
        x = x.view(batch_size, -1)
        x = self.adaptive_log_softmax.log_prob(x)
        
        # ParameterDict (not used in forward pass, but included for completeness)
        param1 = self.parameter_dict['param1']
        param2 = self.parameter_dict['param2']
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
