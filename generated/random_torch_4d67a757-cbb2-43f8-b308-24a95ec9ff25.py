
# This is a random torch model generated by the following modules: ['TripletMarginWithDistanceLoss', 'ReLU6', 'MSELoss', 'Transformer', 'Sigmoid', 'MultiLabelMarginLoss', 'Softmax2d', 'AdaptiveAvgPool2d', 'Tanhshrink']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.transformer = nn.Transformer(d_model=64, nhead=8, num_encoder_layers=3, num_decoder_layers=3)
        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((16, 16))
        self.relu6 = nn.ReLU6()
        self.sigmoid = nn.Sigmoid()
        self.softmax2d = nn.Softmax2d()
        self.tanhshrink = nn.Tanhshrink()
        self.fc1 = nn.Linear(16 * 16 * 64, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: F.pairwise_distance(x, y, p=2))
        self.mse_loss = nn.MSELoss()
        self.multi_label_margin_loss = nn.MultiLabelMarginLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        batch_size = x.size(0)
        
        # Apply AdaptiveAvgPool2d
        x = self.adaptive_avg_pool(x)
        
        # Apply Softmax2d
        x = self.softmax2d(x)
        
        # Reshape for Transformer
        x = x.view(batch_size, -1, 64)  # Reshape to (batch_size, seq_len, d_model)
        
        # Apply Transformer
        x = self.transformer(x, x)
        
        # Apply ReLU6
        x = self.relu6(x)
        
        # Apply Tanhshrink
        x = self.tanhshrink(x)
        
        # Reshape for FC layers
        x = x.view(batch_size, -1)
        
        # Apply FC layers
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        
        # Apply Sigmoid
        x = self.sigmoid(x)
        
        # Compute losses (for demonstration purposes, we use dummy targets)
        dummy_target = torch.randint(0, 10, (batch_size,)).long().to(x.device)
        dummy_target_multi_label = torch.randint(0, 2, (batch_size, 10)).float().to(x.device)
        
        triplet_loss = self.triplet_loss(x, x, x)
        mse_loss = self.mse_loss(x, torch.zeros_like(x))
        multi_label_margin_loss = self.multi_label_margin_loss(x, dummy_target_multi_label)
        
        # Return the final output and the computed losses
        return x, triplet_loss, mse_loss, multi_label_margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

