
# This is a random torch model generated by the following modules: ['LogSoftmax', 'Hardswish', 'InstanceNorm1d', 'Hardtanh', 'Softmax2d', 'PoissonNLLLoss', 'BCELoss', 'LazyBatchNorm1d', 'Identity']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.instance_norm1d = nn.InstanceNorm1d(128)
        self.lazy_batch_norm1d = nn.LazyBatchNorm1d()
        self.hardswish = nn.Hardswish()
        self.hardtanh = nn.Hardtanh()
        self.softmax2d = nn.Softmax2d()
        self.log_softmax = nn.LogSoftmax(dim=1)
        self.identity = nn.Identity()
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Reshape input to 1D for InstanceNorm1d
        x = x.view(x.size(0), -1)  # Flatten to (batch_size, features)
        x = self.instance_norm1d(x)
        
        # Apply LazyBatchNorm1d
        x = self.lazy_batch_norm1d(x)
        
        # Apply Hardswish
        x = self.hardswish(x)
        
        # Apply Hardtanh
        x = self.hardtanh(x)
        
        # Reshape back to 2D for Softmax2d
        x = x.view(x.size(0), 1, int(x.size(1) ** 0.5), int(x.size(1) ** 0.5))  # Reshape to (batch_size, 1, sqrt(features), sqrt(features))
        x = self.softmax2d(x)
        
        # Apply LogSoftmax
        x = x.view(x.size(0), -1)  # Flatten again
        x = self.log_softmax(x)
        
        # Apply Identity (no effect)
        x = self.identity(x)
        
        # Compute PoissonNLLLoss (requires target, so we skip it in forward pass)
        # Compute BCELoss (requires target, so we skip it in forward pass)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

