
# This is a random torch model generated by the following modules: ['L1Loss', 'CTCLoss', 'UpsamplingNearest2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)
        self.l1_loss = nn.L1Loss()
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Upsample the input twice
        x = self.upsample1(x)
        x = self.upsample2(x)
        
        # Compute L1 loss between the upsampled output and a target tensor of the same shape
        target_l1 = torch.zeros_like(x)
        l1_loss_value = self.l1_loss(x, target_l1)
        
        # Compute CTC loss between the upsampled output and a target sequence
        # Assuming the input is of shape (batch_size, channels, height, width)
        # We reshape it to (sequence_length, batch_size, num_classes) for CTC loss
        x_reshaped = x.view(x.size(0), x.size(1), -1).permute(2, 0, 1)  # (sequence_length, batch_size, num_classes)
        target_ctc = torch.randint(0, x.size(1), (x.size(0), 10), dtype=torch.long)  # Random target sequence
        input_lengths = torch.full((x.size(0),), x_reshaped.size(0), dtype=torch.long)
        target_lengths = torch.full((x.size(0),), 10, dtype=torch.long)
        ctc_loss_value = self.ctc_loss(x_reshaped, target_ctc, input_lengths, target_lengths)
        
        # Return both loss values
        return l1_loss_value, ctc_loss_value


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input shape (batch_size, channels, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

