
# This is a random torch model generated by the following modules: ['RMSNorm', 'BCELoss', 'ConvTranspose3d', 'GaussianNLLLoss', 'FractionalMaxPool2d', 'LogSigmoid', 'Unflatten', 'ZeroPad3d', 'Container', 'Hardtanh']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rms_norm = nn.RMSNorm(64)  # Assuming input size 64 for RMSNorm
        self.conv_transpose3d = nn.ConvTranspose3d(1, 10, kernel_size=3, stride=2, padding=1)
        self.fractional_max_pool2d = nn.FractionalMaxPool2d(kernel_size=2, output_size=(14, 14))
        self.log_sigmoid = nn.LogSigmoid()
        self.unflatten = nn.Unflatten(1, (10, 14, 14))
        self.zero_pad3d = nn.ZeroPad3d(1)
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.container = nn.Sequential(
            nn.ConvTranspose3d(10, 20, kernel_size=3, stride=2, padding=1),
            nn.FractionalMaxPool2d(kernel_size=2, output_size=(7, 7)),
            nn.LogSigmoid(),
            nn.Unflatten(1, (20, 7, 7)),
            nn.ZeroPad3d(1),
            nn.Hardtanh(min_val=-1.0, max_val=1.0)
        )
        self.bce_loss = nn.BCELoss()
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Apply RMSNorm
        x = self.rms_norm(x)
        
        # Reshape for ConvTranspose3d
        x = x.view(-1, 1, 8, 8, 8)  # Assuming input is reshaped to 3D
        
        # Apply ConvTranspose3d
        x = self.conv_transpose3d(x)
        
        # Reshape for FractionalMaxPool2d
        x = x.view(-1, 10, 16, 16)
        
        # Apply FractionalMaxPool2d
        x = self.fractional_max_pool2d(x)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Apply Unflatten
        x = self.unflatten(x)
        
        # Apply ZeroPad3d
        x = self.zero_pad3d(x)
        
        # Apply Hardtanh
        x = self.hardtanh(x)
        
        # Apply Container (Sequential)
        x = self.container(x)
        
        # Reshape for BCELoss and GaussianNLLLoss
        x = x.view(-1, 20 * 7 * 7)
        
        # Dummy target for loss functions
        target = torch.rand_like(x)
        var = torch.ones_like(x)
        
        # Apply BCELoss
        bce_loss = self.bce_loss(x, target)
        
        # Apply GaussianNLLLoss
        gaussian_nll_loss = self.gaussian_nll_loss(x, target, var)
        
        return x, bce_loss, gaussian_nll_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 64).cuda()  # Assuming input size 64 for RMSNorm
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

