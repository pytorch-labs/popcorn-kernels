
# This is a random torch model generated by the following modules: ['GRUCell', 'ReplicationPad1d', 'Hardtanh', 'RNN', 'ReplicationPad3d', 'AdaptiveAvgPool1d', 'BatchNorm3d', 'Conv2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm3d(16)
        self.rnn = nn.RNN(input_size=16, hidden_size=32, num_layers=2, batch_first=True)
        self.gru_cell = nn.GRUCell(input_size=32, hidden_size=32)
        self.pad1d = nn.ReplicationPad1d(2)
        self.pad3d = nn.ReplicationPad3d(1)
        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size=16)
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        x = self.conv1(x)  # Shape: (batch_size, 16, height, width)
        x = x.unsqueeze(2)  # Shape: (batch_size, 16, 1, height, width)
        x = self.bn1(x)  # Shape: (batch_size, 16, 1, height, width)
        x = x.squeeze(2)  # Shape: (batch_size, 16, height, width)
        
        # Reshape for RNN
        batch_size, channels, height, width = x.size()
        x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # Shape: (batch_size, height*width, 16)
        
        x, _ = self.rnn(x)  # Shape: (batch_size, height*width, 32)
        
        # Apply GRUCell
        hx = torch.zeros(batch_size, 32).to(x.device)
        for i in range(x.size(1)):
            hx = self.gru_cell(x[:, i, :], hx)
        x = hx  # Shape: (batch_size, 32)
        
        # Apply ReplicationPad1d
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 32)
        x = self.pad1d(x)  # Shape: (batch_size, 1, 36)
        
        # Apply AdaptiveAvgPool1d
        x = self.adaptive_pool(x)  # Shape: (batch_size, 1, 16)
        
        # Apply ReplicationPad3d
        x = x.unsqueeze(1).unsqueeze(1)  # Shape: (batch_size, 1, 1, 1, 16)
        x = self.pad3d(x)  # Shape: (batch_size, 1, 3, 3, 18)
        
        # Apply Hardtanh
        x = self.hardtanh(x)  # Shape: (batch_size, 1, 3, 3, 18)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
