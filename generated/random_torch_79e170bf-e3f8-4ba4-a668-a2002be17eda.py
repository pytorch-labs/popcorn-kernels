
# This is a random torch model generated by the following modules: ['Threshold', 'LazyConvTranspose3d', 'RNNBase', 'LazyBatchNorm2d', 'MaxUnpool1d', 'PixelShuffle', 'GroupNorm', 'ConvTranspose1d', 'PReLU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.threshold = nn.Threshold(0.1, 0.5)
        self.lazy_conv_transpose3d = nn.LazyConvTranspose3d(out_channels=16, kernel_size=3, stride=2)
        self.rnn = nn.RNNBase(mode='LSTM', input_size=16, hidden_size=32, num_layers=2)
        self.lazy_batch_norm2d = nn.LazyBatchNorm2d()
        self.max_unpool1d = nn.MaxUnpool1d(kernel_size=2, stride=2)
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.group_norm = nn.GroupNorm(num_groups=4, num_channels=16)
        self.conv_transpose1d = nn.ConvTranspose1d(in_channels=16, out_channels=8, kernel_size=3, stride=2)
        self.prelu = nn.PReLU()

    def forward(self, x):
        # Apply Threshold
        x = self.threshold(x)
        
        # Reshape for LazyConvTranspose3d
        x = x.view(-1, 1, 8, 8, 8)  # Arbitrary reshape to fit 3D convolution
        x = self.lazy_conv_transpose3d(x)
        
        # Reshape for RNNBase
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x, _ = self.rnn(x)
        
        # Reshape for LazyBatchNorm2d
        x = x.view(x.size(0), x.size(1), 8, 8)  # Arbitrary reshape to fit 2D batch norm
        x = self.lazy_batch_norm2d(x)
        
        # Reshape for MaxUnpool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x = self.max_unpool1d(x, indices=torch.arange(x.size(2)).unsqueeze(0).unsqueeze(0).repeat(x.size(0), x.size(1), 1))
        
        # Reshape for PixelShuffle
        x = x.view(x.size(0), x.size(1), 8, 8)  # Arbitrary reshape to fit PixelShuffle
        x = self.pixel_shuffle(x)
        
        # Apply GroupNorm
        x = self.group_norm(x)
        
        # Reshape for ConvTranspose1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x = self.conv_transpose1d(x)
        
        # Apply PReLU
        x = self.prelu(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
