
# This is a random torch model generated by the following modules: ['Tanhshrink', 'BCELoss', 'MaxPool1d', 'AvgPool1d', 'Threshold', 'EmbeddingBag', 'ConstantPad1d', 'ModuleList']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 64, mode='mean')
        self.constant_pad = nn.ConstantPad1d(2, 3.0)
        self.max_pool = nn.MaxPool1d(kernel_size=2)
        self.avg_pool = nn.AvgPool1d(kernel_size=2)
        self.threshold = nn.Threshold(0.5, 1.0)
        self.tanhshrink = nn.Tanhshrink()
        self.module_list = nn.ModuleList([
            nn.Linear(64, 32),
            nn.Linear(32, 16),
            nn.Linear(16, 8)
        ])
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        x = x.unsqueeze(1)  # Add a dimension for pooling
        x = self.constant_pad(x)
        x = self.max_pool(x)
        x = self.avg_pool(x)
        x = self.threshold(x)
        x = self.tanhshrink(x)
        x = x.squeeze(1)  # Remove the extra dimension
        for layer in self.module_list:
            x = layer(x)
        # Assuming we have a target tensor for BCELoss
        target = torch.rand_like(x)
        loss = self.bce_loss(torch.sigmoid(x), target)
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

