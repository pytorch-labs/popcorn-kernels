
# This is a random torch model generated by the following modules: ['ReplicationPad3d', 'Container', 'ZeroPad2d', 'Tanhshrink', 'AdaptiveMaxPool3d', 'ZeroPad3d', 'GRUCell', 'LogSigmoid', 'ELU', 'GRU']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.replication_pad3d = nn.ReplicationPad3d(1)
        self.zero_pad2d = nn.ZeroPad2d(1)
        self.zero_pad3d = nn.ZeroPad3d(1)
        self.tanhshrink = nn.Tanhshrink()
        self.adaptive_max_pool3d = nn.AdaptiveMaxPool3d((5, 5, 5))
        self.gru_cell = nn.GRUCell(125, 50)  # Assuming input size 125 and hidden size 50
        self.log_sigmoid = nn.LogSigmoid()
        self.elu = nn.ELU()
        self.gru = nn.GRU(50, 10, batch_first=True)  # Assuming input size 50 and hidden size 10

    def forward(self, x):
        # Apply ReplicationPad3d
        x = self.replication_pad3d(x)
        
        # Reshape to apply ZeroPad2d
        x = x.view(x.size(0), x.size(1), x.size(2), -1)
        x = self.zero_pad2d(x)
        
        # Reshape back to 3D for ZeroPad3d
        x = x.view(x.size(0), x.size(1), x.size(2), x.size(3), -1)
        x = self.zero_pad3d(x)
        
        # Apply Tanhshrink
        x = self.tanhshrink(x)
        
        # Apply AdaptiveMaxPool3d
        x = self.adaptive_max_pool3d(x)
        
        # Flatten for GRUCell
        x = x.view(x.size(0), -1)
        hx = torch.zeros(x.size(0), 50).to(x.device)  # Initialize hidden state for GRUCell
        x = self.gru_cell(x, hx)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Apply ELU
        x = self.elu(x)
        
        # Reshape for GRU
        x = x.unsqueeze(1)  # Add sequence dimension
        h0 = torch.zeros(1, x.size(0), 10).to(x.device)  # Initialize hidden state for GRU
        x, _ = self.gru(x, h0)
        
        # Final output
        x = x.squeeze(1)
        return x

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 10, 10, 10).cuda()  # Example input shape (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
