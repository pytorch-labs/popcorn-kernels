
# This is a random torch model generated by the following modules: ['EmbeddingBag', 'GLU', 'LogSigmoid', 'LazyConv2d', 'AdaptiveAvgPool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(num_embeddings=1000, embedding_dim=64, mode='mean')
        self.glu = nn.GLU(dim=1)
        self.log_sigmoid = nn.LogSigmoid()
        self.lazy_conv2d = nn.LazyConv2d(out_channels=32, kernel_size=3, stride=1, padding=1)
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d(output_size=(8, 8, 8))
        self.fc = nn.Linear(32 * 8 * 8 * 8, 10)

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Reshape for GLU
        x = x.unsqueeze(1)  # Add a dimension for GLU
        x = self.glu(x)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Reshape for LazyConv2d
        x = x.unsqueeze(1)  # Add a channel dimension
        x = self.lazy_conv2d(x)
        
        # Reshape for AdaptiveAvgPool3d
        x = x.unsqueeze(2)  # Add a depth dimension
        x = self.adaptive_avg_pool3d(x)
        
        # Flatten for Linear layer
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

