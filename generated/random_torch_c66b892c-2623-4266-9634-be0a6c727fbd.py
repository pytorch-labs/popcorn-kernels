
# This is a random torch model generated by the following modules: ['ConstantPad3d', 'LazyConvTranspose1d', 'RNNBase']
import torch
import torch.nn as nn


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pad = nn.ConstantPad3d(padding=1, value=0)
        self.conv_transpose1 = nn.LazyConvTranspose1d(out_channels=32, kernel_size=3, stride=2)
        self.conv_transpose2 = nn.LazyConvTranspose1d(out_channels=64, kernel_size=3, stride=2)
        self.rnn = nn.RNNBase(mode='LSTM', input_size=64, hidden_size=128, num_layers=2, batch_first=True)
        self.fc = nn.Linear(128, 10)

    def forward(self, x):
        # Pad the input
        x = self.pad(x)
        
        # Apply the first ConvTranspose1d
        x = self.conv_transpose1(x)
        
        # Apply the second ConvTranspose1d
        x = self.conv_transpose2(x)
        
        # Reshape for RNN
        x = x.view(x.size(0), x.size(1), -1)  # Reshape to (batch_size, seq_len, features)
        
        # Pass through RNN
        x, _ = self.rnn(x)
        
        # Take the last output of the RNN
        x = x[:, -1, :]
        
        # Fully connected layer
        x = self.fc(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64, 64).cuda()  # Example input with arbitrary shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

