
# This is a random torch model generated by the following modules: ['LazyConv3d', 'RMSNorm', 'CircularPad2d', 'NLLLoss2d', 'MarginRankingLoss', 'ModuleDict', 'CircularPad1d', 'RNNCellBase']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv3d = nn.LazyConv3d(out_channels=16, kernel_size=3)
        self.rms_norm = nn.RMSNorm(16)
        self.circular_pad2d = nn.CircularPad2d(1)
        self.circular_pad1d = nn.CircularPad1d(1)
        self.rnn_cell = nn.RNNCellBase(input_size=16, hidden_size=32)
        self.module_dict = nn.ModuleDict({
            'conv3d_2': nn.LazyConv3d(out_channels=32, kernel_size=3),
            'rms_norm_2': nn.RMSNorm(32)
        })
        self.nll_loss2d = nn.NLLLoss2d()
        self.margin_ranking_loss = nn.MarginRankingLoss()

    def forward(self, x):
        # Apply LazyConv3d
        x = self.conv3d(x)
        
        # Apply RMSNorm
        x = self.rms_norm(x)
        
        # Reshape for CircularPad2d
        x = x.view(x.size(0), x.size(1), x.size(2), -1)
        x = self.circular_pad2d(x)
        
        # Reshape back for RNNCellBase
        x = x.view(x.size(0), x.size(1), x.size(2), x.size(3), -1)
        x = x.permute(0, 2, 3, 1, 4).contiguous()
        x = x.view(-1, x.size(-2), x.size(-1))
        
        # Apply RNNCellBase
        hx = torch.zeros(x.size(0), 32).to(x.device)
        x = self.rnn_cell(x, hx)
        
        # Apply ModuleDict
        x = self.module_dict['conv3d_2'](x)
        x = self.module_dict['rms_norm_2'](x)
        
        # Reshape for CircularPad1d
        x = x.view(x.size(0), x.size(1), -1)
        x = self.circular_pad1d(x)
        
        # Reshape for NLLLoss2d
        x = x.view(x.size(0), x.size(1), x.size(2), -1)
        
        # Apply NLLLoss2d (assuming target is provided)
        target = torch.randint(0, x.size(1), (x.size(0), x.size(2), x.size(3))).to(x.device)
        x = self.nll_loss2d(x, target)
        
        # Apply MarginRankingLoss (assuming input1, input2, and target are provided)
        input1 = torch.randn_like(x)
        input2 = torch.randn_like(x)
        target = torch.randint(0, 2, (x.size(0),)).to(x.device)
        x = self.margin_ranking_loss(input1, input2, target)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 64, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

