
# This is a random torch model generated by the following modules: ['ParameterDict', 'FeatureAlphaDropout', 'LeakyReLU', 'PixelUnshuffle', 'UpsamplingNearest2d', 'PReLU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.params = nn.ParameterDict({
            'weight1': nn.Parameter(torch.randn(16, 3, 3, 3)),
            'weight2': nn.Parameter(torch.randn(32, 16, 3, 3))
        })
        self.dropout = nn.FeatureAlphaDropout(p=0.5)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)
        self.pixel_unshuffle = nn.PixelUnshuffle(downscale_factor=2)
        self.upsample = nn.UpsamplingNearest2d(scale_factor=2)
        self.prelu = nn.PReLU(num_parameters=32)

    def forward(self, x):
        # Apply PixelUnshuffle to reduce spatial dimensions and increase channels
        x = self.pixel_unshuffle(x)
        
        # Apply first convolution-like operation using ParameterDict
        x = F.conv2d(x, self.params['weight1'], stride=1, padding=1)
        x = self.leaky_relu(x)
        
        # Apply FeatureAlphaDropout
        x = self.dropout(x)
        
        # Apply second convolution-like operation using ParameterDict
        x = F.conv2d(x, self.params['weight2'], stride=1, padding=1)
        x = self.prelu(x)
        
        # Apply upsampling to increase spatial dimensions
        x = self.upsample(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
