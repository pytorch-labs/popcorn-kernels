
# This is a random torch model generated by the following modules: ['MultiMarginLoss', 'CELU', 'BCEWithLogitsLoss', 'LayerNorm', 'LazyInstanceNorm3d', 'LeakyReLU', 'ModuleDict', 'GRU', 'CTCLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.layer_norm = nn.LayerNorm(128)
        self.lazy_instance_norm = nn.LazyInstanceNorm3d()
        self.leaky_relu = nn.LeakyReLU()
        self.celu = nn.CELU()
        self.gru = nn.GRU(input_size=128, hidden_size=64, num_layers=2, batch_first=True)
        self.module_dict = nn.ModuleDict({
            'fc1': nn.Linear(64, 32),
            'fc2': nn.Linear(32, 16)
        })
        self.multi_margin_loss = nn.MultiMarginLoss()
        self.bce_with_logits_loss = nn.BCEWithLogitsLoss()
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, feature_dim)
        x = self.layer_norm(x)
        x = x.unsqueeze(1)  # Add a channel dimension for LazyInstanceNorm3d
        x = self.lazy_instance_norm(x)
        x = x.squeeze(1)  # Remove the channel dimension
        x = self.leaky_relu(x)
        x = self.celu(x)
        
        # GRU expects input of shape (batch_size, sequence_length, feature_dim)
        x, _ = self.gru(x)
        
        # Apply the ModuleDict layers
        x = self.module_dict['fc1'](x)
        x = self.module_dict['fc2'](x)
        
        # Compute losses (for demonstration purposes, we'll compute them but not use them in the output)
        target = torch.randint(0, 16, (x.size(0), x.size(1)), device=x.device)
        multi_margin_loss = self.multi_margin_loss(x.view(-1, 16), target.view(-1))
        
        bce_target = torch.randn_like(x).sigmoid()
        bce_loss = self.bce_with_logits_loss(x, bce_target)
        
        ctc_input = x.permute(1, 0, 2)  # CTC expects (sequence_length, batch_size, num_classes)
        ctc_target = torch.randint(1, 16, (x.size(0), x.size(1) // 2), device=x.device)
        input_lengths = torch.full((x.size(0),), x.size(1), dtype=torch.long, device=x.device)
        target_lengths = torch.full((x.size(0),), x.size(1) // 2, dtype=torch.long, device=x.device)
        ctc_loss = self.ctc_loss(ctc_input, ctc_target, input_lengths, target_lengths)
        
        # Return the final output and the computed losses (for demonstration)
        return x, multi_margin_loss, bce_loss, ctc_loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(2, 10, 128).cuda()  # batch_size=2, sequence_length=10, feature_dim=128
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
