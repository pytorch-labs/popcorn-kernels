
# This is a random torch model generated by the following modules: ['BatchNorm3d', 'LazyConv2d', 'NLLLoss', 'FractionalMaxPool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.bn1 = nn.BatchNorm3d(1)  # Assuming input has 1 channel in the 3D batch norm
        self.conv1 = nn.LazyConv2d(10, kernel_size=5)  # LazyConv2d will infer the input channels
        self.conv2 = nn.LazyConv2d(20, kernel_size=5)  # LazyConv2d will infer the input channels
        self.fmp1 = nn.FractionalMaxPool3d(kernel_size=2, output_size=(10, 10, 10))  # FractionalMaxPool3d
        self.bn2 = nn.BatchNorm3d(20)  # BatchNorm3d after the second convolution
        self.fc1 = nn.Linear(2000, 50)  # Linear layer after flattening
        self.fc2 = nn.Linear(50, 10)  # Final Linear layer
        self.nll_loss = nn.NLLLoss()  # NLLLoss for the loss function

    def forward(self, x):
        # Apply BatchNorm3d
        x = self.bn1(x)
        
        # Reshape to 2D for LazyConv2d
        x = x.view(x.size(0), -1, x.size(3), x.size(4))  # Reshape to (batch_size, channels, height, width)
        
        # Apply LazyConv2d and ReLU
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        
        # Reshape back to 3D for FractionalMaxPool3d
        x = x.view(x.size(0), 20, -1, x.size(2), x.size(3))  # Reshape to (batch_size, channels, depth, height, width)
        
        # Apply FractionalMaxPool3d
        x = self.fmp1(x)
        
        # Apply BatchNorm3d
        x = self.bn2(x)
        
        # Flatten the tensor for the Linear layer
        x = x.view(x.size(0), -1)
        
        # Apply Linear layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        
        # Apply log_softmax for NLLLoss
        x = F.log_softmax(x, dim=1)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 10, 64, 64).cuda()  # Example input shape: (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

