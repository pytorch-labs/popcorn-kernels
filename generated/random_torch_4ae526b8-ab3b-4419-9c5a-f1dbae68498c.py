
# This is a random torch model generated by the following modules: ['InstanceNorm3d', 'SELU', 'Bilinear', 'GroupNorm', 'PReLU', 'Unfold']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.instance_norm = nn.InstanceNorm3d(10)
        self.selu = nn.SELU()
        self.bilinear = nn.Bilinear(10, 10, 20)
        self.group_norm = nn.GroupNorm(2, 20)
        self.prelu = nn.PReLU()
        self.unfold = nn.Unfold(kernel_size=(3, 3), padding=1)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.instance_norm(x)  # Apply InstanceNorm3d
        x = self.selu(x)  # Apply SELU activation
        
        # Reshape for Bilinear layer
        batch_size, channels, depth, height, width = x.shape
        x = x.view(batch_size, channels, -1)  # Flatten spatial dimensions
        x = x.permute(0, 2, 1)  # Swap dimensions for Bilinear
        x = self.bilinear(x, x)  # Apply Bilinear layer
        x = x.permute(0, 2, 1)  # Swap back dimensions
        
        # Reshape for GroupNorm
        x = x.view(batch_size, 20, depth, height, width)  # Reshape back to 5D
        x = self.group_norm(x)  # Apply GroupNorm
        
        x = self.prelu(x)  # Apply PReLU activation
        
        # Reshape for Unfold
        x = x.view(batch_size, 20, depth, height, width)  # Ensure correct shape
        x = self.unfold(x)  # Apply Unfold
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 5, 32, 32).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

