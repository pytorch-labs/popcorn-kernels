
# This is a random torch model generated by the following modules: ['Fold', 'Unflatten', 'Hardswish', 'L1Loss', 'BCELoss']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.unflatten = nn.Unflatten(1, (1, 28, 28))  # Assuming input is flattened, unflatten to (batch, 1, 28, 28)
        self.fold = nn.Fold(output_size=(14, 14), kernel_size=(2, 2), stride=(2, 2))  # Fold to (batch, 1, 14, 14)
        self.hardswish = nn.Hardswish()
        self.l1_loss = nn.L1Loss()
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Unflatten the input to a 4D tensor
        x = self.unflatten(x)
        
        # Fold the tensor to reduce spatial dimensions
        x = self.fold(x)
        
        # Apply Hardswish activation
        x = self.hardswish(x)
        
        # Compute L1 loss with respect to a target tensor (for demonstration, we use a tensor of zeros)
        target_l1 = torch.zeros_like(x)
        l1_loss = self.l1_loss(x, target_l1)
        
        # Compute BCE loss with respect to a target tensor (for demonstration, we use a tensor of ones)
        target_bce = torch.ones_like(x)
        bce_loss = self.bce_loss(torch.sigmoid(x), target_bce)
        
        # Return both losses as a tuple
        return l1_loss, bce_loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 784).cuda()  # Flattened input of shape (batch, 784)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
