
# This is a random torch model generated by the following modules: ['Embedding', 'ChannelShuffle', 'PoissonNLLLoss', 'ParameterList', 'LazyBatchNorm2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Embedding layer
        self.channel_shuffle = nn.ChannelShuffle(4)  # ChannelShuffle layer
        self.lazy_bn = nn.LazyBatchNorm2d()  # LazyBatchNorm2d layer
        self.param_list = nn.ParameterList([nn.Parameter(torch.randn(128)) for _ in range(5)])  # ParameterList with 5 parameters
        self.poisson_loss = nn.PoissonNLLLoss()  # PoissonNLLLoss layer

    def forward(self, x):
        # Assume input x is of shape (batch_size, sequence_length)
        x = self.embedding(x)  # Shape: (batch_size, sequence_length, embedding_dim)
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, sequence_length, embedding_dim)
        x = self.channel_shuffle(x)  # Shape: (batch_size, 1, sequence_length, embedding_dim)
        x = self.lazy_bn(x)  # Shape: (batch_size, 1, sequence_length, embedding_dim)
        
        # Apply parameters from ParameterList
        for param in self.param_list:
            x = x * param.view(1, 1, 1, -1)  # Shape remains the same
        
        # Flatten the tensor for PoissonNLLLoss
        x = x.view(-1)  # Shape: (batch_size * sequence_length * embedding_dim)
        
        # Generate a target tensor for PoissonNLLLoss
        target = torch.randint(0, 10, x.shape).float().to(x.device)
        
        # Apply PoissonNLLLoss
        loss = self.poisson_loss(x, target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (32, 50)).cuda()  # Shape: (batch_size, sequence_length)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

