
# This is a random torch model generated by the following modules: ['PixelUnshuffle', 'LazyConv1d', 'MultiMarginLoss', 'Dropout', 'MSELoss', 'LogSigmoid']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pixel_unshuffle = nn.PixelUnshuffle(downscale_factor=2)
        self.lazy_conv1d = nn.LazyConv1d(out_channels=64, kernel_size=3)
        self.dropout = nn.Dropout(p=0.5)
        self.log_sigmoid = nn.LogSigmoid()
        self.multi_margin_loss = nn.MultiMarginLoss()
        self.mse_loss = nn.MSELoss()

    def forward(self, x):
        # Apply PixelUnshuffle to reduce spatial dimensions
        x = self.pixel_unshuffle(x)
        
        # Reshape to fit LazyConv1d input requirements
        batch_size, channels, height, width = x.shape
        x = x.view(batch_size, channels * height, width)
        
        # Apply LazyConv1d
        x = self.lazy_conv1d(x)
        
        # Apply Dropout
        x = self.dropout(x)
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Compute MultiMarginLoss (requires target, so we generate a dummy target)
        dummy_target = torch.randint(0, x.size(1), (x.size(0),)).to(x.device)
        multi_margin_loss = self.multi_margin_loss(x, dummy_target)
        
        # Compute MSELoss (requires target, so we generate a dummy target)
        dummy_target_mse = torch.randn_like(x)
        mse_loss = self.mse_loss(x, dummy_target_mse)
        
        # Return both losses for demonstration purposes
        return multi_margin_loss, mse_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input with 3 channels, 64x64 spatial dimensions
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

