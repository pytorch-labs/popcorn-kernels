
# This is a random torch model generated by the following modules: ['Embedding', 'Linear', 'MaxPool3d', 'ZeroPad3d', 'ConvTranspose1d', 'LazyConvTranspose2d', 'Bilinear', 'MaxUnpool2d', 'InstanceNorm3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Embedding layer
        self.linear1 = nn.Linear(128, 256)  # Linear layer
        self.maxpool3d = nn.MaxPool3d(kernel_size=(2, 2, 2))  # MaxPool3d layer
        self.zeropad3d = nn.ZeroPad3d(1)  # ZeroPad3d layer
        self.convtranspose1d = nn.ConvTranspose1d(256, 128, kernel_size=3, stride=2)  # ConvTranspose1d layer
        self.lazyconvtranspose2d = nn.LazyConvTranspose2d(64, kernel_size=3, stride=2)  # LazyConvTranspose2d layer
        self.bilinear = nn.Bilinear(64, 64, 32)  # Bilinear layer
        self.maxunpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2)  # MaxUnpool2d layer
        self.instancenorm3d = nn.InstanceNorm3d(32)  # InstanceNorm3d layer

    def forward(self, x):
        # Assume x is a tensor of arbitrary shape
        x = self.embedding(x.long())  # Embedding layer expects integer input
        x = x.view(-1, 128)  # Reshape for Linear layer
        x = F.relu(self.linear1(x))  # Linear layer with ReLU
        x = x.view(-1, 256, 1, 1, 1)  # Reshape for MaxPool3d
        x = self.maxpool3d(x)  # MaxPool3d layer
        x = self.zeropad3d(x)  # ZeroPad3d layer
        x = x.view(-1, 256, 1)  # Reshape for ConvTranspose1d
        x = F.relu(self.convtranspose1d(x))  # ConvTranspose1d layer with ReLU
        x = x.view(-1, 128, 1, 1)  # Reshape for LazyConvTranspose2d
        x = F.relu(self.lazyconvtranspose2d(x))  # LazyConvTranspose2d layer with ReLU
        x = x.view(-1, 64)  # Reshape for Bilinear layer
        x = self.bilinear(x, x)  # Bilinear layer
        x = x.view(-1, 32, 1, 1)  # Reshape for MaxUnpool2d
        x = self.maxunpool2d(x, indices=torch.zeros_like(x).long())  # MaxUnpool2d layer
        x = x.view(-1, 32, 1, 1, 1)  # Reshape for InstanceNorm3d
        x = self.instancenorm3d(x)  # InstanceNorm3d layer
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (1, 10)).cuda()  # Random input for Embedding layer
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

