
# This is a random torch model generated by the following modules: ['MarginRankingLoss', 'MaxPool1d', 'ELU', 'Softmin', 'CTCLoss', 'ReLU', 'LazyConvTranspose3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose1 = nn.LazyConvTranspose3d(out_channels=16, kernel_size=3)
        self.conv_transpose2 = nn.LazyConvTranspose3d(out_channels=32, kernel_size=3)
        self.max_pool1d = nn.MaxPool1d(kernel_size=2)
        self.elu = nn.ELU()
        self.relu = nn.ReLU()
        self.softmin = nn.Softmin(dim=1)
        self.margin_ranking_loss = nn.MarginRankingLoss()
        self.ctc_loss = nn.CTCLoss()

    def forward(self, x):
        # Apply ConvTranspose3d layers
        x = self.conv_transpose1(x)
        x = self.conv_transpose2(x)
        
        # Reshape for MaxPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten spatial dimensions
        x = self.max_pool1d(x)
        
        # Apply activation functions
        x = self.elu(x)
        x = self.relu(x)
        
        # Reshape for Softmin
        x = x.view(x.size(0), -1)  # Flatten all dimensions except batch
        x = self.softmin(x)
        
        # Dummy targets for loss functions (since they require targets)
        target1 = torch.randint(0, x.size(1), (x.size(0),), dtype=torch.long)
        target2 = torch.randint(0, x.size(1), (x.size(0),), dtype=torch.long)
        
        # Apply MarginRankingLoss (requires two inputs and a target)
        margin_target = torch.ones(x.size(0))
        loss1 = self.margin_ranking_loss(x[:, 0], x[:, 1], margin_target)
        
        # Apply CTCLoss (requires log probabilities, targets, input lengths, and target lengths)
        input_lengths = torch.full((x.size(0),), x.size(1), dtype=torch.long)
        target_lengths = torch.randint(1, x.size(1), (x.size(0),), dtype=torch.long)
        loss2 = self.ctc_loss(x.log_softmax(dim=1), target1, input_lengths, target_lengths)
        
        # Return the sum of losses as the output
        return loss1 + loss2


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 32, 32, 32).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

