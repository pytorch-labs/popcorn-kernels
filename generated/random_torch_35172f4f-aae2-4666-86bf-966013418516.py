
# This is a random torch model generated by the following modules: ['CosineSimilarity', 'Flatten', 'Dropout3d', 'ConvTranspose2d', 'LSTMCell']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose1 = nn.ConvTranspose2d(3, 16, kernel_size=3, stride=2, padding=1)
        self.conv_transpose2 = nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1)
        self.dropout3d = nn.Dropout3d(p=0.5)
        self.flatten = nn.Flatten()
        self.lstm_cell = nn.LSTMCell(128, 64)
        self.cosine_sim = nn.CosineSimilarity(dim=1)

    def forward(self, x):
        # Apply ConvTranspose2d layers
        x = F.relu(self.conv_transpose1(x))
        x = F.relu(self.conv_transpose2(x))
        
        # Reshape for Dropout3d
        x = x.unsqueeze(1)  # Add a dummy dimension for 3D dropout
        x = self.dropout3d(x)
        x = x.squeeze(1)  # Remove the dummy dimension
        
        # Flatten the output
        x = self.flatten(x)
        
        # Prepare for LSTM Cell
        batch_size = x.size(0)
        hx = torch.zeros(batch_size, 64).to(x.device)
        cx = torch.zeros(batch_size, 64).to(x.device)
        
        # Apply LSTM Cell
        hx, cx = self.lstm_cell(x, (hx, cx))
        
        # Apply CosineSimilarity
        x = self.cosine_sim(hx, cx)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
