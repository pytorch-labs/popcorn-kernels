
# This is a random torch model generated by the following modules: ['GRUCell', 'AdaptiveMaxPool3d', 'ParameterList', 'Tanhshrink', 'BatchNorm1d', 'SELU', 'BCEWithLogitsLoss', 'MultiMarginLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.gru_cell = nn.GRUCell(input_size=128, hidden_size=256)
        self.adaptive_max_pool3d = nn.AdaptiveMaxPool3d(output_size=(8, 8, 8))
        self.parameter_list = nn.ParameterList([nn.Parameter(torch.randn(10)) for _ in range(5)])
        self.batch_norm1d = nn.BatchNorm1d(num_features=256)
        self.selu = nn.SELU()
        self.tanhshrink = nn.Tanhshrink()
        self.bce_with_logits_loss = nn.BCEWithLogitsLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.adaptive_max_pool3d(x)  # Shape: (batch_size, channels, 8, 8, 8)
        x = x.view(x.size(0), -1)  # Flatten to (batch_size, channels * 8 * 8 * 8)
        x = self.batch_norm1d(x)  # Shape: (batch_size, channels * 8 * 8 * 8)
        x = self.selu(x)  # Shape: (batch_size, channels * 8 * 8 * 8)
        x = x.view(x.size(0), -1, 128)  # Reshape to (batch_size, seq_len, 128)
        
        hx = torch.zeros(x.size(0), 256).to(x.device)  # Initialize hidden state for GRUCell
        for i in range(x.size(1)):
            hx = self.gru_cell(x[:, i, :], hx)  # Shape: (batch_size, 256)
        
        x = self.tanhshrink(hx)  # Shape: (batch_size, 256)
        
        # Apply parameter list (just for demonstration, not used in forward pass)
        for param in self.parameter_list:
            pass  # Parameters are not used in forward pass
        
        # Loss functions are not used in forward pass, but can be used during training
        # For demonstration, let's compute a dummy loss
        dummy_target = torch.randint(0, 2, (x.size(0),)).float().to(x.device)
        bce_loss = self.bce_with_logits_loss(x[:, 0], dummy_target)
        
        dummy_target_multi = torch.randint(0, 5, (x.size(0),)).to(x.device)
        multi_margin_loss = self.multi_margin_loss(x[:, :5], dummy_target_multi)
        
        return x, bce_loss, multi_margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 16, 16, 16).cuda()  # Example input shape: (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

