
# This is a random torch model generated by the following modules: ['LazyBatchNorm3d', 'ReLU6', 'LazyConvTranspose1d', 'BCEWithLogitsLoss', 'MultiMarginLoss', 'FractionalMaxPool2d', 'Conv2d', 'ELU', 'ZeroPad2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.zero_pad = nn.ZeroPad2d(2)
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.LazyBatchNorm3d()
        self.elu = nn.ELU()
        self.fractional_max_pool = nn.FractionalMaxPool2d(kernel_size=2, output_size=(14, 14))
        self.conv_transpose1d = nn.LazyConvTranspose1d(out_channels=32, kernel_size=3, stride=1)
        self.relu6 = nn.ReLU6()
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.LazyBatchNorm3d()
        self.bce_loss = nn.BCEWithLogitsLoss()
        self.multi_margin_loss = nn.MultiMarginLoss()

    def forward(self, x):
        x = self.zero_pad(x)
        x = self.conv1(x)
        x = x.unsqueeze(2)  # Add a dimension to make it 5D for BatchNorm3d
        x = self.bn1(x)
        x = x.squeeze(2)  # Remove the added dimension
        x = self.elu(x)
        x = self.fractional_max_pool(x)
        x = x.view(x.size(0), x.size(1), -1)  # Reshape for ConvTranspose1d
        x = self.conv_transpose1d(x)
        x = x.view(x.size(0), 32, 14, 14)  # Reshape back to 4D
        x = self.relu6(x)
        x = self.conv2(x)
        x = x.unsqueeze(2)  # Add a dimension to make it 5D for BatchNorm3d
        x = self.bn2(x)
        x = x.squeeze(2)  # Remove the added dimension
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 28, 28).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
