
# This is a random torch model generated by the following modules: ['LPPool1d', 'LazyInstanceNorm3d', 'Softmax', 'PoissonNLLLoss', 'LSTMCell', 'UpsamplingBilinear2d', 'ParameterList']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lp_pool = nn.LPPool1d(norm_type=2, kernel_size=3, stride=2)
        self.instance_norm = nn.LazyInstanceNorm3d()
        self.softmax = nn.Softmax(dim=1)
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.lstm_cell = nn.LSTMCell(input_size=128, hidden_size=64)
        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)
        self.parameter_list = nn.ParameterList([nn.Parameter(torch.randn(10)) for _ in range(5)])

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        # Reshape to 1D for LPPool1d
        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, channels, height * width)
        x = self.lp_pool(x)
        
        # Reshape back to 3D for LazyInstanceNorm3d
        x = x.view(x.size(0), x.size(1), x.size(2), 1, 1)  # (batch_size, channels, height, 1, 1)
        x = self.instance_norm(x)
        
        # Reshape to 2D for Softmax
        x = x.view(x.size(0), -1)  # (batch_size, channels * height * 1 * 1)
        x = self.softmax(x)
        
        # Reshape to 3D for LSTMCell
        x = x.view(x.size(0), -1, 128)  # (batch_size, seq_len, 128)
        hx = torch.zeros(x.size(0), 64).to(x.device)
        cx = torch.zeros(x.size(0), 64).to(x.device)
        outputs = []
        for i in range(x.size(1)):
            hx, cx = self.lstm_cell(x[:, i, :], (hx, cx))
            outputs.append(hx)
        x = torch.stack(outputs, dim=1)
        
        # Reshape to 4D for UpsamplingBilinear2d
        x = x.view(x.size(0), x.size(1), 8, 8)  # (batch_size, seq_len, 8, 8)
        x = self.upsample(x)
        
        # Apply ParameterList
        for param in self.parameter_list:
            x = x + param.view(1, -1, 1, 1)
        
        # Compute PoissonNLLLoss (assuming target is the same as input)
        target = x.detach()  # Detach to avoid backprop through target
        loss = self.poisson_nll_loss(x, target)
        
        return x, loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
