
# This is a random torch model generated by the following modules: ['Bilinear', 'ReLU6', 'SELU', 'InstanceNorm2d', 'ModuleList', 'MultiLabelSoftMarginLoss', 'ParameterDict', 'LayerNorm']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.bilinear1 = nn.Bilinear(10, 20, 30)
        self.bilinear2 = nn.Bilinear(30, 40, 50)
        self.relu6 = nn.ReLU6()
        self.selu = nn.SELU()
        self.instance_norm = nn.InstanceNorm2d(10)
        self.layer_norm = nn.LayerNorm(50)
        
        # ModuleList to hold multiple layers
        self.module_list = nn.ModuleList([
            nn.Bilinear(50, 60, 70),
            nn.Bilinear(70, 80, 90),
            nn.Bilinear(90, 100, 110)
        ])
        
        # ParameterDict to hold parameters
        self.param_dict = nn.ParameterDict({
            'weight1': nn.Parameter(torch.randn(110, 120)),
            'weight2': nn.Parameter(torch.randn(120, 130))
        })
        
        self.loss = nn.MultiLabelSoftMarginLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, 10, 20)
        x = self.bilinear1(x[:, :10], x[:, 10:20])
        x = self.relu6(x)
        x = self.selu(x)
        
        # Reshape for InstanceNorm2d
        x = x.view(x.size(0), 10, -1, x.size(-1))
        x = self.instance_norm(x)
        x = x.view(x.size(0), -1)
        
        x = self.bilinear2(x[:, :30], x[:, 30:70])
        x = self.layer_norm(x)
        
        # Pass through ModuleList
        for module in self.module_list:
            x = module(x[:, :module.in1_features], x[:, module.in1_features:module.in1_features + module.in2_features])
        
        # Apply ParameterDict weights
        x = torch.matmul(x, self.param_dict['weight1'])
        x = torch.matmul(x, self.param_dict['weight2'])
        
        # Dummy target for loss calculation
        target = torch.randint(0, 2, (x.size(0), x.size(1))).float()
        loss = self.loss(x, target)
        
        return x, loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 20).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
