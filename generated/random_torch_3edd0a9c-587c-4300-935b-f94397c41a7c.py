
# This is a random torch model generated by the following modules: ['AvgPool3d', 'RNN', 'Embedding', 'GRUCell', 'TransformerEncoderLayer', 'Linear']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Embedding layer
        self.avg_pool = nn.AvgPool3d(kernel_size=(2, 2, 2))  # AvgPool3d layer
        self.rnn = nn.RNN(input_size=128, hidden_size=256, num_layers=2, batch_first=True)  # RNN layer
        self.gru_cell = nn.GRUCell(input_size=256, hidden_size=128)  # GRUCell layer
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model=128, nhead=8), num_layers=3
        )  # TransformerEncoderLayer
        self.linear1 = nn.Linear(128, 64)  # Linear layer
        self.linear2 = nn.Linear(64, 10)  # Linear layer

    def forward(self, x):
        # Assume x is a 3D tensor of shape (batch_size, sequence_length, feature_dim)
        # If not, reshape it accordingly
        x = self.embedding(x)  # Embedding
        x = x.unsqueeze(2).unsqueeze(3)  # Add dummy dimensions for AvgPool3d
        x = self.avg_pool(x)  # AvgPool3d
        x = x.squeeze(3).squeeze(2)  # Remove dummy dimensions
        x, _ = self.rnn(x)  # RNN
        # Apply GRUCell to each time step
        hx = torch.zeros(x.size(0), 128).to(x.device)  # Initialize hidden state for GRUCell
        for t in range(x.size(1)):
            hx = self.gru_cell(x[:, t, :], hx)
        x = hx.unsqueeze(1)  # Add sequence dimension for TransformerEncoder
        x = self.transformer_encoder(x)  # TransformerEncoder
        x = x.squeeze(1)  # Remove sequence dimension
        x = F.relu(self.linear1(x))  # Linear + ReLU
        x = self.linear2(x)  # Linear
        return x

def get_inputs():
    # Randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (32, 20)).cuda()  # (batch_size, sequence_length)
    return [x]

def get_init_inputs():
    # Randomly generate tensors required for initialization based on the model architecture
    return []
