
# This is a random torch model generated by the following modules: ['Flatten', 'AdaptiveMaxPool3d', 'TransformerEncoderLayer', 'LPPool3d', 'Hardsigmoid', 'Bilinear', 'RNNCellBase', 'InstanceNorm2d', 'PixelShuffle', 'InstanceNorm3d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.flatten = nn.Flatten()
        self.adaptive_max_pool3d = nn.AdaptiveMaxPool3d((8, 8, 8))
        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8)
        self.lp_pool3d = nn.LPPool3d(norm_type=2, kernel_size=2, stride=2)
        self.hardsigmoid = nn.Hardsigmoid()
        self.bilinear = nn.Bilinear(64, 64, 128)
        self.rnn_cell_base = nn.RNNCell(input_size=128, hidden_size=64)
        self.instance_norm2d = nn.InstanceNorm2d(num_features=64)
        self.pixel_shuffle = nn.PixelShuffle(upscale_factor=2)
        self.instance_norm3d = nn.InstanceNorm3d(num_features=64)

    def forward(self, x):
        # Assume input is of shape (batch_size, channels, depth, height, width)
        x = self.adaptive_max_pool3d(x)  # Shape: (batch_size, channels, 8, 8, 8)
        x = self.lp_pool3d(x)  # Shape: (batch_size, channels, 4, 4, 4)
        x = self.instance_norm3d(x)  # Shape: (batch_size, channels, 4, 4, 4)
        
        # Flatten the spatial dimensions
        x = x.view(x.size(0), x.size(1), -1)  # Shape: (batch_size, channels, 64)
        x = x.permute(2, 0, 1)  # Shape: (64, batch_size, channels)
        
        # Pass through TransformerEncoderLayer
        x = self.transformer_encoder_layer(x)  # Shape: (64, batch_size, 64)
        x = x.permute(1, 2, 0)  # Shape: (batch_size, 64, 64)
        
        # Apply Bilinear transformation
        x = self.bilinear(x, x)  # Shape: (batch_size, 128)
        
        # Pass through RNNCellBase
        hx = torch.zeros(x.size(0), 64).to(x.device)  # Initialize hidden state
        x = self.rnn_cell_base(x, hx)  # Shape: (batch_size, 64)
        
        # Reshape for 2D operations
        x = x.view(x.size(0), 64, 1, 1)  # Shape: (batch_size, 64, 1, 1)
        x = self.instance_norm2d(x)  # Shape: (batch_size, 64, 1, 1)
        
        # PixelShuffle
        x = self.pixel_shuffle(x)  # Shape: (batch_size, 16, 2, 2)
        
        # Flatten the output
        x = self.flatten(x)  # Shape: (batch_size, 64)
        
        # Apply Hardsigmoid
        x = self.hardsigmoid(x)  # Shape: (batch_size, 64)
        
        return x

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 64, 16, 16, 16).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
