
# This is a random torch model generated by the following modules: ['AvgPool2d', 'AdaptiveAvgPool1d', 'MaxPool3d', 'Bilinear', 'LPPool1d', 'UpsamplingBilinear2d', 'MultiLabelMarginLoss', 'Softmin']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.avgpool2d = nn.AvgPool2d(kernel_size=2, stride=2)
        self.adaptiveavgpool1d = nn.AdaptiveAvgPool1d(output_size=10)
        self.maxpool3d = nn.MaxPool3d(kernel_size=2, stride=2)
        self.bilinear = nn.Bilinear(in1_features=10, in2_features=10, out_features=20)
        self.lppool1d = nn.LPPool1d(norm_type=2, kernel_size=2, stride=2)
        self.upsamplingbilinear2d = nn.UpsamplingBilinear2d(scale_factor=2)
        self.multilabelmarginloss = nn.MultiLabelMarginLoss()
        self.softmin = nn.Softmin(dim=1)

    def forward(self, x):
        # Assume input x is of shape (batch_size, channels, height, width)
        x = self.avgpool2d(x)  # Shape: (batch_size, channels, height//2, width//2)
        
        # Reshape for AdaptiveAvgPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Shape: (batch_size, channels, (height//2 * width//2))
        x = self.adaptiveavgpool1d(x)  # Shape: (batch_size, channels, 10)
        
        # Reshape for MaxPool3d
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, channels, 10)
        x = self.maxpool3d(x)  # Shape: (batch_size, 1, channels//2, 5)
        
        # Reshape for Bilinear
        x1 = x[:, :, :, :5]  # Shape: (batch_size, 1, channels//2, 5)
        x2 = x[:, :, :, 5:]  # Shape: (batch_size, 1, channels//2, 5)
        x1 = x1.view(x1.size(0), -1)  # Shape: (batch_size, (1 * channels//2 * 5))
        x2 = x2.view(x2.size(0), -1)  # Shape: (batch_size, (1 * channels//2 * 5))
        x = self.bilinear(x1, x2)  # Shape: (batch_size, 20)
        
        # Reshape for LPPool1d
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 20)
        x = self.lppool1d(x)  # Shape: (batch_size, 1, 10)
        
        # Reshape for UpsamplingBilinear2d
        x = x.unsqueeze(-1)  # Shape: (batch_size, 1, 10, 1)
        x = self.upsamplingbilinear2d(x)  # Shape: (batch_size, 1, 20, 2)
        
        # Reshape for Softmin
        x = x.view(x.size(0), -1)  # Shape: (batch_size, 1 * 20 * 2)
        x = self.softmin(x)  # Shape: (batch_size, 40)
        
        # MultiLabelMarginLoss requires a target, so we skip it in the forward pass
        # and assume it will be used during training.
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

