
# This is a random torch model generated by the following modules: ['ConvTranspose3d', 'PReLU', 'SyncBatchNorm', 'PixelUnshuffle', 'BCELoss', 'RMSNorm', 'Softsign', 'AdaptiveLogSoftmaxWithLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose3d = nn.ConvTranspose3d(1, 10, kernel_size=3, stride=2, padding=1)
        self.prelu = nn.PReLU()
        self.sync_batch_norm = nn.SyncBatchNorm(10)
        self.pixel_unshuffle = nn.PixelUnshuffle(2)
        self.rms_norm = RMSNorm(10 * 4)  # Assuming RMSNorm is a custom layer
        self.softsign = nn.Softsign()
        self.adaptive_log_softmax = nn.AdaptiveLogSoftmaxWithLoss(10 * 4, 10, [5, 5])
        self.bce_loss = nn.BCELoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.conv_transpose3d(x)
        x = self.prelu(x)
        x = self.sync_batch_norm(x)
        
        # Reshape for PixelUnshuffle
        x = x.permute(0, 2, 1, 3, 4)  # Move depth to the channel dimension
        x = x.reshape(x.size(0), -1, x.size(3), x.size(4))  # Flatten depth and channels
        x = self.pixel_unshuffle(x)
        
        # Reshape back to 3D
        x = x.reshape(x.size(0), -1, x.size(2), x.size(3))
        x = x.permute(0, 2, 1, 3, 4)  # Move channels back
        
        x = self.rms_norm(x)
        x = self.softsign(x)
        
        # Flatten for AdaptiveLogSoftmaxWithLoss
        x = x.view(x.size(0), -1)
        output = self.adaptive_log_softmax(x, torch.randint(0, 10, (x.size(0),)).to(x.device))
        
        # Compute BCE loss (dummy target for demonstration)
        dummy_target = torch.rand_like(output.logits).round()
        loss = self.bce_loss(torch.sigmoid(output.logits), dummy_target)
        
        return output.logits, loss


class RMSNorm(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.scale = dim ** 0.5
        self.gamma = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        return F.normalize(x, dim=-1) * self.scale * self.gamma


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 16, 32, 32).cuda()  # Example input shape
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
