
# This is a random torch model generated by the following modules: ['SiLU', 'InstanceNorm1d', 'GELU', 'Bilinear', 'GRU', 'RReLU', 'MaxUnpool3d', 'AvgPool1d', 'CrossMapLRN2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.silu = nn.SiLU()
        self.instance_norm1d = nn.InstanceNorm1d(128)
        self.gelu = nn.GELU()
        self.bilinear = nn.Bilinear(128, 128, 64)
        self.gru = nn.GRU(64, 128, batch_first=True)
        self.rrelu = nn.RReLU()
        self.max_unpool3d = nn.MaxUnpool3d(kernel_size=2, stride=2)
        self.avg_pool1d = nn.AvgPool1d(kernel_size=2)
        self.cross_map_lrn2d = nn.CrossMapLRN2d(size=5)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        x = self.silu(x)
        
        # Reshape for InstanceNorm1d
        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, channels, height * width)
        x = self.instance_norm1d(x)
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        
        x = self.gelu(x)
        
        # Reshape for Bilinear
        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, channels, height * width)
        x = self.bilinear(x, x)
        
        # Reshape for GRU
        x = x.permute(0, 2, 1)  # (batch_size, height * width, channels)
        x, _ = self.gru(x)
        
        x = self.rrelu(x)
        
        # Reshape for MaxUnpool3d
        x = x.unsqueeze(1)  # Add a dummy dimension for 3D
        x = self.max_unpool3d(x, torch.zeros_like(x))  # Dummy indices
        
        # Reshape for AvgPool1d
        x = x.squeeze(1)  # Remove dummy dimension
        x = x.permute(0, 2, 1)  # (batch_size, channels, height * width)
        x = self.avg_pool1d(x)
        
        # Reshape for CrossMapLRN2d
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        x = self.cross_map_lrn2d(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 128, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
