
# This is a random torch model generated by the following modules: ['LazyInstanceNorm3d', 'Bilinear', 'LazyBatchNorm2d', 'AdaptiveMaxPool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.instance_norm1 = nn.LazyInstanceNorm3d()
        self.instance_norm2 = nn.LazyInstanceNorm3d()
        self.bilinear = nn.Bilinear(10, 10, 20)
        self.batch_norm = nn.LazyBatchNorm2d()
        self.adaptive_max_pool = nn.AdaptiveMaxPool3d((5, 5, 5))

    def forward(self, x):
        # Apply first instance normalization
        x = self.instance_norm1(x)
        
        # Reshape for Bilinear layer
        batch_size, *dims = x.shape
        x = x.view(batch_size, -1, 10)  # Assuming the last dimension is 10 for Bilinear
        x = self.bilinear(x, x)  # Bilinear layer requires two inputs
        
        # Reshape back to 3D for second instance normalization
        x = x.view(batch_size, *dims)
        x = self.instance_norm2(x)
        
        # Reshape for BatchNorm2d
        x = x.view(batch_size, -1, *dims[-2:])  # Assuming the last two dimensions are height and width
        x = self.batch_norm(x)
        
        # Reshape for AdaptiveMaxPool3d
        x = x.view(batch_size, -1, *dims[-3:])  # Assuming the last three dimensions are depth, height, and width
        x = self.adaptive_max_pool(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 10, 10, 10).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

