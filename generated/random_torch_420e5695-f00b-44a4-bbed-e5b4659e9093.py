
# This is a random torch model generated by the following modules: ['ZeroPad1d', 'BatchNorm2d', 'Unfold', 'Hardsigmoid', 'Conv2d', 'CrossMapLRN2d', 'Sigmoid', 'LocalResponseNorm']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.zero_pad = nn.ZeroPad1d(2)
        self.batch_norm = nn.BatchNorm2d(3)
        self.unfold = nn.Unfold(kernel_size=(3, 3), stride=(1, 1))
        self.hardsigmoid = nn.Hardsigmoid()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.cross_map_lrn = nn.CrossMapLRN2d(size=5, alpha=1e-4, beta=0.75, k=1.0)
        self.sigmoid = nn.Sigmoid()
        self.local_response_norm = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=1.0)

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, height, width)
        x = self.zero_pad(x)  # ZeroPad1d
        x = x.unsqueeze(1)  # Add a dummy dimension to match BatchNorm2d input
        x = self.batch_norm(x)  # BatchNorm2d
        x = x.squeeze(1)  # Remove the dummy dimension
        x = self.unfold(x)  # Unfold
        x = x.view(x.size(0), 3, 32, 32)  # Reshape to match Conv2d input
        x = self.hardsigmoid(x)  # Hardsigmoid
        x = self.conv1(x)  # Conv2d
        x = self.cross_map_lrn(x)  # CrossMapLRN2d
        x = self.conv2(x)  # Conv2d
        x = self.sigmoid(x)  # Sigmoid
        x = self.local_response_norm(x)  # LocalResponseNorm
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
