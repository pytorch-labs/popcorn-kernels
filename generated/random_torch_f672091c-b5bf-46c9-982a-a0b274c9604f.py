
# This is a random torch model generated by the following modules: ['TransformerEncoderLayer', 'ConvTranspose1d', 'ModuleList', 'EmbeddingBag', 'Fold', 'Dropout1d', 'ReLU6']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 128, mode='mean')
        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8)
        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=3)
        self.conv_transpose1d = nn.ConvTranspose1d(128, 64, kernel_size=3, stride=2)
        self.dropout1d = nn.Dropout1d(p=0.5)
        self.relu6 = nn.ReLU6()
        self.fold = nn.Fold(output_size=(10, 10), kernel_size=(2, 2), stride=(2, 2))
        self.module_list = nn.ModuleList([nn.Linear(64, 32), nn.Linear(32, 16), nn.Linear(16, 8)])

    def forward(self, x):
        # Assume x is a tensor of arbitrary shape
        x = x.view(-1)  # Flatten the input
        x = self.embedding_bag(x.view(1, -1))  # EmbeddingBag expects a 2D input
        x = x.unsqueeze(0)  # Add batch dimension for TransformerEncoder
        x = self.transformer_encoder(x)
        x = x.squeeze(0)  # Remove batch dimension
        x = x.unsqueeze(1)  # Add channel dimension for ConvTranspose1d
        x = self.conv_transpose1d(x)
        x = self.dropout1d(x)
        x = self.relu6(x)
        x = x.view(x.size(0), -1)  # Flatten for Fold
        x = self.fold(x.view(1, -1, 1, 1))  # Fold expects a 4D input
        x = x.view(x.size(0), -1)  # Flatten for ModuleList
        for layer in self.module_list:
            x = layer(x)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (100,)).cuda()  # Example input for EmbeddingBag
    return [x]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

