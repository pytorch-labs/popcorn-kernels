
# This is a random torch model generated by the following modules: ['LPPool2d', 'ModuleList', 'GRU', 'LazyConvTranspose3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lp_pool = nn.LPPool2d(norm_type=2, kernel_size=2, stride=2)
        self.conv_transpose_layers = nn.ModuleList([
            nn.LazyConvTranspose3d(out_channels=32, kernel_size=3, stride=1),
            nn.LazyConvTranspose3d(out_channels=64, kernel_size=3, stride=1),
            nn.LazyConvTranspose3d(out_channels=128, kernel_size=3, stride=1)
        ])
        self.gru = nn.GRU(input_size=128, hidden_size=64, num_layers=2, batch_first=True)

    def forward(self, x):
        # Apply LPPool2d
        x = self.lp_pool(x)
        
        # Reshape for ConvTranspose3d
        x = x.unsqueeze(1)  # Add a channel dimension
        x = x.unsqueeze(-1)  # Add a depth dimension
        
        # Apply ConvTranspose3d layers
        for conv_transpose in self.conv_transpose_layers:
            x = F.relu(conv_transpose(x))
        
        # Reshape for GRU
        x = x.view(x.size(0), -1, x.size(-1))  # Flatten spatial dimensions
        
        # Apply GRU
        x, _ = self.gru(x)
        
        # Final output
        x = x[:, -1, :]  # Take the last time step output
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input with 3 channels, 64x64 spatial dimensions
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

