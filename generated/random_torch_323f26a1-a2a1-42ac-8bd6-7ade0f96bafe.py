
# This is a random torch model generated by the following modules: ['AvgPool3d', 'ReflectionPad1d', 'MultiheadAttention', 'MaxPool2d', 'Dropout1d', 'RNNCell', 'Softshrink']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.avg_pool3d = nn.AvgPool3d(kernel_size=2)
        self.reflection_pad1d = nn.ReflectionPad1d(padding=2)
        self.multihead_attention = nn.MultiheadAttention(embed_dim=64, num_heads=8)
        self.max_pool2d = nn.MaxPool2d(kernel_size=2)
        self.dropout1d = nn.Dropout1d(p=0.5)
        self.rnn_cell = nn.RNNCell(input_size=64, hidden_size=128)
        self.softshrink = nn.Softshrink(lambd=0.5)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.avg_pool3d(x)  # Apply AvgPool3d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten to (batch_size, channels, depth*height*width)
        x = self.reflection_pad1d(x)  # Apply ReflectionPad1d
        x = x.permute(2, 0, 1)  # Reshape for MultiheadAttention: (seq_len, batch_size, embed_dim)
        x, _ = self.multihead_attention(x, x, x)  # Apply MultiheadAttention
        x = x.permute(1, 2, 0)  # Reshape back to (batch_size, embed_dim, seq_len)
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape for MaxPool2d
        x = self.max_pool2d(x)  # Apply MaxPool2d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten to (batch_size, channels, height*width)
        x = self.dropout1d(x)  # Apply Dropout1d
        x = x.permute(0, 2, 1)  # Reshape for RNNCell: (batch_size, seq_len, input_size)
        hx = torch.zeros(x.size(0), 128).to(x.device)  # Initialize hidden state for RNNCell
        for i in range(x.size(1)):
            hx = self.rnn_cell(x[:, i, :], hx)  # Apply RNNCell
        x = hx  # Use the final hidden state
        x = self.softshrink(x)  # Apply Softshrink
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32, 32).cuda()  # Example input shape: (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

