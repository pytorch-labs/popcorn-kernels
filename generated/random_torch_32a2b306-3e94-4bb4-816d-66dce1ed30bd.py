
# This is a random torch model generated by the following modules: ['GroupNorm', 'CosineEmbeddingLoss', 'ReLU6', 'KLDivLoss', 'PoissonNLLLoss', 'Softsign', 'AvgPool2d', 'MaxPool3d', 'LayerNorm']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.group_norm1 = nn.GroupNorm(2, 4)  # GroupNorm
        self.group_norm2 = nn.GroupNorm(4, 8)  # GroupNorm
        self.relu6 = nn.ReLU6()  # ReLU6
        self.softsign = nn.Softsign()  # Softsign
        self.avg_pool2d = nn.AvgPool2d(kernel_size=2)  # AvgPool2d
        self.max_pool3d = nn.MaxPool3d(kernel_size=2)  # MaxPool3d
        self.layer_norm = nn.LayerNorm([8, 8, 8])  # LayerNorm
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()  # CosineEmbeddingLoss
        self.kl_div_loss = nn.KLDivLoss()  # KLDivLoss
        self.poisson_nll_loss = nn.PoissonNLLLoss()  # PoissonNLLLoss

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        x = self.group_norm1(x)  # Apply GroupNorm
        x = self.relu6(x)  # Apply ReLU6
        x = self.softsign(x)  # Apply Softsign
        x = self.avg_pool2d(x)  # Apply AvgPool2d
        
        # Reshape for MaxPool3d
        x = x.unsqueeze(2)  # Add a new dimension to make it 5D (batch_size, channels, depth, height, width)
        x = self.max_pool3d(x)  # Apply MaxPool3d
        
        # Reshape back to 4D for LayerNorm
        x = x.squeeze(2)  # Remove the depth dimension
        x = self.layer_norm(x)  # Apply LayerNorm
        
        # Apply GroupNorm again
        x = self.group_norm2(x)
        
        # Compute losses (for demonstration purposes, we'll compute losses with dummy targets)
        target_cosine = torch.ones(x.size(0))  # Dummy target for CosineEmbeddingLoss
        loss_cosine = self.cosine_embedding_loss(x.view(x.size(0), -1), x.view(x.size(0), -1), target_cosine)
        
        target_kl = torch.softmax(torch.randn_like(x), dim=1)  # Dummy target for KLDivLoss
        loss_kl = self.kl_div_loss(F.log_softmax(x, dim=1), target_kl)
        
        target_poisson = torch.randn_like(x)  # Dummy target for PoissonNLLLoss
        loss_poisson = self.poisson_nll_loss(x, target_poisson)
        
        # Return the final output and the computed losses
        return x, loss_cosine, loss_kl, loss_poisson


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 4, 32, 32).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

