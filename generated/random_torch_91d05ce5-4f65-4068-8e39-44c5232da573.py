
# This is a random torch model generated by the following modules: ['GaussianNLLLoss', 'FractionalMaxPool3d', 'RNNCell', 'ZeroPad2d', 'ParameterDict', 'ConstantPad3d', 'AdaptiveAvgPool3d', 'BatchNorm2d', 'SELU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.fractional_max_pool3d = nn.FractionalMaxPool3d(kernel_size=2, output_size=(8, 8, 8))
        self.rnn_cell = nn.RNNCell(input_size=8*8*8, hidden_size=128)
        self.zero_pad2d = nn.ZeroPad2d(2)
        self.constant_pad3d = nn.ConstantPad3d(padding=1, value=0)
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d(output_size=(4, 4, 4))
        self.batch_norm2d = nn.BatchNorm2d(num_features=128)
        self.selu = nn.SELU()
        self.parameter_dict = nn.ParameterDict({
            'weight': nn.Parameter(torch.randn(128, 64)),
            'bias': nn.Parameter(torch.randn(64))
        })
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        x = self.fractional_max_pool3d(x)
        x = x.view(x.size(0), -1)  # Flatten for RNNCell
        x = self.rnn_cell(x)
        x = x.view(x.size(0), 128, 1, 1)  # Reshape for ZeroPad2d
        x = self.zero_pad2d(x)
        x = x.unsqueeze(2)  # Add depth dimension for ConstantPad3d
        x = self.constant_pad3d(x)
        x = self.adaptive_avg_pool3d(x)
        x = x.squeeze(2)  # Remove depth dimension for BatchNorm2d
        x = self.batch_norm2d(x)
        x = self.selu(x)
        x = x.view(x.size(0), -1)  # Flatten for linear transformation
        x = torch.matmul(x, self.parameter_dict['weight']) + self.parameter_dict['bias']
        # For GaussianNLLLoss, we need to return both the prediction and the target
        # Here, we assume the target is provided externally
        return x

    def compute_loss(self, output, target, var):
        return self.gaussian_nll_loss(output, target, var)


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 16, 16, 16).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

