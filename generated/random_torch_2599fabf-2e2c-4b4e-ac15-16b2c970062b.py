
# This is a random torch model generated by the following modules: ['MaxUnpool2d', 'LSTMCell', 'AdaptiveLogSoftmaxWithLoss', 'PoissonNLLLoss', 'LayerNorm', 'EmbeddingBag']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(1000, 128, mode='mean')
        self.lstm_cell1 = nn.LSTMCell(128, 64)
        self.lstm_cell2 = nn.LSTMCell(64, 32)
        self.layer_norm = nn.LayerNorm(32)
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.adaptive_log_softmax = nn.AdaptiveLogSoftmaxWithLoss(32, 1000, [100, 500])
        self.poisson_nll_loss = nn.PoissonNLLLoss()

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Reshape for LSTM cells
        x = x.view(1, -1)  # Reshape to (seq_len, batch_size, input_size)
        
        # Initialize hidden states for LSTM cells
        hx1 = torch.zeros(1, 64)
        cx1 = torch.zeros(1, 64)
        hx2 = torch.zeros(1, 32)
        cx2 = torch.zeros(1, 32)
        
        # Pass through LSTM cells
        hx1, cx1 = self.lstm_cell1(x, (hx1, cx1))
        hx2, cx2 = self.lstm_cell2(hx1, (hx2, cx2))
        
        # Apply LayerNorm
        x = self.layer_norm(hx2)
        
        # Reshape for MaxUnpool2d
        x = x.view(1, 1, 8, 4)  # Reshape to (batch_size, channels, height, width)
        
        # Apply MaxUnpool2d (assuming indices are provided)
        indices = torch.randint(0, 4, (1, 1, 8, 4))  # Random indices for unpooling
        x = self.max_unpool2d(x, indices)
        
        # Reshape for AdaptiveLogSoftmaxWithLoss
        x = x.view(1, -1)
        
        # Apply AdaptiveLogSoftmaxWithLoss
        output = self.adaptive_log_softmax(x, torch.tensor([0]))  # Assuming target is 0
        
        # Apply PoissonNLLLoss
        loss = self.poisson_nll_loss(output.output, torch.tensor([0.0]))  # Assuming target is 0.0
        
        return loss

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Random indices for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
