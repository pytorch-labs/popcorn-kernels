
# This is a random torch model generated by the following modules: ['Linear', 'TransformerDecoderLayer', 'LazyConv3d', 'CosineSimilarity', 'AvgPool1d', 'ParameterList', 'ReflectionPad2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.linear1 = nn.Linear(128, 256)
        self.linear2 = nn.Linear(256, 128)
        self.transformer_decoder_layer = nn.TransformerDecoderLayer(d_model=128, nhead=8)
        self.lazy_conv3d = nn.LazyConv3d(out_channels=64, kernel_size=3)
        self.cosine_similarity = nn.CosineSimilarity(dim=1)
        self.avg_pool1d = nn.AvgPool1d(kernel_size=2)
        self.parameter_list = nn.ParameterList([nn.Parameter(torch.randn(64)) for _ in range(5)])
        self.reflection_pad2d = nn.ReflectionPad2d(2)

    def forward(self, x):
        # Apply Linear layers
        x = self.linear1(x)
        x = self.linear2(x)
        
        # Reshape for TransformerDecoderLayer
        x = x.view(-1, 128, 128)
        x = self.transformer_decoder_layer(x, x)
        
        # Reshape for LazyConv3d
        x = x.view(-1, 128, 8, 8, 8)
        x = self.lazy_conv3d(x)
        
        # Reshape for CosineSimilarity
        x = x.view(-1, 64, 8*8*8)
        x = self.cosine_similarity(x, x)
        
        # Reshape for AvgPool1d
        x = x.view(-1, 1, 64)
        x = self.avg_pool1d(x)
        
        # Apply ParameterList
        for param in self.parameter_list:
            x = x + param.view(1, -1, 1)
        
        # Reshape for ReflectionPad2d
        x = x.view(-1, 1, 8, 8)
        x = self.reflection_pad2d(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 128).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

