
# This is a random torch model generated by the following modules: ['MultiLabelMarginLoss', 'Softmax', 'LazyConvTranspose3d', 'MaxUnpool2d', 'MaxPool1d', 'ConvTranspose2d', 'Threshold', 'MSELoss', 'SELU', 'CELU']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lazy_conv_transpose3d = nn.LazyConvTranspose3d(out_channels=16, kernel_size=3)
        self.max_pool1d = nn.MaxPool1d(kernel_size=2)
        self.conv_transpose2d = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3)
        self.threshold = nn.Threshold(threshold=0.5, value=0.0)
        self.selu = nn.SELU()
        self.celu = nn.CELU()
        self.softmax = nn.Softmax(dim=1)
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2)
        self.mse_loss = nn.MSELoss()
        self.multi_label_margin_loss = nn.MultiLabelMarginLoss()

    def forward(self, x):
        # Assuming input is 3D, reshape to 5D for LazyConvTranspose3d
        x = x.unsqueeze(1).unsqueeze(1)  # Add two dimensions to make it 5D
        x = self.lazy_conv_transpose3d(x)
        
        # Reshape to 3D for MaxPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten last two dimensions
        x = self.max_pool1d(x)
        
        # Reshape to 4D for ConvTranspose2d
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))
        x = self.conv_transpose2d(x)
        
        # Apply Threshold
        x = self.threshold(x)
        
        # Apply SELU and CELU
        x = self.selu(x)
        x = self.celu(x)
        
        # Apply Softmax
        x = self.softmax(x)
        
        # Apply MaxUnpool2d (assuming we have indices from a previous MaxPool2d)
        # For simplicity, we'll just use the output of ConvTranspose2d as input to MaxUnpool2d
        # In practice, you would need to store the indices from a MaxPool2d operation
        x = self.max_unpool2d(x, indices=torch.argmax(x, dim=1))
        
        # Compute MSE Loss (assuming we have a target tensor)
        target = torch.randn_like(x)
        mse_loss = self.mse_loss(x, target)
        
        # Compute MultiLabelMarginLoss (assuming we have a target tensor)
        target_labels = torch.randint(0, 2, (x.size(0), x.size(1))).float()
        multi_label_margin_loss = self.multi_label_margin_loss(x, target_labels)
        
        # Return both the output and the losses
        return x, mse_loss, multi_label_margin_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Assuming input is 3D (e.g., RGB image)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
