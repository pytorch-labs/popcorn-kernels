
# This is a random torch model generated by the following modules: ['LazyInstanceNorm3d', 'Flatten', 'ConvTranspose2d', 'LayerNorm', 'MultiMarginLoss', 'LocalResponseNorm', 'AdaptiveMaxPool3d', 'InstanceNorm1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lazy_instance_norm3d = nn.LazyInstanceNorm3d()
        self.flatten = nn.Flatten()
        self.conv_transpose2d = nn.ConvTranspose2d(1, 10, kernel_size=5)
        self.layer_norm = nn.LayerNorm(10)
        self.multi_margin_loss = nn.MultiMarginLoss()
        self.local_response_norm = nn.LocalResponseNorm(2)
        self.adaptive_max_pool3d = nn.AdaptiveMaxPool3d((5, 5, 5))
        self.instance_norm1d = nn.InstanceNorm1d(10)

    def forward(self, x):
        # Apply LazyInstanceNorm3d
        x = self.lazy_instance_norm3d(x)
        
        # Reshape for ConvTranspose2d
        x = x.view(-1, 1, 28, 28)
        
        # Apply ConvTranspose2d
        x = self.conv_transpose2d(x)
        
        # Apply LayerNorm
        x = self.layer_norm(x)
        
        # Apply LocalResponseNorm
        x = self.local_response_norm(x)
        
        # Reshape for AdaptiveMaxPool3d
        x = x.view(-1, 10, 28, 28, 1)
        
        # Apply AdaptiveMaxPool3d
        x = self.adaptive_max_pool3d(x)
        
        # Flatten the output
        x = self.flatten(x)
        
        # Reshape for InstanceNorm1d
        x = x.view(-1, 10, 125)
        
        # Apply InstanceNorm1d
        x = self.instance_norm1d(x)
        
        # Flatten again for MultiMarginLoss
        x = self.flatten(x)
        
        # Dummy target for MultiMarginLoss (since it requires a target)
        target = torch.randint(0, 10, (x.size(0),), device=x.device)
        
        # Apply MultiMarginLoss (usually used in training, but here for demonstration)
        loss = self.multi_margin_loss(x, target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 28, 28, 28).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

