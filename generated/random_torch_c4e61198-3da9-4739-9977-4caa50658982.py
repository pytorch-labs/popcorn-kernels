
# This is a random torch model generated by the following modules: ['ConvTranspose1d', 'PixelShuffle', 'Threshold', 'AvgPool2d', 'SELU', 'Hardtanh', 'Embedding', 'RNN', 'BatchNorm1d', 'ReplicationPad2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding = nn.Embedding(1000, 128)  # Embedding layer
        self.conv_transpose1d = nn.ConvTranspose1d(128, 64, kernel_size=3, stride=2)  # ConvTranspose1d layer
        self.batch_norm1d = nn.BatchNorm1d(64)  # BatchNorm1d layer
        self.rnn = nn.RNN(64, 32, batch_first=True)  # RNN layer
        self.threshold = nn.Threshold(0.5, 0.0)  # Threshold layer
        self.replication_pad2d = nn.ReplicationPad2d(2)  # ReplicationPad2d layer
        self.avg_pool2d = nn.AvgPool2d(kernel_size=2)  # AvgPool2d layer
        self.pixel_shuffle = nn.PixelShuffle(2)  # PixelShuffle layer
        self.selu = nn.SELU()  # SELU activation
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)  # Hardtanh activation

    def forward(self, x):
        # Assume input is a batch of token indices for embedding
        x = self.embedding(x)  # (batch_size, seq_len) -> (batch_size, seq_len, 128)
        x = x.permute(0, 2, 1)  # (batch_size, seq_len, 128) -> (batch_size, 128, seq_len)
        x = self.conv_transpose1d(x)  # (batch_size, 128, seq_len) -> (batch_size, 64, new_seq_len)
        x = self.batch_norm1d(x)  # BatchNorm1d
        x = x.permute(0, 2, 1)  # (batch_size, 64, new_seq_len) -> (batch_size, new_seq_len, 64)
        x, _ = self.rnn(x)  # RNN layer
        x = self.threshold(x)  # Threshold layer
        x = x.unsqueeze(1)  # Add a channel dimension for 2D operations
        x = self.replication_pad2d(x)  # ReplicationPad2d
        x = self.avg_pool2d(x)  # AvgPool2d
        x = self.pixel_shuffle(x)  # PixelShuffle
        x = self.selu(x)  # SELU activation
        x = self.hardtanh(x)  # Hardtanh activation
        return x


def get_inputs():
    # Randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10, 20)).cuda()  # (batch_size, seq_len)
    return [x]


def get_init_inputs():
    # Randomly generate tensors required for initialization based on the model architecture
    return []

