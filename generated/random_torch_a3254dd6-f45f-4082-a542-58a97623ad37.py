
# This is a random torch model generated by the following modules: ['LazyInstanceNorm1d', 'FractionalMaxPool2d', 'ReLU', 'TransformerDecoderLayer', 'LayerNorm', 'AvgPool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.norm1 = nn.LazyInstanceNorm1d()
        self.pool1 = nn.FractionalMaxPool2d(kernel_size=2, output_size=(14, 14))
        self.relu1 = nn.ReLU()
        self.transformer_decoder = nn.TransformerDecoderLayer(d_model=64, nhead=8)
        self.norm2 = nn.LayerNorm(64)
        self.pool2 = nn.AvgPool3d(kernel_size=2)
        self.norm3 = nn.LazyInstanceNorm1d()
        self.pool3 = nn.FractionalMaxPool2d(kernel_size=2, output_size=(7, 7))
        self.relu2 = nn.ReLU()
        self.norm4 = nn.LayerNorm(64)
        self.pool4 = nn.AvgPool3d(kernel_size=2)

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, height, width)
        x = self.norm1(x.view(x.size(0), x.size(1), -1))  # Reshape for LazyInstanceNorm1d
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        x = self.pool1(x)
        x = self.relu1(x)
        
        # Reshape for TransformerDecoderLayer
        x = x.view(x.size(0), x.size(1), -1).permute(2, 0, 1)  # (seq_len, batch_size, d_model)
        x = self.transformer_decoder(x, x)
        x = x.permute(1, 2, 0).view(x.size(1), x.size(2), int(x.size(0)**0.5), int(x.size(0)**0.5))  # Reshape back
        
        x = self.norm2(x.view(x.size(0), x.size(1), -1).permute(0, 2, 1)).permute(0, 2, 1)  # LayerNorm
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        
        # Reshape for AvgPool3d
        x = x.unsqueeze(2)  # Add a dummy dimension for 3D pooling
        x = self.pool2(x)
        x = x.squeeze(2)  # Remove the dummy dimension
        
        x = self.norm3(x.view(x.size(0), x.size(1), -1))  # Reshape for LazyInstanceNorm1d
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        x = self.pool3(x)
        x = self.relu2(x)
        
        x = self.norm4(x.view(x.size(0), x.size(1), -1).permute(0, 2, 1)).permute(0, 2, 1)  # LayerNorm
        x = x.view(x.size(0), x.size(1), int(x.size(2)**0.5), int(x.size(2)**0.5))  # Reshape back
        
        # Reshape for AvgPool3d
        x = x.unsqueeze(2)  # Add a dummy dimension for 3D pooling
        x = self.pool4(x)
        x = x.squeeze(2)  # Remove the dummy dimension
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

