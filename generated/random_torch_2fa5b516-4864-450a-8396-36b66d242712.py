
# This is a random torch model generated by the following modules: ['CTCLoss', 'KLDivLoss', 'CosineEmbeddingLoss', 'Dropout2d', 'InstanceNorm1d', 'PoissonNLLLoss', 'Softmax2d', 'Unflatten']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.dropout2d = nn.Dropout2d(p=0.5)
        self.instance_norm1d = nn.InstanceNorm1d(128)
        self.softmax2d = nn.Softmax2d()
        self.unflatten = nn.Unflatten(1, (16, 8))
        self.ctc_loss = nn.CTCLoss()
        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')
        self.cosine_embedding_loss = nn.CosineEmbeddingLoss()
        self.poisson_nll_loss = nn.PoissonNLLLoss()

    def forward(self, x):
        # Apply Dropout2d
        x = self.dropout2d(x)
        
        # Reshape and apply InstanceNorm1d
        x = x.view(x.size(0), 128, -1)  # Reshape to (batch_size, 128, *)
        x = self.instance_norm1d(x)
        
        # Reshape and apply Softmax2d
        x = x.view(x.size(0), 16, 8, -1)  # Reshape to (batch_size, 16, 8, *)
        x = self.softmax2d(x)
        
        # Unflatten the tensor
        x = self.unflatten(x)
        
        # Compute CTC Loss (dummy target and input_lengths)
        ctc_input = x.view(x.size(0), -1, x.size(-1)).log_softmax(2)
        ctc_target = torch.randint(0, 10, (x.size(0), 10), dtype=torch.long)
        input_lengths = torch.full((x.size(0),), x.size(-1), dtype=torch.long)
        target_lengths = torch.randint(1, 10, (x.size(0),), dtype=torch.long)
        ctc_loss = self.ctc_loss(ctc_input, ctc_target, input_lengths, target_lengths)
        
        # Compute KLDiv Loss (dummy target)
        kl_input = x.view(x.size(0), -1).log_softmax(1)
        kl_target = torch.softmax(torch.randn_like(kl_input), dim=1)
        kl_loss = self.kl_div_loss(kl_input, kl_target)
        
        # Compute Cosine Embedding Loss (dummy input2 and target)
        input1 = x.view(x.size(0), -1)
        input2 = torch.randn_like(input1)
        target = torch.randint(0, 2, (x.size(0),), dtype=torch.float) * 2 - 1
        cosine_loss = self.cosine_embedding_loss(input1, input2, target)
        
        # Compute PoissonNLL Loss (dummy target)
        poisson_input = x.view(x.size(0), -1)
        poisson_target = torch.poisson(torch.ones_like(poisson_input))
        poisson_loss = self.poisson_nll_loss(poisson_input, poisson_target)
        
        # Return the computed losses
        return ctc_loss, kl_loss, cosine_loss, poisson_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 16, 8, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
