
# This is a random torch model generated by the following modules: ['ModuleDict', 'Conv1d', 'PoissonNLLLoss', 'Tanh', 'FeatureAlphaDropout', 'GaussianNLLLoss', 'LazyInstanceNorm1d', 'GELU', 'Softshrink']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.module_dict = nn.ModuleDict({
            'conv1': nn.Conv1d(1, 10, kernel_size=5),
            'conv2': nn.Conv1d(10, 20, kernel_size=5),
            'conv3': nn.Conv1d(20, 30, kernel_size=5),
            'conv4': nn.Conv1d(30, 40, kernel_size=5),
            'conv5': nn.Conv1d(40, 50, kernel_size=5),
        })
        self.norm = nn.LazyInstanceNorm1d()
        self.dropout = nn.FeatureAlphaDropout(0.5)
        self.activation1 = nn.Tanh()
        self.activation2 = nn.GELU()
        self.activation3 = nn.Softshrink()
        self.loss1 = nn.PoissonNLLLoss()
        self.loss2 = nn.GaussianNLLLoss()

    def forward(self, x):
        # Apply Conv1d layers
        x = self.module_dict['conv1'](x)
        x = self.activation1(x)
        x = self.module_dict['conv2'](x)
        x = self.activation2(x)
        x = self.module_dict['conv3'](x)
        x = self.activation3(x)
        x = self.module_dict['conv4'](x)
        x = self.activation1(x)
        x = self.module_dict['conv5'](x)
        x = self.activation2(x)

        # Apply normalization and dropout
        x = self.norm(x)
        x = self.dropout(x)

        # Reshape for loss computation
        x = x.view(x.size(0), -1)

        # Compute losses (dummy targets for demonstration)
        target_poisson = torch.randint(0, 10, (x.size(0),), device=x.device)
        target_gaussian = torch.randn_like(x)
        var_gaussian = torch.ones_like(x)

        loss1 = self.loss1(x, target_poisson)
        loss2 = self.loss2(x, target_gaussian, var_gaussian)

        return x, loss1, loss2


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 128).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

