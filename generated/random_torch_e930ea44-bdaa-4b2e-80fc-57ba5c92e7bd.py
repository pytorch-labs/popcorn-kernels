
# This is a random torch model generated by the following modules: ['RNNCellBase', 'ConvTranspose2d', 'Conv3d', 'ReLU', 'ChannelShuffle']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rnn_cell = nn.RNNCellBase(input_size=128, hidden_size=256)
        self.conv_transpose1 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1)
        self.conv3d1 = nn.Conv3d(128, 64, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.channel_shuffle = nn.ChannelShuffle(groups=4)
        self.conv_transpose2 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1)
        self.conv3d2 = nn.Conv3d(32, 16, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, sequence_length, input_size)
        batch_size, seq_len, input_size = x.size()
        hx = torch.zeros(batch_size, 256).to(x.device)  # Initialize hidden state for RNNCell

        # Process through RNNCellBase
        for t in range(seq_len):
            hx = self.rnn_cell(x[:, t, :], hx)

        # Reshape for ConvTranspose2d
        x = hx.view(batch_size, 256, 1, 1)
        x = self.conv_transpose1(x)
        x = self.relu(x)

        # Reshape for Conv3d
        x = x.unsqueeze(2)  # Add a dimension for Conv3d
        x = self.conv3d1(x)
        x = self.relu(x)

        # ChannelShuffle
        x = x.squeeze(2)  # Remove the added dimension for ChannelShuffle
        x = self.channel_shuffle(x)

        # Reshape for ConvTranspose2d
        x = x.unsqueeze(2)  # Add a dimension for ConvTranspose2d
        x = self.conv_transpose2(x)
        x = self.relu(x)

        # Reshape for Conv3d
        x = x.squeeze(2)  # Remove the added dimension for Conv3d
        x = x.unsqueeze(2)
        x = self.conv3d2(x)
        x = self.relu(x)

        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 128).cuda()  # Example input: (batch_size=1, sequence_length=10, input_size=128)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

