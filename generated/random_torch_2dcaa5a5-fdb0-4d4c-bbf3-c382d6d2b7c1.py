
# This is a random torch model generated by the following modules: ['InstanceNorm2d', 'ConvTranspose2d', 'ZeroPad1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.inst_norm1 = nn.InstanceNorm2d(3)
        self.conv_trans1 = nn.ConvTranspose2d(3, 6, kernel_size=3, stride=2, padding=1)
        self.zero_pad1 = nn.ZeroPad1d(2)
        self.inst_norm2 = nn.InstanceNorm2d(6)
        self.conv_trans2 = nn.ConvTranspose2d(6, 12, kernel_size=3, stride=2, padding=1)
        self.zero_pad2 = nn.ZeroPad1d(1)
        self.inst_norm3 = nn.InstanceNorm2d(12)
        self.conv_trans3 = nn.ConvTranspose2d(12, 24, kernel_size=3, stride=2, padding=1)
        self.zero_pad3 = nn.ZeroPad1d(1)

    def forward(self, x):
        # Assuming input is of shape (batch_size, channels, height, width)
        x = self.inst_norm1(x)
        x = self.conv_trans1(x)
        x = x.permute(0, 2, 3, 1)  # Reshape to (batch_size, height, width, channels)
        x = x.reshape(x.size(0), x.size(1), -1)  # Reshape to (batch_size, height, width * channels)
        x = self.zero_pad1(x)
        x = x.reshape(x.size(0), x.size(1), -1, 6)  # Reshape back to (batch_size, height, width, channels)
        x = x.permute(0, 3, 1, 2)  # Reshape back to (batch_size, channels, height, width)
        x = self.inst_norm2(x)
        x = self.conv_trans2(x)
        x = x.permute(0, 2, 3, 1)  # Reshape to (batch_size, height, width, channels)
        x = x.reshape(x.size(0), x.size(1), -1)  # Reshape to (batch_size, height, width * channels)
        x = self.zero_pad2(x)
        x = x.reshape(x.size(0), x.size(1), -1, 12)  # Reshape back to (batch_size, height, width, channels)
        x = x.permute(0, 3, 1, 2)  # Reshape back to (batch_size, channels, height, width)
        x = self.inst_norm3(x)
        x = self.conv_trans3(x)
        x = x.permute(0, 2, 3, 1)  # Reshape to (batch_size, height, width, channels)
        x = x.reshape(x.size(0), x.size(1), -1)  # Reshape to (batch_size, height, width * channels)
        x = self.zero_pad3(x)
        x = x.reshape(x.size(0), x.size(1), -1, 24)  # Reshape back to (batch_size, height, width, channels)
        x = x.permute(0, 3, 1, 2)  # Reshape back to (batch_size, channels, height, width)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
