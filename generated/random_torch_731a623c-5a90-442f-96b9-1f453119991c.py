
# This is a random torch model generated by the following modules: ['ReflectionPad3d', 'Fold', 'LSTM', 'MaxUnpool2d', 'LazyInstanceNorm3d', 'ModuleDict', 'ReplicationPad1d', 'AdaptiveAvgPool3d', 'TripletMarginLoss']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.reflection_pad3d = nn.ReflectionPad3d(1)
        self.fold = nn.Fold(output_size=(8, 8), kernel_size=(2, 2))
        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)
        self.max_unpool2d = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.lazy_instance_norm3d = nn.LazyInstanceNorm3d()
        self.module_dict = nn.ModuleDict({
            'replication_pad1d': nn.ReplicationPad1d(1),
            'adaptive_avg_pool3d': nn.AdaptiveAvgPool3d((4, 4, 4))
        })
        self.triplet_margin_loss = nn.TripletMarginLoss()

    def forward(self, x):
        # ReflectionPad3d
        x = self.reflection_pad3d(x)
        
        # Fold
        x = x.view(x.size(0), -1, 1)  # Reshape for Fold
        x = self.fold(x)
        
        # LSTM
        x = x.view(x.size(0), -1, 64)  # Reshape for LSTM
        x, _ = self.lstm(x)
        
        # MaxUnpool2d
        x = x.view(x.size(0), 128, 8, 8)  # Reshape for MaxUnpool2d
        indices = torch.randint(0, 4, (x.size(0), 128, 8, 8), device=x.device)  # Dummy indices
        x = self.max_unpool2d(x, indices)
        
        # LazyInstanceNorm3d
        x = x.unsqueeze(1)  # Add channel dimension for 3D normalization
        x = self.lazy_instance_norm3d(x)
        
        # ModuleDict: ReplicationPad1d and AdaptiveAvgPool3d
        x = x.view(x.size(0), -1, x.size(-1))  # Reshape for ReplicationPad1d
        x = self.module_dict['replication_pad1d'](x)
        x = x.view(x.size(0), 128, 8, 8, 8)  # Reshape for AdaptiveAvgPool3d
        x = self.module_dict['adaptive_avg_pool3d'](x)
        
        # TripletMarginLoss (requires three inputs)
        anchor = x[:, 0, :, :, :].view(x.size(0), -1)
        positive = x[:, 1, :, :, :].view(x.size(0), -1)
        negative = x[:, 2, :, :, :].view(x.size(0), -1)
        loss = self.triplet_margin_loss(anchor, positive, negative)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 8, 8, 8).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
