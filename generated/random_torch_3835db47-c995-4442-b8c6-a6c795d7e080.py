
# This is a random torch model generated by the following modules: ['CrossMapLRN2d', 'MaxUnpool3d', 'Softmin', 'ModuleList', 'PixelShuffle', 'EmbeddingBag']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lrn = nn.CrossMapLRN2d(size=5, alpha=1e-4, beta=0.75, k=1.0)
        self.max_unpool = nn.MaxUnpool3d(kernel_size=2, stride=2)
        self.softmin = nn.Softmin(dim=1)
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.embedding_bag = nn.EmbeddingBag(num_embeddings=100, embedding_dim=10, mode='mean')
        
        # Using ModuleList to hold multiple layers
        self.module_list = nn.ModuleList([
            nn.Conv2d(1, 10, kernel_size=3),
            nn.Conv2d(10, 20, kernel_size=3),
            nn.Linear(320, 50),
            nn.Linear(50, 10)
        ])

    def forward(self, x):
        # Apply CrossMapLRN2d
        x = self.lrn(x)
        
        # Apply Conv2d layers from ModuleList
        x = self.module_list[0](x)
        x = F.relu(x)
        x = self.module_list[1](x)
        x = F.relu(x)
        
        # Reshape for MaxUnpool3d
        x = x.unsqueeze(1)  # Add a dummy dimension for 3D
        x, indices = F.max_pool3d(x, kernel_size=2, stride=2, return_indices=True)
        x = self.max_unpool(x, indices)
        x = x.squeeze(1)  # Remove the dummy dimension
        
        # Apply PixelShuffle
        x = self.pixel_shuffle(x)
        
        # Reshape for EmbeddingBag
        x = x.view(x.size(0), -1)  # Flatten
        x = self.embedding_bag(x.long())  # Convert to long for embedding
        
        # Apply Softmin
        x = self.softmin(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
