
# This is a random torch model generated by the following modules: ['LazyLinear', 'BatchNorm3d', 'MaxUnpool3d', 'Conv2d', 'PairwiseDistance', 'LazyBatchNorm3d', 'Sigmoid', 'AdaptiveAvgPool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.lazy_linear = nn.LazyLinear(128)
        self.batch_norm3d = nn.BatchNorm3d(64)
        self.max_unpool3d = nn.MaxUnpool3d(kernel_size=2, stride=2)
        self.conv2d = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.pairwise_distance = nn.PairwiseDistance()
        self.lazy_batch_norm3d = nn.LazyBatchNorm3d()
        self.sigmoid = nn.Sigmoid()
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d((1, 1, 1))

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, depth, height, width)
        # First, apply Conv2d to the last two dimensions (height, width)
        x = x.view(x.size(0), x.size(1), x.size(2), -1)  # Reshape to (batch_size, channels, depth, height*width)
        x = x.permute(0, 1, 3, 2)  # Permute to (batch_size, channels, height*width, depth)
        x = self.conv2d(x)  # Apply Conv2d
        x = x.permute(0, 1, 3, 2)  # Permute back to (batch_size, channels, depth, height*width)
        x = x.view(x.size(0), x.size(1), x.size(2), int(x.size(3)**0.5), int(x.size(3)**0.5))  # Reshape back to 5D

        # Apply BatchNorm3d
        x = self.batch_norm3d(x)

        # Apply MaxUnpool3d (assuming we have indices from a previous MaxPool3d)
        # For simplicity, we'll just apply MaxUnpool3d without actual indices
        x = self.max_unpool3d(x, torch.zeros_like(x, dtype=torch.long))

        # Apply LazyBatchNorm3d
        x = self.lazy_batch_norm3d(x)

        # Apply AdaptiveAvgPool3d
        x = self.adaptive_avg_pool3d(x)

        # Flatten the tensor for LazyLinear
        x = x.view(x.size(0), -1)

        # Apply LazyLinear
        x = self.lazy_linear(x)

        # Apply PairwiseDistance (assuming we have another tensor to compare with)
        # For simplicity, we'll compare with a tensor of zeros
        x = self.pairwise_distance(x, torch.zeros_like(x))

        # Apply Sigmoid
        x = self.sigmoid(x)

        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 16, 32, 32).cuda()  # Example input shape (batch_size, channels, depth, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

