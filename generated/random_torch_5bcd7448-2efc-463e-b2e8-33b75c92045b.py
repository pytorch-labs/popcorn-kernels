
# This is a random torch model generated by the following modules: ['LazyConvTranspose1d', 'Hardswish', 'LazyBatchNorm2d', 'Hardsigmoid', 'ReplicationPad1d', 'PairwiseDistance', 'AdaptiveAvgPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose1 = nn.LazyConvTranspose1d(out_channels=32, kernel_size=3, stride=2)
        self.hardswish = nn.Hardswish()
        self.batch_norm1 = nn.LazyBatchNorm2d()
        self.hardsigmoid = nn.Hardsigmoid()
        self.replication_pad1 = nn.ReplicationPad1d(padding=2)
        self.pairwise_distance = nn.PairwiseDistance(p=2)
        self.adaptive_avg_pool1 = nn.AdaptiveAvgPool1d(output_size=10)
        
        # Repeat some modules up to 5 times
        self.conv_transpose2 = nn.LazyConvTranspose1d(out_channels=64, kernel_size=3, stride=2)
        self.batch_norm2 = nn.LazyBatchNorm2d()
        self.adaptive_avg_pool2 = nn.AdaptiveAvgPool1d(output_size=5)

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, length)
        x = self.conv_transpose1(x)  # Shape: (batch_size, 32, length * 2 - 1)
        x = self.hardswish(x)
        
        # Reshape to fit LazyBatchNorm2d
        x = x.unsqueeze(2)  # Shape: (batch_size, 32, 1, length * 2 - 1)
        x = self.batch_norm1(x)
        x = x.squeeze(2)  # Shape: (batch_size, 32, length * 2 - 1)
        
        x = self.hardsigmoid(x)
        x = self.replication_pad1(x)  # Shape: (batch_size, 32, length * 2 - 1 + 4)
        
        # PairwiseDistance requires two inputs, so we split the tensor
        x1, x2 = x.chunk(2, dim=1)  # Split along the channel dimension
        x = self.pairwise_distance(x1, x2)  # Shape: (batch_size, length * 2 - 1 + 4)
        
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, length * 2 - 1 + 4)
        x = self.adaptive_avg_pool1(x)  # Shape: (batch_size, 1, 10)
        
        # Repeat some modules
        x = self.conv_transpose2(x)  # Shape: (batch_size, 64, 19)
        x = self.hardswish(x)
        
        x = x.unsqueeze(2)  # Shape: (batch_size, 64, 1, 19)
        x = self.batch_norm2(x)
        x = x.squeeze(2)  # Shape: (batch_size, 64, 19)
        
        x = self.adaptive_avg_pool2(x)  # Shape: (batch_size, 64, 5)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 16, 32).cuda()  # Example input shape: (batch_size, channels, length)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
