
# This is a random torch model generated by the following modules: ['Bilinear', 'LSTM', 'Unfold', 'Mish', 'TransformerDecoderLayer', 'LazyConv1d', 'RReLU', 'AdaptiveAvgPool3d', 'AlphaDropout', 'Unflatten']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.bilinear = nn.Bilinear(10, 20, 30)
        self.lstm = nn.LSTM(30, 40, batch_first=True)
        self.unfold = nn.Unfold(kernel_size=(3, 3))
        self.mish = nn.Mish()
        self.transformer_decoder_layer = nn.TransformerDecoderLayer(d_model=40, nhead=4)
        self.lazy_conv1d = nn.LazyConv1d(out_channels=50, kernel_size=3)
        self.rrelu = nn.RReLU()
        self.adaptive_avg_pool3d = nn.AdaptiveAvgPool3d((5, 5, 5))
        self.alpha_dropout = nn.AlphaDropout()
        self.unflatten = nn.Unflatten(1, (10, 5))

    def forward(self, x):
        # Assume input x is of shape (batch_size, 10, 20)
        x = self.bilinear(x, x)  # Shape: (batch_size, 30)
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 30)
        x, _ = self.lstm(x)  # Shape: (batch_size, 1, 40)
        x = x.squeeze(1)  # Shape: (batch_size, 40)
        x = x.unsqueeze(1).unsqueeze(1)  # Shape: (batch_size, 1, 1, 40)
        x = self.unfold(x)  # Shape: (batch_size, 40 * 3 * 3, 1)
        x = self.mish(x)  # Shape: (batch_size, 360, 1)
        x = x.permute(2, 0, 1)  # Shape: (1, batch_size, 360)
        x = self.transformer_decoder_layer(x, x)  # Shape: (1, batch_size, 40)
        x = x.permute(1, 2, 0)  # Shape: (batch_size, 40, 1)
        x = self.lazy_conv1d(x)  # Shape: (batch_size, 50, 1)
        x = self.rrelu(x)  # Shape: (batch_size, 50, 1)
        x = x.unsqueeze(1)  # Shape: (batch_size, 1, 50, 1)
        x = self.adaptive_avg_pool3d(x)  # Shape: (batch_size, 1, 5, 5, 5)
        x = self.alpha_dropout(x)  # Shape: (batch_size, 1, 5, 5, 5)
        x = x.view(x.size(0), -1)  # Shape: (batch_size, 125)
        x = self.unflatten(x)  # Shape: (batch_size, 10, 5)
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 20).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
