
# This is a random torch model generated by the following modules: ['Softshrink', 'EmbeddingBag', 'NLLLoss', 'BatchNorm3d', 'Hardshrink', 'ReplicationPad1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.embedding_bag = nn.EmbeddingBag(num_embeddings=1000, embedding_dim=64, mode='mean')
        self.batch_norm3d = nn.BatchNorm3d(num_features=64)
        self.replication_pad1d = nn.ReplicationPad1d(padding=2)
        self.softshrink = nn.Softshrink(lambd=0.5)
        self.hardshrink = nn.Hardshrink(lambd=0.5)
        self.nll_loss = nn.NLLLoss()

    def forward(self, x):
        # Assuming x is a 1D tensor of indices for EmbeddingBag
        x = self.embedding_bag(x)
        
        # Reshape to 5D tensor for BatchNorm3d
        x = x.view(-1, 64, 1, 1, 1)
        x = self.batch_norm3d(x)
        
        # Reshape back to 2D tensor for ReplicationPad1d
        x = x.view(-1, 64, 1)
        x = self.replication_pad1d(x)
        
        # Apply Softshrink and Hardshrink
        x = self.softshrink(x)
        x = self.hardshrink(x)
        
        # Reshape to 2D tensor for NLLLoss
        x = x.view(-1, 64)
        
        # Assuming a target tensor for NLLLoss
        target = torch.randint(0, 64, (x.size(0),), dtype=torch.long)
        loss = self.nll_loss(x, target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randint(0, 1000, (10,)).cuda()  # Example input for EmbeddingBag
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

