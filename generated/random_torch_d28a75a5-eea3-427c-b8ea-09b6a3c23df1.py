
# This is a random torch model generated by the following modules: ['ParameterDict', 'Flatten', 'LazyConv1d', 'InstanceNorm3d', 'GLU', 'UpsamplingNearest2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.params = nn.ParameterDict({
            'param1': nn.Parameter(torch.randn(10)),
            'param2': nn.Parameter(torch.randn(10))
        })
        self.flatten = nn.Flatten()
        self.conv1 = nn.LazyConv1d(out_channels=16, kernel_size=3)
        self.conv2 = nn.LazyConv1d(out_channels=32, kernel_size=3)
        self.instance_norm = nn.InstanceNorm3d(num_features=32)
        self.glu = nn.GLU(dim=1)
        self.upsample = nn.UpsamplingNearest2d(scale_factor=2)

    def forward(self, x):
        # Apply ParameterDict (not directly used in forward, but can be used in custom logic)
        x = x + self.params['param1'].unsqueeze(0).unsqueeze(0)  # Example usage
        
        # Flatten the input
        x = self.flatten(x)
        
        # Reshape for 1D convolution
        x = x.unsqueeze(1)  # Add channel dimension
        x = self.conv1(x)
        x = self.conv2(x)
        
        # Reshape for InstanceNorm3d
        x = x.unsqueeze(2).unsqueeze(3)  # Add 3D dimensions
        x = self.instance_norm(x)
        
        # Reshape for GLU
        x = x.squeeze(3).squeeze(2)  # Remove 3D dimensions
        x = x.unsqueeze(1)  # Add channel dimension
        x = self.glu(x)
        
        # Reshape for UpsamplingNearest2d
        x = x.unsqueeze(2).unsqueeze(3)  # Add 2D dimensions
        x = self.upsample(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
