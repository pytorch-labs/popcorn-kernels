
# This is a random torch model generated by the following modules: ['MaxPool2d', 'Tanhshrink', 'FractionalMaxPool3d', 'BCELoss', 'LogSigmoid', 'ZeroPad1d', 'RNN', 'GELU', 'LazyInstanceNorm3d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)
        self.tanhshrink = nn.Tanhshrink()
        self.fractional_maxpool3d = nn.FractionalMaxPool3d(kernel_size=2, output_size=(8, 8, 8))
        self.bce_loss = nn.BCELoss()
        self.log_sigmoid = nn.LogSigmoid()
        self.zeropad1d = nn.ZeroPad1d(padding=2)
        self.rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)
        self.gelu = nn.GELU()
        self.lazy_instance_norm3d = nn.LazyInstanceNorm3d()

    def forward(self, x):
        # Assuming input x is of shape (batch_size, channels, height, width)
        x = self.maxpool2d(x)  # Apply MaxPool2d
        x = self.tanhshrink(x)  # Apply Tanhshrink
        
        # Reshape to 3D for FractionalMaxPool3d
        x = x.unsqueeze(2)  # Add a depth dimension
        x = self.fractional_maxpool3d(x)  # Apply FractionalMaxPool3d
        
        # Reshape back to 2D for RNN
        x = x.view(x.size(0), -1, 10)  # Reshape to (batch_size, sequence_length, input_size)
        x, _ = self.rnn(x)  # Apply RNN
        
        # Apply GELU
        x = self.gelu(x)
        
        # Reshape to 3D for LazyInstanceNorm3d
        x = x.unsqueeze(2).unsqueeze(3)  # Add depth and height dimensions
        x = self.lazy_instance_norm3d(x)  # Apply LazyInstanceNorm3d
        
        # Apply ZeroPad1d
        x = x.view(x.size(0), -1)  # Flatten to 1D
        x = self.zeropad1d(x)  # Apply ZeroPad1d
        
        # Apply LogSigmoid
        x = self.log_sigmoid(x)
        
        # Compute BCELoss (assuming target is a random tensor of the same shape)
        target = torch.rand_like(x)
        loss = self.bce_loss(x, target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()  # Example input shape (batch_size, channels, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

