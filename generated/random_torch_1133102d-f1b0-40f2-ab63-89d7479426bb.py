
# This is a random torch model generated by the following modules: ['ConstantPad2d', 'Unflatten', 'Dropout3d', 'Transformer', 'LogSoftmax', 'ConvTranspose1d', 'AvgPool2d', 'CrossEntropyLoss', 'Hardtanh', 'GroupNorm']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.pad = nn.ConstantPad2d(2, 3.0)
        self.unflatten = nn.Unflatten(1, (2, 3))
        self.dropout3d = nn.Dropout3d(0.5)
        self.transformer = nn.Transformer(d_model=64, nhead=8, num_encoder_layers=3, num_decoder_layers=3)
        self.log_softmax = nn.LogSoftmax(dim=1)
        self.conv_transpose1d = nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2)
        self.avg_pool2d = nn.AvgPool2d(kernel_size=2, stride=2)
        self.cross_entropy_loss = nn.CrossEntropyLoss()
        self.hardtanh = nn.Hardtanh(min_val=-1.0, max_val=1.0)
        self.group_norm = nn.GroupNorm(2, 32)

    def forward(self, x):
        # Apply ConstantPad2d
        x = self.pad(x)
        
        # Apply Unflatten
        x = self.unflatten(x)
        
        # Apply Dropout3d
        x = x.unsqueeze(0)  # Add a batch dimension for Dropout3d
        x = self.dropout3d(x)
        x = x.squeeze(0)  # Remove the batch dimension
        
        # Apply GroupNorm
        x = self.group_norm(x)
        
        # Apply Hardtanh
        x = self.hardtanh(x)
        
        # Reshape for ConvTranspose1d
        x = x.view(x.size(0), 64, -1)
        
        # Apply ConvTranspose1d
        x = self.conv_transpose1d(x)
        
        # Reshape for AvgPool2d
        x = x.view(x.size(0), 32, -1, x.size(2))
        
        # Apply AvgPool2d
        x = self.avg_pool2d(x)
        
        # Reshape for Transformer
        x = x.view(x.size(0), -1, 64)
        
        # Apply Transformer
        x = self.transformer(x, x)
        
        # Apply LogSoftmax
        x = self.log_softmax(x)
        
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 64, 64).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
