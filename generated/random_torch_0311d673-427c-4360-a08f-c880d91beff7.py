
# This is a random torch model generated by the following modules: ['FractionalMaxPool2d', 'ZeroPad3d', 'LazyConvTranspose2d', 'GLU', 'BCELoss', 'RNNCellBase', 'Upsample', 'ConstantPad2d', 'TransformerDecoderLayer', 'AdaptiveMaxPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.fractional_max_pool = nn.FractionalMaxPool2d(kernel_size=2, output_size=(14, 14))
        self.zero_pad = nn.ZeroPad3d(padding=(1, 1, 1, 1, 1, 1))
        self.lazy_conv_transpose = nn.LazyConvTranspose2d(out_channels=32, kernel_size=3, stride=2)
        self.glu = nn.GLU(dim=1)
        self.bce_loss = nn.BCELoss()
        self.rnn_cell = nn.RNNCellBase(input_size=32, hidden_size=64)
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')
        self.constant_pad = nn.ConstantPad2d(padding=(1, 1, 1, 1), value=0.5)
        self.transformer_decoder_layer = nn.TransformerDecoderLayer(d_model=64, nhead=8)
        self.adaptive_max_pool = nn.AdaptiveMaxPool1d(output_size=10)

    def forward(self, x):
        # Apply FractionalMaxPool2d
        x = self.fractional_max_pool(x)
        
        # Apply ZeroPad3d (reshape to 3D first)
        x = x.unsqueeze(1)  # Add a channel dimension
        x = self.zero_pad(x)
        x = x.squeeze(1)  # Remove the channel dimension
        
        # Apply LazyConvTranspose2d
        x = self.lazy_conv_transpose(x)
        
        # Apply GLU (split channels and apply GLU)
        x = self.glu(x)
        
        # Apply RNNCellBase (reshape to 2D for RNN)
        batch_size, channels, height, width = x.shape
        x = x.view(batch_size, channels, -1).permute(2, 0, 1)  # Reshape to (seq_len, batch_size, input_size)
        hx = torch.zeros(batch_size, 64).to(x.device)  # Initialize hidden state
        outputs = []
        for i in range(x.size(0)):
            hx = self.rnn_cell(x[i], hx)
            outputs.append(hx)
        x = torch.stack(outputs, dim=0)
        x = x.permute(1, 2, 0).view(batch_size, -1, height, width)  # Reshape back to 4D
        
        # Apply Upsample
        x = self.upsample(x)
        
        # Apply ConstantPad2d
        x = self.constant_pad(x)
        
        # Apply TransformerDecoderLayer (reshape to 2D for transformer)
        x = x.view(batch_size, -1, x.size(-1)).permute(1, 0, 2)  # Reshape to (seq_len, batch_size, d_model)
        memory = torch.zeros_like(x)  # Dummy memory for transformer
        x = self.transformer_decoder_layer(x, memory)
        x = x.permute(1, 2, 0).view(batch_size, -1, height, width)  # Reshape back to 4D
        
        # Apply AdaptiveMaxPool1d (reshape to 2D for pooling)
        x = x.view(batch_size, -1, x.size(-1)).permute(0, 2, 1)  # Reshape to (batch_size, seq_len, channels)
        x = self.adaptive_max_pool(x)
        x = x.permute(0, 2, 1)  # Reshape back to (batch_size, channels, seq_len)
        
        # Apply BCELoss (dummy target for demonstration)
        target = torch.zeros_like(x)
        loss = self.bce_loss(torch.sigmoid(x), target)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Arbitrary input shape
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
