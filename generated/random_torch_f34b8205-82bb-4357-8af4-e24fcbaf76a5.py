
# This is a random torch model generated by the following modules: ['LazyConvTranspose2d', 'LazyConv1d', 'MaxUnpool3d', 'GaussianNLLLoss', 'Conv1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose_2d = nn.LazyConvTranspose2d(out_channels=32, kernel_size=4, stride=2, padding=1)
        self.conv1d_1 = nn.LazyConv1d(out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv1d_2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.max_unpool_3d = nn.MaxUnpool3d(kernel_size=2, stride=2, padding=0)
        self.gaussian_nll_loss = nn.GaussianNLLLoss()

    def forward(self, x):
        # Assuming input is 4D (batch, channels, height, width)
        x = self.conv_transpose_2d(x)  # Output shape: (batch, 32, height*2, width*2)
        
        # Reshape to 3D (batch, channels, length) for Conv1d
        x = x.view(x.size(0), x.size(1), -1)  # Flatten height and width dimensions
        
        x = F.relu(self.conv1d_1(x))  # Output shape: (batch, 64, length)
        x = F.relu(self.conv1d_2(x))  # Output shape: (batch, 128, length)
        
        # Reshape to 5D (batch, channels, depth, height, width) for MaxUnpool3d
        x = x.view(x.size(0), x.size(1), 1, x.size(2), 1)  # Add dummy depth and width dimensions
        
        # Dummy indices for MaxUnpool3d (assuming no actual pooling was done)
        indices = torch.zeros_like(x, dtype=torch.long)
        x = self.max_unpool_3d(x, indices)  # Output shape: (batch, 128, 2, length*2, 1)
        
        # Reshape back to 2D (batch, features) for GaussianNLLLoss
        x = x.view(x.size(0), -1)  # Flatten all dimensions except batch
        
        # Dummy target and var for GaussianNLLLoss
        target = torch.zeros_like(x[:, :1])  # Assuming single output feature
        var = torch.ones_like(x[:, :1])  # Variance is 1
        loss = self.gaussian_nll_loss(x[:, :1], target, var)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()  # Example input shape (batch, channels, height, width)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
