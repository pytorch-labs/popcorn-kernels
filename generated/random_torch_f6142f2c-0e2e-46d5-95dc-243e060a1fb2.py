
# This is a random torch model generated by the following modules: ['TripletMarginWithDistanceLoss', 'Softshrink', 'ReLU6', 'AdaptiveMaxPool1d', 'Unflatten']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.softshrink = nn.Softshrink(lambd=0.5)
        self.relu6 = nn.ReLU6()
        self.adaptive_max_pool1d = nn.AdaptiveMaxPool1d(output_size=10)
        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(2, 5))
        self.triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: F.pairwise_distance(x, y, p=2))

    def forward(self, x):
        # Apply Softshrink
        x = self.softshrink(x)
        
        # Apply ReLU6
        x = self.relu6(x)
        
        # Reshape for AdaptiveMaxPool1d
        x = x.view(x.size(0), x.size(1), -1)  # Reshape to (batch_size, channels, sequence_length)
        x = self.adaptive_max_pool1d(x)
        
        # Unflatten the output
        x = self.unflatten(x)
        
        # Dummy anchor, positive, and negative for TripletMarginWithDistanceLoss
        anchor = x[:, 0, :]  # Use the first part of the unflattened output as anchor
        positive = x[:, 1, :]  # Use the second part of the unflattened output as positive
        negative = torch.randn_like(anchor)  # Random negative example
        
        # Compute triplet loss
        loss = self.triplet_loss(anchor, positive, negative)
        
        return loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 20).cuda()  # Example input shape (batch_size, channels, sequence_length)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
