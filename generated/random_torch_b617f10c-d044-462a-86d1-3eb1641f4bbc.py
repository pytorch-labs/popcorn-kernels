
# This is a random torch model generated by the following modules: ['RNNCellBase', 'CosineEmbeddingLoss', 'Bilinear', 'LeakyReLU', 'RMSNorm', 'FeatureAlphaDropout', 'MaxUnpool3d']
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.rnn_cell = nn.RNNCellBase(input_size=128, hidden_size=256)
        self.bilinear = nn.Bilinear(256, 128, 64)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)
        self.rms_norm = RMSNorm(64)
        self.feature_alpha_dropout = nn.FeatureAlphaDropout(p=0.5)
        self.max_unpool3d = nn.MaxUnpool3d(kernel_size=2, stride=2, padding=0)
        
    def forward(self, x):
        # Assuming x is of shape (batch_size, sequence_length, input_size)
        batch_size, seq_len, input_size = x.size()
        hx = torch.zeros(batch_size, 256).to(x.device)  # Initialize hidden state
        
        # Process through RNNCellBase
        for t in range(seq_len):
            hx = self.rnn_cell(x[:, t, :], hx)
        
        # Apply Bilinear transformation
        x = self.bilinear(hx, x[:, -1, :])
        
        # Apply LeakyReLU
        x = self.leaky_relu(x)
        
        # Apply RMSNorm
        x = self.rms_norm(x)
        
        # Apply FeatureAlphaDropout
        x = self.feature_alpha_dropout(x)
        
        # Reshape for MaxUnpool3d (assuming 3D input)
        x = x.view(batch_size, 1, 8, 8, 8)  # Reshape to 3D tensor
        indices = torch.randint(0, 8, (batch_size, 1, 8, 8, 8)).to(x.device)  # Random indices for unpooling
        x = self.max_unpool3d(x, indices)
        
        return x

class RMSNorm(nn.Module):
    def __init__(self, dim, eps=1e-8):
        super().__init__()
        self.scale = dim ** -0.5
        self.eps = eps
        self.g = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale
        return x / norm.clamp(min=self.eps) * self.g

def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 10, 128).cuda()  # (batch_size, sequence_length, input_size)
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
