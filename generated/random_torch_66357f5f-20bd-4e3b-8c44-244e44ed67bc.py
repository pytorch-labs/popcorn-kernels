
# This is a random torch model generated by the following modules: ['PoissonNLLLoss', 'Unflatten', 'Conv2d', 'NLLLoss2d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.unflatten = nn.Unflatten(1, (32, 16, 16))
        self.poisson_nll_loss = nn.PoissonNLLLoss()
        self.nll_loss2d = nn.NLLLoss2d()

    def forward(self, x):
        # Apply Conv2d layers
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        
        # Reshape the tensor to fit the Unflatten module
        x = x.view(x.size(0), -1)  # Flatten the tensor
        x = self.unflatten(x)  # Unflatten to the desired shape
        
        # Apply PoissonNLLLoss (requires target, so we generate a dummy target)
        target = torch.randint(0, 2, x.shape, dtype=torch.float32).to(x.device)
        poisson_loss = self.poisson_nll_loss(x, target)
        
        # Apply NLLLoss2d (requires log probabilities and target, so we generate a dummy target)
        log_probs = F.log_softmax(x, dim=1)
        nll_target = torch.randint(0, 32, (x.size(0), x.size(2), x.size(3))).to(x.device)
        nll_loss = self.nll_loss2d(log_probs, nll_target)
        
        # Return the losses as outputs (for demonstration purposes)
        return poisson_loss, nll_loss


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 3, 32, 32).cuda()
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
