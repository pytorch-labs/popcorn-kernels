
# This is a random torch model generated by the following modules: ['ConvTranspose3d', 'EmbeddingBag', 'ReLU6', 'Hardsigmoid', 'MarginRankingLoss', 'UpsamplingNearest2d', 'Dropout2d', 'Softshrink', 'GaussianNLLLoss', 'AdaptiveAvgPool1d']
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv_transpose3d = nn.ConvTranspose3d(1, 10, kernel_size=3, stride=2, padding=1)
        self.embedding_bag = nn.EmbeddingBag(1000, 10, mode='mean')
        self.relu6 = nn.ReLU6()
        self.hardsigmoid = nn.Hardsigmoid()
        self.margin_ranking_loss = nn.MarginRankingLoss()
        self.upsampling_nearest2d = nn.UpsamplingNearest2d(scale_factor=2)
        self.dropout2d = nn.Dropout2d(p=0.5)
        self.softshrink = nn.Softshrink()
        self.gaussian_nll_loss = nn.GaussianNLLLoss()
        self.adaptive_avg_pool1d = nn.AdaptiveAvgPool1d(output_size=10)

    def forward(self, x):
        # Assuming x is a 5D tensor for ConvTranspose3d
        x = self.conv_transpose3d(x)
        
        # Reshape for EmbeddingBag (assuming x is flattened to 1D indices)
        x = x.view(-1).long() % 1000  # Ensure indices are within the vocabulary size
        x = self.embedding_bag(x)
        
        # Reshape back to a 4D tensor for ReLU6
        x = x.view(1, 10, 10, 10)
        x = self.relu6(x)
        
        # Apply Hardsigmoid
        x = self.hardsigmoid(x)
        
        # Reshape for UpsamplingNearest2d
        x = x.view(1, 10, 10, 10)
        x = self.upsampling_nearest2d(x)
        
        # Apply Dropout2d
        x = self.dropout2d(x)
        
        # Apply Softshrink
        x = self.softshrink(x)
        
        # Reshape for AdaptiveAvgPool1d
        x = x.view(1, 10, -1)
        x = self.adaptive_avg_pool1d(x)
        
        # GaussianNLLLoss requires a target and variance, which we don't have here
        # So we just return the output for now
        return x


def get_inputs():
    # randomly generate input tensors based on the model architecture
    x = torch.randn(1, 1, 10, 10, 10).cuda()  # 5D tensor for ConvTranspose3d
    return [x]

def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []

